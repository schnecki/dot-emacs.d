Comparison of two optimization based order release models with
fixed and variable lead times and an empirical validation of metamodels of work centres in order release planning
PhD Program Management (Doktoratsstudium)
an der Leopold-Franzens-Universität Innsbruck
Hauptbetreuer: Univ. Prof. Dr. Hubert Missbauer
Weitere Betreuer: Univ. Prof. Reha Uzsoy, Ph.D., P.E.
Beurteiler/in: Univ. Prof. Dr. Martin Grunow
Beurteiler/in: Univ. Prof. Dr. Hubert Missbauer
This thesis is an outcome of research activities that I have conducted during the last four
years working at the Department of Information Systems, Production and Logistics
Management. I gratefully acknowledge and express deep appreciation to the many people
who have helped and supported me in some way during this long and challenging journey of
my PhD study. In particular, some people deserve special thanks.
Firstly, I want to express my gratitude to my advisor Univ. Prof. Dr. Hubert Missbauer. He
aroused my interest in the field of Operations Research while I studied business
administration at the University of Innsbruck. He has been a careful supervisor and a good
teacher and has indispensable contributions to this thesis. I would like to express my
thankfulness to my second advisor Univ. Prof. Reha Uzsoy, Ph.D. His critical remarks and
helpful comments have contributed enormously in the development of this thesis I also thank
Univ. Prof. Dr. Martin Grunow for kindly accepting the invitation to take place in the defense
I am also very thankful to Univ.-Prof. Dr. Ronald Maier. His comments and involvement
throughout my project has improved both the content and the presentation of this thesis. I also
thank him for accepting to be a member of my dissertation committee. In addition, I thank
Univ.-Prof. Mag. Dr. Janette Walde for her support with regression models and for taking part
in my literature review and research proposal committee.
Working as a Ph.D. candidate within the Production and Logistics Management team has
been a great pleasure, I thank all the current and former colleagues in the group including
Stefan Holzmann, Thomas Hutter, Simon Jutz, Anita Klotz, Peter Pürgstaller, Wolfgang
Schnellinger, Christina Stampfer and Philipp Thurnher.
I thank my family and friends, in particular all babysitters, for being as they are and
without their unconditional support I would not be able to achieve success in many things in
my life, including this thesis. Lastly, I thank my girlfriend Katharina, for bearing me
throughout my studies and this project. This dissertation is also her work. The same is true for
my children Moritz, Felix and Johannes, who were always the strongest motivation to keep
1. Introduction ........................................................................................................................... 1
1.1. Research background................................................................................................................ 1
1.2. Research questions and methodology ...................................................................................... 5
1.3. Thesis outline ............................................................................................................................. 9
2. Optimization based order release models ........................................................................... 11
2.1. Order release models with workload independent lead times .............................................. 12
2.2. Order release models using lead times in an iterative scheme ............................................. 13
2.3. Order release models with workload dependent lead times ................................................. 15
2.3.1. Flow time oriented models .................................................................................................................. 15
2.3.2. Work in process oriented models – clearing function models ............................................................. 16
3. Comparison of two optimization based order release model with fixed and variable lead
times .................................................................................................................................... 19
3.1. Linear programs ...................................................................................................................... 26
3.1.1. Input output control model (Puergstaller, Missbauer 2012) ................................................................ 27
3.1.2. Clearing function model (Asmundsson et al. 2006, 2009) .................................................................. 32
3.2. Simulation model (see Puergstaller 2009) .............................................................................. 35
3.2.1. Simulation design ................................................................................................................................ 38
3.2.2. Experimental setting ............................................................................................................................ 38
3.2.3. Parameter setting of the two optimization based order release models ............................................... 43
3.3. Safety stock adjustment procedure (Kohler-Gudum, de Kok 2002).................................... 49
3.4. Results ...................................................................................................................................... 52
3.5. Summary and assessment of results ....................................................................................... 62
4. Empirical validation of meta-models of work centres in order release planning ............. 65
4.1. One-dimensional clearing functions ....................................................................................... 67
4.2. Multi-dimensional clearing functions .................................................................................... 70
4.2.1. Two-dimensional clearing functions ................................................................................................... 70
4.2.2. Three-dimensional and “simple” clearing functions ........................................................................... 74
4.3. Estimation of clearing functions ............................................................................................. 76
4.3.1. Regression through the origin .............................................................................................................. 76
4.3.2. Applied statistical tests ........................................................................................................................ 78
4.3.3. Nearest neighbour analysis .................................................................................................................. 79
4.4. Data sets ................................................................................................................................... 80
4.4.1. Production system ................................................................................................................................ 80
4.4.2. Simulation models ............................................................................................................................... 81
4.4.2.1. Simulation model of the production system ................................................................................. 81
4.4.2.2. Simplified queueing models ......................................................................................................... 82
4.5. Editing of raw data, deduction of the independent variables and selection of nonbottleneck and bottleneck machines ............................................................................................. 83
4.6. Results ...................................................................................................................................... 86
4.6.1. Non-bottleneck machines - Simulation data. ....................................................................................... 86
4.6.2. Non-bottleneck machines - Empirical data. ......................................................................................... 89
4.6.3. Bottleneck machines - Simulation data. .............................................................................................. 93
4.6.4. Bottleneck machines - Empirical data. ................................................................................................ 97
5. Conclusions ....................................................................................................................... 101
Appendix A (article) .............................................................................................................. 105
A1. Problem Description .............................................................................................................. 105
A2. Literature review and hypotheses ........................................................................................ 108
A3. Estimating clearing functions ............................................................................................... 113
A4. Data sets under study ............................................................................................................ 114
A4. 1. Production system. ............................................................................................................................ 114
A4.2. Simulation model of the production system. ..................................................................................... 115
A4.3. Simplified queueing models. ............................................................................................................. 115
A4.4. Editing of crude data and deduction of variables............................................................................... 116
A4.5 Selection of bottleneck and non-bottleneck machines. ....................................................................... 117
A5. Results .................................................................................................................................... 118
A5.1. Non-bottleneck machines - Simulation data. ..................................................................................... 118
A5.2. Non-bottleneck machines - Empirical data. ....................................................................................... 120
A5.3. Bottleneck machines - Simulation data. ............................................................................................ 123
A5.4. Bottleneck machines - Empirical data. .............................................................................................. 126
A6. Conclusions and implications ............................................................................................... 127
List of literature ..................................................................................................................... 129
Figure 1. Two level hierarchical planning structure (Betrand et al. 1990) .............................................. 2
Figure 2. Order release decision problem ............................................................................................... 3
Figure 3. Characteristic curves (after Wiendahl 1995) ........................................................................... 4
Figure 4. General procedure of an iterative order release model .......................................................... 13
Figure 5. Examples of clearing functions (following Karmarkar 1989, adapted) ................................. 17
Figure 6. Flow of the production orders through the production system (Puergstaller 2009, p. 30) ..... 29
Figure 7. Model of the production system in the input output control model
(Puergstaller, Missbauer 2012, p. 673).................................................................................. 29
Figure 8. Model of the production system in the clearing function model
(Puergstaller, Missbauer 2012, p. 674).................................................................................. 34
Figure 9. Production system - simulation model .................................................................................. 35
Figure 10. Rolling horizon planning as part of the simulation study (following
Puergstaller, Missbauer, 2012, adapted)................................................................................ 37
Figure 11. General procedure of a fixed lead time order release model ............................................... 40
Figure 12. General procedure of a clearing function model ................................................................. 41
Figure 13. Initial runs for estimating the parameters of the optimization based order release models .. 44
Figure 14. Parameter setting of the optimization based order release models ...................................... 46
Figure 15. Outer linearization of a clearing function with C=960, k=40 .............................................. 48
Figure 16. The safety stock adjustment procedure as depicted in Boulaksil et al. 2009 ....................... 49
Figure 17. The safety stock adjustement procedure for the ready rate
(Kohler-Gudum, de Kok 2002, p. 147) ................................................................................. 51
Figure 18.Share of two different products in the total WIP and output mix in production stage one ... 54
Figure 19. Differences between the share in WIP and output mix (WIP mix minus output mix) in
production stage one ............................................................................................................. 55
Figure 20. Differences between the share in WIP and output mix (WIP mix minus output mix) in
production stage three ........................................................................................................... 56
Figure 21. Examples of clearing functions (following Karmarkar 1989, adapted) ............................... 68
Figure 22. Output (Xt) as a function of load (Wt-1 + At) from equation (59) for Wt-1=0, 30, 60, 90, 120.
Parameter setting: β=0.9, k=30, C=100. ................................................................................ 73
Figure 23. Estimated equation (59) on empirical data .......................................................................... 73
Figure 24. Structure of the production system ...................................................................................... 80
Figure 25. Scatter plot of ManNB machine ρ=54.4% and PriNB machine ρ= 51.17%, simulation data
.............................................................................................................................................. 87
Figure 26. Scatter plot of ManNB machine ρ=57.5%, empirical data .................................................. 91
Figure 27. Non-bottleneck packaging machine ρ=19.2%, empirical .................................................... 91
Figure 28. Order arrivals over the periods for SCOPL and SCOPS ..................................................... 97
Table 1. Findings with regard to the comparison of models with workload independent- and dependent
lead times. ............................................................................................................................. 21
Table 2. Definition of the symbols used. .............................................................................................. 28
Table 3. Definition of the symbols used. .............................................................................................. 30
Table 4. Definition of the symbols used. .............................................................................................. 32
Table 5. Definition of the symbols used. .............................................................................................. 33
Table 6. Routings and operation times in minutes for all product of the simulation model .................. 36
Table 7. Definition of the symbols used in the demand and order arrival model .................................. 39
Table 8. Mean and standard deviation of the normally distributed percentage of the total demand ..... 39
Table 9. Parameter setting for different average bottleneck utilization levels and period lengths ........ 42
Table 10. Experimental design ............................................................................................................. 42
Table 11. Definition of the symbols used in the demand and order arrival model ................................ 47
Table 12. Simulation results for IOC and ACF for different settings of total demand variability ........ 52
Table 13. Simulation results for IOC and ACF for different settings of product mix variability .......... 53
Table 14. Effective Processing Time (EPT) distribution for constant total demand and
constant/varying product mix ................................................................................................ 57
Table 15. Simulation results for IOC and ACF for varying product mix and total demand .................. 58
Table 16. Simulation results for IOC and ACF for varying period lengths and constant total demand
and product mix .................................................................................................................... 59
Table 17. Simulation results for IOC and ACF for varying period lengths and variable total demand
and constant product mix ...................................................................................................... 59
Table 18. Simulation results for IOC and ACF for varying period lengths and constant total demand
and variable product mix....................................................................................................... 60
Table 19. Simulation results for IOC and ACF for varying period lengths and variable total demand
and variable product mix....................................................................................................... 60
Table 20. Simulation results for IOC and ACF for varying period lengths and variable total demand
and variable product mix for an average bottleneck utilization level of 85% ........................ 61
Table 21. Simulation results for IOC and ACF for varying period lengths and variable total demand
and variable product mix for an average bottleneck utilization level of 75% ........................ 62
Table 22. R2 of non-bottleneck machines from simulation data ........................................................... 87
Table 23. R2 of linear two- and three-dimensional clearing functions of PriNB, simulation ................ 89
Table 24. R2 of non-bottleneck machines from empirical data ............................................................. 90
Table 25. R2 of linear two- and three-dimensional clearing functions of ManNB, empirical ............... 92
Table 26. R2 of bottleneck machines from simulation data .................................................................. 93
Table 27. R2 of bottleneck machines from simulation data with shortened period length .................... 94
Table 28. R2 of regression functions fitted to data of M/M/1 queues .................................................. 95
Table 29. R2 of regression functions fitted to data of a SCOP controlled production unit .................... 96
Table 30. R2 of bottleneck machines from empirical data .................................................................... 97
Table 31. R2 of “simple” nonlinear three-dimensional regression functions of different datasets of the
PackBN machine, empirical data .......................................................................................... 99
Table 32. R2 of nonlinear two- and three-dimensional clearing functions of PackBN, empirical ......... 99
The problems of planning and controlling production in discrete manufacturing
industries have been a key application domain for industrial engineering and operations
research since the emergence of these fields as recognized disciplines. The problem of
(discrete-time) production planning as first formulated by Holt et al. (1960) is in its essence
the problem of companies who need to meet an external demand with a limited set of
production resources (capacities) in a given time period. Over the last 50 years a general
planning logic has evolved starting with the bill-of-material explosion in the 1960s which
led to more complex hierarchically organized systems like Material Requirement Planning
(Orlicky 1975) and Manufacturing Resource Planning (MRP-II) (Wight 1983). The MRP-II
framework forms the basis for most of the manufacturing planning and control (MPC)
systems and supply chain planning systems in industrial use today. MPC systems plan and
control all aspects of manufacturing, including managing materials, scheduling machines
and people, coordinating suppliers and key customers. Depending on the market and the
business strategies these activities change over time (Vollmann et al. 2005). Today’s
modern Advanced Planning Systems (see De Kok, Fransoo 2003; Stadtler, Kilger 2005) try
to complement MPC systems by concentrating on planning and coordinating the material
flow between companies or manufacturing plants, leveraging the data collection and
organization capabilities of the Enterprise Resource Planning used by many companies
In this thesis we focus on MPC for multi-stage, multi-product production systems which
is the underlying concept in most production planning and scheduling systems prevailing in
practice. The MPC task is a complex problem, consisting of a number of separate
coordinated planning decisions which are subject to a multitude of restrictions such as
human cognition, mathematics or computational power which makes a simultaneous
solution of the problem infeasible1. Therefore, these issues are solved by organizing them in
a hierarchical manner (Bitran et al. 1982; Hax, Candea 1984)2. The planning process is
executed in a decentralized manner with two planning levels (see Bertrand et al. 1990).
See Georgiadis, Michaloudis (2012) for issues regarding the dynamics of MPC systems and their applicability.
For a comprehensive discussion of the hierarchical planning concept see Fleischmann, Meyr (2003) and de
Figure 1. Two level hierarchical planning structure (Bertrand et al. 1990)
Figure 1 shows the two level hierarchical planning structure. The top level (goods flow
control) coordinates the material flow over the entire logistic chain or manufacturing
process3. Inventories are held in so called “stock keeping units” (SKUs). The complexity
involved is generally addressed by aggregating segments of the production process into
departments or production units. A production unit is defined as a production department
which in the short term is self contained with respect to the use of its resources, and which
is responsible for the production of a specific set of products from a specific set of materials
and components (see Bertrand et al. 1990, p. 14 for a comparison of these terms and
concepts used in the MRP literature). From the goods flow control point of view, the
production units are treated as black boxes. This implies that the internal structure of the
production units is not relevant to the top level. The targets set by the top level have to be
feasible in terms of the resource constraints at the base level. This is done by employing the
anticipated version of the base level within the top level model. Thus, the top level has to
anticipate the performance measures of the production units such as lead times, inventory
levels and the total available capacity. The term “anticipation” was introduced by
Schneeweiss (1995, 2003) in the hierarchical planning approach. In a two-level hierarchy,
firstly, the higher level takes into account the relevant characteristics of the base level which
Schneeweiss calls the “anticipated base level”. Choosing an anticipated base level and
taking into account its impact on the decisions made by the top level is then called
anticipation (Schneeweiss 1995, p. 6). Thus, the top level determines the optimal releases of
The top level frequently is hierarchical in itself; see Vollmann et al. (2005) for its structure in today’s MPC
work orders for a fixed planning horizon and therefore sets the targets for the production
units. The analysis of models that use different anticipation functions is the central interest
The base level (production unit control) is primarily responsible for accepting realistic
objectives regarding capacity levels, production levels and work orders and performing
detailed scheduling within the production units which involves determining the start and
finish dates of the operations and their production sequence at the facilities.
Figure 2 depicts the order release decision problem in this context. We are interested in
the decision problem of releasing the amount of work (orders) for each product over time in
Jobs are held back in a pool (see Figure 2) which is used to store jobs when they initially
arrive before releasing them to the shop floor where they enter the first stage of processing.
In practice, the job pool is situated in the office of the production planner who decides
which orders to release to the shop floor (base level). The main difficulty is the anticipation
of the dynamic behavior of the material flows (production processes) and the insufficient
management of flow times and work-in-process (WIP).
The objective of order release planning in general is to maintain a certain level of WIP to
achieve a certain utilization of the production system and thus control the flow times in
order to meet the required due dates of the orders. Figure 3 depicts the basic relationship
between the average WIP, mean flow time and the output of a manufacturing system which
are usually referred to as ”characteristic curves”, originally introduced by Wiendahl (1995).
Figure 3.. Characteristic curves (after Wiendahl 1995)
The tradeoff between reducing flow times and WIP while trying to maintain high
put is managed by some mechanism or model relating to the workload control
(WLC) concept in the literature. WLC research has been conducted since the work of Wight
(1970) who was probably the first to understand and describe the importance of controlled
term WLC to refer to a group of MPC systems which seek to control workloads,
work they group together three streams of research:
methods (Melnyk, Ragatz 1989; Melnyk et al. 1991;
Ahmed, Fisher 1992) that include three control levels: job entry, job release and
2) Workload controlling methods building on input output control from Wight (1970),
Belt (1976) (Tatsiopoulos, Kingsman 1983; Hendry,
Kingsman 1991; Hendry, Kingsman 1993; Kingsman 2000).
(LUMS4 approach) adds the customer enquiry stage to the above mentioned three
3) Load Oriented Manufacturing Control (Bechte 1988, 1994; Wiendahl et al. 1992)
which concentrates on the job release stage and is mainly empirical work.
Th rer et al. (2011) another stream evolved that seeks to control workloads
and integrate these into a comprehensive PPC system (Land, Gaalman 1996). Missbauer,
Lancaster University Management School (LUMS)
Uzsoy (2011) adduce three additional workload controlling methods that are similar to input
output control (stream two above), namely kanban (Sugimori et al. 1977) which is based on
rather restrictive assumptions, CONWIP which was introduced by Spearman et al. (1990)
and the Drum-Buffer-Rope concept of Goldratt, Cox (1986).
Missbauer (2009) adds a new dimension in his review of the WLC-literature by
distinguishing between two main concepts. Firstly, he calls the above mentioned WLC
mechanisms5 “rule based order release mechanisms”. In his definition research on rule
based mechanisms aims at developing a knowledge base specifying which order release
mechanism should be used under different environmental conditions. Thus one can choose
between a variety of design options (e.g., continuous or discrete timing convention; see
Bergamaschi et al. 1997) and parameter settings (e.g., target WIP) of the order release
mechanism (see Wiendahl 1995, Hendry, Kingsman 1991; Stevenson, Hendry 2006; Land
2004). In contrast, so called “optimization based order release models” are based on an
explicit model of the material flow and the time-dependent WIP level over a longer
planning horizon, usually divided into discrete periods (Missbauer 2009, p. 390ff.). These
optimization based order release models constitute the focal point of interest to this thesis.
The aim of optimization based order release models is to determine the optimal aggregate
material flow through the production units by means of an optimization model (mostly a
linear program (LP)) that yields the amount of released work in each period over the
planning horizon. The model has to predict the aggregate material flow, characterized by the
WIP levels, output and final product inventory over time which, in turn results from the
aggregate order release plan. Differences in the approaches are in the formulation of the
lead time and in the capacity constraints. Following Missbauer, Uzsoy (2011) the literature
on optimization based order release models can be divided into two streams: Order release
models that incorporate workload independent lead times or lead time distributions
(Hackman, Leachman 1989; de Kok, Fransoo 2003; Spitter et al. 2005a, 2005b;
Puergstaller, Missbauer 2012; Hung Leachman 1996) and models that allow for workload
dependent lead times (Lautenschlaeger 1999; Voss, Woodruff 2003; Karmarkar 1989;
Missbauer 2002; Asmundsson et al. 2006, 2009; Selçuk 2007).
Comparisons of models out of both streams are rather scarce in literature (Asmundsson et
al. 2006, 2009; Kacar et al. 2012; Puergstaller, Missbauer 2012). Asmundsson et al. (2006,
He does not include the input output control approach from Wight (1970), Plossl, Wight (1973) and Belt (1976)
2009) compare the fixed lead time model of Hackman, Leachman (1989) with their
allocated clearing function (ACF) model. The approach of Hackman, Leachman (1989)
models the capacity as a fixed upper bound on the number of hours available at the resource
in a time period. It includes non-integer input and output time-lags between stages for each
item which are independent of the workload (Asmundsson et al. 2009, p.143). In general, a
clearing function describes the amount of output “cleared” from a manufacturing facility in
a certain period as a function of some measure of WIP (e.g., average WIP, load) over time.
The ACF model incorporates workload dependent lead times which means that they can
vary according to the utilization of the work centre under study. Kacar et al. (2012) compare
the ACF of Asmundsson et al. (2006, 2009) with the iterative approach of Hung, Leachman
(1996) which uses workload independent lead time distribution. In this model a LP model
takes lead time estimates as input from a simulation model which in turn takes the release
Both papers (Asmundsson et al. 2009; Kacar et al. 2012) find that in most cases the ACF
(if estimated accurately) outperforms the workload independent lead time models, because
it estimates the WIP levels at the work centres more precisely. One point of critique
concerning the made comparisons in these two studies is that the models of Hung,
Leachman (1996) and Hackman, Leachman (1989) do not directly take the WIP in front of
the work centres into account (unlike the ACF model). This means that the buffering
capability of WIP cannot be utilized and they do not allow the model to decide when to
process the order within the lead time which means that the comparison is favorable for the
ACF model. This limitation would be mitigated by comparing the ACF model with a model
that incorporates the WIP in front of the work centre which was done in the study by
Puergstaller, Missbauer (2012) choose (next to the ACF model) a LP model based on
input output control from Wight (1970), Plossl, Wight (1973) and Belt (1976) in their
comparison of rule based and optimization based models. The basic idea of the IOC model
is to manage the flow of work through the shop so that the size of the queue at each work
centre remains relatively stable around a predetermined level. In order to do this, one must
control the input rate to each work centre to match the output rate. In its basic version, input
output control estimates the time-dependent WIP level at a work centre for the periods of a
specified planning horizon from the initial WIP level, the time-dependent work input which
results from the release schedule and work output which results from the work centre
capacity (Puergstaller, Missbauer 2012, p. 671ff).
The authors find that the ACF model leads to substantially lower inventory but to worse
due-date performance, which makes a comparison difficult. Hence, the authors limit
themselves to interpret the comparison of the rule based mechanism and the input output
control model. Therefore, the first part of this thesis aims at filling the gap of comparing
these two models, namely the IOC model with workload independent lead times of
Puergstaller, Missbauer (2012) and the ACF model that incorporates workload dependent
lead times of Asmundsson et al. (2006, 2009).
The comparison between these two specific models seems promising since the two
models only differ from each other with respect to the treatment of lead times. Therefore,
we want to know whether the increased complexity of modeling workload dependent lead
times (ACF model) yields justifiable improvements or whether the limitations of these more
complex model leads to a decrease in the performance of the model. As discussed above,
the ACF model has been shown to work well in simulation experiments (Asmundsson et al.
2006, 2009; Kacar et al. 2012), but they tend to exhibit problematic behavior, namely shortterm oscillations of the planned release quantities, which might be a response to sudden
changes of the demand. This “nervous” behavior has been shown for clearing functions in
Missbauer (2002) and has been reported as a property of optimization models if steady-state
properties are assumed to hold for short periods (Lautenschlaeger 1999). Karmarkar (1993)
also states that “what happens in the transition between periods is not clear” (Karmarkar
1993, p. 317).Therefore, we formulate the following research question:
Research question RQ1: Under what conditions of the process and demand variability and
the stationarity of the system under investigation does the allocated clearing function
outperform the input output control model?
The comparison is done using a multi-model approach. Two LP-models representing
each approach will be compared facing the same objective function. The resulting optimal
release quantities will thereafter be executed by a simulation model. The performance of the
models is compared by applying the Safety Stock Adjustment Procedure (SSAP, KohlerGudum, de Kok, 2002). The SSAP is used to fix the service level of an algorithm at a prespecified value by installing an appropriate amount of safety stock.
The second part of this thesis focuses on the limitations of clearing function models. As
stated above a clearing function is a functional relationship between the output and some
measure of WIP of a manufacturing facility. Over time several functional forms of this onedimensional clearing function (a functional relationship between one dependent and one
independent parameter) were developed (Graves 1986; Srinivasan et al. 1988; Karmarkar
1989; Missbauer 1998; Asmundsson 2006, 2009; Selçuk 2007). The main limitation of
existing clearing function models is due to the fact that they are deduced from steady-state
queueing models and assume that the output in period t can be modeled as a function of one
independent variable (WIP level or available work in the period under consideration) to a
sufficient degree of accuracy. This only holds for steady-state situations, but in the actual
operation of a work centre steady-state situations and various transient states can occur in
any sequence, and this trajectory of the system is controlled by the order release decisions
that are made by the model. Hence “the clearing functions employed by most researchers to
date represent an average relation over a wide range of operating states, but may be quite
inaccurate for a given sample path of system evolution.” (Kacar, Uzsoy 2010, p. 1708).
Therefore, we must ask whether a one-dimensional clearing function is sufficient. The
numerical analysis of one transient period of an M/M/1 model in Missbauer (2011) indicates
that this is not the case. The expected output in the period given a certain expected load
(available work) in the period can strongly depend on the composition of the load
(proportion of initial WIP and work input) and on the probability distribution of the initial
WIP. These insights suggest that the history of the process and the uncertainty of the load
estimation influence the output that can be expected in a given period t given a certain
estimated load. As a consequence one should extend the one-dimensional clearing function
to models incorporating two and three independent variables yielding multi-dimensional
clearing function models (Haeussler, Missbauer 2014, p.103ff).
In literature only a few other papers deal with multi-dimensional clearing functions for
order release planning (Andersson et al. 1981; Anli et al. 2008; Kacar, Uzsoy 2013; Albey
et al. 2011). However, these papers do not analyze transient effects. Therefore, the task of
this paper is at first to test whether additional independent variables lead to better fits when
estimating clearing functions to data which is prevalently made by a regression analysis in
literature (Missbauer 1998, 2002; Kacar et al., 2012; Kacar, Uzsoy 2013; Asmundsson et al.
2009) and secondly, to find functional forms of two- and three-dimensional clearing
functions. Therefore, we formulate the following research question:
Research question RQ2: Do multi-dimensional clearing functions whose independent
variables reflect the process history and the uncertainty of the load estimation, lead to
improvements of the fit when compared to one-dimensional clearing functions?
The fit of the clearing functions will be made by a regression through the origin and
evaluated by the adjusted R2. The linear and nonlinear regressions will be fitted to
simulation and empirical data obtained from a make-to-order production system.
To sum up, the planned thesis tries at first to fill the gap of comparing two optimization
based order release models that differ only in their treatment of lead times. We compare a
fixed lead time model with a model that allows for load dependent lead times. The main
contribution of this part is to show whether the increased complexity of modeling workload
dependent lead times yields justifiable improvements especially under challenging
conditions. Secondly, this thesis devotes itself to improve the so called clearing function
models which belong to order release models with workload dependent lead times and
constitutes a very recent stream of research. Work on this type of models can be regarded as
being fundamental research, and the main contribution of the second part of this thesis is to
discuss the potential of extending the state of the art models in order to overcome its
weakness of being based on steady-state assumptions.
The next chapter will describe optimization based order release models which are firstly
order release models that incorporate workload independent lead times (Section 2.1),
secondly order release models that use an iterative scheme (Section 2.2) and thirdly
approaches with workload dependent lead times (Section 2.3). The latter can be divided into
flow time oriented and work in process (WIP) oriented models which will be discussed in
In Chapter 3 research question RQ1 is addressed. We start with the used linear
programming (LP) models for order release planning in Section 3.1. In the first Subsection
3.1.1, we will describe the LP of Puergstaller, Missbauer (2012) which is based on the input
output control (IOC) model of Wight (1970), Plossl, Wight (1973) and Belt (1976).
Thereafter, we will outline the allocated clearing function (ACF) model of Asmundsson et
al. (2006, 2009) in Section 3.1.2. In order to compare these two LP models both use the
same objective function. In Section 3.2 we will describe the simulation model of
Puergstaller, Missbauer (2012) which is used to compare the two LP models. The
experimental design and the setting of the parameters for the order release models in the
simulation model are presented thereafter in Section 3.2.2 and 3.2.3.
A difficulty that earlier studies encountered when comparing order release models is the
fact that the performance is on the one hand measured by the customer service level and the
inventory level on the other hand. One model may yield a higher service level than others,
but may lead to higher inventory levels as well (see Puergstaller, Missbauer 2012). A
technique that proves to be very useful in the comparison of algorithms is the Safety Stock
Adjustment Procedure (SSAP, Kohler-Gudum, de Kok, 2002) which will be described in
Since Chapter 3 analyzes the relative performance of one particular clearing function to
another order release model, we focus on the limitations of clearing functions in general in
Chapter 4 which details and extends Haeussler, Missbauer (2014) (included as Appendix
A). In Section 4.1 we discuss the state of the art clearing functions incorporating one
independent variable. Thereafter in Section 4.2.1, we describe the proposed clearing
functions with two independent variables and propose a preliminary functional form for
nonlinear two-dimensional clearing functions. Furthermore in Section 4.2.2, we introduce
“simple” quadratic regression functions that represent three-dimensional clearing functions.
In Section 4.3 we describe the estimation procedure of the clearing function and the details
of the regression through the origin (4.3.1), the statistical tests applied (4.3.2) and the
nearest neighbor analysis (4.3.3). Section 4.4 describes the two data sets used for the
regression analyses. We first use real industry data from an optical storage media producer
and secondly we analyze data from a simulation model of this production system.
Furthermore, we use data from two simplified queueing models, a M/M/1 and a SCOP
controlled queue, which will be described in Subsection 4.4.2.2. Thereafter in Section 4.5,
we outline the process of editing the raw data and how we select non-bottleneck and
bottleneck machines. Finally, Chapter 5 presents the final conclusions.
2. Optimization based order release models
In this chapter we focus on order release models that determine the optimal aggregate
material flow through the production units by means of an optimization model that yields the
amount of released work in each period over the planning horizon. The model has to predict
the aggregate material flow, characterized by the WIP levels, output and final product
inventory over time which, in turn results from the aggregate order release plan. A
considerable body of literature has approached the issue of modeling the production unit by
formulating various mathematical programming models. All models of interest described in
the next chapters view material flows as being a continuous medium and divide the planning
horizon into discrete planning periods. The objective function is generally minimizing the
variable costs of production, holding inventories and backlogs over the planning horizon, and
the decision variables represent the physical flows of material through the production
resources and are associated with each period (Missbauer, Uzsoy 2011). The constraints can
be classified into inventory balance constraints, capacity- and domain specific restrictions
depending on the environment being considered. Differences in the below described
approaches are in the formulation of the lead times and in the capacity constraints.
Almost all work on mathematical programming models of these problems can trace its
ancestry to the work of Whitin (1954), Modigliani, Hohn (1955) and the most popular work
by Holt et al. (1960) and can either be considered as extensions of the well-known work of
Wight (1970) or the production planning models that use linear programming (LP) models
introduced by Johnson, Montgomery (1974)6. In the following sections we shall investigate
the basic assumptions of these models in more detail.
For a historical review of the development of optimization models for aggregate material flow planning in
2.1. Order release models with workload independent lead times
As mentioned above Wight (1970) was maybe the first to understand and describe the
importance of controlled release and thereafter led to the first definition of MRP II systems
(Wight 1983). He observed that many serious manufacturing problems in traditional maketo-order companies can be solved by effectively planning and controlling plant inputs and
outputs. Nevertheless, he did not suggest any specific technique or model to solve the order
release problem (Bergamaschi et al. 1997). The basic idea of Wight’s approach, which was
further developed by Plossl, Wight (1973) and Belt (1976), is to manage the flow of work
through the shop so that the size of the queue at each work centre remains relatively stable
around a predetermined level. In order to do this, one must control the input rate to each
work centre to match the output rate which is relatively straightforward for the work centres
at which new jobs enter the shop, referred to by Graves (1986) as "gateway work centres”.
For non-gateway work centres it is not clear how to maintain this input output control,
especially if they receive input from multiple sources which is mostly the case in practice.
An optimization model in this sense needs to explicitly model the work centres, the
(continuous) material flows between the work centres would be represented by inventory
balance equations and would incorporate workload independent and therefore fixed (in this
case integer) lead times for each work centre. Puergstaller (2009) introduces an LP model
which follows the basic idea of Wight (1970), Plossl, Wight (1973) and Belt (1976). This
means that on the one hand Puergstaller’s model assumes fixed integer lead times and on
the other hand models the WIP in front of the work centres explicitly, unlike the model by
Hackman, Leachman 1989. The latter approach models the capacity as a fixed upper bound
and incorporates non integer input and output time-lags between stages for each item.
Finally, the models by de Kok, Fransoo and Spitter (de Kok, Fransoo 2003; Spitter et al.
2005a, 2005b) use integer fixed lead times while allowing capacity consumption at any time
within the fixed lead time, not necessarily in consecutive periods.
2.2. Order release models using lead times in an iterative scheme
Untill now all described models assumed a constant lead time over the entire planning
nother approach is constituted by Hung Leachman (1996) who use workload
distributions. Their approach is based on the step-separated
formulation by Leachman, Carmon (1992) which requires the estimated lead times for each
product that is needed to reach a resource after being released into the plant. Instead of fixed
lead times that remain constant over the entire planning horizon, the model associates
values of the lead time parameters with the start of each planning period. Therefore, the
model needs to estimate the fraction of the released quantity of a product that contributes to
the output of a resource in a later period. The difficulty is thatt this fraction depends on the
resource utilization, which on the one hand is determined by the WIP in the system and on
the other hand by the releases that are determined by the planning model in use.
times is to estimate the lead times in an
iterative scheme where the releases obtained from the solution to the production planning
models (mostly LP models) are fed into a simulation or a queueing
realized lead times they would impose on the production system (see
rocedure of an iterative order release model
These models embed an LP model representing the production planning model under
udy and estimate lead times in an iterative scheme. Given initial lead time estimates, the
quantities obtained from the LP model are the input to a simulation or a queueing
facility Thereafter, the flow times that the plan imposes in the
production system are assessed.. If these flow times do not match the initial lead times used
in the LP, the LP is resolved with new lead time estimates. The hope is that this will
converge. At present the convergence properties of these methods are not well understood
and the highly time consuming nature of experiments are the biggest limitations of this
approach (see Byrne, Hossain 2005; Hung, Leachman 1996; Irdem et al. 2010; Kacar et al.
2012). If convergence occurs, the estimated lead times are used to calculate the fraction of
the released quantity that contributes to an output in a later period.
Several iterative approaches have been suggested in the literature (Zäpfel 1984; Hung,
Leachman 1996; Byrne, Bakir 1999; Kim, Kim 2001; Byrne, Hossain 2005; Bang, Kim
2010; Irdem et al. 2010; Kacar, Uzsoy 2013; Riaño 2003). One notable approach is the
model of Riaño (2003) who uses an iterative scheme similar to the model by Hung,
Leachman (1996), but instead of a simulation model, Riaño’s model estimates the lead
times using a model of the transient behavior of a queueing network. Here the release
decisions directly depend on the expected state of the system which is unknown until the
decisions have been evaluated by the anticipation model. Similar to the other iterative
approaches convergence is also problematic in his model (Missbauer, Uzsoy 2011).
Closely related to the iterative approach are models that directly use simulation
optimization7 and LP models that incorporate the simulation model (Helber et al. 2011a,
2011b). On the one hand, both of these techniques have the attractive feature of avoiding the
interaction between the LP and the simulation model, but on the other hand share the
drawback of very high computational requirements for modeling more complex
manufacturing systems (Kacar et al. 2012; Liu et al. 2011; Helber et al. 2011a, 2011b).
Therefore, the latter two approaches are not yet alternatives to the above described iterative
technique, which itself is a very recent research direction.
See Fu (1994) for an introduction to the method of simulation optimization.
2.3. Order release models with workload dependent lead times
A major disadvantage of the above described approaches with fixed lead times is their
failure to consider the nonlinear relationship between resource utilization and lead times
which is well known from practice and queueing theory. Thus the lead time norms set by
the workload independent models must allow high utilization at least of the bottleneck work
centres, which means that the model cannot take advantage of the possibility to reduce lead
times in periods of low capacity utilization (Puergstaller, Missbauer 2012, p. 671).
Furthermore, the above described approaches that use lead time distributions do not always
converge and face heavy computational burdens. Therefore, a number of authors
(Lautenschlaeger 1999; Voss, Woodruff 2003; Karmarkar 1989; Missbauer 2002;
Asmundsson et al. 2006, 2009; Selçuk 2007) have developed models that allow lead times
to vary according to the utilization of the work centre under study.
Within the literature on order release models with workload dependent lead times
Missbauer, Uzsoy (2011) identify two approaches: flow time oriented models which capture
a functional relationship between load and estimated flow times, and WIP oriented models
which are mainly clearing function models. We will start our discussion with the flow time
oriented models and thereafter describe the most recent research direction of WIP oriented
Only a few authors have proposed LP formulations that model the dependency between
flow times and resource utilization (Lautenschlager 1999; Voss, Woodruff 2003).
Lautenschlaeger (1999) suggests a model where production in a given period becomes
available over two subsequent periods. In order to consider load-dependent lead times the
model determines the fraction of the planned production in a period that has to be started
one period ahead. This fraction is a function of the planned utilization of the work centre.
Therefore, two modes for the production volume are defined, one with zero lead time and a
second with lead time of one period. The maximum production volumes in each mode are
limited, which leads to a utilization-dependent lead time distribution (see Pahl et al. 2005
for a comprehensive description of this approach).
Voss, Woodruff (2003) propose a very similar approach where they introduce a function
that links lead time to workload which is approximated using piecewise linearization. They
assume a steady-state relationship between the utilization of a work centre and the
expected lead time at that resource. Thus they define several “break points” that constitute
different utilization levels and therefore specify different lead times.
To sum up, the models discussed so far in this section, describe the behavior of the
production unit by explicitly modelling the lead time (in the material balance constraints).
We now turn our attention to models where the lead time behavior of the production unit is
not modeled explicitly. Here the lead times are implicitly taken into account by modeling
the relationship between some measure of the expected WIP level and the expected output
2.3.2. Work in process oriented models – clearing function models
The focus of this section lies on models that allow for workload dependent lead times
and explicitly represent the WIP level in front of the work centre and include the finished
goods inventory (FGI) in the LP model. The purpose of considering both WIP and FGI is
as follows. WIP levels must be controlled to ensure timely production, while FGI must be
planned to ensure effective satisfaction of demand, meaning that both types of inventory
serve different purposes and are controlled in different ways. In models of this type, work
centres are represented explicitly, and the material flow from order release through the
required work centres and to the inventory of the final products or SKU’s is represented by
inventory balance equations (Puergstaller, Missbauer 2012). A number of authors have
proposed different WIP oriented order release models (Srinivasan et al. 1988; Karmarkar
1989; Missbauer 1998; Asmundsson 2006, 2009; Selçuk 2007; Anli et al. 2007). Graves
(1986) developed the idea of clearing in his model for tactical planning of a job shop and
assumes a linear relationship between load (initial WIP plus work input) and output for
each work centre8. Based on this idea several WIP oriented models were introduced that
are referred to as ”clearing function” models. A clearing function therefore, represents the
relationship between some measure of WIP (load, average WIP) in front of the work centre
and the expected output of the work centre. Over time several functional forms of the
clearing function have been developed. Figure 5 illustrates some linear and nonlinear
The approach of Graves (1986) was recently extended by Teo et al. (2012) which will not be described here
since this paper (as the original) concentrates on tactical planning rather than on the detailed production plans.
Figure 5.. Examples of clearing functions (following Karmarkar 1989,, adapted)
The “Fixed Lead Time”Time” function in Figure 5 represents the first WIP based approach
introduced by Graves (1986). In this model a constant proportion of the available work is
processed in each planning period. Capacity is treated as infinite at least within the relevant
range of the load, and the fixed lead time is independent of the WIP level. The nonlinear,
“saturating” clearing function depicted in Figure 5 was introduced by Karmarkar (1989)
and has been applied by several researchers
researchers (Missbauer 2002; Asmundsson et al. 2006,
2009; Selçuk 2007). The concave shape of the saturating clearing function is due to limited
capacity and can be derived analytically (Karmarkar 1989, 1993; Srinivasan et al. 1988;
Missbauer 1998; Selçuk et al. 2008) or can be approximated by fitting the curve to data via
regression analysis (Hwang, Uzsoy 2005; Asmundsson et al. 2006;
The first LP model incorporating a clearing function was presented in Karmarkar
in a singlee product and single facility setting. This model was
multi facilities settings (Missbauer 2002, Asmundsson et al. 2009) and to
models including lot sizing (Hwang, Uzsoy 2005). In order to use nonlinear clearing
ctions in optimization models one has to decide whether to solve the model using
nonlinear programming (Hwang, Uzsoy 2005) or to approximate the clearing function by
linear segments to obtain a tractable model.
model. This is mostly done by outer linearization
issbauer 1998, 2002; Anli et al. 2007; Asmundsson et al. 2009; Kacar et al.2012;
Puergstaller, Missbauer 2012), but can also be done by inner linearization (Selçuk et al.
2009) introduce the allocated clearing function (ACF)
model which is the most advanced and used LP model for clearing functions in the
literature to date (Kacar et al. 2012; Puergstaller, Missbauer 2012), since it is the only
approach that solves the problem of allocating the available capacity to multiple products
in the queue in front of the work centres. The LP assumes that the product mix of the
output is the same as the product mix in the queue.
The main advantage of the clearing function models is that they jointly optimize the
lead times and the release times of the orders. One of the main limitations of the mostly
used clearing function models to date is its derivation from steady-state queueing theory9
which assumes that the functional relationship between the expected or maximum output in
a period to the planned measure of WIP in a period holds over time. This means that one
has to assume that the period is long enough for the workstation to reach a steady-state and
that the steady-state behavior of a queueing system in general is a sufficient approximation
for the dynamics within the period. Two studies by Missbauer (2002, 2009) show the
problems of this stationarity assumption especially under time-varying demand. He argues
that transient analysis of queueing networks should be used to develop more precise
models of the dynamic behavior which is analyzed in more detail in Missbauer (2011). We
follow this study by addressing the issue of estimating clearing functions under transient
It is not essential to use steady-state models, e.g. a clearing function based on transient queueing models was
proposed in Missbauer (2011), but the major drawback of using transient models is the complexity involved.
3. Comparison of two optimization based order release model with fixed
A relatively small number of studies compare different optimization based order release
planning models (Asmundsson et al. 2006, 2009; Kacar et al. 2012; Puergstaller, Missbauer
2012). Firstly, Asmundsson et al. (2006, 2009) compare their allocated clearing function
(ACF) with the fixed lead time model of Hackman, Leachman (1989). The authors use a
simulation model of a multi-stage production system consisting of five or ten machines
producing three different products representing a scaled down wafer fabrication facility and
analyze the impact of demand and process variability10 on both model’s performance. Their
experimental factors are the demand (stationary and seasonal), the period length (long and
short), machine failures (no failures, moderate and high breakdowns) and dispatching rules
(first in first out and earliest due date). They show that in cases of high variability their ACF
(if estimated accurately) outperforms the fixed lead time model, because it estimates the WIP
levels at the work centres more precisely. In order to estimate the clearing function accurately
they introduce a new approach since the estimation with a smallest sum of squares approach
as pursued by most studies in the literature (Missbauer 1998, 2002; Irdem, Uzsoy 2009;
Kacar, Uzsoy 2013; Asmundsson et al. 2009) yielded worse performance than the fixed lead
time approach. Therefore, they use a quantile regression which they call the “target
percentage method” which estimates a more conservative clearing function. The results of the
conservative clearing functions were promising, but did not outperform the fixed lead time
model in all situations. In the time stationary demand case the conservative clearing function
formulation achieves major reductions in lateness at the cost of some increase in inventory.
Based on this study, it can be concluded that the variability (process and demand variability)
in the system is the main factor affecting the model. Additionally, the authors conclude that
“…when the steady-state assumption within the planning period holds at least approximately,
as it appears to for the low breakdown scenarios, the ACF model performs well relative to the
fixed lead time model” (Asmundsson et al. 2009, p. 155).
Kacar et al. (2012) compare the ACF of Asmundsson et al. (2006, 2009) with the iterative
approach of Hung, Leachman (1996). They simulate a multi-stage production system
consisting of 12 machines which produces three products and is organized as a re-entrant flow
shop. As experimental factors they use three different demand patterns (stationary, seasonal
Variability here means variation in the model (also uncertainty in the literature; e.g. Buzacott, Shantikumar
with equally- and seasonal demand with unequally distributed product mix), two different
average bottleneck utilization levels (70% and 90%) and two machine failure cases (long and
short). They show that the ACF outperforms the iterative approach in all tested scenarios.
Puergstaller, Missbauer (2012) choose (next to the ACF model) a LP model based on input
output control in their comparison of rule based and optimization based models. The authors
use a simulation model of a multi-stage make-to-order manufacturer consisting of nine
machines producing 24 different products which is organized as a hybrid flow shop. They
compare the rule based mechanism of Hendry, Kingsman (1991) with the ACF of
Asmundsson et al. (2006, 2009) and an input output control (IOC) model based on the studies
by Wight (1970), Plossl, Wight (1973) and Belt (1976). As experimental factors they use two
different demand patterns (stationary and seasonal), two cases of demand predictability (high
and low predictability), two different product mixes (constant and varying) and two different
planning horizons (seven and twelve periods). The findings with regard to the comparison of
the two optimization based order release models are somewhat inconclusive. They find that in
all scenarios the clearing function model leads to substantially lower inventory, but to worse
due-date performance, which makes a comparison difficult. Therefore, the authors limit
themselves to interpret the comparison of the rule based mechanism with the input output
A summary of the findings with regard to the comparison of optimization based order
release models with workload independent and dependent lead times is depicted in Table 1.
Table 1. Findings with regard to the comparison of models with workload independent- and dependent lead times.
Although the literature reviewed above (Asmundsson et al. 2006, 2009; Kacar et al.
2012) shows that the ACF model outperforms the workload independent lead time models
(see Table 1) the main limitations of the ACF model still remain. Firstly, there exists no
generally accepted method to estimate clearing functions from simulation data, which will
be addressed in Section 4 in more detail. And secondly, if transient states occur in the
production system under study the relative advantage over other optimization based order
release models might at least partly diminish since the clearing function models are derived
from steady-state queueing theory (Missbauer 2011). This is supported empirically by the
study of Asmundsson et al. (2009) who show that when the steady-state assumption seems
to be violated (high breakdown scenarios) the state of the art clearing function yields worse
Additionally, the comparisons made by Asmundsson et al. (2009) and Kacar et al.
(2012) are to some extend advantageous for the ACF model since their reference models
(Hackman, Leachman 1989; Hung, Leachman 1996) do not model the WIP in front of the
work centres and therefore do not use the buffering capability of the WIP. This limitation
was partly overcome by the study by Puergstaller, Missbauer (2012) who introduce an IOC
model that incorporates the WIP in front of the work centre and therefore the timedependent output of the work centres are separate decisions. However, the authors did not
succeed in comparing the ACF model with the IOC model. Therefore, an in-depth
comparison of these two models would be a considerable contribution to the field of
research. We formulate the following research question from the literature reviewed above:
Research question RQ1: Under what conditions of the process and demand variability and
the stationarity of the system under investigation does the allocated clearing function
outperform the input output control model?
The comparison is done by using a multi-model approach. Two LP-models representing
each approach will be compared facing the same objective function. The resulting optimal
release quantities will thereafter be executed by a simulation model (see Section 3.2). The
performance of the models is compared by applying the Safety Stock Adjustment
Procedure (SSAP, Kohler-Gudum, de Kok, 2002) which will be described in detail in
Section 3.3. The SSAP is used to fix the service level of an algorithm at a pre-specified
value by installing an appropriate amount of safety stock. The single performance measure
Note that the study of Asmundsson et al. (2009) overcomes this limitation methodologically by using a
is therefore the total inventory level, consisting of the WIP and the finished goods
inventory that results from the simulated material flow that is controlled by the order
As we discussed above, earlier studies (Asmundsson et al. 2009; Kacar et al. 2012)
showed that the clearing function models outperform fixed lead time models due to their
ability to capture the system dynamics quite well. More precisely, these studies show that
under increased demand variability (seasonal demand pattern) the clearing function
outperforms the fixed lead time model. Therefore, we hypothesize that
Hypothesis H1: The ACF model outperforms the IOC model as the variation of the total
Additionally, the studies by Asmundsson et al. (2009) and Kacar et al. (2012) also
analyze the influence of higher process variability. In general, one can choose from various
design options to induce process variability in the simulation model (e.g., varying process
or setup times, varying product mix, machine failures etc.). Asmundsson et al. (2009) and
Kacar et al. (2012) analyze this effect by introducing different machine breakdown
scenarios and find that the ACF model outperforms the workload independent lead time
models under study in cases of severe machine breakdowns. This thesis follows the study
by Puergstaller, Missbauer (2012) who analyze the influence of product mix variation. The
effect of a variable product mix on the performance of the ACF model is difficult to
predict. On the one hand the study by Asmundsson et al. 2006 shows only little evidence
that the clearing function is affected by the product mix (at least in their case with three
products; Asmundsson et al. 2006, p. 104). On the other hand literature on multidimensional clearing functions (Haeussler, Missbauer 2014) suggests that one-dimensional
clearing functions (as the ACF model) are not sufficient to model the material flow if the
product mix or other characteristics of the system (e.g., lot sizes) vary over time. They
argue that one-dimensional clearing functions represent an average relationship over a long
period in which product mix and other system characteristics are stable.
Therefore, given the findings of Puergstaller, Missbauer (2012) that the IOC model (and
the rule based mechanism) are less affected by the product mix than by the demand
variation we expect the ACF model to perform worse than the IOC model in cases of
increased product mix variability. We hypothesize that
Hypothesis H2: The ACF model performs worse than the IOC model as the variation of the
With regard to the overall variability in the system under study we face a tradeoff
between the Hypotheses H1 and H2. On the one hand it is difficult to estimate the decrease
in performance of the ACF model when facing a varying product mix and on the other
hand in cases of seasonal demand, earlier studies show that the ACF model outperforms
the fixed lead time models. Therefore, we hypothesize that the latter effect outweighs the
former meaning that the ACF model performs better than the IOC model.
Hypothesis H3: The ACF model performs better than the IOC model as the variation of the
total demand and the variation of the product mix increases.
Additionally, we test scenarios that should make one of the main limitations of the ACF
model apparent which is its derivation from steady-state queueing models. If transient
states occur the advantage in the performance compared to the fixed lead time model might
at least partly diminish since the clearing function models are derived from steady-state
queueing theory (Missbauer 2011). Queueing models obtain estimates of performance
measures (e.g., average time in system) under long run steady-state conditions, which may
be of limited value in the production planning context where planning periods may not be
long enough to justify steady-state assumptions. Thus in transient states the expected
output for example is affected by the initial state of the resource under investigation (see
Missbauer 2011) which is not included in the ACF model. Therefore, we test whether the
performance of the ACF model decreases when the length of the planning period
decreases, since (in relation) shorter period lengths lead to longer transient phases
(Missbauer 2006; see Odoni, Roth 1983 for analytical expressions). Furthermore, transient
phases are especially apparent at highly utilized machines since these frequently face
critical load levels or are temporarily overloaded. Therefore, we hypothesize that the
performance of the ACF model decreases when applied to shorter period lengths and when
facing higher average bottleneck utilizations.
Hypothesis H4a: The performance of the ACF model decreases as the period length
Hypothesis H4b: The performance of the ACF model decreases as the period length
decreases, especially in cases of high average bottleneck utilization.
The comparison between these two models is especially interesting since these two
models only differ from each other in their treatment of lead times (workload independent
or dependent). Therefore, the comparison should lead to two insights: Firstly, whether the
increased complexity (variable lead times) of the clearing function model leads to the
expected improvements in the performance measures and secondly whether these
improvements compensate the decrease in the performance measures that results from the
limitations of clearing functions (steady-state assumption).
The first part of the thesis at hand starts by presenting the two linear programs used in
this study representing the two optimization based order release models (Section 3.1).
Thereafter, we describe the used simulation model and the experimental design of this
study in Section 3.2. Then we describe the safety stock adjustment procedure (KohlerGudum, de Kok 2002) which was used to compare the performance of the models in
Section 3.3. Afterwards, we present the results of the comparison in Section 3.4 which are
summarized and shortly concluded in Section 3.5.
Almost all work on linear programming (LP) models in the production planning
literature can be considered as extensions of the production planning models introduced by
Manne (1957), Hanssmann, Hess (1960) and the most popular work by Johnson,
Montgomery (1974). The latter introduce the path-based LP which means that the decision
variables specify the quantity of a specific product type produced by a specific process in a
specific period (see Bakir 2011 for a detailed description). The basic structure of LP models
in production planning result in the following form:
where χj and cj are the inventory and production costs of product j respectively. Fjt
denotes the amount of finished goods inventory at the end of period t, Xjt denotes the
amount of products j produced during period t, Djt the demand of product j in period t and Ct
the maximum possible output of the resource under study. Most LP models involve
additional constraints specific to the application domain under study, but the model above
represents the essentials of inventory balance between periods and aggregate capacity
In general LP models in the field of order release research are different with respect to
the handling of the conflicting goals of high utilization, low WIP and short lead times. In
this thesis we compare one LP model that builds on fundamental and very early thoughts on
production planning and one model arising from a very recent research stream. The former
is a model that uses workload independent lead times and is based on the studies from the
1970s by Wight (1970), Plossl, Wight (1973) and Belt (1976) and was further developed by
a recent study by Puergstaller, Missbauer (2012). The second LP model was introduced by
Asmundsson et al. (2006, 2009) and belongs to the WIP-oriented models and incorporates
workload dependent lead times. Both linear programs are performed using LINGO 11.0.
3.1.1. Input output control model (Puergstaller, Missbauer 2012)
The basic idea of Wight (1970) is to manage the flow of work through the shop so that
the size of the queue at each work centre remains relatively stable around a predetermined
level. In order to do this, one must control the input rate to each work centre to match the
output rate which gave this approach its name “input output control”. In its basic version,
input output control estimates the time-dependent WIP level at a work centre for the
periods of a specified planning horizon from the initial WIP level, the time-dependent
work input which results from the release schedule and work output which results from
the work centre capacity (Puergstaller, Missbauer 2012). An optimization model in this
sense needs to explicitly model the work centres, the (continuous) material flows between
the work centres would be represented by inventory balance equations and would
incorporate workload independent and therefore fixed (in this case integer) lead times for
To illustrate this approach we start with a single product single stage model (SPIOC)
where time is divided into discrete-time periods (t =1…T) using the notation in Table 2:
Variables (measured in number of orders):
Inventory after the resource at the end of period t
WIP before the resource at the end of period t
Finished goods inventory at the end of period t
Amount of orders produced during period t
Holding costs for the WIP before the resource (per order and period)
Holding costs for inventory after the resource (per order and period)
Operation time at the resource (time units per order)
Holding costs for finished goods inventory (per order and period)
For the SPIOC model we have chosen a simple objective function of minimizing the
sum of inventory holding costs where the model differentiates between a WIP inventory
before the resource (Wt), an inventory after the resource (It) and a finished goods
Constraints (6) - (8) are the inventory balance equations for these three types of
inventories assuming that the released orders will be available after the planned lead time
(τ). Constraint (6) defines the WIP before the resource, which is calculated by adding the
released products to the WIP in the preceding period and by subtracting the output of the
resource in period t. Constraint (7) defines the inventory after the resource which consists
of the inventory in the preceding period plus the output of the resource in period t minus
the releases from the past (shifted by the planned lead time). Constraint (8) is the finished
goods inventory equation which consists of the finished goods inventory in the preceding
period plus the releases in this fixed lead time offset minus the demand in the period.
Constraint (9) limits the WIP that can be cleared within the planned lead time.
Additionally, constraint (10) restricts the output per period, so that it does not exceed the
available capacity. Finally, constraint (11) guarantees that only non-negative values are
taken into consideration for the decision variables.
Puergstaller, Missbauer (2012) introduce a LP model that is an extension to the SPIOC
model shown above and is in line with the basic idea of Wight (1970), Plossl, Wight
(1973) and Belt (1976) which means that the model assumes fixed integer lead times
while explicitly representing the WIP in front of the work centres. The input output
control (IOC) model of Puergstaller, Missbauer (2012) is quite similar to the LP model
presented in the study by de Kok, Fransoo (2003) and is applicable to a multistage,
multiproduct production system. Thus assuming that the WIP can be cleared within the
planned lead time and since these planned lead times are assumed to hold for each
operation, the arrival dates of the orders at the work centres are determined by the release
dates (see Figure 6)) which is quite common in the WLC literature (Wight 1970; Plossl,
Wight 1973;; Land, Gaalman 1996; Kingsman 2000).
Figure 6.. Flow of the production orders through the production system (Puergstaller 2009, p. 30)
The IOC model of Puergstaller, Missbauer (2012) assumes that the production system
consists of N work centres. Each work centre is represented as a WIP inventory before the
work centre, the work centre itself and a WIP inventory after the work centre.
product passes each work centre at most once following a specified routing. At the end of
the production system is a finished goods inventory (see Figure 7)) using the notation
Figure 7.. Model of the production system in the input output control
Demand forecasts are given for each product and period of the specified planning
horizon. The model can be formulated as follows (Puergstaller, Missbauer 2012, p. 673)
min ∑∑∑ (ω nj W jtn +ψ nj I njt+ ) + ∑∑ ( χ j Fjt+ + φ j Fjt− )
I njt+ − I jt = I nj ,+t −1 − I jt −1 + X njt − R
∑ ξ j Wjt ≤ ∑ ∑ ξ j X jl + (t + τ t − Τ)C
Fjt+ , Fjt− , I njt+ , R jt ,W jtn , X njt ≥ 0
Variables (measured in number of orders):
Backlog of product j at the end of period t
Costs for backlog of product j (per order and period)
= 1, if product j is produced at work centre n; = 0 otherwise
Amount of product j released before the planning horizon, transferred from work
centre n to work centre k in period t (orders)
Amount of product j released before the planning horizon, transferred from work
centre n to finished goods inventory in period t (orders)
Backlog of product j after work centre n at the end of period t (orders)
The objective of the IOC model is to minimize the total holding and backlogging costs
for each product j at each work centre n over the planning horizon.
Constraint sets (13) – (15) are again the inventory balance equations using information
about the planned releases. In the release variables Rnk the first work centre index denotes
the source, the second work centre index the destination and in the variable Rnf index f
denotes the finished goods inventory. The model differentiates between releases that have
to be determined (decision variables) and releases on which decisions have already been
made (before the current planning horizon) denoted as R . The decision variable Rjt
determines how many units of products j should be released within a lead time offset τm
being the lead time of all preceding work centres m which depend on the routing of
product j (denoted as υj which is 1 if product j is produced at work centre m and 0
otherwise). The setting of the integer planned lead times will be described in Section 3.2.3
Constraint sets (16) and (17) limit the WIP inventory before the work centre so that it
can be cleared within the planned lead times. Additionally, constraint set (18) restricts the
output per period, so that it does not exceed the available capacity. Note that the
inventories after the work centre (It-) in this model are allowed to be negative which can
result from the stochastic nature of the material flow which means that the released
quantities before the planning horizon can actually be higher than the available capacity of
the work centre. Finally, constraint (19) guarantees that only non-negative values are
(Puergstaller, Missbauer 2012, p. 674ff.).
3.1.2. Clearing function model (Asmundsson et al. 2006, 2009)
To illustrate this approach we start with the single product and single stage model
(SPCF) of Karmarkar (1989) which can be stated using the additional notation in Table 4
Variables (measured in number of orders):
WIP measure used for the clearing function
For the SPCF model we have chosen a simple objective function of minimizing the
production, inventory and release costs. Constraints (21) and (22) are the inventory
balance equations for the WIP before the resource (Wt) and finished goods inventory (Ft).
Constraint (23) represents the nonlinear capacity constraint. The variable W t
constitutes some measure of the WIP (e.g., the load) used for the clearing function which
can take different functional forms. Finally, constraint (24) guarantees that only nonnegative values are taken into consideration for the decision variables. The SPCF model
shows the specific feature of clearing function models that the lead time is not explicitly
modeled since they are represented in constraint (23) implicitly.
This model was thereafter extended to multi-product and multi-facilities settings
(Missbauer 2002, Asmundsson et al. 2002, 2006, 2009) and to models including lot sizing
(Hwang, Uzsoy 2005). In this study we use the allocated clearing function (ACF) of
Asmundsson et al. (2006 2009) which is the most advanced and used LP model for
clearing functions in literature to date (Kacar et al. 2012; Puergstaller, Missbauer 2012),
since it is the only approach that solves the problem of allocating the available capacity to
multiple products in the queue in front of the work centres. The LP assumes that the
product mix of the output is the same as the product mix in the queue. Using the
additional notation in Table 5, the ACF is defined as:
min ∑∑∑ (ω nj W jtn +ψ nj I njt ) + ∑∑ ( χ j Fjt+ + φ j Fjt− )
I njt = I nj ,t −1 + X njt − ∑ Y jtnk − Y jtnf
ξ jn X njt ≤ αOn Z njt + βOnξ jn (Wjtn + X njt )
Fjt+ , Fjt− , I njt , Rnjt ,W jtn , X njt , Z njt ≥ 0
Linear segments of the clearing function (o=1,…,O)
Variables (measured in number of orders):
Amount of product j transferred from work centre n to work centre k in period t
Amount of product j transferred from work centre n to finished goods inventory in
Fraction of maximum output of work centre n allocated to product j in period t
Intersection of tangent o of the linearized clearing function of work centre n
Slope of tangent o of the linearized clearing function of work centre n
The objective of the ACF model is the same as for the IOC model discussed above.
Constraint sets (26) – (28) are the inventory balance equations where
amount of product j transferred from work centre k to work centre n and vice versa for the
and the amount of product j transferred from work centre n to the
finished goods inventory in period t ( Y jtnf see Figure 8).
Figure 8. Model of the production system in the clearing function model
Constraints (29) and (30) provide the relationship between the output and capacity
loading of the work centres according to the outer linearization. Whereas α On denotes the
intersection of tangent o of the linearized clearing function of work centre n, Z njt the
fraction of maximum output of work centre n that is allocated to product j in period t and
β On is the slope of the tangent o of the linearized clearing function of work centre n. The
linearization (and estimation) procedure of the clearing function will be described in
Section 3.2.3 below. Finally, constraint (31) guarantees that only non-negative values are
taken into consideration for the decision variables (Puergstaller, Missbauer 2012, p. 675).
3.2. Simulation model (see Puergstaller 2009)
The simulation model is a scaled down model of an Austrian optical storage media
producer (for a description of the real factory see Section 4.4.1) and consists of nine
individual machines that are non-exchangeable (see Figure 9).
Figure 9. Production system - simulation model
The system produces 24 products following the routings depicted in Table 6 (column 2 to
4). The data of the products are based on the practical case. As in the practical case, there
are no sequence-dependent setup times and no flexibility in the capacities since the real
factory runs 24 hours a day and seven days a week. A planning period is a day, and the
average operation times are approximately 42, 66 and 53 minutes in stages 1, 2 and 3
respectively (see columns 5 to 7 in Table 6). The first-come-first-served dispatching rule is
Table 6. Routings and operation times in minutes for all product of the simulation model
The production in the simulation model is driven by customer orders since the real
manufacturer follows a make-to-order approach. The interval between arrival date and
required due date of an order determines the possible release times. The order arrival model
is formulated as follows: The arrival date is generated as the required due date minus the
quoted delivery time. The required due date is based on the demand which specifies the
number of orders to be delivered at the end of the respective period and the quoted delivery
time is a random variable whose distribution is taken from empirical data (see Puergstaller
2009, p.67ff.). Order release is performed at the beginning of each period in a rolling
horizon setting as depicted in Figure 10.
Figure 10. Rolling horizon planning as part of the simulation study (following
At the beginning of the simulation the total demand is generated (see next Section 3.2.2).
At the first period of the planning horizon, which is set to seven periods in our study,
demand forecasts are made and the order releases are determined by the two LP models (see
Section 3.1). Note that we do not analyze the influence of demand predictability on the
performance of the two order release models (as in Puergstaller, Missbauer 2012). Thus, we
do not consider forecast errors in our study which is a topic for future research (see
Stampfer et al. 2014). Thereafter, the planned orders are released at the beginning of the
period and at the end of the period the model collects data for the next period.
Given the above stated hypotheses we have five different experimental factors that we
need to take into consideration. We have the two different optimization based order release
models, the IOC model and the ACF model that we want to compare. With regard to
hypothesis H1 (and H3) that the ACF model outperforms the IOC model as the variation of
the total demand increases we differentiate between constant and seasonal demand
scenarios. In order to analyze hypotheses H2 and H3 we analyze the influence of a constant
or variable product mix on the performance of the two order release models. Finally, to test
hypothesis H4a and H4b we include two further factors. Firstly, we test two different period
lengths and test three different utilization levels. The comparison will be made by applying
the safety stock adjustment procedure which makes the two models comparable on a single
performance measure (see Section 3.3). In our study this measure is the resulting total
inventory level, consisting of the held WIP in front of the machines and the finished goods
In total we use five experimental factors: Total demand and product mix variability,
order release method, period length and average bottleneck utilizations which will be
described in detail in the following paragraphs.
Total demand- and product mix variability:
The system faces fluctuating demand which is represented by a sinusoidal demand in the
simulation model, following the notation given in Table 7. The demand was generated in
two steps (Steele at al. 1995). In Step 1 the total demand for each planning period was
Because the total demand is defined as “total demand during a period”, different mean
demand, amplitudes and cycle length values were used for different period lengths to obtain
the desired utilization levels (see below). For example, when period length is 960 minutes
the total mean demand during a period is me=55 units, the amplitude in the case of varying
demand is a=44 units and the cycle length c=89 periods.
Step 2 of the demand generation procedure (Steele at al. 1995) gives us the product mix
variability. Therefore, the demand for the individual products is calculated from the total
demand (32) multiplied by the proportions (35), which are stated as normally distributed
(33) and standardized (34) (for the used symbols see Table 7).
The demand is rounded to integer values. The means and standard deviations of the
products are given in Table 8 (see Puergstaller 2009, p. 69).
Percentage of the total demand that is allocated to product j in period t
Adjusted percentage of the total demand, that is allocated to product j in period t
Amplitude of the seasonal part of the total demand (number of orders)
Cycle length of the seasonal part of the total demand (periods)
Constant part of the total demand (number of orders)
µ jp σ jp Mean and standard deviation of the normally distributed percentage of the total demand that
Table 7. Definition of the symbols used in the demand and order arrival model
Table 8. Mean and standard deviation of the normally distributed percentage of the total demand
Note that due to the rounding to integers of the demand for the individual products we do
not always obtain nonzero demands for all 24 products. In the case of constant demand and
constant product mix we obtain demands for 16 and for variable demand and constant
product mix we get orders for 19 products.. For
have a demand for all 24 products over time.
The two order release models used in this study (the ACF and IOC model) are
represented by two LPs which are described
described in Section 3.1 and whose decisions are
model Figure 11 depicts the general procedure of the IOC
Figure 11.. General procedure of a fixed lead time order release model
The IOC model starts with some lead time estimates which are parameters and have to be
determined beforehand. We will use two different approaches for determining these
estimates which are deduced from data generated in two initial
round down (SRD) and secondly, we use an optimization model (integer programming
rounding (IPR)) to round the measured average flow times of the initial runs (see
3.2.3).. Thereafter, the resulting optimal release pattern is thereafter executed in the
simulation model from which the dependent variables are measured (see Figure 11).
For the ACF model the LP jointly optimizes the release of the orders and the lead times
which are also executed in the simulation model and the results are evaluated thereafter (see
Figure 12.. General procedure of a clearing function model
considered in order to determine whether the length of the planning periods
affects the performance of the order release models. In particular, we are interested in
whether this factor affects the quality of the clearing functions, since the data used to
te the functions is dependent on the period length. The demand is defined as demand
during a period which means that we use different values for the total demand (35). As
described above, the total mean demand during a period changes depending on the period
length and the average bottleneck utilization (see below).
Note that by shortening the period length from 960 to 360 minutes the estimation
procedure of the clearing function changes slightly since the step width of the linearization
changes accordingly (see Section 3.2.3). The parameter setting for the IOC model (more
precisely the setting of the planned lead times) is not affected by reducing the period
lengths. We take the same planned lead times for both period lengths since the average
demand during the period and the general structure stays the same. Additionally, pilot
studies with differently set planned lead times led to a worse performance of the IOC
The simulation run length in all simulations is 1484 days and depending on the period
gth the number of periods changes accordingly. When period length is 960 minutes, there
are 1484*24*60/960 = 2226 periods in a simulation and with a period length of 360 minutes
we have 1484*24*60/360 = 5936 periods respectively. The ratio between the period
and the weighted average of the operation times in our study is about 40 to 1 for a period
minut and about 15 to 1 for 360 minutes. Quite similar ratios were used in
the study by Asmundsson et al. (2009) who analyze ratios of 48 to
The four experimental factors above (total demand and product mix variability, order
release method and period length) are tested on an average bottleneck utilization of 95%.
We also include experiments where we change the average bottleneck utilization which are
limited to scenarios with high demand and product mix variability.
The average bottleneck utilization follows
where ρn denotes the average utilization of machine n, X n the average output of machine
n and C n is the average capacity of machine n over the considered periods which is the
considered period length in the simulation model. As stated above we set the factors that
determine the total demand (37) (repeated for convenience) in order to get the targeted
Table 9 depicts the different settings of the parameters of equation (37).
Table 9. Parameter setting for different average bottleneck utilization levels and period lengths
The experimental factors of the simulation study are summarized in Table 10.
0, 100% of the observed standard deviation per
A full factorial design will be used for the first four experimental factors; the influence of
the bottleneck utilization will only be tested on scenarios with high demand and product
mix variability. So in total 30 different scenarios will be simulated (2·2·3·2+2·3=30). For
each scenario 15 independent runs will be performed. The common random number
technique is used to reduce variance among the scenarios. The length of each run was 25
seasonal cycles, including a warm-up period of 5 seasonal cycles. Welch’s procedure was
applied to approximate the length of the warm-up period (see Law, Kelton 2000). The
simulation study is performed using FLEXSIM to simulate the demand, order arrival model,
the production system as well as the order release methods
3.2.3. Parameter setting of the two optimization based order release models
In this section we describe how we set the parameters of the two order release models
under study. For the IOC model we need to estimate the planned lead times and for the
ACF model we need to obtain data to estimate the used clearing function.
We start with a short literature review on the setting of planned lead times in this
context. In the production planning literature many approaches (e.g., MRP (Orlicky 1975);
MRP II (Wight 1983); Hendry, Kingsman 1991) and LP models (e.g., Billington et al.
1983; Hackman, Leachman 1989) use (exogenous) planned lead times. The most common
and practical approaches to set planned lead times are firstly to use historical data, mostly
some quantile or other statistical measure of the measured cycle times, or secondly to use
Several studies in the literature describe analytical models to determine optimal planned
lead times in single-stage (Weeks 1981; Kanet 1986; Matsuura, Tsubone 1993; Matsuura
et al. 1996) and in multi-echelon models (Yano 1987; Gong et al. 1994). Furthermore,
several studies concentrate on the estimation of planned lead times (Hackman, Leachman
1989; Vepsalainen, Morton 1988; Lu et al 1994; Hung, Hou 2001). Here the lead times are
unrelated to the workload of the resources, but the utilization is indirectly considered by
testing the influence of the set lead times by the use of simulation studies.
However, there is not much work that analyzes the setting of planned lead times in
(Teo et al. 2012). Rao et al. (2005) focus on the strategic decision of determining the fixed
delivery lead time to maximize profits for a single-stage system and analyze how to hedge
for supply chain risks by guaranteeing maximum lead times for a make-to-order production
system. They show that in a stochastic setting the optimal lead time is similar to a
newsvendor problem. Teo et al. (2012) extend this model to a multi-stage and multi43
product environment and propose a tactical
tactical planning model that is based on the early work
of Graves (1986). They focus on the optimal planning window12 of the planning horizon at
the MPS stage and the optimal planned lead times that minimize subcontracting and
In this study we use two initial runs for all investigated combinations of total demand
and product mix variability and different utilization levels
times and also to obtain data to estimate the used clearing function (see Figure 13).
Figure 13. Initial runs for estimating the parameters of the optimization based order release models
Firstly, we use the simulation model of Section 3.2 with immediate
ce the WIP levels obtained from initial run 1 are unrealistically high at the
bottleneck work centres we use a rule based order release
In general, rule based mechanisms assume that a pool of unreleased orders is available
situation on the shop floor is known. These
orders are to be released for a short time horizon (usually one planning period) in order to
maintain the workload norm. The release mechanism assumes that the capacity of the work
centres is fixed. The orders are released periodically at the beginning of the planning
period. The feasibility of releasing each order from the pool is checked in the sequence of
decreasing buffer time which is defined as the required due date minus the estimated flow
The planning window is defined as the difference between the quoted delivery time and the total planned
production lead time for a job (Teo et al. 2011, p.400)
We follow the study of Puergstaller, Missbauer (2012) and use a rule based order
release mechanism which is similar to the procedure described in Land (2004). We only
limit the WIP norm at the two bottleneck centres (one work centre in the printing- and one
in the packaging section). Thus orders are released if they do not violate the specified WIP
norms at the bottleneck work centres (see Puergstaller 2009, p. 87ff). Since a flow shop is
simulated, the aggregate workload is used as the WIP measure which is defined as the sum
of the operation times at work centre n of all orders that have been released, but have not
yet completed their processing at work centre n. If an order cannot be released in the
current period, it is considered again in the next planning period (see Land 2004, p.151). A
time limit of two periods is used. This mechanism closely matches the core part of the
order release stage of the LUMS approach (Hendry, Kingsman 1991; Stevenson, Hendry
In our study the WIP norms and planned lead times for the rule based mechanism are
obtained from initial run 1 (see Figure 13). For the WIP norms we use the aggregate
workload measure (direct load plus load in transit; Land 2004, p.43ff). The direct load is
obtained by fitting a clearing function (38) to the measured load (Λt) and output (Xt) per
period of the bottleneck work centres. The functional form of the clearing function (38)
was introduced by Missbauer (2002) which is given by
X t = [C+k+Λ t - C2 + 2Ck + k 2 − 2CΛ t + 2kΛ t + Λ 2t ].
Where C is the capacity of the work centre under study and the parameter k is the shape
parameter which can be calculated analytically (see Missbauer 2002) or estimated from the
data. In our analysis we estimate C and k from our data. Based on this ordinary least
squares regression, we calculate the direct load of the bottleneck work centres at the
utilization level of 99%. In order to get the aggregate load we add the load in transit, which
is defined as the quantity of work coming from orders that queue at other work centres for
preceding operations to be completed (Breithaupt et al. 2002, p.197).
The planned lead times for the bottleneck work centres are also derived from the
clearing function (38) by dividing the direct load at the utilization level of 99% with the
output of the work centre. The planned lead times for the non-bottleneck work centres are
the flow times of initial run 1. Finally, all of these fractional lead times are rounded to
integers using an integer programming rounding (IPR) approach described below.
Based on initial run 2 we set the planned lead times for the IOC model and estimate the
model Figure 14 shows the entire parameter setting
Figure 14.. Parameter setting of the optimization based order release models
The planned lead times of the IOC model were set with two different approaches. The
programming rounding (IPR) approach which rounds the average
measured flow times of initial run 2 with an optimization model.
the measured average flow times up and down to integer values using the following
optimization model (Turkseven 2005; Puergstaller 2009;
Observed average flow time at work centre n
Table 11. Definition of the symbols used in the demand and order arrival model
The objective of the optimization model is to minimize the rounded lead times of all
work centres (38), whereas the lead times are rounded to the next larger or smaller positive
integer value (39-41). The sum of the rounded lead times per product has to be greater or
equal than the sum of the measured lead times per product (42).
Secondly, since the study by Kacar et al. 2013 shows that the performance of this
rounding approach varies from scenario to scenario we follow their study by simply
rounding down (SRD) the measured average flow times of initial run 2. The SRD approach
naturally underestimates the lead times which will lead to lower inventory levels, but also
worse due date performance of the IOC model.
Similar to the parameter setting of the IOC model, the two initial runs are performed in
order to estimate the clearing functions for the ACF model (see Figure 14). From initial run
2 the load (Λt) and output (Xt) per period are measured and the clearing function (38) is
fitted by an ordinary least squares regression. Thereafter, it is linearized using outer
linearization which is the most common approach in the literature (Missbauer 1998, 2002;
Anli et al. 2007; Asmundsson et al. 2009; Kacar et al.2012; Puergstaller, Missbauer 2012).
We use five tangents whereas the slope=0 for the last segment (o5 in Figure 15) and
intersection=0 for the first tangent (o1 in Figure 15).
Figure 15.. Outer linearization of a clearing function with C=960, k=40
In contrast to the studies by Turkseven (2005), Asmundsson et al. (2009) and Irdem et
al. (2010) who use a nonlinear optimization model to linearize the clearing function (see
we calculate the intersection and the slope of the tangents (α
αO = ⋅ C + k − s + os − γ − s ⋅ (o −1) ⋅ 1+
γ = (C + k )2 + 2s ⋅ (C − k − Co + ko) + s 2 ⋅ (1 − 2o + o2 )
The parameter s denotes the step width of the load level from
+1 which was set to s=480 for a period length of 960 minutes and
s=180 for a period length of 360 minutes (following Missbauer 1998;
case (variable total demand and product mix) where we limited the load to 200% of the
We only use one treatment for the clearing function model. The reason for this is that
the clearing function claims that its functional form is only influenced by the production
3.3. Safety stock adjustment procedure (Kohler-Gudum, de Kok 2002)
As mentioned earlier, the study of Puergstaller, Missbauer (2012) which also compares
the IOC with the ACF model, finds inconclusive results in the performance measures of
these two models. This issue of conflicting performance measures (inventories, due date
performance) can be solved by two approaches. Firstly, one could modify the parameters of
the clearing function (e.g., shape parameter) in order to get comparable performance
measures. This approach was pursued by the study of Asmundsson et al. (2009) who use a
quantile regression (they call it “target percentage method”) which means that their
“conservative clearing function” lies below a certain percentage of data points which yields
better results with regard to due date performance. Secondly, one could apply the safety
stock adjustment procedure (SSAP) which will be pursued in this study.
The SSAP is used to fix the service level of an algorithm at a pre-specified value by
installing an appropriate amount of safety stock. The safety stock is measured in the
inventory and consequently the algorithms can be compared on a single performance
measure (see Figure 16) which allows for a quite broad usage (see Kohler-Gudum, de Kok
2002; Selçuk et al. 2008; Boulaksil et al. 2009; Jansen 2012).
Figure 16. The safety stock adjustment procedure as depicted in Boulaksil et al. 2009
Figure 16A on the left hand side illustrates the inventory development of a simulation
study and Figure 16B shows how the horizontal axis is shifted in order to limit the number
of backorders to a pre-determined level (Boulaksil et al. 2009). This is done in two major
steps. Firstly, the maximum and minimum value of the net stock is determined during a
simulation run. This represents an interval for which the probability that the net stock is
within this interval is close to 1. Secondly, the frequency function of the net stock process is
determined leading to a discrete probability distribution. Based on this probability
distribution the safety stock is adjusted to ensure the specified target service level. Based on
the adjusted safety stock and the probability distribution the performance measures can be
calculated (see Kohler-Gudum, de Kok 2002, p. 145).
The original paper by Kohler-Gudum, de Kok (2002) presents four different service level
measures: the cycle service level, the fill rate, the ready rate and the probability that an
arbitrary customer has to wait. In this study we use the ready rate and set the target service
level (βs) to 95%. The ready rate represents a time dimension of demand satisfied without
backorders which is the same as the probability of no stockout at the end of a period. The
where NB denotes the number of periods with additional backordered demand and NP the
total number of periods under consideration. Let Ψ0 be an arbitrary initial choice of the
safety stock. Given the approximation to the empirical probability distribution of the net
stock process (Xt(Ψ0)) the task of the SSAP is to find the safety stock adjustment quantity
(x1-γ) that satisfies the target service level (βs) of 95%. The adjustment quantity can be found
by linear interpolation between the quantities xτ and xτ-1:
( (1 − γ ) − pτ ) xτ + ( pτ − (1 − γ ) ) xτ
which leads to the calculation of the adjusted safety stock (Ψ*):
( (1 − γ ) − pτ ) xτ + ( pτ − (1 − γ ) ) xτ
The procedure is illustrated in Figure 17 (for a detailed description see Kohler-Gudum,
Figure 17.. The safety stock adjustment procedure for the ready rate
The SSAP can be summarized in five tasks (see Kohler-Gudum, de Kok 2002,
1) Perform a simulation run with an arbitrary safety stock (Ψ0) and initial net stock.
Record the minimum ending and the maximum beginning net stock.
2) Record relevant data and calculate the performance measures (service level,
3) Compute the approximate empirical distribution of the ending net stock (Xt),
0,…,K Here k denotes the number of chosen
pk = P { X t ( Ψ 0 ) ≤ xk } , for k = 0,…,K.
intervals of the probability distribution and xK represents the maximum recorded
net stock in the net stock process Xt(Ψ0) determined in step 1.
th given empirical distribution calculate the adjustment quantity and the
5) Calculate the performance measure directly from the recorded data or verify the
performance measures by running another simulation with the adjusted safety
One minor issue arises when using the SSAP for our study. The
but the products in this study are customer
applying the SSAP we have to assume that we can actually produce to stock, but since one
of the basic assumptions of the SSAP is safety stocks independence13 we do not think that
this assumption is problematic. Therefore, we calculate the performance measures directly
Table 12 exhibits the results for the two different parameter settings of the planned lead
times for the IOC model (IPR and SRD see Section 3.2.3) and the ACF model for constant
product mix and constant/varying total demand for a period length of 960 minutes. The first
column denotes the two optimization based order release models with two different
parameterizations in the case of the IOC model. The columns two to four show the average
held WIP in front of the work centres (WIP), the average inventory in the finished goods
inventory (FGI) and the average total inventory (Total). The FGI values are the values
adjusted by the safety stock needed to reach the target ready rate of 95%.
The last column depicts the ready rate (RR) that was reached without the adjusted safety
stock (Ψ*). The lowest row depicts the difference between the lowest resulting measure
from the two different parameterized IOC models and the ACF model. Thus, when the
resulting difference is negative the ACF has higher inventories and vice versa. The values
marked with an asterisk are significantly different from each other which is tested by using
a t-test or a Welch’s t-test in cases of unequal variances.
Table 12. Simulation results for IOC and ACF for different settings of total demand variability
Hypothesis H1 stated that the ACF model outperforms the IOC model as the variation of
the demand increases. The left side of Table 12 shows the performance of the two models
with constant product mix and constant total demand. In this case the IOC model yields
slightly lower inventory levels. The right hand side of Table 12 depicts the constant product
mix and variable total demand scenario. One can see that hypothesis H1 is confirmed since
with increasing variation of the demand the ACF model outperforms the IOC model.
In Kohler-Gudum, de Kok (2002) safety stock independence refers to independence of net requirements and
Additionally, when looking at the first two rows of Table 12 one can see that the setting of
the planned lead times (round procedure IPR or SRD) has a crucial impact on the
Table 13 shows the results for constant total demand and constant/varying product mix.
The left hand side of Table 12 is repeated for convenience.
Table 13. Simulation results for IOC and ACF for different settings of product mix variability
Hypothesis H2 claims that the ACF model performs worse than the IOC model as the
variation of the product mix increases. As one can see in Table 13 this hypothesis can be
confirmed. The assumption of the ACF model that the product mix of the output is the same
as the product mix in the queue (see LP in Section 3.1.2 above) must be questioned (see
Missbauer 2011; Jansen 2012). Therefore, we examine the results of the constant total
demand, variable product mix case in more detail. We present the ratios of the WIP- and
output mix of some products in different production stages over time in order to analyze
whether the deviation from the equality assumption is prevalent. The share of product j in
the total WIP at work centre n in period t is calculated as
Note that the ACF model assumes that the WIP mix on average is the same as the
output mix and by the nature of the piecewise linearization departures from this ratio are to
be expected. However, the question arises whether the differences are small enough to be
neglected. We start with the analysis of the first manufacturing stage where the machine
under study faces an average utilization level of approximately 65% and 12 of the 24
products are manufactured. For the sake of brevity we only present the analysis of two
representative products manufactured at the machines under study.
Figure 18 depicts the plots for two different products over an entire seasonal cycle.
1 5 9 13 17 21 25 29 33 37 41 45 49 53 57 61 65 69 73 77 81 85 89
1 5 9 13 17 21 25 29 33 37 41 45 49 53 57 61 65 69 73 77 81 85 89
Figure 18.Share of two different products in the total WIP and output mix in production stage one
As one can see in Figure 18 at production stage one there are differences in the WIP and
output mix although they are limited in the case of product P6 and nearly non-existing for
Figure 19 depicts the differences in the ratios of WIP mix and output mix for these two
products over time (differences between the blue and red line in Figure 18). We subtract the
share in the total output from the share in total WIP thus when the resulting difference is
positive the share of the product in the total WIP is higher than the share of this product in
1 5 9 13 17 21 25 29 33 37 41 45 49 53 57 61 65 69 73 77 81 85 89
Figure 19. Differences between the share in WIP and output mix (WIP mix minus output mix) in
Figure 19 shows that there are differences between the share in the total WIP and the
share in the total output in some periods, in order to analyze the total deviation from each
other we calculate the average absolute difference (AAD) for product j at work centre n for
The AAD for product P6 is 4.68% and 0.54% for product P7 which is quite low, but not
surprising since we until now only analyzed a moderately utilized machine (approx. 65%
average utilization) at production stage one. Therefore, we now analyze a bottleneck
machine with an average utilization of approximately 88% from production stage three.
Figure 20 depicts the differences between the shares in WIP and output mix for two
Without warm-up period of 5 seasonal cycles we consider 19 seasonal cycles which is equal to 1691periods.
1 5 9 13 17 21 25 29 33 37 41 45 49 53 57 61 65 69 73 77 81 85 89
Figure 20. Differences between the share in WIP and output mix (WIP mix minus output mix) in
Figure 20 shows that the differences between the ratio of WIP and output can be quite
high for some products at the bottleneck machine under study (see P4 in Figure 20). This is
also shown in the AAD measure which is 16.37% for product P4. An explanation for the
high differences in the ratios of WIP and output mix at this bottleneck machine is that the
workload that is carried over from the previous period(s) has a different product mix than
the new part of the workload. Thus, the results for product P4 above reaffirm the hypothesis
that the ACF model (the one-dimensional clearing function in general) is not sufficient to
model the material flow if the product mix varies over time.
The effect of increasing process variability due to the varying product mix seems to
influence the performance of the ACF model. This was also shown in and different context
in the study of Asmundsson et al. (2009) who show the same decreasing performance of the
ACF model in cases of severe machine failures.15 Therefore, in order to relate our results to
the findings of their study we analyze how much more variability was induced in our study.
We calculate the mean and coefficient of variation (CV) of the effective processing times
(EPT) of the system under study. The EPT describes the processing times seen by an
outside observer and includes all unexplained variation (Hopp Spearman 2008; Lefeber,
Armbruster 2011). Table 14 shows the mean, standard deviation and the CV of the EPTs for
constant total demand and constant/varying product mix.
The study of Asmundsson et al. (2009) resolves this issue methodologically by estimating the clearing
function using an quantile regression instead of an ordinary least squares regression.
Table 14. Effective Processing Time (EPT) distribution for constant total demand and
As one can see in Table 14, the CV of the EPT increases from 0.94 in the constant total
demand and product mix scenario to a value of 1.10 in the case of constant total demand and
varying product mix. The difference in the means of the EPTs in these two scenarios is due
to the calculation of the product mix (rounding to integer demands for each product; see
Section 3.2.2) where we only have nonzero demand for 16 (instead of 24) products in the
constant total demand and product mix scenario. We conclude that the varying product mix
in our simulation study has (quite likely) the same effect on the EPT as the consideration of
machine failures as pursued in the study of Asmundsson et al. (2009).
The problem of the ACF model seems to be that the clearing function specifies the
relation between the aggregate load and aggregate output of the resources for all products.
Therefore, the shape of the clearing function is determined for a certain average product mix
which assumed to be stable over time since the clearing function does not change over time.
A solution to this issue would be to change the shape of the clearing function over time. The
work of Kacar (2012) who uses simulation-optimization to fit the clearing function
represents the first step in this direction.
Finally, the worse performance of the ACF model in this case could also be due to using
discrete planning periods and thus ignoring any transient effects that arise at the boundaries
between the periods. This causes discrepancies between the realized- and the predicted
output by the clearing function which is based on steady-state (Missbauer 2009). Providing
an in depth analysis of this issue is beyond the scope of this thesis and must be left to future
research, but the general approach would be to run the simulation without the rolling
horizon and compare the realized with the planned output per product and period.
A solution approach to the issues related to transient behavior is presented in Missbauer
(2011) who shows that an extension of the one-dimensional clearing function to models
incorporating two and three independent variables could remedy this effect. He shows that
the expected output in the period given a certain expected load (available work) in the
period can strongly depend on the composition of the load (proportion of initial WIP and
work input) and on the uncertainty (probability distribution) of the initial WIP (For an indepth discussion see Haeussler, Missbauer 2014 or Chapter 4).
Table 15 depicts the performance of the two order release models under study when
facing a variable total demand and a variable product mix.
Variable total demand and variable product mix
Table 15. Simulation results for IOC and ACF for varying product mix and total demand
With regard to hypothesis H3 we expect the ACF model to outperform the IOC model
as the variation of the demand and the variation of the product mix increases. We confirm
this hypothesis for our analysis since the ACF model clearly outperforms the IOC model.
Therefore, the results of this study confirm the findings of earlier comparative studies
(Asmundsson et al. 2009; Kacar et al. 2012) that the ACF model outperform fixed lead
time models in cases of high variability. Additionally, we find that the decrease in the
performance of the ACF model in cases of varying product mix (hypothesis H2) are more
than compensated when adding high demand variability as an experimental factor (see
Table 15). This means that under these conditions (period length of 960 minutes and
average bottleneck utilization of 95%) the benefit of allowing variable lead times
outweighs the limitations of the ACF model.
Now let us turn to the analysis of another limitation of the ACF model. In hypothesis
H4a we stated that the performance of the ACF model decreases as the period length
decreases. Therefore, we compare the scenarios with a period length of 960 minutes to
scenarios with a shortened period length of 360 minutes. Since we are interested in
whether a shorter period length affects the quality of the clearing functions we use different
values for the total demand (see Section 3.2.2) in order to keep the demand during the
In order to make the comparison interpretable we also depict the difference in the
performance measures in per cent numbers (see second lowest row in Table 16). We divide
the inventory level from the IOC model by the one obtained from the ACF model which
means that when the ratio is below 100% the IOC model yields lower inventories and vice
Constant total demand and constant product mix
Table 16. Simulation results for IOC and ACF for varying period lengths and constant total demand
As one can see in Table 16 we can confirm hypothesis H4a for the case with constant
total demand and product mix since the performance of the ACF model decreases in
comparison to the IOC model when reducing the period length to 360 minutes.
Table 17 depicts the resulting inventory levels for different period lengths under
variable total demand and constant product mix.
Variable total demand and constant product mix
Table 17. Simulation results for IOC and ACF for varying period lengths and variable total demand
Hypothesis H4a has to be rejected for tests with variable total demand and constant
product mix since the ACF model copes equally well for long and short period lengths in
comparison to the IOC model. The demand variability seems not to influence the
performance of the clearing function when we reduce the period length.
Table 18 shows the results for the constant demand and variable product mix scenario.
Constant total demand and variable product mix
Table 18. Simulation results for IOC and ACF for varying period lengths and constant total demand
In this case the period length has a clear impact on the performance of the ACF model
and therefore we can confirm hypothesis H4a. For a long period length the IOC model
holds 81.17% of the total inventory held by the ACF model. This difference becomes even
larger by reducing the period length to 360 minutes where the IOC model holds 72.99% of
Table 19 shows the most realistic test scenario where both demand and process
variability is high in the production system.
Variable total demand and variable product mix
Table 19. Simulation results for IOC and ACF for varying period lengths and variable total demand
Again we confirm hypothesis H4a. The performance of the ACF model decreases by
reducing the period length, but still yields lower inventory levels than the IOC model (see
Until now, all analyses were made with a parameter setting that yielded an average
bottleneck utilization of 95%. Additionally, we hypothesized (H4b) that the decrease in the
performance of the ACF model is mostly apparent when the system is highly utilized.
Therefore, we also conduct tests with the most variable scenario (variable total demand and
product mix) facing parameter settings yielding two lower average bottleneck utilization
Table 20 depicts the performance measures for a variable total demand and product mix
scenario and 85% average bottleneck utilization.
Variable total demand and variable product mix
Table 20. Simulation results for IOC and ACF for varying period lengths and variable total demand
and variable product mix for an average bottleneck utilization level of 85%
For a period length of 960 minutes, the ACF model largely outperforms the IOC model
that holds 54% more inventories. But when the period length is reduced to 360 minutes,
this advantage is reduced vastly and the IOC only holds about 12% more total inventory.
This means that when the period length is long enough the ACF model outperforms the
IOC model, because of its ability to capture the system dynamics so well, but when we
reduce the period length this advantage decreases. Therefore, we have to reject hypothesis
H4b since the differences in the performance measures are higher in the case of 85%
compared to 95% average bottleneck utilization. An explanation for this might be that with
an average bottleneck utilization of 85% the resource faces critical load levels more often
and is only temporarily overloaded which would increase the transient effects.
Finally, Table 21 shows the resulting inventories for an average utilization level of 75%
Variable total demand and variable product mix
Table 21. Simulation results for IOC and ACF for varying period lengths and variable total demand
and variable product mix for an average bottleneck utilization level of 75%
For a period length of 960 minutes the IOC model performs a bit better than the ACF
model by holding 98.91% of the total inventory of the ACF model. When we reduce the
period length to 360 minutes the IOC model holds 3.64% more inventories than the ACF
model. It seems like an average bottleneck utilization of 75% is too low that the period
length has a major impact on the performance of the ACF model and the differences in the
inventory levels might be due to the parameter setting of one or both approaches.
The objective of order release planning in general is to maintain a certain level of WIP
to achieve a certain utilization of the production system, thus controlling the flow times in
order to meet the required due dates of the orders. The tradeoff between reducing flow
times and WIP while trying to maintain high throughput can be managed by models
relating to the workload control (WLC) concept. One research direction deals with
optimization based order release models which can be divided into two streams
(Missbauer, Uzsoy 2011). Firstly, order release models that incorporate workload
independent lead times or lead time distributions (Hackman, Leachman 1989; de Kok,
Fransoo 2003; Spitter et al. 2005a, 2005b; Puergstaller, Missbauer 2012; Hung Leachman
1996) and models that allow for workload dependent lead times (Lautenschlaeger 1999;
Voss, Woodruff 2003; Karmarkar 1989; Missbauer 2002; Asmundsson et al. 2006, 2009;
Selçuk 2007). Comparisons of models from different streams are rather scarce in literature
and this thesis continued this stream of research (Asmundsson et al. 2009; Kacar et al.
This study compared the IOC model (workload independent lead times) of Puergstaller,
Missbauer (2012) with the ACF model (workload dependent lead times) of Asmundsson et
al. (2006, 2009). We analyzed this using a multi-model approach where the two order
release models are represented by LP models that face the same objective function and
whose decisions are executed in a simulation model thereafter. We analyzed the impact of
total demand variability (constant and seasonal demand), product mix variability (constant
or variable product mix), the period length (long and short) and the average bottleneck
utilization. Since earlier studies had problems when comparing order release models we
applied the safety stock adjustment procedure that fixes the service level at a pre-specified
value which enabled us to compare them on a single performance measure (the
The results showed the superiority of the ACF model in comparison to the IOC model
as the demand and total variability (process and demand variability) in the system
increases. In these scenarios the IOC models fails because of the general weakness of fixed
lead time models that set lead time norms that must allow high utilization at the bottleneck
work centres which cannot be reduced in periods of low capacity utilization. The IOC
model performs better in the case of low total variability and in the constant demand and
variable product mix scenario. Reasons for the worse performance of the ACF model in the
case of variable product mix are twofold. Firstly, we found that the assumption of the ACF
model that the product mix of the output is approximately the same as the product mix in
the queue does not hold, especially not at bottleneck work centres. This means that the
shape of the clearing function is determined for a certain average product mix which is
assumed to be stable over time since the clearing function does not change over time.
Three solutions to this issue seem possible: Firstly, one can change the shape of the
clearing function over time (e.g. with simulation optimization; see Kacar 2012). Secondly,
the estimation of clearing functions could be done differently (e.g. quantile regression; see
Asmundsson et al. 2009) and thirdly an extension of the ACF model is imaginable, but is a
Secondly, the main limitation of one-dimensional clearing functions as used in the ACF
model is their derivation form steady-state models. However, in the actual operation of a
work centre steady-state situations and various transient states can occur in any sequence.
This issue is addressed in Missbauer (2011) who shows that an extension of the onedimensional clearing function to models incorporating two and three independent variables
could remedy this effect (For an in-depth discussion see Haeussler, Missbauer 2014 or
In order to analyze the influence of these transient effects on the ACF model we also
conducted experiments with a shortened period length and tested scenarios with different
bottleneck utilization levels. We found that the performance of the ACF model in
comparison to the IOC model got worse in every scenario except in the case of constant
product mix and varying demand. Note that although the performance of the ACF model
decreased by reducing the period length, it still performed better in the above described
scenarios (constant product mix/variable demand, variable product mix/variable demand).
This indicates the relevance of research concerning clearing functions that take transient
effects into account and secondly from a planning perspective shows the crucial influence
of the choice of the period length. Experiments with an average bottleneck utilization of
85% (instead of 95% in the tested scenarios above) showed that in the case of high total
variability, a shortening of the period length decreased the performance of the ACF model
even more. An explanation for this might be that at this utilization level the resources face
critical load levels more often and are only temporarily overloaded which would increase
The study presented in the first part of this thesis provides important insights, but we are
aware of its limitations. Firstly, although the findings are largely in line with the relevant
literature the results are limited to the simulated case. The validity of the results for other
types of production systems must be assessed in future studies. Secondly, adding further
experimental factors would be beneficial like introducing machine failures or it would also
be interesting to include scenarios with altered length of the planning horizon and the
effect of demand predictability as in Puergstaller, Missbauer (2012). The interested reader
is referred to a recent working paper by Stampfer et al. (2014). Additionally, the IOC
model uses integer lead times (as mostly done in practice) which might lead to a
disadvantage in most scenarios. A comparison with fractional lead times would be more
favorable for this type of model which was done very recently by Kacar et al. (2013). And
finally, there exists no generally accepted method to set the integer lead times for the IOC
model and to estimate clearing functions to data.
4. Empirical validation of meta-models of work centres in order release
In this second part of the thesis we limit our attention to clearing function models. A
clearing function is defined as the functional relationship between an appropriate measure of
WIP at a work centre n in period t and the expected or maximum output of this work centre n
in period t. Clearing functions model the effects of the discontinuity and stochasticity of the
material flow at the work centres that limit the possible output. They can be interpreted as
meta-models and avoid analytical descriptions of the queueing processes in the manufacturing
system. In line with queueing-theoretical results, usually a concave, saturating shape of the
clearing function is assumed as suggested by Karmarkar (1989). Clearing function models
have been described and tested extensively by simulation studies (see Chapter 3; Asmundsson
et al., 2006, 2009; Kacar et al. 2012). Asmundsson et al. (2006, 2009) and Kacar et al (2012)
show that clearing functions (when estimated correctly) produce production plans that are
much more aligned with the ability of the production system to execute them compared to
fixed lead time approaches. However, clearing function models tend to exhibit problematic
behavior, namely short-term oscillations of the planned release quantities, as a response to
sudden changes of the demand. Moreover, it is difficult to model the product mix of the
output in a certain period that results from the product mix of the work input or of the WIP,
respectively (see first part of this thesis). This indicates that modeling the material flow by
clearing functions imposes certain limitations. We limit our attention to one aspect of this
modeling task, namely the dependence of the total output (aggregated over the products) in a
certain period t on the history of the process (work input and output over time) that leads to a
certain WIP level in period t. Conventional clearing functions assume that the output in period
t can be modeled as a function of one independent variable (WIP level or available work,
termed load, in the period under consideration) to a sufficient degree of accuracy. This holds
for steady-state situations, and likewise a clearing function can be formulated for specified
transient states like, for instance, the first period in the ramp-up phase of a queueing model
(Missbauer, 1998, p. 250ff.). However, in the actual operation of a production unit steadystate situations and various transient states can occur in any sequence, and this trajectory of
the system is controlled by the order release decisions that are made by the model. Hence “the
clearing functions employed by most researchers to date represent an average relation over a
wide range of operating states, but may be quite inaccurate for a given sample path of system
evolution.” (Kacar and Uzsoy, 2010). Therefore, we must ask whether a one-dimensional
clearing function is sufficient. The numerical analysis of one transient period of an M/M/1
model in Missbauer (2011) indicates that this is not the case. The expected output in the
period given a certain expected load in the period can strongly depend on the composition of
the load and on the uncertainty of the initial WIP. Meaning that on the one hand it depends on
the proportion of initial WIP and work input (that together constitute the load) and on the
other hand on the probability distribution of the initial WIP. These insights suggest that the
history of the process and the uncertainty of the load estimation influence the output in a
period t that can be expected given a certain estimated load (Haeussler, Missbauer 2014,
p.103ff). Therefore, we formulate our second research question:
Research question RQ2: Do multi-dimensional clearing functions, where the independent
variables reflect the process history and the uncertainty of the load estimation, lead to
improvements of the fit when compared to one-dimensional clearing functions?
To sum up, the task is at first to test whether these newly included independent variables
lead to better fits when estimating clearing functions to data. We use empirical data obtained
from a make-to-order production system and simulation data from a scaled down simulation
model thereof. Furthermore, we also analyze data from two simplified queueing models in
order to explore structural properties. We fit state of the art and extended clearing functions to
these types of data which will be made by a regression through the origin. All regressions will
be performed with linear and nonlinear functions and the improvement of the fit is measured
by comparing the adjusted coefficient of determination of the various models. The second
task is to find functional forms of two- and three-dimensional clearing functions which will be
addressed by introducing a preliminary functional form for a nonlinear two dimensional
clearing function. Additionally, to the already identified gaps in the literature the author wants
to note that in the literature no attempt was made to fit state of the art clearing functions on
empirical data since the work by Fine, Graves in 1989, but all studies on this topic were made
using simulation data. This thesis aims at addressing this gap as well by using empirical data
of a make-to-order optical storage media producer.
The remainder of the thesis is structures as follows: Section 4.1 describes the state of the
art one-dimensional clearing functions. Thereafter in Section 4.2, we describe multidimensional clearing functions which are clearing functions that incorporate two or more
independent variables. Section 4.3 outlines the used method to estimate the clearing functions
to data, the applied statistical test and the nearest neighbor analysis. In section 4.4 we describe
the real production system and the used simulation models. Afterwards, we outline the editing
of raw data, deduction of the independent variables and the selection of non-bottleneck and
bottleneck machines in section 4.5. After presenting our results in Section 4.6.we conclude,
point out implications of this study and give insights for future research in Section 5.
As discussed above clearing function describes the amount of output “cleared” from a
manufacturing facility in a certain period as a function of some measure of WIP (e.g.,
average WIP, load). We define the load Λn,t of a work centre n in period t as the initial
WIPn,t-1 plus the input An,t of work centre n in period t:
Using the load as the WIP measure, the one-dimensional clearing function is a
functional relationship of the form (Karmarkar 1989):
where Xn,t and Cn,t denote the output and the capacity of work centre n in period t,
respectively. Over time several functional forms of the one-dimensional clearing function
were developed (overview in Missbauer, Uzsoy 2011). The most prevalent method used to
fit clearing functions is the use of regression functions (Missbauer 1998, 2002; Kacar et al.,
2012; Kacar, Uzsoy 2013; Asmundsson et al. 2009) which will be applied in this thesis as
well. Figure 21 illustrates three basic functional forms with Load (Λt) as independent
ring functions (following Karmarkar 1989, adapted)
The “Fixed Lead Time”- function in Figure 21 represents the first WIP based approach
introduced by Graves (1986). In this model a constant proportion of the available work is
processed in each planning period. Capacity is assumed as infinite at least within the
relevant range of the load, and the fixed lead time is independent
nonlinear, “saturating” clearing function depicted in Figure 21 has been introduced by
(1989 as an instrument to model congestion on capacitated production
resources and since then have been applied by several researchers (Missbauer 2002;
Asmundsson et al. 2006, 2009; Selçuk 2007;
If there are no relevant capacity constraints
constraints at the work centre under study we can
assume that the output is proportional to the load. This represents the fixed lead time
function in Figure 21 and will be denoted as linear one-dimensional
This relation should hold for non-bottleneck
non bottleneck work centres which normally have a low
load. If the load is high at certain times and congestion effects occur (saturating part of the
function), the work centre behaves as a (at least temporary) bottleneck with loadload
dependent flow times.16 Therefore, we hypothesize:
We shall analyze empirically at which average utilization (presumably far below 100%) these congestion
phenomena become relevant which means that for planning purposes the work centre must be treated as a
Hypothesis H5: The fit of linear one-dimensional clearing functions is high when applied on
Hypothesis H6: For non-bottleneck machines, we neither expect an increase of the R2 values
by adding independent variables to a linear clearing function nor by using
For capacity-constrained (bottleneck) facilities that are subject to congestion,
(queueing) theory suggests that clearing functions must exhibit a nonlinear shape. In the
one-dimensional case extensive work was done to find functional forms of nonlinear
clearing functions which are mostly derived from queueing theory (Srinivasan et al. 1988;
Karmarkar 1989; Missbauer 1998, 2002). This paper contributes to the discussion of
finding suitable independent variables of multi-dimensional clearing functions. Starting
point for this are nonlinear regression functions with one independent variable proposed by
literature. Karmarkar (1989) proposes the following function:
Missbauer (1998) derives the following equation from a M/G/1 queueing model in
X t = [C+k+Λ t - C2 + 2Ck + k 2 − 2CΛ t + 2kΛ t + Λ 2t ].
The parameter k can be calculated analytically (see Missbauer 2002) or estimated from
the data. In our analysis we estimate C and k from our data sets. These functions approach
the capacity C asymptotically as the workload increases to infinity. If the output can be
expected to reach full capacity at finite workload levels, a functional form for this case is
presented in Nyhuis, Wiendahl (2009, p. 66ff.). In the course of this study we will only use
functional form (56), since Karamarkar’s function (55) is less suitable for discrete-time
models on a periodic basis (Missbauer 1998, p. 257).
4.2. Multi-dimensional clearing functions
4.2.1. Two-dimensional clearing functions
All of the above described clearing functions are limited to one independent variable.
Using these functions in an order release model is adequate if it can be assumed that
knowing the planned value of this variable for a future period t allows prediction of the
output in this period t to a sufficient degree of accuracy. Literature suggests that nonlinear
one-dimensional clearing functions lead to good output prediction and when incorporated
in a production planning model outperform fixed lead time models (Asmundsson et al.
2006, 2009; Kacar et al. 2012). On the other hand, queueing-theoretical studies show that
clearing functions with one independent variable do not predict the output sufficiently if
the system under study faces transient states (Missbauer 2011). Transient phases are
especially apparent at highly utilized machines since these frequently face critical load
levels or are temporarily overloaded (see first part of this thesis). Therefore, we
Hypothesis H7: One-dimensional clearing functions do not yield a high fit at bottleneck
machines in comparison to multi-dimensional clearing functions.
If this is the case, we must ask which additional independent variables can be expected
to improve the fit of the clearing function to the data sets.
Only a few other papers deal with multi-dimensional clearing functions for order release
planning. Anli et al. (2008) assume that the expected WIP level for each unfinished SKU,
facility and period is a non-linear function of the planned production volumes (of all
SKUs) of the facility and the variables representing system variability and control polices.
The relationship is estimated by mean value analysis, Caramanis et al. (2001) use the
Queueing Network Analyzer (Whitt 1983) (see Missbauer, Uzsoy (2011) for a description
of this approach). Albey et al. (2011) analyze the output of a single facility in terms of
quantity and product mix as the product mix of the released orders changes. However,
these papers do not analyze transient effects. Kacar, Uzsoy (2010) test the performance of
various multi-dimensional linear clearing function formulations including similar
independent variables as in this paper (see below).
The benefit of including variables expressing the variability of input, output and WIP
over time is difficult to predict. Clearly, characteristics of the manufacturing system like
product mix, lot sizes or system variability influence the expected output. In our study
these characteristics are given and determine the shape parameter k of the clearing function
(56) and (59). If these characteristics vary over time, including independent variables that
reflect these characteristics may be beneficial. In our data no major change in product mix
and lot sizes occur, and we expect that the variability of arrival and departure process at the
machines does not change substantially over time. Therefore, we hypothesize:
Hypothesis H8: Independent variables that take the history of the process into account lead
to improvements of the fit to data of bottleneck machines. Variables that
express the variability of WIP and work input are not expected to improve
Since the variability of WIP and work input during the period is not represented in the
data, we use the variability of WIP at the start/end of the period and of the work input
In an early paper on hierarchical production planning (Andersson et al. 1981) linear
two-dimensional clearing functions have been proposed to predict the output, measured in
value, of a manufacturing system. Their two-dimensional clearing function splits up the
load of machine n in period t into initial WIP and input of machine n in period t, leading to
There is theoretical evidence for this: Missbauer (2011) shows that if the expected load
E[WIPn,t-1]+E[At] (measured in number of orders) for a period t is kept constant, the
expected output E[Xt] depends on the composition of the load (proportion of E[WIPn,t-1]
and E[At]). This indicates that additional independent variables that reflect the history of
the process (roughly speaking: the time-dependent capacity loading before the period
under consideration) improves the output prediction.
To the best of our knowledge no functional form for a saturating multi-dimensional
clearing function that takes transient effects into account has been provided so far. The
two- and three-dimensional transient clearing functions in Missbauer (2011) are calculated
numerically from the transient-state probabilities for an M/M/1 system. We cannot provide
a definitive solution to this problem, but use a preliminary functional form for a twodimensional saturating clearing function. Functional forms for saturating multidimensional clearing functions in principle result from the transient behavior of queueing
systems, and obtaining analytical formulations from transient queueing models has not
been possible so far. We use a preliminary functional form for a two-dimensional
saturating clearing function that is based on the following structural properties:
1. The initial WIP (Wt-1), measured in time units (hours of work), is a lower bound on
the output Xt up to the available capacity C (for the sake of brevity we omit the index
2. For positive input At the output Xt is bounded from above by Min[Wt-1 + At; C].
3. The shape of the clearing function is concave and saturating; it approaches the
∞. This can be seen from Missbauer (2011) and – derived by
means of simulation and partial differential equations – from Armbruster et al.
Hence we assume that for given Wt-1 ≤ C as At increases the function exhibits the same
pattern as equation (56). This leads to the following functional forms depending whether
the regression is applied to simulation (58) or empirical data (59):
( C - Wt -1 ) ⋅ 1 [C + k + A - C 2 + 2Ck + k 2 − 2CA + 2kA + A2 ] if W < C
( C - βWt -1 ) ⋅ 1 [C + k + A - C 2 + 2Ck + k 2 − 2CA + 2kA + A2 ] if W < C
with k, C and, for empirical data (59) also β as parameters which are estimated by
regression (for simulation data β=1). Note that property 1 above reflects the operation rule
usually assumed in simulation models. It need not hold for empirical data or – even in
simulation – in the case of machine downtimes. We can consider this by assuming that
Wt-1 is cleared at a constant speed β that is below the capacity:
This assumes that β is independent of At. Figure 22 depicts equation (59) and shows
that, parameterized appropriately, it exhibits a shape very similar to the transient clearing
Figure 22.. Output (Xt) as a function of load (Wt-1 + At) from equation (59) for Wt-1=0, 30, 60, 90, 120.
In our regression analyses we use functional form (58) for tests with simulation data and
(59) for empirical data. Figure 23 shows an application of equation (59) to empirical data.
Figure 23.. Estimated equation (59) on empirical data
In order to use equation (58) and (59) in our regression analyses, we had to introduce a
procedure to determine the parameters C and β,, since the equations include conditions
n to use the saturating part of the equation or the upper boundary C or C/β,
respectively. Therefore, we iteratively search for these values of the parameters C and β
which minimize the sum of squared residuals. As initial values for C we use the estimate
from the nonlinear saturating regression function by Missbauer (1998) following (56) and
thereafter use the estimates from the regression yielding the lowest sum of squared
residuals until convergence occurs (Haeussler, Missbauer 2014, p.114ff).
With regard to equation (59) we extend the procedure and also include parameter β,
setting its initial value to 1 and stop when both parameters (C and β) converge or stop after
25 iterations and take the estimates yielding the lowest sum of squared residuals.
Providing a functional form for a saturating, three-dimensional clearing function must
In addition to the linear two-dimensional clearing function (57) and the saturating twodimensional clearing function (59), we will test general two-dimensional clearing functions
where I1 and I2 represent two out of a set of six possible independent variables. The
deduction of the six variables will be described in Section 4.5. Each of the six variables is
combined with each other (one combination is omitted; see below) which yields 14 (15
minus 1) possible combinations. The intention of comparing these two-dimensional
clearing functions (57) and (60) is firstly, to evaluate the fit of the two-dimensional
clearing functions that use the independent variables suggested by Andersson et al. (1981)
and secondly, to have a reference R2 value for three-dimensional clearing functions.
4.2.2. Three-dimensional and “simple” clearing functions
Three-dimensional clearing functions are regressions with three independent variables
where I1, I2 and I3 represent three independent variables which will be combined with
each other which yields 20 (24 minus 4) possible combinations.
In the course of this analysis linear and nonlinear regression functions will be used. We
start with a linear one-dimensional clearing function (54) of the form (repeated for
Furthermore, the linear regression through the origin will be extended to a linear twodimensional clearing function following (57) or (60) leading to
and three variables following this logic. In the course of our analysis the independent
variables I1, I2 and I3 (for three-dimensional clearing functions) will be chosen from six
different variables which will be described in Section 4.5.
As described above, several authors (Karmarkar 1989; Missbauer 1998, 2002) use
queueing relationships to develop analytical expressions for nonlinear one-dimensional
clearing functions (see (55) and (56)). Missbauer’s function (56) will be tested and the
resulting R2 will be used as a benchmark for a “simple” regression function (64) that does
not incorporate knowledge about the (mostly saturating) structure of the underlying data.
Hence the “simple” regression with one independent variable follows
If the R2 of this quadratic regression function is as high as the fit of the saturating
regression function (56) then (64) will be extended to two independent variables, yielding
X j,t =b1I12 +b2 I1 +b3 I2 2 +b 4 I2 +b5 I1I2
and finally, we will extend the formula to regressions with three independent variables
and obtain a functional form inspired by the regression function used in Noguera, Watson
X j,t =b1I1 +b 2 I 2 +b 3 I 3 +b 4 I1I 2 +b 5 I1I 3 + b 6 I 2 I 3 + b 7 I1I 2 I 3 + b8 I12 + b 9 I 22 + b10 I 32 .
All coefficients (b1 to b10) will be tested on a significance level of 95%, meaning that in
a majority of cases the final regression functions of nonlinear two-dimensional clearing
functions and three-dimensional clearing functions are shorter versions of equations (65)
The weakness of the quadratic functions (64) – (66) is obvious; they can predict a
decrease of the output as the independent variables (e.g., initial WIP) exceed a certain
value. This can actually happen in certain cases, but normally it cannot be assumed,
especially in simulation models. Thus the quadratic functions are not robust (as defined in
Little 1970), and their predictive power is limited. Since we only use these functions for
deriving appropriate independent variables, we expect relevant insights especially for the
(noisy) empirical data. Therefore, we hypothesize:
Hypothesis H9a: “Simple” nonlinear regression functions are well suited as representations
of saturating clearing functions within the range of the independent
variables that occurred in the data, especially for empirical data.
Hypothesis H9b: For simulation data the “simple” regression functions yield lower fits in
comparison to the saturating two-dimensional clearing functions (59).
The use of ordinary least squares regressions for estimating the clearing function
parameters can be questioned. Kacar, Uzsoy (2013) show that in the case of linear multidimensional clearing functions high fits to data do not automatically guarantee good
performance of the release model. The relationship between the clearing function
estimation and the performance of the order release model is not yet fully understood. The
impact of the parameter estimation on the tradeoff between inventory and due-date
performance may play a role as well as the systematic difference between the estimated
clearing function and the clearing function used for planning (Missbauer 2011). We
assume that a set of independent variables that leads to a higher reliability of the expected
output is a good starting point for predicting the output in order release models even
though adjustments of the parameters might be necessary due to the reasons sketched
above. Testing the robustness of our results if a fitting procedure based on simulationbased optimization is used (as in Kacar 2012) is a topic for future research.
The most prevalent method used to fit clearing functions is the use of regression
functions (Missbauer 1998, 2002; Kacar et al. 2012; Asmundsson et al. 2009) which will
be applied in this paper as well. Throughout the paper we apply regressions through the
origin which is a special case of an ordinary least squares regression. The reasoning for this
is obvious for nonlinear regression functions that exhibit a concave, saturating shape. It is
less obvious for linear regression functions, because in this case the fit can be better for
non-zero intercept (see Fine, Graves 1989). The reasoning is as follows: In the context of
the order release model the planned output cannot exceed the planned load due to the
nonnegativity of the planned WIP. Hence in the context of order release models a linear
clearing function with a positive intercept leads to a functional relationship between load
and maximum output that consists of two linear segments, namely the segment
Xt ≤ WIPn,t-1 + At and the linear clearing function (and possibly the capacity constraint
Xt ≤ C as third segment). Hence the relationship between load and output that is actually
assumed in the release model is an approximation to a nonlinear function. Therefore, we
use a regression through the origin: Nonlinear regression functions are tested separately,
and a linear regression through the origin means a proportional clearing function that has
the suitable property of load-independent lead times (Graves 1986), and we explore to
what extent this assumption holds especially for non-bottlenecks (see below).
In general, a regression is used to estimate parameters and to give a “best fit” of data.
Most commonly this is evaluated by a least squares method, which minimizes the sum of
squared errors, which is the difference between an observed value and the value given by
the model (see Wooldridge 2006, p. 34). A regression through the origin is a special case
of an ordinary least squares regression. The least squares estimate for linear regressions
through the origin with one independent variable is denoted as
where Xi denotes the dependent variable for observation i, Ii the independent variable
for observation i and n the number of observations. The slope parameter b can be
To measure the improvements of adding independent variables to the model the
adjusted coefficient of determination (for brevity denoted as R2) of regressions through the
origin is used (Wooldridge 2006; Kvalseth 1985), defined by
Where Xi denotes the ith fitted value of the dependent variable X.
One noteworthy consequence of forcing the regression through the origin is that the R2
can be negative (see (69) or Wooldridge 2006; Kvalseth 1985). This means that the
average of the dependent variable “explains” more of the variation than the independent
The main purpose of this study is to identify independent variables that increase the fit
of the regression model to the data (measured by the R2). Thus, we are interested in the
significance of certain independent variables in the fitted regression functions which is
tested with a t-test on a 95% confidence level. In the course of this study non-significant
coefficients are only an issue when testing the “simple” nonlinear two- and threedimensional regression functions (65) and (66) where we firstly included all coefficients
and then deleted the non-significant parameters from the model one by one until all
In order to guarantee the applicability of the significance test to the data sets we pursue
several statistical tests. The main problems of regression analyses in general are
heteroskedasticity, autocorrelation and multicollinearity. We detect heteroskedasticity by
applying the White-test at the 95% significance level and when heteroskedasticity occurs
we use the Newey-West procedure to adjust the standard error terms. The Newey-West
standard errors are robust to heteroskedasticity and autocorrelation, meaning that the
significance tests are applicable again. The identification of autocorrelation is tested by
applying the Lagrange Multiplier test (also called Breusch-Godfrey test) at the 95%
significance level, because the Durbin-Watson and Durbin-Watson-h tests are not
applicable for regressions through the origin. The reasons for autocorrelation in a
regression can be manifold (see Pindyck, Rubinfeld 1998, p. 159ff.). In this study we
expect autocorrelation as a consequence of misspecifications, meaning when we use a
linear regression functions although the “real” relation is nonlinear or when we use the
“simple” quadratic regression function although the relation between the variables is not
quadratic. If we face autocorrelation in the error terms we test the significance of the
coefficients by applying robust standard errors (Newey-West standard errors).
Additionally, all regressions with more than one independent variable are tested for
multicollinearity which might occur e.g., for WIP or the input to a work centre in
consecutive periods. We use the variance inflation factor which is measured for every
independent variable and is calculated using auxiliary regressions, meaning that each
independent variable is treated as a dependent variable and is regressed on the other
independent variables. The obtained R2 is then used for the calculation of the variance
inflation factor. The smaller the variance inflation factor, the more useful the predictor is to
the analysis; the higher the variance inflation factor, the higher the degree of
multicollinearity. There is some discussion on the critical threshold of multicollinearity
measures (see O’Brien 2007; Tabachnick, Fidell 2007), but we consider a variance
inflation factor greater than 10 to be an indicator of multicollinearity problems.
Finally, we face the issue that fitting regression functions with up to ten coefficients
(66) to data might not guarantee that this particular regression would be applicable to other
datasets, since there simply is a higher possibility that one gains better fits with more
coefficients. This problem is apparent for the “simple” functional forms and therefore we
conducted a nearest neighbor analysis for all datasets where the “simple” nonlinear threedimensional regression functions (66) were applied. This analysis is used to test the
validity of the results. This is done by splitting up the data sets into two equal parts using
the nearest neighbor analysis. Thereafter, we apply the regression functions on both parts
of the dataset in order to test whether the same independent variables lead to the highest R2
values and whether the fits are equally high in comparison to the fits to the total data set.
The nearest neighbor analysis is a method where cases are classified depending on their
similarity. This means that similar cases are near each other and dissimilar are distant from
each other, thus the distance between the cases is the measure of similarity. Before the
classification is made one has to select a dependent variable (target) and independent
variables (features) and thereafter the software selects three independent variables (using
forward selection) from which the nearest neighbor analysis is conducted. Finally, the
number of neighbors and the distance metric has to be specified. The former is calculated
by the software (SPSS 21) which chooses the “best” number of neighbors (normally
referred to as k) by calculating the lowest sum-of squared error for a certain range of
possible values for k. The distances between the data points can be calculated by a
Euclidean and a City block metric which were both applied in this thesis.
The first data set we use was collected from a customer driven optical storage media
producer which is organized as a flexible flow shop. The system consists of five sections:
manufacturing and graphics section are very flexible and do not state a planning problem
therefore these two sections are not included in the following analysis. Figure 24 depicts
Figure 24. Structure of the production system
Production is performed in a three stage process where each product moves through
these sections in different routings. The facility operates 24 hours a day, seven days a week
in four shifts whereas shifting bottlenecks occur due to the varying product mix.
The manufacturing section consists of 16 machines, ten for CD and six for DVD
production. Within these two groups the machines work parallel and are fully substitutable.
A worker in this section is normally responsible for up to three machines at the same time
and determines the sequence of orders that should be processed based on a preliminary list
provided by management. The printing section consists of six machines which can be
classified into three groups based on the printing technology, namely three serigraphy
machines (SD), two kammann offset machines (KOD) and one metronic offset (MOD)
machine. Workers are, depending on their skill and experience, assigned to one or two
machines at once. The KOD machines work parallel and are fully substitutable and the SD
machines work parallel, but are only partly substitutable. Orders can also be substituted
between the two offset printing technologies (MOD and KOD) due to high utilization or
quality requirements. The workers choose the priority of orders similar to the
manufacturing section, but their list gets updated every two hours. The packaging section
consists of seven machines, one of which is a shrinking machine (V2), two machines pack
CD and DVD into boxes (V1 and V3) and two additional machines wrap DVDs or CDs in
paper, cardboard or plastic bags (V4). Within V1, V3 and V4 departments the machines
work in parallel and are partly substitutable. The team leader assigns workers to machines
according to priorities of orders that are set by a rather mandatory sequence, whereas three
machines require one and four machines require two workers. Note that especially in the
printing and packaging section the decision of the team leaders how to allocate their
discretionary time is crucial and its impact on productivity must not be underestimated
(Krishnan, Srinivasan 2007). In these three above mentioned sections data of 29 machines
over a period of 12 months was collected (from January 16th to December 30th). The
maximum capacity, setup time and processing time per item of each machine and the days
of business were provided by the company. Information on the orders included the order
number, the routing, the arrival date at each machine, the start and end dates of processing,
the setup and processing time and the number of items of the orders.
4.4.2.1. Simulation model of the production system
Regarding research question RQ2 where we want to analyze whether multidimensional clearing functions yield higher fits to data when compared to onedimensional clearing functions we want to generate data from the simulation model that
should most likely represent the conditions under which the empirical data was collected
(for a description of the simulation model see Section 3.2 above). Therefore, we use the
scenario with the highest possible variability, namely seasonal demand and varying
product mix. The orders are released immediately when they arrive at the order pool,
because the company did not apply any reproducible order release logic. Furthermore, we
also generated data by simulating simplified queueing models which will be described in
In addition to the above described scaled down simulation model of a real production
system we also use simulations of two simplified queueing models. At first we test our
regression functions on data of a M/M/1 queue with different average utilization levels
(approx. 95% and 80%) and different period lengths (960min and 360min.).
Secondly, since in order release models the orders are released by a higher planning
level, the assumption of order arrivals according to a renewal process is problematic,
because the number of arrivals during a sufficiently long period is nearly fixed. Therefore,
we analyze a production unit with order releases controlled by the Supply Chain
Operations Planning (SCOP) function (see Jansen 2012, p. 91ff.) which we simplify to its
nucleus. We assume a single machine that produces J products. In each period one order
arrives for each product. The arrival time of a product j relative to the period boundaries
(i.e., the time from start of the period until arrival of product j) depends on the product
(uniform distribution within the period), but is the same for each period, that is, the same
arrival pattern repeats again and again. For each product the operation time, which is the
same in each period, is a realization of an exponentially distributed random variable.
FCFS dispatching is used. This pattern occurs when J products with identical data and
constant demand rates are produced to stock controlled by reorder point systems, and the
initial inventories are uniformly distributed. It can be shown that for J –> ∞, the
interarrival times are asymptotically exponentially distributed (Missbauer 1999). Note
that the dynamic behavior of the system is determined by its initial conditions. We select
initial conditions with different arrival patterns within the periods (evenly spread within
the period vs. concentrated in certain phases of the periods).
4.5. Editing of raw data, deduction of the independent variables and selection of
As described above we use two data sets in order to address research question RQ2,
whether multi-dimensional clearing functions lead to improvements of the fit when
compared to one-dimensional clearing functions. The first data set was obtained from the
above described real world manufacturer (Section 4.4.1) in the course of a project where
the machine related data was collected by an automatic production data acquisition system.
We tested the data for validity and conferred with the company in order to sort out all
inconsistencies. Minor changes in the data were made regarding false entries on holidays.
The second data set was deduced from a scaled-down simulation model of the real
manufacturing system (see Section 3.2) and from a simulation of simplified queueing
For this study the deduction of the dependent variable Xn,t (output of machine n in
period t) was made in the same manner for empirical and simulation data. Both data sets
provided information on all orders that were finished at the machines in each period
(calendar days) with the end-of-processing date, the number of items per order and the
operation time (setup + processing time) per order at each machine in minutes. All orders
with the same end-of-processing date were aggregated yielding the output, measured in
time units, for each considered calendar day for each machine.
With regard to the empirical data, periods were set to calendar days, starting from 12:00
am to 11:59 pm. This leads to following imputations regarding the assignment of input or
output to a machine. An order that arrives at the queue of a machine at 10:01 pm on
January 1st and ends its processing at 12:01 am the next day, leads to an allocation of two
hours input on January 1st and two hours output (assumed that there was no waiting time or
other delay) on January 2nd, although most of the processing took place on January 1st.
Certainly, this case is an exception and is cancelled out with the present amount of data.
Additionally, only 1 percent of the orders have an operation time longer than 4 hours,
Concerning the independent variables, we firstly deduce the input variables An,t
essentially in the same way as Xn,t. by listing all orders that arrived at the machine with
their arrival dates and corresponding operation time in minutes. Finally, orders with the
same arrival date were summed up and listed chronologically. The input to a machine was
deduced from the simulation data by listing the operation times of all orders that arrived at
Thereafter, the work-in-process variables can be calculated by
The initial WIP of the respective machine (Wn,0 where t=0 is January 16th) was
determined as follows: The variables An,t and Xn,t only encompass orders that arrived after
the first period of the empirical data set (January 1st, 2005, which is t = -15 in our
notation), the same holds for the WIP variables Wn,t. The WIP on January 1st, 2005,
resulting from this set of orders (Wn,-15) is zero by definition. This is the starting point for
For estimating the output in period t for each work centre n (Xn,t), we start with WIPn,t-1,
An,t as independent variables. Additionally, we consider another two independent variables
by splitting up WIPn,t-1 into its components, namely WIPn,t-2, and An,t-1. This is in line with
recent work of Kacar, Uzsoy (2013) who find that multi-dimensional linear clearing
functions with WIP at the start of the period and releases during the period under
consideration and in the immediately preceding period (which is equivalent with our
independent variable An,t-1) improve the performance of the order release model compared
to clearing functions that only consider WIP and releases in the period under consideration.
One can ask whether the output in the previous periods (Xτ; τ = 1,…,t-1) as one
component of the process history should be included as possible independent variable. An
M(t)/G/1 system with λ(t) < µ acts as a low-pass filter; high-frequency oscillations of the
time-dependent arrival rate λ(t) hardly influence the output process (Hazra, Park 1994).
This might indicate that the past output values should be included. However, this effect is
questionable for the period lengths in our data (5 – 15 times the mean service time). So we
expect that a possible correlation of the output in consecutive periods is a consequence of
the planning system that smoothes the output over time. As far as this is a result of the
order release decisions, it should not be considered as a property of the production unit.
However, in the empirical data this correlation can also result from informal smoothing
mechanisms at the shop floor level that should be anticipated at the order release level.
After some preliminary analyses we excluded the output values in the previous periods due
to the weak theoretical basis. Moreover, including the output variables could distort the R2
values for linear regressions since, unlike WIP and work input, the output cannot exceed
Finally, we analyze independent variables that are proxies for the variability of the WIP
and work input during the period. We use two different coefficients of variation (CV) of
the WIP with different time horizons, one with a long horizon of 40 periods
(CV[WIPn,t-41,…,WIPn,t-1] hereinafter CVL[WIPn,t-1]) and one with a short horizon of 20
periods (CV[WIPn,t-21,…,WIPn,t-1] hereinafter CVS[WIPn,t-1]).
This yields six independent variables (An,t; WIPn,t-1; WIPn,t-2; An,t-1; CVL[WIPn,t-1] and
CVS[WIPn,t-1]) which will be tested in linear and nonlinear two- and three-dimensional
regression functions following (60) and (61).
In order to answer our hypotheses (H5-H9), we select two machines in each section from
the empirical as well as from simulation data. One represents a non-bottleneck and the
second a bottleneck machine. We use the long term production definition of bottlenecks by
Lawrence, Buss (1995) where the average utilization of the respective machine is
where ρj denotes the average utilization of machine n, X n the average output of machine
n and C n the average capacity of machine n over the considered periods.
The average capacity was either provided by the company or is the period length in the
simulation model. Machines having an average utilization above 75% will be denoted as
bottleneck and machines below 60% will be denoted as non-bottlenecks (see Asmundsson
et al. 2006; Selçuk et al. 2008 for similar classifications). If no machine qualifies for one of
these classes the machine with the lowest and/or highest average utilization of the section
will be chosen and will be considered in the interpretation. The reason for selecting two
machines from each section which differ with respect to their utilization is twofold. Firstly,
we test hypotheses that presumably hold for low- or highly utilized machines and secondly,
we want to analyze at which average utilization congestion phenomena and therefore
nonlinear clearing functions become relevant. For planning purposes this means that work
centres that face congestion effects must be treated as bottlenecks. We analyze the value of
this threshold and test whether it differs depending on the source of data (simulation or
In each section, namely manufacturing (Man), printing (Pri) and packaging (Pack) two
machines, a bottleneck and a non-bottleneck machine, were selected based on their average
utilization (71) yielding twelve machines (six machines of each data set) which will be
used in the analysis. Accordingly, this chapter is structured into two parts, the first
presenting the analysis for non-bottleneck and the second the results on bottleneck
machines. In the latter section we also analyze data obtained from two single-stage
queueing systems in order to explore specified structural properties.
4.6.1. Non-bottleneck machines - Simulation data.
Table 22 depicts the results of the applied regressions to data of non-bottleneck (NB)
machines of simulation data. The rows depict the R2 values for the non-bottleneck machine
of the manufacturing section “ManNB”, the printing section “PriNB” and the results for
the packaging section which is abbreviated as “PackNB”. The second column shows the
utilization of the machines (Util.). The remaining columns show the R2 values of the
different applied functional forms. At first, the linear one-dimensional clearing function
(Lin.1D) following equation (54). Secondly, the two different nonlinear one-dimensional
clearing functions (Nonlin.1D): Missbauer’s clearing function following (56) abbreviated
with “Missb.” and our introduced “simple” regression functions following equation (64).
Furthermore, we depict the values of the estimated coefficient (b, k and C respectively)
Finally, the last two columns show the linear two-dimensional clearing functions
“Lin.2D” following (63) and the R2 values of the linear three-dimensional clearing
functions “Lin.3D” being an extension of equation (63). The depicted values represent the
highest R2 of all respective combinations, a detailed list of combinations (and estimated
coefficients) that yielded an increase in the fit will be presented subsequently. To the best
of our knowledge no significance test is applicable to improvements in the R2 values in
The R2 values marked with an asterisk in the column of the linear two-dimensional
clearing functions (Lin.2D) are regression functions that do not incorporate the
independent variables suggested by Andersson
the horizontal bars in the cells indicate that the R2 values of a regression with a smaller
number of independent variables could not be increased and therefore these values were
According to hypothesis H5, we expect a good fit of the linear one-dimensional
function (54)) to the data. As one can see in Table 22, H5 can only be confirmed for the
bottleneck machine PackNB. At the two other non-bottleneck machines from
simulation data (ManNB and PriNB) the fit of the one-dimensional
comparatively low with an R2 value of 0.54
540 and 0.746.. This is probably due to the fact
that the data points of these machiness with an average utilization of 54.4%
already show a beginning saturating shape as depicted in Figure 25.
Figure 25.. Scatter plot of ManNB machine ρ=54.4%
This means that for planning purposes these two machines should be treated as
bottlenecks despite our subjectively set categories of denoting a machine as a bottleneck or
non-bottleneck. One can see in Table 22 that a linear clearing function which from a
planning perspective should suffice for non-bottlenecks yields relative low fits and
therefore even at these low utilization levels a nonlinear clearing function becomes
According to hypothesis H6, we neither expect nonlinear one-dimensional clearing
functions nor multi-dimensional clearing functions to improve the R2 values of the linear
one-dimensional clearing functions. Hypothesis H6 is only confirmed for the PackNB
machine. Therefore, we conclude that our hypotheses regarding non-bottleneck machines
only seem to hold for machines where the throughput does not approach the maximum
capacity and therefore the data points do not exhibit a saturating shape as depicted above
for the ManNB and PriNB machine (Figure 25).
Additionally, we confirm hypothesis H9a that “simple” nonlinear regression functions
are well suited as representations of saturating clearing functions for all non-bottleneck
machines from simulation data. Since the “simple” one-dimensional nonlinear regressions
lead to comparatively high R2 values as the nonlinear clearing functions by Missbauer (see
As already mentioned above the two non-bottleneck machines ManNB and PriNB
should from a planning perspective be treated as bottlenecks and therefore nonlinear
clearing functions should be applied which yield very high fits of 0.986 and 0.977 (see
Table 22). However, applying linear two- and three-dimensional clearing functions can be
reasonable as earlier studies show (Andersson et al. 1981; Kacar, Uzsoy 2010).
Adding one independent variable to the linear one-dimensional clearing functions
increases the fit to a R2 value of 0.891 at the ManNB and to 0.909 at the PriNB machine. If
another independent variable is added to the linear two-dimensional clearing function the fit
can be increased to a value of 0.900 at ManNB and to 0.917 at PriNB respectively (see
For the sake of brevity only the combinations for PriNB are depicted in Table 23 that
increase the R2 values of the linear one- and two-dimensional clearing functions. Since we
apply a linear regression function to a possibly nonlinear relation we expect problems
regarding autocorrelation and therefore put an asterisk on all combinations where
autocorrelation was detected and the robust standard errors (Newey-West procedure) were
Table 23. R2 of linear two- and three-dimensional clearing functions of PriNB, simulation
Note that the same combinations also yielded an increase of the fit for the ManNB
machine and furthermore that in neither case we measured multicollinearity which might
be expected when including An,t and An,t-1 in one regression function. The relative increase
from combining An,t and An,t-1 compared to combining An,t-1 with WIPt-1 seems surprising,
and further experiments are necessary to explain this.
From these results we draw two conclusions. Firstly, the proposed independent
variables that take the history of the process into account (An,t-1, WIPn,t-2) and also to some
extent the proxy variables for the variability of the WIP (CVL[WIPn,t-1], CVS[WIPn,t-1])
lead to an improvement of the fit to the data with a linear two- and three-dimensional
clearing function. And secondly, from a production planning perspective the analysis of
simulation data shows that linear two- and three-dimensional clearing functions
incorporating the suggested variables seem promising and should be tested in order release
4.6.2. Non-bottleneck machines - Empirical data.
Table 24 follows the same design as the above described Table 22for simulation data and
depicts the R2 values of the applied regression functions on non-bottleneck machines of
empirical data. Additionally, we show the resulting R2 values for two nonlinear twodimensional clearing functions “Nonl.2D”. At first, the new preliminary functional form
denoted as “2Dcf” following (59) and secondly, the simple two-dimensional regression
function following (65). All values marked with two asterisks were regression functions
Table 24. R of non-bottleneck machines from empirical data
Note that all of the highest fits of linear and “simple” two-dimensional clearing
functions on empirical data were obtained by regression functions with the independent
variables (An,t, WIPn,t-1) suggested by Andersson et al. (1981).
According to hypothesis H5, we expect a good fit of the linear one-dimensional clearing
function (54) to the data. As one can see in Table 24, H5 can only be confirmed for the
non-bottleneck machine PriNB. At the non-bottleneck machine ManNB the fit of the onedimensional clearing function is comparatively low with an R2 value of 0.664 and the fit to
the data of the PackNB machine is even negative.
Regarding the ManNB machine, the linear one-dimensional clearing function yields a
low fit which might be due to the fact that the data exhibits a weak saturating shape of the
data points as depicted in Figure 26. This means similar to the above described cases with
simulation data that for planning purposes this machine should be treated as a bottleneck
and therefore even at this relatively low average utilization levels a nonlinear clearing
Figure 26. Scatter plot of ManNB machine ρ=57.5%, empirical data
With regard to the non-bottleneck machine in the packaging section (PackNB) where
the linear one-dimensional clearing function yields a negative R2 value one can see in
Figure 27 that there are five peaks of output at different load situations at the machine.
Figure 27. Non-bottleneck packaging machine ρ=19.2%, empirical
Since the team leader of the packaging section is the only one who operates this
shrinking machine it is not surprising that the available work in front of the machine is not
automatically processed by arrival, but is worked off when the queue in front of the
machine is too long or the team leader has some free discretionary time. One can conclude
that the supervisory time allocation has a significant impact on productivity (see Krishnan,
Srinivasan 2007; Berglund et al. 2010). In this case, the effect of allocating discretionary
time of the team leader leads to the dissolution of the (in general) existing correlation
between output and load of a machine. This highlights the difference between the
simulation and empirical data set. The former can be described as mainly equipment
centered (Kempf 1996), the queues in front of machines are automatically cleared and the
latter contains human related factors (e.g., allocation of workers, motivation,
According to hypothesis H6, we expect neither nonlinear one-dimensional clearing
functions nor multi-dimensional clearing functions to improve the R2 values of the linear
one-dimensional clearing functions. Hypothesis H6 can be confirmed for the nonbottleneck printing machine (PriNB). Additionally, we confirm hypothesis H9a that
“simple” nonlinear regression functions are well suited as representations of saturating
clearing functions especially for empirical data, since the “simple” one-dimensional
nonlinear regressions leads to comparatively high R2 values as the nonlinear clearing
As already mentioned above the non-bottleneck machine ManNB should from a
planning perspective be treated as a bottleneck and therefore the nonlinear clearing
function should be applied which yields a high fit of 0.738 (see Table 24). However, the
aim of this paper is to analyze which additional independent variables increase the fit and
therefore we also apply linear two- and three-dimensional regressions (see Table 25).
Table 25. R of linear two- and three-dimensional clearing functions of ManNB, empirical
As already shown for the non-bottleneck machines from simulation data we also
conclude for empirical data that the proposed independent variables that take the history of
the process into account (An,t-1, WIPn,t-2) lead to an improvement of the fit to the data with
linear three-dimensional clearing functions.
Two insights can be provided when comparing the analysis of non-bottleneck machines
with simulation and empirical data. At first, simulation data exhibit significantly less
spread which results in very high R2 values (>0.95) in comparison to the fits to the
empirical data (<0.85). Secondly, different to the analysis of simulation data only the linear
two-dimensional clearing function proposed by Andersson et al. (1981) leads to an
increase in the fit for empirical data. We conclude that from a production planning
perspective incorporating the suggested variables in a linear multi-dimensional clearing
function seems promising even for machines with a moderate utilization (ρ > 50%).
4.6.3. Bottleneck machines - Simulation data.
Table 26 depicts the R2 values of the applied regressions on bottleneck machines (BN)
Table 26. R2 of bottleneck machines from simulation data
With regard to hypothesis H7 we expect that one-dimensional clearing functions do not
yield a high R2 at bottleneck machines in comparison to multi-dimensional clearing
functions. We reject hypothesis H7 for all bottleneck machines from simulation data which
is unexpected and will be discussed in more detail below.
Concerning hypothesis H9a, we test whether “simple” nonlinear regression functions
are well suited for representations of saturating clearing functions. As one can see in Table
26, H9a is rejected for the PriBN and the PackBN machine and can only be partly
confirmed for the manufacturing bottleneck machine (ManBN) which is not very highly
utilized with an average utilization of 62.81%.
Of course the linear one-dimensional clearing functions yield very low fits in all cases,
but the nonlinear one-dimensional clearing functions reach very high R2 values reaching
from 0.979 to 0.996 (Missb.). The function is fairly close to the “ideal” shape
Xn,t = Min(Λn,t ;C), and many data points are at this upper bound. We assume that this is
due to the relatively long periods (960 minutes in relation to the operation times which are
at most 66 minutes). As the period length increases the impact of the stochasticity of the
process on the output per period becomes lower. It can be shown that for the M/M/1 model
clearing function (56) approaches the “ideal” shape as the period length approaches infinity
(see Missbauer 1998, p. 250ff.). Therefore, we pursue an additional scenario with our
simulation model and several tests with simplified queueing models in order to get more
insights into the behavior of the system.
Table 27 depicts the R2 values of the applied regressions on bottleneck machines (BN)
of simulation data with a shortened period length of 360 minutes. This is about five times
the average operation time which was also assumed in Missbauer (2011). For the sake of
brevity, the analysis only includes the highly utilized bottleneck machines from the
printing- (PriBNS) and packaging section (PackBNS).
Table 27. R2 of bottleneck machines from simulation data with shortened period length
The results show that the period length has an influence on the fits of the regression
functions. Hypothesis H7 is confirmed for the PriBNS machine since the fit of the
nonlinear one-dimensional clearing function of 0.743 can be increased by the nonlinear
two-dimensional clearing function by 0.196 to a R2 value of 0.939. For the PackBNS
machine we only partly confirm hypothesis H7 since on the one hand the nonlinear onedimensional clearing function yields a high fit of 0.937, but on the other hand can be
slightly increased by a two-dimensional clearing function to a value of 0.977 (see
Hypothesis H9a is rejected for all tested bottleneck machines from simulation data with
a shorter period length, since “simple” regression functions are not well suited for
representations of saturating clearing functions. And we confirm hypothesis H9b that the
saturating two-dimensional functions (2Dcf in Table 27) yield higher fits than the “simple”
In order to analyze whether these results are a consequence of the shop configuration of
the used simulation model we perform our regressions on data of two simplified queueing
models with different utilization levels and different period lengths. At first, we analyze a
M/M/1 queue and secondly, we test a SCOP controlled production unit.
Table 28 depicts the results of the applied regressions to data of the M/M/1 queue. At
first we test a scenario where the ratio between the period length and the mean service time
is large (about 15 to 1) which is denoted as “MM1L”. This scenario represents the initial
tests with the simulation model above. And secondly, we test a scenario where we
shortened the period length (ratio of about 5 to 1) abbreviated as “MM1S”.
Table 28. R2 of regression functions fitted to data of M/M/1 queues
The results for the scenarios with long period length (MM1L) are similar to the initially
described results from bottleneck machines of our simulation model. The linear onedimensional clearing functions yield very low fits and again this fit is increased to rather
high R2 values by the nonlinear one-dimensional clearing functions (0.81 to 0.837).
Reducing the period length does not have the same influence on the fits as it was the case
with the bottleneck machines of the simulation model. It seems that in the case of the
M/M/1 queue the spread of the data does not substantially increase by decreasing the
period length and therefore the fits of the nonlinear one-dimensional clearing function
The pursued tests with the two-dimensional saturating
clearing function (2Dcf) show firstly, that the high fits of the nonlinear one-dimensional
clearing function (Missb.) can be increased further. And secondly, that hypothesis H9b is
once more confirmed for simulation data, since the saturating two-dimensional clearing
functions can increase the fits of the one-dimensional regressions.
Turning to the analysis of the SCOP controlled production unit, we simulate two
scenarios similar to the above pursued tests. Firstly, “SCOPL” denotes the scenario where
the simulated machine produces 24 products and secondly, in order to reduce the ratio
between mean service time and period length a scenario with 9 products abbreviated as
“SCOPS” is tested. Table 29 depicts the performed regressions on the SCOP controlled
Table 29. R of regression functions fitted to data of a SCOP controlled production unit
The results for the scenarios with long period length (SCOPL) are similar to the results
for bottleneck machines of our simulation model. The linear one-dimensional clearing
functions yield very low fits which are increased to high R2 values by the nonlinear onedimensional clearing functions (see Table 29). In this case of the SCOP controlled queue
reducing the period length has a substantial influence on the fits of the regression
functions: R2 decreases substantially for Nonl.1D, but in one case (utilization 72.98%) it
can be increased from 0.614 to 0.880 by adding a second independent variable (Nonl.2D).
This was not the case for an utilization of 93.8% where almost no optimization potential
from using a two-dimensional clearing function can be observed. This important insight is
in line with what we would expect from theory.
Additionally, in the SCOPS case the order arrivals were very uneven over the periods
Figure 28.. Order arrivals over the periods for SCOPL and SCOPS
shows the arrival pattern for SCOPL on the left (24 products) and for SCOPS
on the right side (9 products) over the period length of 960 minutes. The arrival pattern is
the same for each period leading to strongly non-stationary
COPS case which might support the explanation for the results discussed above.
4.6.4. Bottleneck machines - Empirical data.
Table 30 depicts the R2 values of the applied regression functionss on bottleneck
Table 30. R2 of bottleneck machines from empirical data
Note that all nonlinear three-dimensional
three dimensional clearing functions (following (14)) were
regression functions with less than ten coefficients due to non
Concerning hypothesis H7 we expect that one-dimensional clearing functions do not
yield a high fit at bottleneck machines in comparison to multi-dimensional clearing
functions. We have to reject this hypothesis for the ManBN and PriBN machine, since the
fit of the nonlinear one-dimensional clearing function cannot be substantially increased by
adding independent variables (see Table 30). The reason for low fits of the regression
functions is possibly due to the broad spread of the empirical data. For the PackBN
machine we confirm this hypothesis, because the saturating two-dimensional clearing
function yields an increase in the fit and in this case the “simple” two- and threedimensional functions improve this fit further to 0.721 and 0.750 respectively.
With regard to hypothesis H9a we stated that the “simple” nonlinear regression
functions are well suited for representations of saturating clearing functions especially for
empirical data. We can confirm this hypothesis for all bottleneck machines from empirical
data, since the “simple” regression functions yield comparatively high or even higher fits
to the data. Additionally, we apply a nearest neighbor analysis as described in Section 4.3.3
for the nonlinear three-dimensional clearing functions (last column in Table 30).
The nearest neighbor analysis should gain insights into whether the fit of certain
independent variables is independent of the data. Therefore, the data sets are split up into
two equal parts and thereafter we apply the regression functions on both parts of the
dataset in order to test whether the same independent variables lead to the highest R2
values and whether the fits are equally high in comparison to the fits to total data set. The
split is made by choosing cases from the dataset depending on their similarity. This means
that similar cases are near each other and dissimilar are distant from each other, thus the
distance between the cases is the measure of similarity. The distances between the data
points can be calculated by an Euclidean and a “City block” metric. We tested both
distance metrics which are denoted as “E” for and “C” respectively in Table 31 below.
In the following we show the results exemplarily for one machine from simulation and
Table 31. R2 of “simple” nonlinear three-dimensional regression functions of different datasets of the
Table 31 shows the combinations that yielded the highest R2 values where the first row
denoted as “Total” shows the results when applying the regression function on the whole
data set (as in Table 31above). As one can see the analyses show that the three independent
variables that yield the highest fit are always the same and the R2 values do not differ too
much. However, as stated above the “simple” regressions cannot be seen as suitable
clearing functions for order release planning in practice, but they serve two purposes. At
first the idea of the paper was to test a hypothesis raised in a paper by Missbauer (2011)
which stated that a clearing function should incorporate three independent variables.
Secondly, we are not able to provide a three-dimensional saturating function and therefore
we use the “simple” functional forms in order to see whether there is potential to increase
Finally, Hypothesis H8 stated that independent variables that take the history of the
process into account lead to improvements of the fit to data of bottleneck machines. This
hypothesis has to be partly rejected for ManBN and PriBN machine, but can be confirmed
for the PackBN machine of empirical data (see Table 30).
Table 32 shows the combinations yielding the improvements in the R2 values at the
PackBN machine in a nonlinear two- and three-dimensional clearing functions.
Table 32. R2 of nonlinear two- and three-dimensional clearing functions of PackBN, empirical
The results show that the “simple” nonlinear two-dimensional regressions with the
highest resulting fits to the data was the two-dimensional clearing function incorporating
the independent variables proposed by Andersson et al. (1981). Furthermore, we confirm
hypothesis H8 that the proposed independent variables that take the history of the process
into account (An,t-1, WIPn,t-2) and also to some extent the proxy variables for the variability
of the WIP (CVL[WIPn,t-1] and CVS[WIPn,t-1]) lead to an improvement of the fit when
applying nonlinear two- and three-dimensional clearing functions (see Table 32).
Two insights can be provided when comparing the analysis of bottleneck machines of
simulation and empirical data. At first, we conclude that in general analyses of bottleneck
machines with simulation data exhibits significantly less spread in the data. As a
consequence the fit of the different regression function when applied to empirical data is
substantially lower. Secondly, the analysis of bottleneck machines from simulation and
empirical data has shown that our preliminary saturating two-dimensional clearing function
yields promising fits to the data and therefore we are confident that the performance of an
order release model would increase by incorporating this type of clearing function.
In this thesis we addressed two research questions with regard to optimization based order
release models. In the first part of the thesis we continued a very recent stream of research by
comparing two models that fall into this category. We tested the performance of two models
that have their source in the workload control (WLC) theory, one with fixed lead times and
the other incorporating variable lead times. The former is represented by the input output
control (IOC) model of Puergstaller, Missbauer (2012) (see Section 3.1.1) and the latter
model is represented by the allocated clearing function (ACF) model which was introduced
by Asmundsson et al. (2006; 2009). The comparison of these two models is firstly interesting
since they only differ from each other with respect to the treatment of lead times and
secondly, we want to know whether the increased complexity of the ACF model yields
justifiable improvements or whether the limitations of this model leads to a decrease in the
performance of the model. The performance of these two models is tested with a simulation
study (described in Section 3.2). The problems of earlier studies (Puergstaller, Missbauer
2012) that find inconclusive results was solved by applying the safety stock adjustment
procedure which was described in Section 3.3.
The results showed that the ACF model outperforms the IOC model in cases of high
demand- and high total variability (process and demand variability). The weakness of the IOC
model is that the fix lead time norms must allow high utilization at the bottleneck work
centres which cannot be reduced in periods of low capacity utilization. The IOC model
performed better in the case of low total variability and in the constant demand and variable
product mix scenario. Reasons for the worse performance of the ACF model in the case of
variable product mix are twofold. Firstly, we found that the assumption of the ACF model
that the product mix of the output is approximately the same as the product mix in the WIP
before the work centre is violated, especially at bottleneck work centres. The problem is that
the shape of the clearing function is determined for a certain average product mix which is
assumed to be stable over time since the clearing function does not change over time.
This issue could be overcome by changing the shape of the clearing function over time
(e.g. with simulation optimization). The thesis by Kacar (2012) represents the first step in this
direction. Furthermore, one could use another estimation procedure for the clearing function,
although no alternative to an ordinary least squares regression which is based on a sound
theoretical basis seems to be at hand and therefore this remains a topic for future research.
Secondly, the main limitation of one-dimensional clearing functions as used in the ACF
model is their derivation form steady-state models. However, in the actual operation of a work
centre steady-state situations and various transient states can occur in any sequence. In order
to analyze the influence of these transient effects on the ACF model we also conducted
experiments with a shortened period length and tested scenarios with different bottleneck
utilization levels. We found that the performance of the ACF model in comparison to the IOC
model got worse in every scenario except in the case of constant product mix and varying
demand where the difference between these two models was equally high. One notable insight
from the analysis with a reduced period length was that although the performance of the ACF
model decreased it still held fewer inventories in scenarios where it was superior in the case
of the long period length (with smaller margins). This indicates the relevance of research
concerning clearing functions that take transient effects into account and secondly from a
planning perspective shows the crucial influence of the choice of the period length.
Experiments with a lower average bottleneck utilization (85%) showed that in the case of high
total variability, a shortening of the period length decreased the performance of the ACF
model more than in the scenario with a higher average bottleneck utilization (95%). An
explanation for this might be that at this utilization level the resources more often face critical
load levels and are only temporarily overloaded which would increase the transient effects.
To sum up, the increased complexity of the ACF model led to improvements in the
performance measures in the most variable cases which are those closest to reality. This
superiority in comparison to the IOC model did even prevail under challenging experimental
settings (increased transient effects). Although research on clearing functions is still
fundamental research and some limitations remain, this comparison showed the potential of
this approach. Naturally, the validity of the results for other types of production systems must
be assessed in future studies. Further comparison of the ACF model with fixed lead time
models using fractional lead times would be a logical extension of this research (see Kacar et
The above mentioned issue with regard to transient effects is also addressed in Missbauer
(2011) who shows that an extension of the one-dimensional clearing function to models
incorporating two and three independent variables could remedy this effect. Therefore, the
aim of the study in the second part of this thesis was to continue this work by exploring the fit
of various clearing functions (linear and nonlinear; regressions with one, two and three
independent variables). In order to analyze clearing functions with two and three independent
variables we had to introduce a preliminary functional form of two-dimensional nonlinear
clearing functions and tested “simple” quadratic regression functions representing threedimensional clearing functions as described in Section 4.2. The fit was tested on simulation
and empirical data obtained from a make-to-order production system described in Section 4.4.
The fit of the clearing functions was made by a regression through the origin and measured by
The findings of the second part led to suggestions which combinations of independent
variables should be used in a clearing function in order to improve the estimation of a work
centre’s output in future periods and hence improve order release planning models. The
implications of the study for design and application of clearing function models can be
summarized as follows. The comparison of empirical and simulation data showed that
empirical data exhibit substantially more spread of the output compared to simulation results.
This leads to less accurate output predictions and makes it difficult to select the right
functional form for clearing functions. In particular, it can be difficult to decide whether the
maximum capacity is load-independent (saturating clearing function) or can be increased by
higher shop loading or even decreases at high WIP levels. If, e.g., sales and production
department disagree on this question, it can be difficult to provide a clear answer based on
hard data. This also shows the limitations of simulation-based research on order release
models and indicates the limited practical usability of clearing functions in general and the
For non-bottleneck work centres linear clearing functions provide a good fit which means
that load-independent lead times or lead time distributions are a good approximation. This
supports the idea to simplify the order release model by representing non-bottlenecks as loadindependent delays (Missbauer 1998). However, work centres behave as non-bottlenecks only
if the average utilization is substantially below 100 percent (in our study below about 50
percent). This threshold value might depend on the individual case, but the essential insight
seems to be stable. With regard to order release models this paper confirmed earlier studies
(Andersson et al. 1981; Kacar, Uzsoy 2010) that linear multi-dimensional clearing function
can be useful for work centres up to a certain utilization level.
For bottleneck work centres the clearing function must model the effects of congestion at
higher utilization levels. Saturating clearing functions where the estimated output approaches
the capacity as the capacity load increases clearly outperform the “simple” quadratic
regression function for simulation data (where the saturating shape is implied by the
assumptions of the simulation model), for empirical data this effect is much less pronounced.
The fit of a one-dimensional saturating clearing function and the possibilities for
improvements by adding independent variables that represent the history of the process
(roughly speaking: the time-dependent capacity loading before the period under
consideration) depend both on the period length (with the mean operation time as time unit)
and on the stationarity of the process. For a period length of about 15 the fit of the onedimensional clearing function was extremely high and thus the output prediction was very
accurate for simulation data, which was somewhat surprising. Reducing the period length to
about five reduced the fit, and extending the clearing function to two independent variables
led to substantial improvements especially for high utilization (>90%). The analysis of the
single-stage systems (Poisson and SCOP- controlled input) indicates that the improvements of
the fit by adding independent variables are limited in steady-state situations, but can be
substantial if the system faces frequent transient states.
This raises the question to what extent the differences in the fit (R2 values) of the clearing
functions predict the differences in the performance of order release models that use these
clearing functions. Exploring this would be a logical continuation of our research. The order
release models decide on the stationarity/non-stationarity of the system by determining timevarying order releases, and this decision can be flawed if the model underestimates transient
effects. It might well be possible that the substantial improvements that can be obtained from
two-dimensional clearing functions in one strongly non-stationary scenario points to a
relevant direction and should encourage future research on this topic (Haeussler, Missbauer
Published in International Journal of Production Economics17, 149, 102-116, as:
Empirical validation of meta-models of work centres in order release
University of Innsbruck, Department of Information Systems, Production and Logistics Management
We consider the problem of planning future order releases in hierarchical production planning and control
systems. An established research direction is the clearing function concept: The planned material flow through a
production unit is modelled by inventory balance equations for WIP and final products, and the consequences of
the stochastic properties of the material flow are modelled by clearing functions, which represent the functional
relationship between the level of WIP and the maximum output of a work centre in a period.
Theoretical insights suggest that modelling the output of a work centre in a period as a function of one
independent variable is not sufficient for this type of models because of the time-varying transient states. This
paper tests one- and two dimensional clearing functions on simulation and empirical data obtained from a maketo-order production system. The fit of the clearing functions will be made by a regression through the origin and
evaluated by the adjusted R2. The fits of the different clearing functions differ depending on the source of data.
The possibilities for improvements by adding independent variables depend both on the period length and on the
stationarity of the process. The findings lead to suggestions which additional independent variables should be
added to a clearing function in order to improve the estimation of a work centre’s future output and hence
Keywords: Production planning, Order release, Workload control, Regression analysis
Manufacturing planning and control (MPC) systems play an important role in managing
the flow of material through manufacturing organizations. Over the last 50 years many
production planning systems were designed. It started with the Bill of Material (BOM)
explosion in the 1960s which evolved into hierarchically organized systems like Material
Requirement Planning MRP (Orlicky 1975) and MRPII (Wight 1983) twenty years later.
These in turn led to today's modern structures like Enterprise Resource Planning Systems
(ERP) and Advanced Planning Systems (APS) (Bertrand et al. 1990; de Kok & Fransoo 2003;
Stadtler & Kilger 2005). All of these approaches try to optimize the material flow through the
company, between manufacturing plants, vendors and other stakeholders as well.
MPC systems, especially for discrete manufacturing, are often structured hierarchically and
consist of two levels. The top level coordinates the production units that constitute the logistic
chain by coordinated releases of production orders and thus sets the targets for the production
units. The base level performs detailed scheduling within the production units. The interface
between the top level (Supply Chain Operations Planning) and the base level (production unit
control; for these terms, see Bertrand et al. 1990; De Kok & Fransoo 2003) is order release
which is defined as the transfer of the control over the respective work orders from the top to
the base level, that is, to the decision making units within the production units. Releasing
orders at the right time in order to maintain short, predictable flow times and high due date
performance requires an anticipation function (Schneeweiss 2003) that predicts the flow times
Impact Factor 2012: 2.08. 5-Year Impact Factor: 2.594. ©Thomson Reuters Journal Citation Reports 2013.
of the work orders as a function of the order release decisions. The paper deals with this
anticipation or modeling task. More specifically, we concentrate on multi-period models for
order release planning that optimize order releases based on an anticipation of the material
flow that results from specified release quantities over time.
These models represent the production unit as a network of work centres j=1,..., J. The
planning horizon is divided into planning periods t=1,..., T. The material flow is represented
by inventory balance equations for WIP at each work centre and for final products, usually
distinguishing different products or groups of products with similar routing. Since the
material flow is modelled as continuous, the resulting network flow model is a fluid model in
A crucial topic for this type of models is the highly nonlinear relationship between workin-process (WIP), average flow time and output which is well-known from simulation (e.g.,
Wiendahl 1995) and queueing models (e.g., Hopp & Spearman 2008).
There are essentially two ways to consider this relationship in order release models.
Models with fixed lead times that are based on the workload control concept are extensions of
Input/Output Control introduced in the 1970s (see Wight 1970; Plossl & Wight 1973; Belt
1976). These models aim at keeping the level of WIP, measured in hours of work, at the work
centres at a level that is consistent with the flow time norm (see, e.g., Kingsman 2000; de Kok
& Fransoo 2003). The models are relatively straightforward and seem to perform well
compared to traditional order release mechanisms that are based on the workload control
concept (Puergstaller & Missbauer 2012). Performance is measured by indicators like stock
keeping unit (SKU) inventory, WIP level and due-date performance that result from the actual
or simulated material flow that is controlled by the order releases determined by the model.
However, a fixed lead time constraint in order release models imposes essential limitations
especially in the case of time-varying demand. Using fixed lead times requires a norm-setting
decision level that determines the target lead times (see de Kok & Fransoo 2003, p. 617ff.).
The impact of time-varying demand on the performance of fixed lead time models must be
seen in this context. Therefore, the topic of this paper are models that allow time-varying and
hence load-dependent lead times. In this case the nonlinear relationship between WIP, flow
time and output must be represented in the model.
Models of this type determine order releases, output and time-varying lead times
simultaneously over time. There are several ways to design models that perform this task (for
overviews, see Missbauer & Uzsoy 2011; Puergstaller & Missbauer 2012). We limit our
attention to clearing function models. A clearing function is defined as the functional
relationship between an appropriate measure of WIP at a work centre j in period t and the
expected or maximum output of this work centre j in period t. Clearing functions model the
effects of the discontinuity and stochasticity of the material flow at the work centres that limit
the possible output. They can be interpreted as meta-models and avoid analytical descriptions
of the queueing processes in the manufacturing system. In line with queueing-theoretical
results, usually a concave, saturating shape of the clearing function is assumed as suggested
by Karmarkar (1989). The clearing functions of the work centres are nonlinear constraints to
the output and are usually approximated by a set of linear functions (tangents). The resulting
linear program assigns capacity to products in a manner that satisfies a set of constraints that
represent system capacity and dynamics at an aggregate level and eventually yields the
optimal release quantity per product and period.
Clearing function models have been described and tested extensively by simulation (see
Missbauer 2002; Asmundsson et al. 2006, 2009). Asmundsson et al. (2006), (2009) show that
clearing functions, when estimated correctly, produce production plans that are much more
aligned with the ability of the production system to execute them compared to fixed lead time
approaches. They compare the performance of clearing function formulations to that of a
conventional fixed lead time model in a semiconductor wafer fabrication facility and find that
the clearing function models yield significantly better on time delivery than the fixed lead
time model. However, clearing function models tend to exhibit problematic behavior, namely
short-term oscillations of the planned release quantities, as a response to sudden changes of
the demand. Moreover, it is difficult to model the product mix of the output in a certain period
that results from the product mix of the work input or of the WIP, respectively. This indicates
that modeling the material flow by clearing functions imposes certain limitations.
We limit our attention to one aspect of this modeling task, namely the dependence of the
total output (aggregated over the products) in a certain period t on the history of the process
(work input and output over time) that leads to a certain WIP level in period t.
Conventional clearing functions assume that the output in period t can be modelled as a
function of one independent variable (WIP level or available work, termed load, in the period
under consideration) to a sufficient degree of accuracy. This holds for steady-state situations,
and likewise a clearing function can be formulated for specified transient states like, for
instance, the first period in the ramp-up phase of a queueing model (Missbauer 1998, p.
250ff.). However, in the actual operation of a production unit steady-state situations and
various transient states can occur in any sequence, and this trajectory of the system is
controlled by the order release decisions that are made by the model. Hence “the clearing
functions employed by most researchers to date represent an average relation over a wide
range of operating states, but may be quite inaccurate for a given sample path of system
evolution.” (Kacar & Uzsoy 2010). Therefore, we must ask whether a one-dimensional
The numerical analysis of one transient period of an M/M/1 model in Missbauer (2011)
indicates that this is not the case. The expected output in the period given a certain expected
load (available work) in the period can strongly depend on the composition of the load and on
the uncertainty of the initial WIP. Meaning that on the one hand it depends on the proportion
of initial WIP and work input (that together constitute the load) and on the other hand on the
probability distribution of the initial WIP. These insights suggest that the history of the
process and the uncertainty of the load estimation influence the output in a period t that can be
expected given a certain estimated load. This leads to the hypothesis that a multi-dimensional
clearing function where the independent variables reflect the process history and the
uncertainty of the load estimation lead to improvements of the fit of these functions to
different data sets compared to the usual one-dimensional clearing function.
The contribution of this paper is twofold: Firstly, we test whether an extension of the stateof-the-art clearing functions by adding independent variables leads to improvements of the fit
of these functions to different data sets. We use empirical data obtained from a make-to-order
production system and simulation data obtained from a scaled-down model of the same
production system. In order to explore specified structural properties we also analyze data
obtained from two single-stage queueing systems. We fit existing and extended clearing
functions to these real industry data as well as to the simulation data. This will be tested by
running regressions through the origin with up to three independent variables. All regressions
will be performed with linear and nonlinear functions. The improvement of the fit is measured
by comparing the adjusted coefficient of determination of the various models.
Secondly, we expand this discussion by analyzing the fit of the clearing functions for
simulation and empirical data; the latter, to our knowledge, has only been published once in
this research area by Fine & Graves (1989). This paper tries to fill this gap and aims at
stimulating the discussion of the applicability of clearing function models in practical settings.
We hope to get insights from empirical data that are either not apparent from simulations, like
the influence of human related factors, or are different to simulation data like the amount of
spread in the data. Hence, we expect different findings concerning our hypotheses depending
The remainder of this paper is structured as follows: Section 2 describes the relevant
literature regarding clearing functions and derives the hypotheses that are tested. Section 3
outlines the used method to estimate the clearing functions from the obtained empirical and
simulation data. In section 4 we describe the real industry production system and the used
simulation studies, the editing of the crude data and the deduction of the variables under
study. After presenting our results in section 5 we conclude, point out the implications
study and give insights for future research in section 6.
This review basically encompasses three related fields of research which are the basis for
our five hypotheses. Firstly, there exists a large body of literature on one-dimensional
functions which constitutes the foundation of this paper. Secondly, some works on multimulti
dimensional clearing functions (clearing functions with more than one independent variable)
will review the work on fitting clearing functions to data. For
a comprehensive overview on clearing functions and related topics, see Missbauer & Uzsoy
As discussed earlier, a clearing function describes the amount of output “cleared” from a
cturing facility in a certain period as a function of some measure of WIP (e.g., average
WIP, load). We define the load (Λj,t) of a work centre j in period t as the initial WIPj,t-1 plus
the input Aj,t of work centre j in period t:
Using the load as the WIP measure, the one-dimensional
one dimensional clearing function is a functional
relationship of the form (Karmarkar 1989):
where Xj,t and Cj,t denote the output and the capacity of work centre j in period
In the literature several functional forms of the one-dimensional
developed (overview in Missbauer & Uzsoy 2011). The most prevalent method used to fit
clearing functions is the use of regression functions which will be applied in this paper as
1 illustrates three basic functional forms if the load is the independent variable.
1. Examples of clearing functions (following Karmarkar 1989, adapted)
The “Fixed Lead Time”- function in Figure A1 represents the approach introduced by
Graves (1986). In this model a constant proportion of the available work is processed in each
planning period. Capacity is assumed as infinite at least within the relevant range of the load,
and the fixed lead time is independent of the WIP level. Note that there is no specific
relationship to stochastic arrival and departure processes at the work centres.
Nonlinear, saturating clearing functions as an instrument to model congestion on
capacitated production resources have been introduced by Karmarkar (1989) and since then
have been applied by several researchers (Missbauer 2002; Asmundsson et al. 2006, 2009;
Selçuk 2007). The concave shape of the saturating clearing function is due to limited capacity
and can be derived analytically (Karmarkar 1989, 1993; Missbauer 1998; Selçuk et al. 2008)
or can be approximated by fitting the curve to simulation data (Hwang & Uzsoy 2005;
If there are no relevant capacity constraints we can assume that the output is proportional
to the load (Fixed lead time function in Figure A1; equation (3)).
This should be the case for non-bottleneck work centres which normally have a low load.
If the load is high at certain times and congestion effects occur (saturating part of the clearing
function), the work centre behaves as a (at least temporary) bottleneck with load-dependent
flow times. We shall analyze empirically at which average utilization (presumably far below
100%) these congestion phenomena become relevant which means that for planning purposes
the work centre must be treated as a bottleneck. Therefore, we hypothesize:
Hypothesis H1: The fit of linear one-dimensional clearing functions is high when applied
Hypothesis H2: For non-bottleneck machines, we neither expect an increase of the R2
values by adding independent variables to a linear clearing function nor by using nonlinear
For capacity-constrained (bottleneck) facilities that are subject to congestion, theory
suggests that clearing functions must exhibit a nonlinear shape. In the one-dimensional case
extensive work was done to find functional forms of nonlinear clearing functions which are
mostly derived from queueing theory (Karmarkar 1989; Missbauer 1998, 2002). This paper
contributes to the discussion of finding suitable independent variables of multi-dimensional
Starting point for this are nonlinear regression functions with one independent variable
In (4) and (5), Xt denotes the output in period t, C is the maximum possible output and k
determines the curvature of the clearing function. Karmarkar (1989) proposes the following
Missbauer (1998) derives the following equation from a M/G/1 queueing model in steadystate:
X t = [C+k+Λ t - C2 + 2Ck + k 2 − 2CΛ t + 2kΛ t + Λ 2t ].
The parameter k can be calculated analytically (see Missbauer 2002) or can be estimated
from the data. In our analysis we estimate C and k from our data sets. These functions
approach the capacity C asymptotically as the workload increases to infinity. If the output can
be expected to reach full capacity at finite workload levels, a functional form for this case is
presented in Nyhuis & Wiendahl (2009, p. 66ff.). In the course of this study we will only use
functional form (5), since Karamarkar’s function is less suitable for models on a periodic
All of the above described clearing functions are limited to one independent variable.
Using these functions in an order release model is adequate if it can be assumed that knowing
the planned value of this variable for a future period t allows prediction of the output in this
period t to a sufficient degree of accuracy. Literature suggests that nonlinear one-dimensional
clearing functions lead to good output prediction and when incorporated in a production
planning model outperform fixed lead time models (Asmundsson et al. 2006, 2009; Irdem &
Uzsoy 2009; Kacar & Uzsoy 2009). On the other hand, queueing-theoretical studies show that
clearing functions with one independent variable do not predict the output sufficiently if the
system under study faces transient states (Missbauer 2011; see Section 1). Transient phases
are especially apparent at highly utilized machines since these frequently face critical load
Hypothesis H3: One-dimensional clearing functions do not yield a high fit at bottleneck
machines in comparison to multi-dimensional clearing functions.
If this is the case, we must ask which additional independent variables can be expected to
improve the fit of the clearing function to the data sets.
In an early paper on hierarchical production planning (Andersson et al. 1981) linear twodimensional clearing functions have been proposed to predict the output, measured in value,
of a manufacturing system. Their two-dimensional clearing function splits up the load of
machine j in period t into initial WIP and input of machine j in period t, leading to the general
There is theoretical evidence for this: Missbauer (2011) shows that if the expected load
E[WIPj,t-1]+E[At] (measured in number of orders) for a period t is kept constant, the expected
output E[Xt] depends on the composition of the load (proportion of E[WIPj,t-1] and E[At]). This
indicates that additional independent variables that reflect the history of the process (roughly
speaking: the time-dependent capacity loading before the period under consideration)
To the best of our knowledge no functional form for a saturating multi-dimensional
clearing function that takes transient effects into account has been provided so far. The twoand three-dimensional transient clearing functions in Missbauer (2011) are calculated
numerically from the transient-state probabilities for an M/M/1 system. We cannot provide a
definitive solution to this problem, but use a preliminary functional form for a twodimensional saturating clearing function (see Appendix B for its derivation and use in the
( C-β WIPj,t-1 ) ⋅ 1 [C+k+A - C2 +2Ck+k 2 -2CA +2kA +A2 ] if WIP < C
with k, C and, for empirical data, also β as parameters estimated by regression (for
simulation data β) The reasoning behind this functional form is given in Appendix B.
Providing a functional form for a saturating, three-dimensional clearing function must be left
Only a few other papers deal with multi-dimensional clearing functions for order release
planning. Anli et al. (2008) assume that the expected WIP level for each unfinished SKU,
facility and period is a non-linear function of the planned production volumes (of all SKUs)
of the facility and the variables representing system variability and control polices. The
relationship is estimated by mean value analysis, Caramanis et al. (2001) use the Queueing
Network Analyzer (Whitt 1983) (see Missbauer & Uzsoy (2011) for a description of this
approach). Albey et al. (2011) analyze the output of a single facility in terms of quantity and
product mix as the product mix of the released orders changes. However, these papers do not
analyze transient effects. Kacar and Uzsoy (2010) test the performance of various multidimensional linear clearing function formulations including similar independent variables as
The benefit of including variables expressing the variability of input, output and WIP over
time is difficult to predict. Clearly, characteristics of the manufacturing system like product
mix, lot sizes or system variability influence the expected output. In our study these
characteristics are given and determine the shape parameter k of the clearing function (5) and
(7). If these characteristics vary over time, including independent variables that reflect these
characteristics may be beneficial. In our data no major change in product mix and lot sizes
occur, and we expect that the variability of arrival and departure process at the machines does
not change substantially over time. Therefore, we hypothesize:
Hypothesis H4: Independent variables that take the history of the process into account lead
to improvements of the fit to data of bottleneck machines. Variables that express the
variability of WIP and work input are not expected to improve the fit to the data.
Since the variability of WIP and work input during the period is not represented in the
data, we use the variability of WIP at the start/end of the period and of the work input during
In addition to the linear two-dimensional clearing function (6) and the saturating twodimensional clearing function (7), we will test general two-dimensional clearing functions of
where I1 and I2 represent two out of a set of six possible independent variables. The deduction
of the six variables will be described in section 4.3. Each of the six variables is combined with
each other (one combination is omitted; see below) which yields 14 (15 minus 1) possible
combinations. The intention of comparing these two-dimensional clearing functions (6) and
(8) is firstly, to evaluate the fit of the two-dimensional clearing functions that use the
independent variables suggested by Andersson et al. (1981) and secondly, to have a reference
R2 value for three-dimensional clearing functions.
Three-dimensional clearing functions are regressions with three independent variables
where I1, I2 and I3 represent three independent variables which will be combined with each
other which yields 20 (24 minus 4) possible combinations.
In the course of this analysis linear and nonlinear regression functions will be used. We
start with a linear one-dimensional clearing function (3) of the form (repeated for
Furthermore, the linear regression through the origin will be extended to a linear twodimensional clearing function following (6) or (8) leading to
and three variables following this logic. In the course of our analysis the independent
variables I1, I2 and I3 (for three-dimensional clearing functions) will be replaced by six
different variables which will be described in section 4.3.
As described above, several authors (Karmarkar 1989; Missbauer 1998, 2002) use
queueing relationships to develop analytical expressions for nonlinear one-dimensional
clearing functions (see (4) and (5)). Missbauer’s function (5) will be tested and the resulting
R2 will be used as a benchmark for a “simple” regression function (12) that does not
incorporate knowledge about the (mostly saturating) structure of the underlying data. Hence
the “simple” regression with one independent variable follows
If the R2 of this quadratic regression function is as high as the fit of the saturating
regression function (5) then (12) will be extended to two independent variables, yielding
X j,t =b1I12 +b 2 I1 +b3 I 2 2 +b 4 I 2 +b5 I1I 2
and finally, we will extend the formula to regressions with three independent variables and
obtain a functional form inspired by the regression function used in Noguera & Watson
X j,t =b 1 I1 +b 2 I 2 +b 3 I 3 +b 4 I1 I 2 +b 5 I1 I 3 + b 6 I 2 I 3 + b 7 I1 I 2 I 3 + b 8 I12 + b 9 I 22 + b 10 I 32 .
All coefficients (b1 to b10) will be tested of their significance with a significance level of
95%, meaning that in a majority of cases the final regression functions of nonlinear twodimensional clearing functions and three-dimensional clearing functions are shorter versions
of equations (13) and (14) (for details see appendix A).
The weakness of the quadratic functions (12) – (14) is obvious; they can predict a decrease
of the output as the independent variables (e.g., initial WIP) exceed a certain value. This can
actually happen in certain cases, but normally it cannot be assumed, especially in simulation
models. Thus the quadratic functions are not robust (as defined in Little 1970), and their
predictive power is limited. Since we only use these functions for deriving appropriate
independent variables, we expect relevant insights especially for the (noisy) empirical data.
Hypothesis H5a: “Simple” nonlinear regression functions are well suited as representations
of saturating clearing functions within the range of the independent variables that occurred
in the data, especially for empirical data.
Hypothesis H5b: For simulation data the “simple” regression functions yield lower fits in
comparison to the saturating two-dimensional clearing functions (7).
A widely accepted method to fit clearing functions to simulation data is to use regression
functions (Missbauer 1998, 2002; Irdem & Uzsoy 2009; Kacar & Uzsoy 2010; Asmundsson
et al. 2009). Throughout the paper we apply regressions through the origin which is a special
case of an ordinary least squares regression. The reasoning for this is obvious for nonlinear
regression functions that exhibit a concave, saturating shape. It is less obvious for linear
regression functions, because in this case the fit can be better for non-zero intercept (see Fine
& Graves 1989). The reasoning is as follows: In the context of the order release model the
planned output cannot exceed the planned load due to the nonnegativity of the planned WIP.
Hence in the context of the order release model a linear clearing function with a positive
intercept leads to a functional relationship between load and maximum output that consists of
two linear segments, namely the segment Xt ≤ WIPj,t-1 + At and the linear clearing function
(and possibly the capacity constraint Xt ≤ C as third segment). Hence the relationship between
load and output that is actually assumed in the release model is an approximation to a
nonlinear function. Therefore, we use a regression through the origin: Nonlinear regression
functions are tested separately, and a linear regression through the origin means a proportional
clearing function that has the suitable property of load-independent lead times (Graves 1986),
and we explore to what extent this assumption holds especially for non-bottlenecks (see
One noteworthy consequence of forcing the regression through the origin is that the
adjusted coefficient of determination (for brevity denoted as R2) can be negative (for its
calculation see Wooldridge 2006; Kvalseth 1985). A negative R2 means that the average of
the dependent variable “explains” more of the variation than the independent variables
The main purpose of this paper is to identify independent variables that increase the fit of
the regression model to the data (measured by the R2). Thus, we are interested in the
significance of certain independent variables in the fitted regression functions. Therefore, we
test the significance of every regression coefficient (b1 to b10) with a t-test on a 95%
confidence level. In order to guarantee the applicability of the significance test to the data sets
we pursue several statistical tests. Therefore, in the course of our analysis all regressions are
tested on heteroskedasticity and autocorrelation (the applied tests are described in appendix
A). We will use the Newey-West procedure to adjust the standard error terms which makes
them robust to heteroskedasticity and autocorrelation, meaning that the significance tests are
applicable again. The reasons for autocorrelation in a regression can be manifold (see Pindyck
& Rubinfeld 1998, p. 159ff.). In this study we expect autocorrelation as a consequence of
misspecifications, meaning when we use a linear regression functions although the “real”
relation is nonlinear or when we use the “simple” quadratic regression function although the
relation between the variables is not quadratic. Furthermore, all regressions with more than
one independent variable are tested on multicollinearity (see appendix A) which might occur
e.g., for WIP or the input to a work centre in consecutive periods.
The use of ordinary least squares regressions for estimating the clearing function
parameters can be questioned. Kacar & Uzsoy (2010) show that in the case of linear multidimensional clearing functions high fits to data do not automatically guarantee good
performance of the release model. The relationship between the clearing function estimation
and the performance of the order release model is not yet fully understood. The impact of the
parameter estimation on the tradeoff between inventory and due-date performance may play a
role as well as the systematic difference between the estimated clearing function and the
clearing function used for planning (Missbauer 2011). We assume that a set of independent
variables that leads to a higher reliability of the expected output is a good starting point for
predicting the output in order release models even though adjustments of the parameters
might be necessary due to the reasons sketched above. Testing the robustness of our results if
a fitting procedure based on simulation-based optimization is used (as in Kacar 2012) is a
A4. 1. Production system. The first data set we use was collected from a customer driven
optical storage media producer which is organized as a flexible flow shop. The system
essentially consists of three sections: manufacturing, printing and packaging. Figure A2
depicts the workflow through the facility.
Figure A2. Structure of the production system
Production is performed in a three stage process, each product moves through these
sections in different routings. The production operates 24 hours a day, seven days a week in
four shifts. Shifting bottlenecks occur due to the varying product mix.
The manufacturing section consists of 16 machines, ten for CD and six for DVD
production. Within these two groups the machines work parallel and are fully substitutable. A
worker in this section is normally responsible for up to three machines at the same time and
decides on the sequence of orders that should be processed based on a preliminary list
provided by a superior department. The printing section consists of six machines which can
be classified into three groups depending on the printing technology, namely three serigraphy
machines (SD), two kammann offset machines (KOD) and one metronic offset (MOD)
machine. Workers are, depending on their skill and experience, assigned to one or two
machines at once. The KOD machines work parallel and are fully substitutable and the SD
machines work parallel, but are only partly substitutable. Orders can also be substituted
between the two offset printing technologies (MOD and KOD) due to high utilization or
quality requirements. The workers choose the priority of orders similar to the manufacturing
section, but their list gets updated every two hours. The packaging section consists of seven
machines, where one of them is a shrinking machine (V2), two machines pack CD and DVD
into boxes (V1 and V3) and further two machines wrap DVDs or CDs in paper, cardboard or
plastic bags (V4). Within the divisions V1, V3 and V4 the machines work parallel and are
partly substitutable. The team leader assigns workers to machines according to priorities of
orders that are set by a rather mandatory sequence, whereas three machines require one and
four machines require two workers. Note that especially in the printing and packaging section
the decision of the team leaders how to allocate their discretionary time is crucial and its
impact on productivity must not be underestimated (Krishnan & Srinivasan 2007). In these
three above mentioned sections data of 29 machines over a period of 12 months was collected
(from January 1st to December 30th). The maximum capacity and the days of business were
provided by the company. Information on the orders included the order number, the routing,
the arrival times , the start and end dates (exact time) of processing at each machine, the setup
and processing time and the number of items of the orders.
A4.2. Simulation model of the production system. The second data set was obtained from a
scaled-down model of the real manufacturing system described above. The simulation model
consists of 9 work centres that produce 24 different products. All settings like the demand
pattern, processing times, product mix, routing of the products and length of the periods were
adopted from the real world case (for a detailed description of the used order arrival-, material
flow and demand generation model we refer to Puergstaller & Missbauer 2012). Similar to the
practical case the production in the simulation model is driven by customer orders. The
interval between arrival date and required due date of an order determines the possible release
times. Thereafter, the orders are released immediately when they arrive at the order pool.
Immediate releases were chosen for the simulation model, because the company did not apply
any reproducible release logic. Furthermore, the optical storage media producer faces
fluctuating demand which is represented by a sinusoidal demand in the simulation model and
the company faces a high variability in the product mix which was taken into account in the
simulation model as well. The simulation study was performed using FLEXSIM.
A4.3. Simplified queueing models. In order to analyze the impact of different order arrival
processes at the machines we also conduct our regression analyses on data of two simplified
queueing models. At first we test our regression functions on data of a M/M/1 queue with
different utilization levels and different period lengths.
Secondly, since in order release models the orders are released by a higher planning level,
the assumption of order arrivals according to a renewal process is problematic, because the
number of arrivals during a sufficiently long period is nearly fixed. Therefore, we analyze a
production unit with order releases controlled by the Supply Chain Operations Planning
(SCOP) function (see Jansen 2012, p. 91ff.) which we simplify to its nucleus. We assume a
single machine that produces J products. In each period one order arrives for each product.
The arrival time of a product j relative to the period boundaries (i.e., the time from start of the
period until arrival of product j) depends on the product (uniform distribution within the
period), but is the same for each period, that is, the same arrival pattern repeats again and
again. For each product the operation time, which is the same in each period, is a realization
of an exponentially distributed random variable. FCFS dispatching is used. This pattern
occurs when J products with identical data and constant demand rates are produced to stock
controlled by reorder point systems, and the initial inventories are uniformly distributed. It
can be shown that for J –> ∞, the interarrival times are asymptotically exponentially
distributed (Missbauer 1999). Note that the dynamic behavior of the system is determined by
its initial conditions. We select initial conditions with different arrival patterns within the
periods (evenly spread within the period vs. concentrated in certain phases of the periods).
A4.4. Editing of crude data and deduction of variables. The empirical data was obtained in the
course of a project with a company and was collected by an automatic production data
acquisition system. The data was tested for validity and it was conferred with the company in
order to sort out all inconsistencies. Minor changes in the data were made regarding false
For this study the deduction of the dependent variable Xj,t (output of machine j in period t)
was made in the same manner for empirical and simulation data. Both data sets provided
information on all orders that were finished at the machines in each period (calendar days)
with the end-of-processing date, the number of items per order and the operation time (setup +
processing time) per order at each machine in minutes. All orders with the same end-ofprocessing date were aggregated yielding the output, measured in time units, for each
considered calendar day for each machine.
With regard to the empirical data, periods were set to calendar days, starting from 12:00
am to 11:59 pm. This leads to following imputations regarding the assignment of input or
output to a machine. An order that arrives at the queue of a machine at 10:01 pm on January
1st and ends its processing at 12:01 am the next day, leads to an assignation of two hours
input on January 1st and two hours output (assumed that there was no waiting time or other
delay) on January 2nd, although most of the processing took place on January 1st. Certainly,
this case is an exception and is cancelled out with the present amount of data. Additionally,
only 1 percent of the orders have an operation time longer than 4 hours, which makes this
Concerning the independent variables, we firstly deduce the input variables Aj,t essentially
in the same way as the Xj,t. by listing all orders that arrived at the machine with their arrival
dates and corresponding operation time in minutes. Finally, orders with the same arrival date
were summed up and listed chronologically. The input to a machine was deduced from the
simulation data by listing the operation times of all orders that arrived at the machine per
Thereafter, the work-in-process variables can be calculated by
The initial WIP of the respective machine (Wj,0 where t=0 is January 16th) was determined
as follows: The variables Aj,t and Xj,t only encompass orders that arrived after the first period
of the empirical data set (January 1st, , which is t = -15 in our notation), the same holds for the
WIP variables Wj,t. The WIP at January 1st, , resulting from this set of orders (Wj,-15) is zero
by definition. This is the starting point for calculating Wj,0 in (15).
For estimating the output in period t for each work centre j (Xj,t), we start with WIPj,t-1, Aj,t
as independent variables. Additionally, we consider another two independent variables by
splitting up WIPj,t-1 into its components, namely WIPj,t-2, and Aj,t-1. This is in line with recent
work of Kacar & Uzsoy (2010) who find that multi-dimensional linear clearing functions with
WIP at the start of the period and releases during the period under consideration and in the
immediately preceding period (which is equivalent with our independent variable Aj,t-1)
improve the performance of the order release model compared to clearing functions that only
consider WIP and releases in the period under consideration.
One can ask whether the output in the previous periods (Xτ; τ = 1,…,t-1) as one component
of the process history should be included as possible independent variable. An M(t)/G/1
system with λ(t) < μ acts as a low-pass filter; high-frequency oscillations of the timedependent arrival rate λ(t) hardly influence the output process (Hazra & Park 1994). This
might indicate that the past output values should be included. However, this effect is
questionable for the period lengths in our data (5 – 15 times the mean service time). So we
expect that a possible correlation of the output in consecutive periods is a consequence of the
planning system that smoothes the output over time. As far as this is a result of the order
release decisions, it should not be considered as a property of the production unit. However,
in the empirical data this correlation can also result from informal smoothing mechanisms at
the shop floor level that should be anticipated at the order release level. After some
preliminary analyses we excluded the output values in the previous periods due to the weak
theoretical basis. Moreover, including the output variables could distort the R2 values for
linear regressions since, unlike WIP and work input, the output cannot exceed capacity.
Finally, we analyze independent variables that are proxies for the variability of the WIP
and work input during the period (see section 2). We use two different coefficients of
variation (CV) of the WIP with different time horizons, one with a long horizon of 40 periods
(CV[WIPj,t-41,…,WIPj,t-1] hereinafter CVL[WIPj,t-1]) and one with a short horizon of 20 periods
(CV[WIPj,t-21,…,WIPj,t-1] hereinafter CVS[WIPj,t-1]). These two independent variables are
This yields six independent variables (Aj,t; WIPj,t-1; WIPj,t-2; Aj,t-1; CVL[WIPj,t-1]and
CVS[WIPj,t-1]) which will be tested in linear and nonlinear two- and three-dimensional
regression functions following (8) and (9).
A4.5 Selection of bottleneck and non-bottleneck machines. In order to answer our hypotheses,
we select two machines in each section (manufacturing, printing and packaging) from the
empirical as well as from simulation data. One represents a non-bottleneck and the second a
bottleneck machine where the two selected machines must not be substitutable in the case of
empirical data. We use the long term production definition of bottlenecks by Lawrence &
Buss (1995) where the average utilization of the respective machine is calculated following
where ρj denotes the average utilization of machine j, X j the average output of machine j and
C j is the average capacity of machine j over the considered periods.
For empirical data the average capacity was provided by the company, for simulation data
the average capacity is equal to the period length. Machines having an average utilization
above 75% will be denoted as bottleneck and machines below 60% will be denoted as nonbottlenecks (see Asmundsson et al. 2006; Selçuk et al. 2008 for similar classifications). If no
machine qualifies for one of these classes the machine with the lowest and/or highest average
utilization of the section will be chosen and will be considered in the interpretation. The
reason for selecting two machines from each section which differ with respect to their
utilization is twofold. Firstly, we test hypotheses that presumably hold for low- or highly
utilized machines and secondly, we want to analyze at which average utilization congestion
phenomena and therefore nonlinear clearing functions become relevant. For planning
purposes this means that work centres that face congestion effects must be treated as
bottlenecks. We analyze the value of this threshold and test whether it differs depending on
the source of data (simulation or empirical data).
In each section, namely manufacturing (Man), printing (Pri) and packaging (Pack) two
machines, a bottleneck and a non-bottleneck machine, were selected based on their average
utilization (16) yielding twelve machines (six machines of each data set) which will be used
in the analysis. Accordingly, this chapter is structured into two parts, the first presents the
performed analysis on non-bottleneck and the second shows the results on bottleneck
machines. In the latter section we also analyze data obtained from two single-stage queueing
systems in order to explore specified structural properties.
A5.1. Non-bottleneck machines - Simulation data. Table A1 depicts the results of the applied
regressions to data of non-bottleneck (NB) machines of simulation data. The rows depict the
R2 values for the non-bottleneck machine of the manufacturing section “ManNB”, the
printing section “PriNB” and the results for the packaging section which is abbreviated as
“PackNB”. The second column shows the utilization of the machines (Util.). The remaining
columns show the R2 values of the different applied functional forms. At first, the linear onedimensional clearing function (Lin.1D) following equation (3). Secondly, the two different
nonlinear one-dimensional clearing functions (Nonlin.1D): Missbauer’s clearing function
following (5) abbreviated with “Missb.” and our introduced “simple” regression functions
following equation (12). Furthermore, we depict the values of the estimated coefficient (b, k
Finally, the last two columns show the linear two-dimensional clearing functions “Lin.2D”
following (11) and the R2 values of the linear three-dimensional clearing functions “Lin.3D”
being an extension of equation (11). The depicted values represent the highest R2 of all
respective combinations, a detailed list of combinations (and estimated coefficients) that
yielded an increase in the fit will be presented subsequently. To the best of our knowledge no
significance test is applicable to improvements in the R2 values in regressions.
Table A1. R of non-bottleneck machines from simulation data
The R2 values marked with an asterisk in the column of the linear two-dimensional
clearing functions (Lin.2D) are regression functions that do not incorporate the independent
variables suggested by Andersson et al. (1981) following (6). Furthermore, the horizontal bars
in the cells indicate that the R2 values of a regression with a smaller number of independent
variables could not be increased and therefore these values were omitted for reasons of
According to hypothesis H1, we expect a good fit of the linear one-dimensional clearing
function (3) to the data. As one can see in table A1, H1 can only be confirmed for the nonbottleneck machine PackNB. At the two other non-bottleneck machines from simulation data
(ManNB and PriNB) the fit of the one-dimensional clearing function is comparatively low
with an R2 value of 0.540 and 0.746. This is probably due to the fact that the data points of
these machines with an average utilization of 54.4% and 51.17% already show a beginning
saturating shape as depicted in figure A3.
3. Scatter plot of ManNB machine ρ=54.4% and PriNB machine ρ= 51.17%,
This means that for planning purposes these two machines should be treated as bottlenecks
despite our subjectively set categories of denoting a machine as a bottleneck
1 that a linear clearing function which from a planning
perspective should suffice for non-bottlenecks
non bottlenecks yields relative low fits and therefore even at
these low utilization levels a nonlinear clearing function
According to hypothesis H2, we neither expect nonlinear one-dimensional
multi dimensional clearing functions to improve the R2 values of the linear oneone
dimensional clearing functions. Hypothesis H2 is only confirmed
Therefore, we conclude that our hypotheses regarding non-bottleneck
hold for machines where the throughput does not approach the maximum capacity and
therefore the data points do not exhibit a saturating shape
Additionally, we confirm hypothesis H5a that “simple” nonlinear regression functions are
well suited as representations of saturating clearing functions for all non-bottleneck
om simulation data. Since the “simple” one-dimensional
one dimensional nonlinear regressions lead to
comparatively high R2 values as the nonlinear clearing functions by Missbauer (see table A1).
As already mentioned above the two non-bottleneck
non bottleneck machines ManNB and PriNB should
from a planning perspective be treated as bottlenecks and therefore nonlinear clearing
functions should be applied which yield very high fits of 0.986 and 0.977 (see table A1).
However, applying linear twotwo and three-dimensional
earlier studies show (Andersson et al. 1981; Kacar & Uzsoy 2010).
Adding one independent variable to the linear one-dimensional
one dimensional clearing functions increases
the fit to a R2 value of 0.891 at the ManNB and to 0.909 at the PriNB machine. If another
independent variable is added to the linear two-dimensional
two dimensional clearing function the fit can be
increased to a value of 0.900 at ManNB and to 0.917 at PriNB respectively (see table A1).
For the sake of brevity only the combinations for PriNB are depicted in table A2 that
increase the R2 values of the linear one- and two-dimensional
two dimensional clearing functions. Since we
apply a linear regression function to a possibly nonlinear relation we expect problems
regarding autocorrelation and therefore put an asterisk
autocorrelation was detected and the robust standard errors (Newey-West
Table A2. R2 of linear two- and three-dimensional clearing functions of PriNB, simulation
Note that the same combinations also yielded an increase of the fit for the ManNB machine
and furthermore that in neither case we measured multicollinearity which might be expected
when including Aj,t and Aj,t-1 in one regression function. The relative increase from combining
Aj,t and Aj,t-1 compared to combining Aj,t-1 with WIPt-1 seems surprising, and further
experiments are necessary to explain this.
From these results we draw two conclusions. Firstly, the proposed independent variables
that take the history of the process into account (Aj,t-1, WIPt-2) and also to some extent the
proxy variables for the variability of the WIP (CVL[WIPj,t-1], CVS[WIPj,t-1]) lead to an
improvement of the fit to the data with a linear two- and three-dimensional clearing function.
And secondly, from a production planning perspective the analysis of simulation data shows
that linear two- and three-dimensional clearing functions incorporating the suggested
variables seems promising and should be tested in order release models in future studies.
A5.2. Non-bottleneck machines - Empirical data. Table A3 follows the same design as the
above described table A1 for simulation data and depicts the R2 values of the applied
regression functions on non-bottleneck machines of empirical data. Additionally, we present
the resulting R2 values for two nonlinear two-dimensional clearing functions “Nonl.2D”. At
first, the new preliminary functional form denoted as “2Dcf” following (7) and secondly, the
simple two-dimensional regression function following (13). All values marked with two
asterisks were regression functions facing multicollinearity issues.
Table A3. R2 of non-bottleneck machines from empirical data
Note that all of the highest fits of linear and “simple” two-dimensional clearing functions
on empirical data were obtained by regression functions with those independent variables (Aj,t,
WIPt-1) suggested by Andersson et al. (1981).
According to hypothesis H1, we expect a good fit of the linear one-dimensional clearing
function (3) to the data. As one can see in table A3, H1 can only be confirmed for the nonbottleneck machine PriNB. At the non-bottleneck machine ManNB the fit of the onedimensional clearing function is comparatively low with an R2 value of 0.664 and the fit to
the data of the PackNB machine is even negative.
Regarding the ManNB machine, the linear one-dimensional clearing function yields a low
fit which might be due to the fact that the data exhibits a weak saturating shape of the data
points as depicted in figure A4. This means similar to the above described cases with
simulation data that for planning purposes this machine should be treated as a bottleneck and
therefore even at this relatively low average utilization levels a nonlinear clearing function
Figure A4. Scatter plot of ManNB machine ρ=57.5%, empirical data
With regard to the non-bottleneck machine in the packaging section (PackNB) where the
linear one-dimensional clearing function yields a negative R2 value one can see in figure A5
that there are five peaks of output at different load situations at the machine.
Figure A5. Non-bottleneck packaging machine ρ=19.2%, empirical
Since the team leader of the packaging section is the only one who operates this shrinking
machine it is not surprising that the available work in front of the machine is not
automatically processed by arrival, but is worked off when the queue in front of the machine
is too long or the team leader has some free discretionary time. One can conclude that the
supervisory time allocation has a significant impact on productivity (see Krishnan &
Srinivasan 2007; Berglund et al. 2010). In this case, the effect of allocating discretionary time
of the team leader leads to the dissolution of the (in general) existing correlation between
output and load of a machine. This highlights the difference between the simulation and
empirical data set. The former can be described as mainly equipment centered (Kempf 1996),
the queues in front of machines are automatically cleared and the latter contains human
related factors (e.g., allocation of workers, motivation, skill/experience of workers etc.).
According to hypothesis H2, we neither expect nonlinear one-dimensional clearing
functions nor multi-dimensional clearing functions to improve the R2 values of the linear onedimensional clearing functions. Hypothesis H2 can be confirmed for the non-bottleneck
printing machine (PriNB). Additionally, we confirm hypothesis H5a that “simple” nonlinear
regression functions are well suited as representations of saturating clearing functions
especially for empirical data, since the “simple” one-dimensional nonlinear regressions leads
to comparatively high R2 values as the nonlinear clearing functions by Missbauer (see table
As already mentioned above the non-bottleneck machine ManNB should from a planning
perspective be treated as a bottleneck and therefore the nonlinear clearing function should be
applied which yields a high fit of 0.738 (see table A3). However, the aim of this paper is to
analyze which additional independent variables increase the fit and therefore we also apply
linear two- and three-dimensional regressions (see table A4).
Table A4. R of linear two- and three-dimensional clearing functions of ManNB, empirical
As already shown for the non-bottleneck machines from simulation data we also conclude
for empirical data that the proposed independent variables that take the history of the process
into account (Aj,t-1, WIPt-2) lead to an improvement of the fit to the data with linear threedimensional clearing functions.
Two insights can be provided when comparing the analysis of non-bottleneck machines of
simulation and empirical data. At first, simulation data exhibit significantly less spread which
results in very high R2 values (>0.95) in comparison to the fits to the empirical data (<0.85).
Secondly, different to the analysis of simulation data only the linear two-dimensional clearing
function proposed by Andersson et al. (1981) leads to an increase in the fit for empirical data.
We conclude that from a production planning perspective incorporating the suggested
variables in a linear multi-dimensional clearing function seems promising even for machines
A5.3. Bottleneck machines - Simulation data. Table A5 depicts the R2 values of the applied
regressions on bottleneck machines (BN) of simulation data.
Table A5. R2 of bottleneck machines from simulation data
With regard to hypothesis H3 we expect that one-dimensional clearing functions do not
yield a high R2 at bottleneck machines in comparison to multi-dimensional clearing functions.
We reject hypothesis H3 for all bottleneck machines from simulation data which is
unexpected and will be discussed in more detail below.
Concerning hypothesis H5a, we test whether “simple” nonlinear regression functions are
well suited for representations of saturating clearing functions. As one can see in table A5,
H5a is rejected for the PriBN and the PackBN machine and can only be partly confirmed for
the manufacturing bottleneck machine (ManBN) which is not very highly utilized with an
Of course the linear one-dimensional clearing functions yield very low fits in all cases, but
the nonlinear one-dimensional clearing functions reach very high R2 values reaching from
0.979 to 0.996 (Missb.). The function is fairly close to the “ideal” shape Xj,t = Min(Λj,t ;C), and
many data points are at this upper bound. We assume that this is due to the relatively long
periods (960 minutes in relation to the operation times which are at most 66 minutes). As the
period length increases the impact of the stochasticity of the process on the output per period
becomes lower. It can be shown that for the M/M/1 model clearing function (5) approaches
the “ideal” shape as the period length approaches infinity (see Missbauer 1998, p. 250ff.).
Therefore, we pursue an additional scenario with our simulation model and several tests with
simplified queueing models in order to get more insights into the behavior of the system.
Table A6 depicts the R2 values of the applied regressions on bottleneck machines (BN) of
simulation data with a shortened period length of 360 minutes. This is about five times the
average operation time which was also assumed in Missbauer (2011). For the sake of brevity,
the analysis only includes the highly utilized bottleneck machines from the printing- (PriBNS)
Table A6. R2 of bottleneck machines from simulation data with shortened period length
The results show that the period length has an influence on the fits of the regression
functions. Hypothesis H3 is confirmed for the PriBNS machine since the fit of the nonlinear
one-dimensional clearing function of 0.743 can be increased by the nonlinear twodimensional clearing function by 0.196 to a R2 value of 0.939. For the PackBNS machine we
only partly confirm hypothesis H3 since on the one hand the nonlinear one-dimensional
clearing function yields a high fit of 0.937, but on the other hand can be slightly increased by
a two-dimensional clearing function to a value of 0.977 (see table A6).
Hypothesis H5a is rejected for all tested bottleneck machines from simulation data with a
shorter period length, since “simple” regression functions are not well suited for
representations of saturating clearing functions. And we confirm hypothesis 5b that the
saturating two-dimensional functions (2Dcf in table A6) yield higher fits than the “simple”
In order to analyze whether these results are a consequence of the shop configuration of the
used simulation model we perform our regressions on data of two simplified queueing models
with different utilization levels and different period lengths. At first, we analyze a M/M/1
queue and secondly, we test a SCOP controlled production unit.
Table A7 depicts the results of the applied regressions to data of the M/M/1 queue. At first
we test a scenario where the ratio between the period length and the mean service time is large
(about 15 to 1) which is denoted as “MM1L”. This scenario represents the initial tests with
the simulation model above. And secondly, we test a scenario where we shortened the period
length (ratio of about 5 to 1) abbreviated as “MM1S”.
Table A7. R2 of regression functions fitted to data of M/M/1 queues
The results for the scenarios with long period length (MM1L) are similar to the initially
described results from bottleneck machines of our simulation model. The linear onedimensional clearing functions yield very low fits and again this fit is increased to rather high
R2 values by the nonlinear one-dimensional clearing functions (0.81 to 0.837). Reducing the
period length does not have the same influence on the fits as it was the case with the
bottleneck machines of the simulation model. It seems that in the case of the M/M/1 queue the
spread of the data does not substantially increase by decreasing the period length and
therefore the fits of the nonlinear one-dimensional clearing function remain high (see table
A7). The pursued tests with the two-dimensional saturating clearing function (2Dcf) show
firstly, that the high fits of the nonlinear one-dimensional clearing function (Missb.) can be
increased further. And secondly, that hypothesis H5b is once more confirmed for simulation
data, since the saturating two-dimensional clearing functions can increase the fits of the onedimensional regressions.
Turning to the analysis of the SCOP controlled production unit, we simulate two scenarios
similar to the above pursued tests. Firstly, “SCOPL” denotes the scenario where the simulated
machine produces 24 products and secondly, in order to reduce the ratio between mean
service time and period length a scenario with 9 products abbreviated as “SCOPS” is tested.
Table A8 depicts the performed regressions on the SCOP controlled production unit.
Table A8. R2 of regression functions fitted to data of a SCOP controlled production unit
The results for the scenarios with long period length (SCOPL) are similar to the results for
bottleneck machines of our simulation model. The linear one-dimensional clearing functions
yield very low fits which are increased to high R2 values by the nonlinear one-dimensional
clearing functions (see table A8). In this case of the SCOP controlled queue reducing the
period length has a substantial influence on the fits of the regression functions: R2 decreases
substantially for Nonl.1D, but in one case (utilization 72.98%) it can be increased from 0.614
to 0.880 by adding a second independent variable (Nonl.2D). In this case the order arrivals
were very uneven over the periods (note that the arrival pattern is the same for each period),
leading to strongly non-stationary states of the system. This was not the case in the case with
utilization 93.8% where almost no optimization potential from using a two-dimensional
clearing function can be observed. This important insight is in line with what we would
A5.4. Bottleneck machines - Empirical data. Table A9 depicts the R2 values of the applied
regression functions on bottleneck machines of empirical data.
Table A9. R2 of bottleneck machines from empirical data
Note that all nonlinear three-dimensional clearing functions (following (14)) were
regression functions with less than ten coefficients due to non significant coefficients.
Concerning hypothesis H3 we expect that one-dimensional clearing functions do not yield
a high fit at bottleneck machines in comparison to multi-dimensional clearing functions. We
have to reject this hypothesis for the ManBN and PriBN machine, since the fit of the
nonlinear one-dimensional clearing function cannot be substantially increased by adding
independent variables (see table A9). The reason for low fits of the regression functions is
possibly due to the broad spread of the empirical data. For the PackBN machine we confirm
this hypothesis, because the saturating two-dimensional clearing function yields an increase in
the fit and in this case the “simple” two- and three-dimensional functions improve this fit
With regard to hypothesis H5a we stated that the “simple” nonlinear regression functions
are well suited for representations of saturating clearing functions especially for empirical
data. We can confirm this hypothesis for all bottleneck machines from empirical data, since
the “simple” regression functions yield comparatively high or even higher fits to the data.
Finally, Hypothesis H4 stated that independent variables that take the history of the process
into account lead to improvements of the fit to data of bottleneck machines. This hypothesis
has to be partly rejected for ManBN and PriBN machine, but can be confirmed for the
PackBN machine of empirical data (see table A9).
Table A10 shows the combinations yielding the improvements in the R2 values at the
PackBN machine in a nonlinear two- and three-dimensional clearing functions.
Table A10. R2 of nonlinear two- and three-dimensional clearing functions of PackBN,
The results show that the “simple” nonlinear 2D regressions with the highest resulting fits
to the data was the two-dimensional clearing function incorporating the independent variables
proposed by Andersson et al. (1981). Furthermore, we confirm hypothesis H4 that the
proposed independent variables that take the history of the process into account (Aj,t-1, WIPt-2)
and also to some extent the proxy variables for the variability of the WIP (CVL[WIPj,t-1] and
CVS[WIPj,t-1]) lead to an improvement of the fit when applying nonlinear two- and threedimensional clearing functions (see table A10).
Two insights can be provided when comparing the analysis of bottleneck machines of
simulation and empirical data. At first, we conclude that in general analyses of bottleneck
machines with simulation data exhibits significantly less spread in the data. As a consequence
the fit of the different regression function when applied to empirical data is substantially
lower. Secondly, the analysis of bottleneck machines from simulation and empirical data has
shown that our preliminary saturating two-dimensional clearing function yields promising fits
to the data and therefore we are confident that the performance of an order release model
would increase by incorporating this type of clearing function.
The aim of this research was to improve the estimation of the output in future periods in
the context of order release models based on clearing functions. Therefore, this paper
explored the fit of various clearing function formulations (linear and nonlinear, one, two and
three independent variables) on simulation and empirical data obtained from a make-to-order
production system. The fit of the clearing functions was made by a regression through the
origin and measured by the adjusted R2. Additionally, this paper introduced a preliminary
functional form of nonlinear clearing functions with two independent variables and tested
“simple” quadratic regression functions representing three-dimensional clearing functions.
The findings led to suggestions which combination of independent variables should be used in
a clearing function in order to improve the estimation of a work centre’s output in future
periods and hence improve order release planning models. The implications of the study for
design and application of clearing function models can be summarized as follows.
The comparison of empirical and simulation data showed that empirical data exhibit
substantially more spread of the output compared to simulation results. This leads to less
accurate output predictions and makes it difficult to select the right functional form for
clearing functions. In particular, it can be difficult to decide whether the maximum capacity is
load-independent (saturating clearing function) or can be increased by higher shop loading or
even decreases at high WIP levels. If, e.g., sales and production department disagree on this
question, it can be difficult to provide a clear answer based on hard data. This also shows the
limitations of simulation-based research on order release models and indicates the need for
For non-bottleneck work centres linear (proportional) clearing functions provide a good fit
which means that load-independent lead times or lead time distributions are a good
approximation. This supports the idea to simplify the order release model by representing
non-bottlenecks as load-independent delays (Missbauer 1998). However, work centres behave
as non-bottlenecks only if the average utilization is substantially below 100 percent (in our
study below about 50 percent). This threshold value might depend on the individual case, but
the essential insight seems to be stable. With regard to order release models this paper
confirmed earlier studies (Andersson et al. 1991; Kacar & Uzsoy 2010) that linear multidimensional clearing function can be useful for work centres up to a certain utilization level.
For bottleneck work centres the clearing function must model the effects of congestion at
higher utilization levels. Saturating clearing functions where the estimated output approaches
the capacity as the capacity load increases clearly outperform the “simple” quadratic
regression function for simulation data (where the saturating shape is implied by the
assumptions of the simulation model), for empirical data this effect is much less pronounced.
The fit of a one-dimensional saturating clearing function and the possibilities for
improvements by adding independent variables that represent the history of the process
(roughly speaking: the time-dependent capacity loading before the period under
consideration) depend both on the period length (with the mean operation time as time unit)
and on the stationarity of the process. For a period length of about 15 the fit of the onedimensional clearing function was extremely high and thus the output prediction was very
accurate for simulation data, which was somewhat surprising. Reducing the period length to
about five reduced the fit, and extending the clearing function to two independent variables
led to substantial improvements especially for high utilization (>90%). The analysis of the
single-stage systems (Poisson and SCOP- controlled input) indicates that the improvements of
the fit by adding independent variables are limited in steady-state situations, but can be
substantial if the system faces frequent transient states.
This raises the question to what extent the differences in the fit (R2 values) of the clearing
functions predict the differences in the performance of order release models that use these
clearing functions. Exploring this would be a logical continuation of our research. The order
release models decide on the stationarity/non- stationarity of the system by determining timevarying order releases, and this decision can be flawed if the model underestimates transient
effects. It might well be possible that the substantial improvements that can be obtained from
two-dimensional clearing functions in one strongly non-stationary scenario points to a
relevant direction and should encourage future research on this topic.
Albey, E., Bilge, U., Uzsoy, R., 2011. Empirical Estimation of Multi-Dimensional Clearing
Functions for Multiple Product Single Machine Production Environments. Working paper,
Andersson, H., Axsaeter, S., Joensson, H., 1981. Hierarchical material requirements planning.
International Journal of Production Research, 19, 45-57.
Anli, O.M., Caramanis, M., Paschalidis, I.C., 2007. Tractable supply chain production planning,
modeling nonlinear lead time and quality of service constraints. Journal of Manufacturing
Armbruster, D., Fonteijn, J., Wienke, M., 2012. Modeling production planning and transient
clearing functions. Logistics Research, 5(3-4), 133-139.
Armbruster, D., Uzsoy, R., 2012. Multiple Time Scales in Production Planning: Clearing
Functions, Discrete-Event Simulation and Partial Differential Equations. Tutorials in operations
Asmundsson, J., Rardin, R., Uzsoy, R., 2006. Tractable nonlinear production planning models
for semiconductor wafer fabrication facilities. IEEE Transactions on Semiconductor
Asmundsson, J., Rardin, R., Turkseven, C., Uzsoy, R., 2009. Production planning with
resources subject to congestion. Naval Research Logistics, 56, 142-157.
Bakir, I., 2011. Linear Programming Formulations for Production Planning Problems with
Alternative Routings. Master thesis, North Carolina State University, USA.
Bang, J.Y., Kim, Y.D., 2010. Hierarchical production planning for semiconductor wafer
fabrication based on linear programming and discrete-event simulation. IEEE Transactions on
Automation Science and Engineering, 7(2), 326-336.
Bergamaschi, D., Cigolini, R., Perona, M., Portoli, A., 1997. Order review and release strategies
in a job shop environment: a review and a classification. International Journal of Production
Bertrand, J.W.M., Wortmann, J.C., Wijngaard, J., 1990. Production control: A structural and
design oriented approach. Elsevier, Amsterdam.
Bitran, G.R., Haas, E.A., Hax, A.C., 1982. Hierarchical Production Planning: A Two-Stage
System. Operations Research, 30(2), 232-251.
Boulaksil, Y., Fransoo, J.C., van Halm, E.N.G., 2009, Setting safety stocks in multi-stage
inventory systems under rolling horizon mathematical programming models. OR Spectrum, 31,
Breithaupt, J.W., Land, M., Nyhuis, P., 2002, The workload control concept: theory and
practical extensions of Load Oriented Order Release. Production Planning & Control, 13, 625638.
Buzacott, J.A., Shanthikumar, J.G., 1994. Safety Stock Versus Safety Times in MRP Controlled
Production Systems, Management Science, 40(12), 1678–1689.
Byrne, M.D., Bakir, M.A., 1999. Production Planning Using a Hybrid Simulation-Analytical
Approach. International Journal of Production Economics, 59, 305-311.
Byrne, M.D., Hossain, M.M., 2005. Production Planning: An Improved Hybrid Approach.
International Journal of Production Economics, 93-94, 225-229.
Caramanis, M., Pan, H., Anli, O.M., 2001. A Closed-Loop Approach to Efficient and Stable
Supply Chain Coordination in Complex Stochastic Manufacturing. Proceedings of the American
Control Conference. Arlington, VA., 1381-1388.
De Bodt, M., Van Wassenhove, L., 1983. Cost increases due to demand uncertainty in MRP lot
De Kok, T., Fransoo, J., 2003. Planning supply chain operations: Definition and comparison of
planning concepts. In: De Kok, A.G., Graves S.C., (Eds.). Supply Chain Management: Design,
Coordination and Operation, Elsevier, Amsterdam, 597-675.
Fine, C., Graves, S.C., 1989. A tactical planning model for manufacturing subcomponents of
mainframe computers. Journal of Manufacturing and Operations Management, 2, 4-34.
Fleischmann, B., Meyr, H., 2003. Planning hierarchy, modelling and advanced planning
systems. Handbooks in Operations Research and Management Science, 11, 455–523.
Fu, M.C., 1994. Optimization via simulation: A review. Annals of Operations Research, 53,
Georgiadis, P., Michaloudis, C., 2002. Real-time production planning and control system for
job-shop manufacturing: A system dynamics analysis. European Journal of Operational
Gong, L., De Kok, T., Ding, J., 1994. Optimal lead times planning in a serial production system.
Grasso, E.T., Taylor, B.W.III., 1984. A simulation based investigation of supply/timing
uncertainty in MRP systems. International Journal of Production Research, 22(3), 485-497.
Graves, S.C., 1986. A tactical planning model for a job shop. Operations Research, 34, 522-533.
Kohler-Gudum, C., 2002. Managing variability in a supply chain. An inventory control
perspective. PhD thesis, Copenhagen Business School.
Hackman, S.T., Leachman, R.C., 1989. A general framework for modeling production.
Haeussler, S., Missbauer, H., 2014. Empirical validation of metamodels of work centres in order
release planning. . International Journal of Economics, 149, 102-116.
Hanssmann, F. and S. W. Hess (1960). "A Linear Programming Approach to Production and
Employment Scheduling." Management Technology 1(1): 46-51.
Hax, A.C., Candea, D., 1984. Production and Inventory Management. Prentice-Hall, Englewood
Hazra, M.M., Park, S.K., 1994. Characterizing a nonstationary M/G/1 queue using bode plots.
Proceedings of the 1994 Winter Simulation Conference, 377-382.
Helber, S., Schimmelpfeng, K., Stolletz, R., 2011a. Setting inventory levels of conwip flow
lines via linear programming. BuR: Business Research Official Open Access Journal of
Verband der Hochschullehrer für Betriebswirtschaft, 4(1), 98-115.
Helber, S., Schimmelpfeng, K., Stolletz, R., Lagershausen, S., 2011b. Using linear
programming to analyze and optimize stochastic flow lines. Annual Operations Research, 182,
Hendry, L.C., Kingsman, B.G., 1991. Job Release: Part of a Hierarchical System to Manage
Manufacturing Lead Times in Make-to- Order Companies. The Journal of the Operational
Hendry, L.C., Kingsman, B.G., 1993. Customer enquiry management: part of a hierarchical
system to control lead times in make-to-order companies. Journal of the Operational Research
Holt, C.C., Modigliani, F., Muth, J.F., Simon, H.A., 1960. Planning Production, Inventories and
Work Force. Prentice Hall, Englewood Cliffs, NJ.
Hopp, W.J., Spearman M.L., 2008. Factory Physics: FOundations of Manufacturing
Management. Irwin McGraw-Hill, Boston, MA.
Hung, Y., Leachman, R.C., 1996. A production planning methodology for semi- conductor
manufacturing based on iterative simulation and linear programming calculations. IEEE
Transactions on Semiconductor Manufacturing, 9(2), 257–269.
Hung, Y.F., Hou, M.C., 2001. A production planning approach based on iterations of linear
programming optimization and flow time prediction. Journal of the Chinese Institute of
Hwang, S., Uzsoy, R., 2005. A Single Stage Multi-Product Dynamic Lot Sizing Model with
Work in Process and Congestion. Research Report, School of Industrial Engineering, Purdue
Jansen, M.M., 2012. Anticipation in Supply Chain Operations Planning. PhD thesis, Eindhoven
Johnson, L.A., Montgomery, D.C., 1974. Operations Research in Production Planning,
Scheduling and Inventory Control. John Wiley, New York.
Kacar, N.B., Irdem, D.F., Uzsoy, R., 2012. An experimental comparison of production planning
using clearing functions and iterative linear programming-simulation algorithms. IEEE
Transactions on Semiconductor Manufacturing, 25(1), 104-117.
Kacar, N., Uzsoy, R., 2010. Estimating clearing functions from simulation data. Proceedings of
Kacar, N., Uzsoy, R., 2013. A comparison of multiple linear regression approaches for fitting
clearing functions to empirical dataInternational Journal of Production Research. Forthcoming,
Kanet, J.J., 1986. Toward a better understanding of lead times in MRP systems. Journal of
Karmarkar, U.S., 1989. Capacity loading and release planning with work in progress (WIP) and
lead times. Journal of Manufacturing and Operations Management, 2, 105-123.
Karmarkar, U.S., 1993. Manufacturing lead times, order release and capacity loading. In:
Graves S.C., Rinnooy Kan, A.H.G., Zipkin, P.H., (Eds.). Handbooks in Operations Research &
Kim, B., Kim, S., 2001. Extended model for a hybrid production planning approach.
International Journal of Production Economics, 73(2), 165–173.
Kingsman, B.G., Tatsiopoulos, I.P., Hendry, L.C., 1989. A structural methodology for
managing manufacturing lead times in make-to-order companies. European Journal of
Kingsman, B.G., 2000. Modelling input-output workload control for dynamic capacity planning
in production planning systems. International Journal of Production Economics, 68(1), 73–93.
Kohler-Gudum, C., De Kok, T., 2002. A safety stock adjustment procedure to enable target
service levels in simulation of generic inventory systems. Technical report, Eindhoven
Krishnan, M., Srinivasan, A., 2007. How do shop-floor supervisors allocate their time?.
International Journal of Production Economics, 105(1), 97-115.
Kvalseth, T.O., 1985. Cautionary Note about R2. The American Statistician, 39(4), 279-285.
Lambrecht, M.R., Muckstadt, J.A., Luyten, R., 1984. Protective Stocks in Multi-Stage
Production Systems. International Journal of Production Research, 22, 1001–1025.
Land, M., 2004. Workload Control in Job Shops, Grasping the Tap. Labyrinth Publications,
Lautenschlaeger, M., 1999. Mittelfristige Produktionsprogrammplanung mit auslastungs
abhängigen Vorlaufzeiten, Peter Lang, Frankfurt am Main.
Lawrence, S.R., Buss, A.H., 1995. Economic Analysis of Production Bottlenecks. Mathematical
2011. Aggregate modeling of manufacturing systems. In:
Kempf, K.G., Keskinocak, P., Uzsoy, R., (Eds.). Planning Production and Inventories in the
Extended Enterprise: A State of the Art Handbook. Berlin: Springer, 509–536.
Liu, J., Li, C., Yang, F., Wang, H., Uzsoy, R., 2011. Production planning for semiconductor
manufacturing via simulation optimization. Proceedings of the 2011 Winter Simulation
Lu, S.C.H., Ramaswamy, D., Kumar, P.R., 1994. Efficient scheduling policies to reduce mean
and variance of cycle-time in semiconductor manufacturing plants. IEEE Transactions on
Missbauer, H., 1998. Bestandsregelung als Basis fuer eine Neugestaltung von PPS-Systemen.
Missbauer, H., 1999. Die Implikationen durchlauforientierter Losgrößenbildung für die
Komplexität der Produktionsplanung und -steuerung. Zeitschrift für Betriebswirtschaft 69 (2),
Missbauer, H., 2002. Aggregate order release planning for time-varying demand. International
Journal of Production Research, 40(3), 699-718.
Missbauer, H., 2011. Order release planning with clearing functions: A queuing-theoretical
analysis of the clearing function concept. International Journal of Production Economics,
Missbauer, H., Uzsoy, R., 2011. Optimization models of production planning problems. In:
Kempf, K.G., Keskinocak, P., Uzsoy, R., (Eds.). Planning Production and Inventories in the
Extended Enterprise: A State of the Art Handbook. Berlin: Springer, 437-508.
Manne, A.S. 1957. A Note on the Modigliani-Hohn Production Smoothing Model. Management
Matsuura, H., Tsubone, H., 1993. Setting planned lead times in capacity requirements planning.
Journal of the Operational Research Society, 44(8), 809–816.
Matsuura, H., Tsubone, H., Kanezashi, M. 1996. Setting planned lead times for multi operation
jobs. European Journal of Operational Research, 88, 287–303.
Modigliani, F., Hohn, F.E., 1955. Production planning over time and the nature of the
expectation and planning horizon. Econometrica, 23(1), 46-66.
Molinder, A., 1997. Joint optimization of lot-sizes, safety stocks and safety lead times in a MRP
system. International Journal of Production Research, 35(4), 983–994.
Modigliani, F., Hohn, F.E., 1955. Production planning over time and the nature of the
expectation and planning horizon. Econometrica, 23(1), 46-66.
Noguera, J.H., Watson, E.F. 2006. Response surface analysis of a multi-product batch
processing facility using a simulation metamodel. International Journal of Production
O’Brien, R.M., 2007. A Caution Regarding Rules of Thumb for Variance Inflation Factors.
Odoni, A.R., Roth, E., 1983. An empirical investigation of the transient behavior of stationary
queueing systems. Operation Research 31(3), 432–455.
Orlicky, J., 1975. Material requirements planning: the new way of life in production and
inventory management. McGraw-Hill, New York.
Pahl, J., Voss, S., Woodruff, D.L., 2005. Production planning with load dependent lead times.
4OR: Quarterly Journal of Operational Research, 3, 257–302.
Pindyck, R.S., Rubinfeld, D.L., 1998. Econometric models and econometric forecasts. Boston,
Bestandsregelungskonzepten bei Kundenauftragsfertigung. Doctoral thesis, University of
Puergstaller, P., Missbauer, H., 2012. Rule-based vs. optimization-based order release in
workload control: A simulation study of a MTO manufacturer. International Journal of
Rao, U.S., Swaminathan, J.M., Zhang, J., 2005. Demand and production with uniform
guaranteed lead time. Production and Operations Management, 14(4), 400–412.
Riaño, G., 2003. Transient Behaviour of Stochastic Networks: Application to Production
Planning with Load-Dependent Lead Times. Thesis, Georgia Institute of Technology.
Schneeweiss, C., 2003. Distributed decision making. Springer, Berlin.
Selçuk, B., 2007. Dynamic Performance of Hierarchical Planning Systems: Modeling and
Evaluation with Dynamic Planned Lead Times. Ph.D. Thesis, Technische Universiteit
Selçuk, B., Fransoo, J., De Kok, T., 2008. Work-in-process clearing in supply chain operations
planning. IIE Transactions, 40(3), 206–220.
Spitter, J.M., de Kok, A.G., Dellaert, N.P., 2005a. Timing Production in LP Models in a Rolling
Schedule. International Journal of Production Economics, 93-94, 319-329.
Spitter, J.M., Hurkens, C.A.J., de Kok, A.G., Lenstra, J.K., Negenman, E.G., 2005b. Linear
Programming Models with Planned Lead Times for Supply Chain Operations Planning.
European Journal of Operational Research, 163, 706-720.
Srinivasan, A., Carey, M., Morton, T.E., 1988. Resource Pricing and Aggregate Scheduling in
Manufacturing Systems. Graduate School of Industrial Administration, Carnegie-Mellon
Stevenson, M., Hendry, L.C., 2006. Aggregate load-oriented workload control: a review and a
re-classification of a key approach. International Journal of Production Economics, 104(2),
Stadtler, H., Kilger, C., 2005. Supply Chain Management And Advanced Planning: Concepts,
Models, Software And Case Studies. Springer, Berlin.
Steele, D.C., Berry, W.L., Chapman, S.N., 1995. Planning and control in multi-cell
manufacturing. Decision Sciences, 26(1), 1-34.
Sugimori, Y.K., Kusukoki, F.C., Uchikawa, S., 1977. Toyota production system and kanban
system: materialization of just-in-time and respect-for-human system. International Journal of
Tabachnick, B.G., Fidell, L.S., 2007. Using Multivariate Statistics. Boston: Allyn and Bacon.
Tatsiopoulos, I.P., Kingsman, B.G., 1983. Lead time management. European Journal of
Teo, C.C., Bhatnagar, R., Graves, S.C., 2012. An application of master schedule smoothing and
planned lead time control. Production and Operations Management, 21(2), 211–223.
Thuerer, M., Stevenson, M., Silva, C., 2011. Three decades of workload control research: a
systematic review of the literature. International Journal of Production Research, 49(23), 69056935.
Turkseven, C.H., 2005. Computational evaluation of clearing functions for production planning
models. Master thesis, Purdue University.
Vepsalainen, A.P., Morton, T.E., 1988. Improving local priority rules with global lead-time
estimates: A simulation study. Journal of Manufacturing and Operations Management, 1, 102–
Vollmann, T.E., Berry, W.L., Whybark, D.C., Jacobs, F.R., 2005. Manufacturing
Planning and Control for Supply Chain Management. McGraw-Hill, New York.
Voss, S., Woodruff, D.L., 2003. Introduction to Computational Optimization Models for
Production Planning in a Supply Chain. Springer, Berlin.
Weeks, J.K., 1981. Optimizing planned lead times and delivery date. Proceedings of the 21st
American Production and Inventory Control Society Annual Meeting, pp. 177–188.
Whitin, T.M., 1954. Erich Schneider’s Inventory Control Analysis. Journal of the Operations
Research Society of America, 2(3), 329–334.
Whybark, D.C., Williams, J.G., 1976. Material requirements under uncertainty. Decision
Wiendahl, H., 1995. Load Oriented Manufacturing Control. Springer, Berlin.
Wight, O., 1970. Input/Output Control. A real handle on lead time. Production and Inventory
Wight, O., 1983. MRPII: Unlocking America's productivity potential. Williston, USA.
Wooldridge, J., 2006. Introductory Econometrics: A Modern Approach. Mason, OH.
Yano, C.A., 1987. Setting planning lead times in serial production systems with earliness costs.
