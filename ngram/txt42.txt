Management science is characterized by a scientific approach to managerial decision making. It attempts
to apply mathematical methods and the capabilities of modern computers to the difficult and unstructured
problems confronting modern managers. It is a young and novel discipline. Although its roots can be
traced back to problems posed by early civilizations, it was not until World War II that it became identified
as a respectable and well defined body of knowledge. Since then, it has grown at an impressive pace,
unprecedented for most scientific accomplishments; it is changing our attitudes toward decision-making, and
infiltrating every conceivable area of application, covering a wide variety of business, industrial, military, and
Management science has been known by a variety of other names. In the United States, operations
research has served as a synonym and it is used widely today, while in Britain operational research seems
to be the more accepted name. Some people tend to identify the scientific approach to managerial problemsolving under such other names as systems analysis, cost–benefit analysis, and cost-effectiveness analysis.
We will adhere to management science throughout this book.
Mathematical programming, and especially linear programming, is one of the best developed and most
used branches of management science. It concerns the optimum allocation of limited resources among
competing activities, under a set of constraints imposed by the nature of the problem being studied. These
constraints could reflect financial, technological, marketing, organizational, or many other considerations. In
broad terms, mathematical programming can be defined as a mathematical representation aimed at programming or planning the best possible allocation of scarce resources. When the mathematical representation uses
linear functions exclusively, we have a linear-programming model.
In 1947, George B. Dantzig, then part of a research group of the U.S. Air Force known as Project SCOOP
(Scientific Computation Of Optimum Programs), developed the simplex method for solving the general
linear-programming problem. The extraordinary computational efficiency and robustness of the simplex
method, together with the availability of high-speed digital computers, have made linear programming the
most powerful optimization method ever designed and the most widely applied in the business environment.
Since then, many additional techniques have been developed, which relax the assumptions of the linearprogramming model and broaden the applications of the mathematical-programming approach. It is this
spectrum of techniques and their effective implementation in practice that are considered in this book.
Since mathematical programming is only a tool of the broad discipline known as management science,
let us first attempt to understand the management-science approach and identify the role of mathematical
It is hard to give a noncontroversial definition of management science. As we have indicated before,
this is a rather new field that is renewing itself and changing constantly. It has benefited from contributions
originating in the social and natural sciences, econometrics, and mathematics, much of which escape the
rigidity of a definition. Nonetheless it is possible to provide a general statement about the basic elements of
Management science is characterized by the use of mathematical models in providing guidelines to
managers for making effective decisions within the state of the current information, or in seeking further
information if current knowledge is insufficient to reach a proper decision.
There are several elements of this statement that are deserving of emphasis. First, the essence of management science is the model-building approach—that is, an attempt to capture the most significant features of the
decision under consideration by means of a mathematical abstraction. Models are simplified representations
of the real world. In order for models to be useful in supporting management decisions, they have to be simple
to understand and easy to use. At the same time, they have to provide a complete and realistic representation
of the decision environment by incorporating all the elements required to characterize the essence of the
problem under study. This is not an easy task but, if done properly, it will supply managers with a formidable
tool to be used in complex decision situations.
Second, through this model-design effort, management science tries to provide guidelines to managers or,
in other words, to increase managers’ understanding of the consequences of their actions. There is never an
attempt to replace or substitute for managers, but rather the aim is to support management actions. It is critical,
then, to recognize the strong interaction required between managers and models. Models can expediently
and effectively account for the many interrelationships that might be present among the alternatives being
considered, and can explicitly evaluate the economic consequences of the actions available to managers within
the constraints imposed by the existing resources and the demands placed upon the use of those resources.
Managers, on the other hand, should formulate the basic questions to be addressed by the model, and then
interpret the model’s results in light of their own experience and intuition, recognizing the model’s limitations.
The complementarity between the superior computational capabilities provided by the model and the higher
judgmental capabilities of the human decision-maker is the key to a successful management-science approach.
Finally, it is the complexity of the decision under study, and not the tool being used to investigate the
decision-making process, that should determine the amount of information needed to handle that decision
effectively. Models have been criticized for creating unreasonable requirements for information. In fact,
this is not necessary. Quite to the contrary, models can be constructed within the current state of available
information and they can be used to evaluate whether or not it is economically desirable to gather additional
The subject of proper model design and implementation will be covered in detail in Chapter 5.
The management-science literature includes several approaches to classifying models. We will begin with a
categorization that identifies broad types of models according to the degree of realism that they achieve in
representing a given problem. The model categories can be illustrated as shown in Fig. 1.1.
The first model type is an operational exercise. This modeling approach operates directly with the real
environment in which the decision under study is going to take place. The modeling effort merely involves
designing a set of experiments to be conducted in that environment, and measuring and interpreting the results
of those experiments. Suppose, for instance, that we would like to determine what mix of several crude oils
should be blended in a given oil refinery to satisfy, in the most effective way, the market requirements for
final products to be delivered from that refinery. If we were to conduct an operational exercise to support that
decision, we would try different quantities of several combinations of crude oil types directly in the actual
refinery process, and observe the resulting revenues and costs associated with each alternative mix. After
performing quite a few trials, we would begin to develop an understanding of the relationship between the
crude oil input and the net revenue obtained from the refinery process, which would guide us in identifying
In order for this approach to operate successfully, it is mandatory to design experiments to be conducted
carefully, to evaluate the experimental results in light of errors that can be introduced by measurement inaccuracies, and to draw inferences about the decisions reached, based upon the limited number of observations
performed. Many statistical and optimization methods can be used to accomplish these tasks properly. The
essence of the operational exercise is an inductive learning process, characteristic of empirical research in the
natural sciences, in which generalizations are drawn from particular observations of a given phenomenon.
Operational exercises contain the highest degree of realism of any form of modeling approach, since
hardly any external abstractions or oversimplifications are introduced other than those connected with the
interpretation of the observed results and the generalizations to be drawn from them. However, the method
is exceedingly, usually prohibitively, expensive to implement. Moreover, in most cases it is impossible to
exhaustively analyze the alternatives available to the decision-maker. This can lead to severe suboptimization
in the final conclusions. For these reasons, operational exercises seldom are used as a pure form of modeling
practice. It is important to recognize, however, that direct observation of the actual environment underlies
most model conceptualizations and also constitutes one of the most important sources of data. Consequently,
even though they may not be used exclusively, operational exercises produce significant contributions to the
improvement of managerial decision-making.
The second type of model in this classification is gaming. In this case, a model is constructed that is an
abstract and simplified representation of the real environment. This model provides a responsive mechanism
to evaluate the effectiveness of proposed alternatives, which the decision-maker must supply in an organized
and sequential fashion. The model is simply a device that allows the decision-maker to test the performance
of the various alternatives that seem worthwhile to pursue. In addition, in a gaming situation, all the human
interactions that affect the decision environment are allowed to participate actively by providing the inputs
they usually are responsible for in the actual realization of their activities. If a gaming approach is used in our
previous example, the refinery process would be represented by a computer or mathematical model, which
The model should reflect, with an acceptable degree of accuracy, the relationships between the inputs and
outputs of the refinery process. Subsequently, all the personnel who participate in structuring the decision
process in the management of the refinery would be allowed to interact with the model. The production manager would establish production plans, the marketing manager would secure contracts and develop marketing
strategies, the purchasing manager would identify prices and sources of crude oil and develop acquisition
programs, and so forth. As before, several combinations of quantities and types of crude oil would be tried,
and the resulting revenues and cost figures derived from the model would be obtained, to guide us in formulating an optimal policy. Certainly, we have lost some degree of realism in our modeling approach with
respect to the operational exercise, since we are operating with an abstract environment, but we have retained
some of the human interactions of the real process. However, the cost of processing each alternative has been
reduced, and the speed of measuring the performance of each alternative has been increased.
Gaming is used mostly as a learning device for developing some appreciation for those complexities
inherent in a decision-making process. Several management games have been designed to illustrate how
marketing, production, and financial decisions interact in a competitive economy.
Simulation models are similar to gaming models except that all human decision-makers are removed from
the modeling process. The model provides the means to evaluate the performance of a number of alternatives, supplied externally to the model by the decision-maker, without allowing for human interactions at
intermediate stages of the model computation.
Like operational exercises and gaming, simulation models neither generate alternatives nor produce an
optimum answer to the decision under study. These types of models are inductive and empirical in nature;
they are useful only to assess the performance of alternatives identified previously by the decision-maker.
If we were to conduct a simulation model in our refinery example, we would program in advance a large
number of combinations of quantities and types of crude oil to be used, and we would obtain the net revenues
associated with each alternative without any external inputs of the decision-makers. Once the model results
were produced, new runs could be conducted until we felt that we had reached a proper understanding of the
Many simulation models take the form of computer programs, where logical arithmetic operations are
performed in a prearranged sequence. It is not necessary, therefore, to define the problem exclusively in
analytic terms. This provides an added flexibility in model formulation and permits a high degree of realism
to be achieved, which is particularly useful when uncertainties are an important aspect of the decision.
Finally, the fourth model category proposed in this framework is the analytical model. In this type of model,
the problem is represented completely in mathematical terms, normally by means of a criterion or objective,
which we seek to maximize or minimize, subject to a set of mathematical constraints that portray the conditions
under which the decisions have to be made. The model computes an optimal solution, that is, one that satisfies
all the constraints and gives the best possible value of the objective function.
In the refinery example, the use of an analytical model implies setting up as an objective the maximization
of the net revenues obtained from the refinery operation as a function of the types and quantities of the crude
oil used. In addition, the technology of the refinery process, the final product requirements, and the crude
oil availabilities must be represented in mathematical terms to define the constraints of our problem. The
solution to the model will be the exact amount of each available crude-oil type to be processed that will
maximize the net revenues within the proposed constraint set. Linear programming has been, in the last two
decades, the indisputable analytical model to use for this kind of problem.
Analytical models are normally the least expensive and easiest models to develop. However, they introduce the highest degree of simplification in the model representation. As a rule of thumb, it is better to be
as much to the right as possible in the model spectrum (no political implication intended!), provided that the
resulting degree of realism is appropriate to characterize the decision under study.
Most of the work undertaken by management scientists has been oriented toward the development and
implementation of analytical models. As a result of this effort, many different techniques and methodologies
have been proposed to address specific kinds of problems. Table 1.1 presents a classification of the most
important types of analytical and simulation models that have been developed.
Table 1.1 Classification of Analytical and Simulation Models
Statistics and subjective assessment are used in all models to determine values for
parameters of the models and limits on the alternatives.
The classification presented in Table 1.1 is not rigid, since strategy evaluation models are used for
improving decisions by trying different alternatives until one is determined that appears ‘‘best.’’ The important
distinction of the proposed classification is that, for strategy evaluation models, the user must first choose
and construct the alternative and then evaluate it with the aid of the model. For strategy generation models,
the alternative is not completely determined by the user; rather, the class of alternatives is determined by
establishing constraints on the decisions, and then an algorithmic procedure is used to automatically generate
the ‘‘best’’ alternative within that class. The horizontal classification should be clear, and is introduced because
the inclusion of uncertainty (or not) generally makes a substantial difference in the type and complexity of
the techniques that are employed. Problems involving uncertainty are inherently more difficult to formulate
This book is devoted to mathematical programming—a part of management science that has a common
base of theory and a large range of applications. Generally, mathematical programming includes all of
the topics under the heading of strategy generation except for decision theory and control theory. These
two topics are entire disciplines in themselves, depending essentially on different underlying theories and
techniques. Recently, though, the similarities between mathematical programming and control theory are
becoming better understood, and these disciplines are beginning to merge. In mathematical programming,
the main body of material that has been developed, and more especially applied, is under the assumption of
certainty. Therefore, we concentrate the bulk of our presentation on the topics in the upper righthand corner
of Table 1.1. The critical emphasis in the book is on developing those principles and techniques that lead
to good formulations of actual decision problems and solution procedures that are efficient for solving these
In order to provide a preliminary understanding of the types of problems to which mathematical programming
can be applied, and to illustrate the kind of rationale that should be used in formulating linear-programming
problems, we will present in this section three highly simplified examples and their corresponding linearprogramming formulations.
Charging a Blast Furnace∗ An iron foundry has a firm order to produce 1000 pounds of castings containing
at least 0.45 percent manganese and between 3.25 percent and 5.50 percent silicon. As these particular castings
are a special order, there are no suitable castings on hand. The castings sell for $0.45 per pound. The foundry
has three types of pig iron available in essentially unlimited amounts, with the following properties:
Excel spreadsheet available at http://web.mit.edu/15.053/www/Sect1.3_Blast_Furnace.xls
Further, the production process is such that pure manganese can also be added directly to the melt. The costs
It costs 0.5 cents to melt down a pound of pig iron. Out of what inputs should the foundry produce the castings
The first step in formulating a linear program is to define the decision variables of the problem. These are
the elements under the control of the decision-maker, and their values determine the solution of the model.
In the present example, these variables are simple to identify, and correspond to the number of pounds of pig
A, pig B, pig C, and pure manganeseto be used in the production of castings. Specifically, let us denote the
The next step to be carried out in the formulation of the problem is to determine the criterion the decisionmaker will use to evaluate alternative solutions to the problem. In mathematical-programming terminology,
this is known as the objective function. In our case, we want to maximize the total profit resulting from the
production of 1000 pounds of castings. Since we are producing exactly 1000 pounds of castings, the total
income will be the selling price per pound times 1000 pounds. That is:
To determine the total cost incurred in the production of the alloy, we should add the melting cost of
$0.005/pound to the corresponding cost of each type of pig iron used. Thus, the relevant unit cost of the pig
iron, in dollars per thousand pounds, is:
and the total profit we want to maximize is determined by the expression:
Total profit = Total income − Total cost.
Total profit = 450 − 26x1 − 30x2 − 20x3 − 8x4 .
It is worthwhile noticing in this example that, since the amount of castings to be produced was fixed in
advance, equal to 1000 pounds, the maximization of the total profit, given by Eq. (2), becomes completely
equivalent to the minimization of the total cost, given by Eq. (1).
We should now define the constraints of the problem, which are the restrictions imposed upon the values
of the decision variables by the characteristics of the problem under study. First, since the producer does not
want to keep any supply of the castings on hand, we should make the total amount to be produced exactly
Next, the castings should contain at least 0.45 percent manganese, or 4.5 pounds in the 1000 pounds of
castings to be produced. This restriction can be expressed as follows:
The term 4.5x1 is the pounds of manganese contributed by pig iron A since each 1000 pounds of this pig iron
contains 4.5 pounds of manganese. The x2 , x3 , and x4 terms account for the manganese contributed by pig
iron B, by pig iron C, and by the addition of pure manganese.
Similarly, the restriction regarding the silicon content can be represented by the following inequalities:
Constraint (5) establishes that the minimum silicon content in the castings is 3.25 percent, while constraint
(6) indicates that the maximum silicon allowed is 5.5 percent.
Finally, we have the obvious nonnegativity constraints:
If we choose to minimize the total cost given by Eq. (1), the resulting linear programming problem can
Often, this algebraic formulation is represented in tableau form as follows:
The bottom line of the tableau specifies the optimal solution to this problem. The solution includes
the values of the decision variables as well as the minimum cost attained, $25.54 per thousand pounds; this
solution was generated using a commercially available linear-programming computer system. The underlying
solution procedure, known as the simplex method, will be explained in Chapter 2.
Fig. 1.2 Optimal cost of castings as a function of the cost of pure manganese.
It might be interesting to see how the solution and the optimal value of the objective function is affected
by changes in the cost of manganese. In Fig. 1.2 we give the optimal value of the objective function as this
cost is varied. Note that if the cost of manganese rises above $9.86/lb., then no pure manganese is used. In the
range from $0.019/lb. to $9.86 lb., the values of the decision variables remain unchanged. When manganese
becomes extremely inexpensive, less than $0.019/lb., a great deal of manganese is used, in conjuction with
Similar analyses can be performed to investigate the behavior of the solution as other parameters of the
problem (for example, minimum allowed silicon content) are varied. These results, known as parametric
analysis, are reported routinely by commercial linear-programming computer systems. In Chapter 3 we will
show how to conduct such analyses in a comprehensive way.
Portfolio Selection∗ A portfolio manager in charge of a bank portfolio has $10 million to invest. The
securities available for purchase, as well as their respective quality ratings, maturities, and yields, are shown
The bank places the following policy limitations on the portfolio manager’s actions:
1. Government and agency bonds must total at least $4 million.
2. The average quality of the portfolio cannot exceed 1.4 on the bank’s quality scale. (Note that a low
number on this scale means a high-quality bond.)
3. The average years to maturity of the portfolio must not exceed 5 years.
Assuming that the objective of the portfolio manager is to maximize after-tax earnings and that the tax rate is
50 percent, what bonds should he purchase? If it became possible to borrow up to $1 million at 5.5 percent
∗ Excel spreadsheet available at http://web.mit.edu/15.053/www/Sect1.3_Portfolio_Selection.xls
before taxes, how should his selection be changed?
Leaving the question of borrowed funds aside for the moment, the decision variables for this problem are
simply the dollar amount of each security to be purchased:
= Amount to be invested in bond A; in millions of dollars.
= Amount to be invested in bond B; in millions of dollars.
= Amount to be invested in bond C; in millions of dollars.
= Amount to be invested in bond D; in millions of dollars.
= Amount to be invested in bond E; in millions of dollars.
We must now determine the form of the objective function. Assuming that all securities are purchased at par
(face value) and held to maturity and that the income on municipal bonds is tax-exempt, the after-tax earnings
z = 0.043xA + 0.027xB + 0.025xC + 0.022xD + 0.045xE .
Now let us consider each of the restrictions of the problem. The portfolio manager has only a total of ten
million dollars to invest, and therefore:
Further, of this amount at least $4 million must be invested in government and agency bonds. Hence,
The average quality of the portfolio, which is given by the ratio of the total quality to the total value of the
Note that the inequality is less-than-or-equal-to, since a low number on the bank’s quality scale means a
high-quality bond. By clearing the denominator and re-arranging terms, we find that this inequality is clearly
0.6xA + 0.6xB − 0.4xC − 0.4xD + 3.6xE ≤ 0.
The constraint on the average maturity of the portfolio is a similar ratio. The average maturity must not
which is equivalent to the linear constraint:
Note that the two ratio constraints are, in fact, nonlinear constraints, which would require sophisticated
computational procedures if included in this form. However, simply multiplying both sides of each ratio
constraint by its denominator (which must be nonnegative since it is the sum of nonnegative variables)
transforms this nonlinear constraint into a simple linear constraint. We can summarize our formulation in
The values of the decision variables and the optimal value of the objective function are again given in the last
Now consider the additional possibility of being able to borrow up to $1 million at 5.5 percent before
taxes. Essentially, we can increase our cash supply above ten million by borrowing at an after-tax rate of 2.75
percent. We can define a new decision variable as follows:
y = amount borrowed in millions of dollars.
There is an upper bound on the amount of funds that can be borrowed, and hence
The cash constraint is then modified to reflect that the total amount purchased must be less than or equal to
the cash that can be made available including borrowing:
Now, since the borrowed money costs 2.75 percent after taxes, the new after-tax earnings are:
z = 0.043xA + 0.027xB + 0.025xC + 0.022xD + 0.045xE − 0.0275y.
We summarize the formulation when borrowing is allowed and give the solution in tableau form as follows:
Production and Assembly A division of a plastics company manufactures three basic products: sporks,
packets, and school packs. A spork is a plastic utensil which purports to be a combination spoon, fork, and
knife. The packets consist of a spork, a napkin, and a straw wrapped in cellophane. The school packs are
boxes of 100 packets with an additional 10 loose sporks included.
Production of 1000 sporks requires 0.8 standard hours of molding machine capacity, 0.2 standard hours
of supervisory time, and $2.50 in direct costs. Production of 1000 packets, including 1 spork, 1 napkin, and 1
straw, requires 1.5 standard hours of the packaging-area capacity, 0.5 standard hours of supervisory time, and
$4.00 in direct costs. There is an unlimited supply of napkins and straws. Production of 1000 school packs
requires 2.5 standard hours of packaging-area capacity, 0.5 standard hours of supervisory time, 10 sporks,
Any of the three products may be sold in unlimited quantities at prices of $5.00, $15.00, and $300.00 per
thousand, respectively. If there are 200 hours of production time in the coming month, what products, and
how much of each, should be manufactured to yield the most profit?
The first decision one has to make in formulating a linear programming model is the selection of the
proper variables to represent the problem under consideration. In this example there are at least two different
sets of variables that can be chosen as decision variables. Let us represent them by x’s and y’s and define
x1 = Total number of sporks produced in thousands,
x2 = Total number of packets produced in thousands,
x3 = Total number of school packs produced in thousands,
y1 = Total number of sporks sold as sporks in thousands,
y2 = Total number of packets sold as packets in thousands,
y3 = Total number of school packs sold as school packs in thousands.
We can determine the relationship between these two groups of variables. Since each packet needs one
spork, and each school pack needs ten sporks, the total number of sporks sold as sporks is given by:
Similarly, for the total number of packets sold as packets we have:
Finally, since all the school packs are sold as such, we have:
From Eqs. (7), (8), and (9) it is easy to express the x’s in terms of the y’s, obtaining:
As a matter of exercise, let us formulate the linear program corresponding to the present example in two
forms: first, using the x’s as decision variables, and second, using the y’s as decision variables.
The objective function is easily determined in terms of both y- and x-variables by using the information
provided in the statement of the problem with respect to the selling prices and the direct costs of each of the
units produced. The total profit is given by:
Total profit = 5y1 + 15y2 + 300y3 − 2.5x1 − 4x2 − 8x3 .
Equations (7), (8), and (9) allow us to express this total profit in terms of the x-variables alone. After
Now we have to set up the restrictions imposed by the maximum availability of 200 hours of production
time. Since the sporks are the only items requiring time in the injection-molding area, and they consume 0.8
standard hours of production per 1000 sporks, we have:
In addition to these constraints, we have to make sure that the number of sporks, packets, and school packs
sold as such (i.e., the y-variables) are nonnegative. Therefore, we have to add the following constraints:
Finally, we have the trivial nonnegativity conditions
Note that, besides the nonnegativity of all the variables, which is a condition always implicit in the
methods of solution in linear programming, this form of stating the problem has generated six constraints,
(15) to (20). If we expressed the problem in terms of the y-variables, however, conditions (18) to (20)
correspond merely to the nonnegativity of the y-variables, and these constraints are automatically guaranteed
because the y’s are nonnegative and the x’s expressed by (10), (11), and (12), in terms of the y’s, are the sum
of nonnegative variables, and therefore the x’s are always nonnegative.
By performing the proper changes of variables, it is easy to see that the linear-programming formulation
in terms of the y-variables is given in tableau form as follows:
Since the computation time required to solve a linear programming problem increases roughly with the
cube of the number of rows of the problem, in this example the y’s constitute better decision variables than
the x’s. The values of the x’s are easily determined from Eqs. (10), (11), and (12).
Although in this introductory chapter we are not going to discuss the details of computational procedures for
solving mathematical programming problems, we can gain some useful insight into the characteristics of the
procedures by looking at the geometry of a few simple examples. Since we want to be able to draw simple
graphs depicting various possible situations, the problem initially considered has only two decision variables.
The Problem∗ Suppose that a custom molder has one injection-molding machine and two different dies to
fit the machine. Due to differences in number of cavities and cycle times, with the first die he can produce 100
cases of six-ounce juice glasses in six hours, while with the second die he can produce 100 cases of ten-ounce
fancy cocktail glasses in five hours. He prefers to operate only on a schedule of 60 hours of production per
week. He stores the week’s production in his own stockroom where he has an effective capacity of 15,000
cubic feet. A case of six-ounce juice glasses requires 10 cubic feet of storage space, while a case of ten-ounce
cocktail glasses requires 20 cubic feet due to special packaging. The contribution of the six-ounce juice
glasses is $5.00 per case; however, the only customer available will not accept more than 800 cases per week.
The contribution of the ten-ounce cocktail glasses is $4.50 per case and there is no limit on the amount that
can be sold. How many cases of each type of glass should be produced each week in order to maximize the
We first define the decision variables and the units in which they are measured. For this problem we are
interested in knowing the optimal number of cases of each type of glass to produce per week. Let
x1 = Number of cases of six-ounce juice glasses produced per
week (in hundreds of cases per week), and
x2 = Number of cases of ten-ounce cocktail glasses produced
per week (in hundreds of cases per week).
Excel spreadsheet available at http://web.mit.edu/15.053/www/Sect1.4_Glass_Problem.xls
The objective function is easy to establish since we merely want to maximize the contribution to overhead,
since the decision variables are measured in hundreds of cases per week. We can write the constraints in
a straightforward manner. Because the custom molder is limited to 60 hours per week, and production of
six-ounce juice glasses requires 6 hours per hundred cases while production of ten-ounce cocktail glasses
requires 5 hours per hundred cases, the constraint imposed on production capacity in units of production
Now since the custom molder has only 15,000 cubic feet of effective storage space and a case of six-ounce
juice glasses requires 10 cubic feet, while a case of ten-ounce cocktail glasses requires 20 cubic feet, the
constraint on storage capacity, in units of hundreds of cubic feet of space per week, is:
Finally, the demand is such that no more than 800 cases of six-ounce juice glasses can be sold each week.
Since the decision variables must be nonnegative,
and we have the following linear program:
Graphical Representation of the Decision Space
We now look at the constraints of the above linear-programming problem. All of the values of the decision
variables x1 and x2 that simultaneously satisfy these constraints can be represented geometrically by the
shaded area given in Fig. 1.3. Note that each line in this figure is represented by a constraint expressed as
an equality. The arrows associated with each line show the direction indicated by the inequality sign in each
constraint. The set of values of the decision variables x1 and x2 that simultaneously satisfy all the constraints
indicated by the shaded area are the feasible production possibilities or feasible solutions to the problem.
Any production alternative not within the feasible region must violate at least one of the constraints of the
problem. Among these feasible production alternatives, we want to find the values of the decision variables
x1 and x2 that maximize the resulting contribution to overhead.
To find an optimal solution we first note that any point in the interior of the feasible region cannot be an
optimal solution since the contribution can be increased by increasing either x1 or x2 or both. To make this
point more clearly, let us rewrite the objective function
Fig. 1.3 Graphical representation of the feasible region.
If z is held fixed at a given constant value, this expression represents a straight line, where 450
intercept with the x2 axis (i.e., the value of x2 when x1 = 0), and − 500
value of x2 corresponding to a unit increase in the value of x1 ). Note that the slope of this straight line is
constant, independent of the value of z. As the value of z increases, the resulting straight lines move parallel
to themselves in a northeasterly direction away from the origin (since the intercept 450
increases, and the slope is constant at − 450 ). Figure 1.4 shows some of these parallel lines for specific values
of z. At the point labeled P1, the line intercepts the farthest point from the origin within the feasible region,
and the contribution z cannot be increased any more. Therefore, point P1 represents the optimalsolution.
Since reading the graph may be difficult, we can compute the values of the decision variables by recognizing
that point P1 is determined by the intersection of the production-capacity constraint and the storage-capacity
yields x1 = 6 73 , x2 = 4 27 ; and substituting these values into the objective function yields z = 5142 67 as the
maximum contribution that can be attained.
Note that the optimal solution is at a corner point, or vertex, of the feasible region. This turns out to be a
general property of linear programming: if a problem has an optimal solution, there is always a vertex that is
optimal. The simplex method for finding an optimal solution to a general linear program exploits this property
by starting at a vertex and moving from vertex to vertex, improving the value of the objective function with
each move. In Fig. 1.4, the values of the decision variables and the associated value of the objective function
are given for each vertex of the feasible region. Any procedure that starts at one of the vertices and looks for
an improvement among adjacent vertices would also result in the solution labeled P1.
An optimal solution of a linear program in its simplest form gives the value of the criterion function, the
levels of the decision variables, and the amount of slack or surplus in the constraints. In the custom-molder
example, the criterion was maximum contribution, which turned out to be z = $5142 67 ; the levels of the
decision variables are x1 = 6 73 hundred cases of six-ounce juice glasses and x2 = 4 27 hundred cases of
ten-ounce cocktail glasses. Only the constraint on demand for six-ounce juice glasses has slack in it, since
the custom molder could have chosen to make an additional 1 47 hundred cases if he had wanted to decrease
the production of ten-ounce cocktail glasses appropriately.
Solving a linear program usually provides more information about an optimal solution than merely the values
of the decision variables. Associated with an optimal solution are shadow prices (also referred to as dual
variables, marginal values, or pi values) for the constraints. The shadow price on a particular constraint
represents the change in the value of the objective function per unit increase in the righthand-side value of
that constraint. For example, suppose that the number of hours of molding-machine capacity was increased
from 60 hours to 61 hours. What is the change in the value of the objective function from such an increase?
Since the constraints on production capacity and storage capacity remain binding with this increase, we need
to find a new optimal solution. The new values of the decision variables are x1 = 6 57 and x2 = 4 17 , and the
z = 500x1 + 450x2 = 500 6 57 + 450 4 17 = 5,221 37 .
The shadow price associated with the constraint on production capacity then becomes:
The shadow price associated with production capacity is $78 47 per additional hour of production time. This
is important information since it implies that it would be profitable to invest up to $78 47 each week to increase
production time by one hour. Note that the units of the shadow price are determined by the ratio of the units
of the objective function and the units of the particular constraint under consideration.
Fig. 1.5 Range on the slope of the objective function.
We can perform a similar calculation to find the shadow price 2 67 associated with the storage-capacity
constraint, implying that an addition of one hundred cubic feet of storage capacity is worth $2 67 . The shadow
price associated with the demand for six-ounce juice glasses clearly must be zero. Since currently we are not
producing up to the 800-case limit, increasing this limit will certainly not change our decision and therefore
Finally, we must consider the shadow prices associated with the nonnegativity constraints. These shadow
prices often are called the reduced costs and usually are reported separately from the shadow prices on the
other constraints; however, they have the identical interpretation. For our problem, increasing either of the
nonnegativity constraints separately will not affect the optimal solution, so the values of the shadow prices,
or reduced costs, are zero for both nonnegativity constraints.
The data for a linear program may not be known with certainty or may be subject to change. When solving linear programs, then, it is natural to ask about the sensitivity of the optimal solution to variations in the data. For
example, over what range can a particular objective-function coefficient vary without changing the optimal solution?
It is clear from Fig. 1.5 that some variation of the contribution coefficients is possible without a change
in the optimal levels of the decision variables. Throughout our discussion of shadow prices, we assumed that
the constraints defining the optimal solution did not change when the values of their righthand sides were
varied. Further, when we made changes in the righthand-side values we made them one at a time, leaving
the remaining coefficients and values in the problem unchanged. The question naturally arises, over what
range can a particular righthand-side value change without changing the shadow prices associated with that
constraint? These questions of simple one-at-a-time changes in either the objective-function coefficients or
the right-hand-side values are determined easily and therefore usually are reported in any computer solution.
Changes in the Coefficients of the Objective Function
We will consider first the question of making one-at-a-time changes in the coefficients of the objective function.
Suppose we consider the contribution per one hundred cases of six-ounce juice glasses, and determine the
range for that coefficient such that the optimal solution remains unchanged. From Fig. 1.5, it should be clear
that the optimal solution remains unchanged as long as the slope of the objective function lies between the
slope of the constraint on production capacity and the slope of the constraint on storage capacity.
We can determine the range on the coefficient of contribution from six-ounce juice glasses, which we
denote by c1 , by merely equating the respective slopes. Assuming the remaining coefficients and values in
the problem remain unchanged, we must have:
Production slope ≤ Objective slope ≤ Storage slope.
Since z = c1 x1 + 450x2 can be written as x2 = (z/450) − (c1 /450)x1 , we see, as before, that the objective
Similarly, by holding c1 fixed at 500, we can determine the range of the coefficient of contribution from
ten-ounce cocktail glasses, which we denote by c2 :
where the current value of c2 = 450. The objective ranges are therefore the range over which a particular
objective coefficient can be varied, all other coefficients and values in the problem remaining unchanged, and
have the optimal solution (i.e., levels of the decision variables) remain unchanged.
From Fig. 1.5 it is clear that the same binding constraints will define the optimal solution. Although
the levels of the decision variables remain unchanged, the value of the objective function, and therefore the
shadow prices, will change as the objective-function coefficients are varied.
It should now be clear that an optimal solution to a linear program is not always unique. If the objective
function is parallel to one of the binding constraints, then there is an entire set of optimal solutions. Suppose
It would be parallel to the line determined by the production-capacity constraint; and all levels of the decision
variables lying on the line segment joining the points labeled P1 and P2 in Fig. 1.6 would be optimal solutions.
Changes in the Righthand-Side Values of the Constraints
Now consider the question of making one-at-a-time changes in the righthand-side values of the constraints.
Suppose that we want to find the range on the number of hours of production capacity that will leave all of
the shadow prices unchanged. The essence of our procedure for computing the shadow prices was to assume
that the constraints defining the optimal solution would remain the same even though a righthand-side value
was being changed. First, let us consider increasing the number of hours of production capacity. How much
can the production capacity be increased and still give us an increase of $78 47 per hour of increase? Looking
at Fig. 1.7, we see that we cannot usefully increase production capacity beyond the point where storage
capacity and the limit on demand for six-ounce juice glasses become binding. This point is labeled P3 in
Fig. 1.7. Any further increase in production hours would be worth zero since they would go unused. We can
determine the number of hours of production capacity corresponding to the point labeled P3, since this point
Fig. 1.6 Objective function coincides with a constraint.
Fig. 1.7 Ranges on the righthand-side values.
is characterized by x1 = 8 and x2 = 3 21 . Hence, the upper bound on the range of the righthand-side value
for production capacity is 6(8) + 5(3 21 ) = 65 21 hours.
Alternatively, let us see how much the capacity can be decreased before the shadow prices change. Again
looking at Fig. 1.7, we see that we can decrease production capacity to the point where the constraint on
storage capacity and the nonnegativity constraint on ten-ounce cocktail glasses become binding. This point
is labeled P4 in Fig. 1.7 and corresponds to only 37 21 hours of production time per week, since x1 = 0 and
x2 = 7 21 . Any further decreases in production capacity beyond this point would result in lost contribution of
$90 per hour of further reduction. This is true since at this point it is optimal just to produce as many cases
of the ten-ounce cocktail glasses as possible while producing no six-ounce juice glasses at all. Each hour
of reduced production time now causes a reduction of 15 of one hundred cases of ten-ounce cocktail glasses
valued at $450, i.e., 15 (450) = 90. Hence, the range over which the shadow prices remain unchanged is the
range over which the optimal solution is defined by the same binding constraints. If we take the righthandside value of production capacity to be b1 , the range on this value, such that the shadow prices will remain
where the current value of production capacity b1 = 60 hours. It should be emphasized again that this
righthand-side range assumes that all other righthand-side values and all variable coefficients in the problem
In a similar manner we can determine the ranges on the righthand-side values of the remaining constraints:
Observe that there is no upper bound on six-ounce juice-glass demand b3 , since this constraint is nonbinding
We have seen that both cost and righthand-side ranges are valid if the coefficient or value is varied by
itself, all other variable coefficients and righthand-side values being held constant. The objective ranges
are the ranges on the coefficients of the objective function, varied one at a time, such that the levels of the
decision variables remain unchanged in the optimal solution. The righthand-side ranges are the ranges on the
righthand-side values, varied one at a time, such that the shadow prices associated with the optimal solution
remain unchanged. In both instances, the ranges are defined so that the binding constraints at the optimal
Until now we have described a number of the properties of an optimal solution to a linear program, assuming
first that there was such a solution and second that we were able to find it. It could happen that a linear program
has no feasible solution. An infeasible linear program might result from a poorly formulated problem, or from
a situation where requirements exceed the capacity of the existing available resources. Suppose, for example,
that an additional constraint was added to the model imposing a minimum on the number of production hours
worked. However, in recording the data, an error was made that resulted in the following constraint being
The graphical representation of this error is given in Fig. 1.8.
The shading indicates the direction of the inequalities associated with each constraint. Clearly, there are
no points that satisfy all the constraints simultaneously, and the problem is therefore infeasible. Computer
routines for solving linear programs must be able to tell the user when a situation of this sort occurs. In
general, on large problems it is relatively easy to have infeasibilities in the initial formulation and not know
it. Once these infeasibilities are detected, the formulation is corrected.
Another type of error that can occur is somewhat less obvious but potentially more costly. Suppose that
we consider our original custom-molder problem but that a control message was typed into the computer
incorrectly so that we are, in fact, attempting to solve our linear program with ‘‘greater than or equal to’’
constraints instead of ‘‘less than or equal to’’ constraints. We would then have the following linear program:
The graphical representation of this error is given in Fig. 1.9.
Fig. 1.8 An infeasible group of constraints.
Clearly, the maximum of the objective function is now unbounded. That is, we apparently can make
our contribution arbitrarily large by increasing either x1 or x2 . Linear-programming solution procedures also
detect when this kind of error has been made, and automatically terminate the calculations indicating the
direction that produces the unbounded objective value.
In linear programming, the decision space is continuous, in the sense that fractional answers always are
allowed. This is contrasted with discrete or integer programming, where integer values are required for
some or all variables. In our custom-molding example, if the customer will accept each product only in
even hundred-case lots, in order to ease his reordering situation, and if, further, we choose not to store either
product from one week to the next, we must seek an integer solution to our problem. Our initial reaction is
to round off our continuous solution, yielding
which in this case is feasible, since we are rounding down. The resulting value of contribution is z = $4800.
Is this the optimal integer solution? We clearly could increase the total contribution if we could round either
x1 or x2 up instead of down. However, neither the point x1 = 7, x2 = 4, nor the point x1 = 6, x2 = 5 is
Another alternative would be to start with our trial solution x1 = 6, x2 = 4, and examine ‘‘nearby’’
solutions such as x1 = 5, x2 = 5, which turns out to be feasible and which has a contribution of z = $4750,
not as high as our trial solution. Another ‘‘nearby’’ solution is x1 = 7, x2 = 3, which is also feasible
and has a contribution z = $4850. Since this integer solution has a higher contribution than any previous
integer solution, we can use it as our new trial solution. It turns out that the optimal integer solution for our
with a contribution of z = $4900. It is interesting to note that this solution is not particularly ‘‘nearby’’ the
optimal continuous solution x1 = 6 73 , x2 = 4 27 .
Basically, the integer-programming problem is inherently difficult to solve and falls in the domain of
combinatorial analysis rather than simple linear programming. Special algorithms have been developed to
find optimal integer solutions; however, the size of problem that can be solved successfully by these algorithms
is an order of magnitude smaller than the size of linear programs that can easily be solved. Whenever it is
possible to avoid integer variables, it is usually a good idea to do so. Often what at first glance seem to be integer
variables can be interpreted as production or operating rates, and then the integer difficulty disappears. In our
example, if it is not necessary to ship in even hundred-case lots, or if the odd lots are shipped the following
week, then it still is possible to produce at rates x1 = 6 73 and x2 = 4 27 hundred cases per week. Finally, in
any problem where the numbers involved are large, rounding to a feasible integer solution usually results in
In linear programming the variables are continuous and the functions involved are linear. Let us now consider
the decision problem of the custom molder in a slightly altered form. Suppose that the interpretation of
production in terms of rates is acceptable, so that we need not find an integer solution; however, we now have
a nonlinear objective function. We assume that the injection-molding machine is fairly old and that operating
near capacity results in a reduction in contribution per unit for each additional unit produced, due to higher
maintenance costs and downtime. Assume that the reduction is $0.05 per case of six-ounce juice glasses and
$0.04 per case of ten-ounce cocktail glasses. In fact, let us assume that we have fit the following functions to
per-unit contribution for each type of glass:
The resulting total contribution is then given by:
Hence, we have the following nonlinear programming problem to solve:
This situation is depicted in Fig. 1.10. The curved lines represent lines of constant contribution.
Note that the optimal solution is no longer at a corner point of the feasible region. This property alone
makes finding an optimal solution much more difficult than in linear programming. In this situation, we
cannot merely move from vertex to vertex, looking for an improvement at each iteration. However, this
particular problem has the property that, if you have a trial solution and cannot find an improving direction
to move in, then the trial solution is an optimal solution. It is this property that is generally exploited in
computational procedures for nonlinear programs.
A CLASSIFICATION OF MATHEMATICAL PROGRAMMING MODELS
We are now in a position to provide a general statement of the mathematical programming problem and
formally summarize definitions and notation introduced previously. Let us begin by giving a formal representation of the general linear programming model.
In mathematical terms, the linear programming model can be expressed as the maximization (or minimization) of an objective (or criterion) function, subject to a given set of linear constraints. Specifically, the
linear programming problem can be described as finding the values of n decision variables, x1 , x2 , . . . , xn ,
such that they maximize the objective function z where
A Classification of Mathematical Programming Models
where c j , ai j , and bi are given constants.
It is easy to provide an immediate interpretation to the general linear-programming problem just stated
in terms of a production problem. For instance, we could assume that, in a given production facility, there
are n possible products we may manufacture; for each of these we want to determine the level of production
which we shall designate by x1 , x2 , . . . , xn . In addition, these products compete for m limited resources,
which could be manpower availability, machine capacities, product demand, working capital, and so forth,
and are designated by b1 , b2 , . . . , bm . Let ai j be the amount of resource i required by product j and let c j be
the unit profit of product j. Then the linear-programming model seeks to determine the production quantity
of each product in such a way as to maximize the total resulting profit z (Eq. 22), given that the available
resources should not be exceeded (constraints 23), and that we can produce only positive or zero amounts of
Linear programming is not restricted to the structure of the problem presented above. First, it is perfectly
possible to minimize, rather than maximize, the objective function. In addition, ‘‘greater than or equal to’’ or
‘‘equal to’’ constraints can be handled simultaneously with the ‘‘less than or equal to’’ constraints presented
in constraints (23). Finally, some of the variables may assume both positive and negative values.
There is some technical terminology associated with mathematical programming, informally introduced
in the previous section, which we will now define in more precise terms. Values of the decision variables
x1 , x2 , . . . , xn that satisfy all the constraints of (23) and (24) simultaneously are said to form a feasible
solution to the linear programming problem. The set of all values of the decision variables characterized by
constraints (23) and (24) form the feasible region of the problem under consideration. A feasible solution
that in addition optimizes the objective function (22) is called an optimal feasible solution.
As we have seen in the geometric representation of the problem, solving a linear program can result in
i) The linear program could be infeasible, meaning that there are no values of the decision variables
x1 , x2 , . . . , xn that simultaneously satisfy all the constraints of (23) and (24).
ii) It could have an unbounded solution, meaning that, if we are maximizing, the value of the objective
function can be increased indefinitely without violating any of the constraints. (If we are minimizing, the
value of the objective function may be decreased indefinitely.)
iii) In most cases, it will have at least one finite optimal solution and often it will have multiple optimal
The simplex method for solving linear programs, which will be discussed in Chapter 2, provides an
efficient procedure for constructing an optimal solution, if one exists, or for determining whether the problem
Note that, in the linear programming formulation, the decision variables are allowed to take any continuous
value. For instance, values such that x1 = 1.5, x2 = 2.33, are perfectly acceptable as long as they satisfy
constraints (23) and (24). An important extension of this linear programming model is to require that all or
some of the decision variables be restricted to be integers.
Another fundamental extension of the above model is to allow the objective function, or the constraints,
or both, to be nonlinear functions. The general nonlinear programming model can be stated as finding the
values of the decision variables x1 , x2 , . . . , xn that maximize the objective function z where
Often in nonlinear programming the righthand-side values are included in the definition of the function
f i (x1 , x2 , . . . , xn ), leaving the righthand side zero. In order to solve a nonlinear programming problem,
some assumptions must be made about the shape and behavior of the functions involved. We will leave
the specifics of these assumptions until later. Suffice it to say that the nonlinear functions must be rather
well-behaved in order to have computationally efficient means of finding a solution.
Optimization models can be subject to various classifications depending on the point of view we adopt.
According to the number of time periods considered in the model, optimization models can be classified as
static (single time period) or multistage (multiple time periods). Even when all relationships are linear, if
several time periods are incorporated in the model the resulting linear program could become prohibitively
large for solution by standard computational methods. Fortunately, in most of these cases, the problem
exhibits some form of special structure that can be adequately exploited by the application of special types
of mathematical programming methods. Dynamic programming, which is discussed in Chapter 11, is one
approach for solving multistage problems. Further, there is a considerable research effort underway today, in
the field of large-scale linear programming, to develop special algorithms to deal with multistage problems.
Another important way of classifying optimization models refers to the behavior of the parameters of
the model. If the parameters are known constants, the optimization model is said to be deterministic. If the
parameters are specified as uncertain quantities, whose values are characterized by probability distributions,
the optimization model is said to be stochastic. Finally, if some of the parameters are allowed to vary systematically, and the changes in the optimum solution corresponding to changes in those parameters are determined,
the optimization model is said to be parametric. In general, stochastic and parametric mathematical programming give rise to much more difficult problems than deterministic mathematical programming. Although
important theoretical and practical contributions have been made in the areas of stochastic and parametric
programming, there are still no effective general procedures that cope with these problems. Deterministic
linear programming, however, can be efficiently applied to very large problems of up to 5000 rows and an
almost unlimited number of variables. Moreover, in linear programming, sensitivity analysis and parametric
programming can be conducted effectively after obtaining the deterministic optimum solution, as will be seen
A third way of classifying optimization models deals with the behavior of the variables in the optimal
solution. If the variables are allowed to take any value that satisfies the constraints, the optimization model
is said to be continuous. If the variables are allowed to take on only discrete values, the optimization model
is called integer or discrete. Finally, when there are some integer variables and some continuous variables
in the problem, the optimization model is said to be mixed. In general, problems with integer variables
are significantly more difficult to solve than those with continuous variables. Network models, which are
discussed in Chapter 8, are a class of linear programming models that are an exception to this rule, as their
special structure results in integer optimal solutions. Although significant progress has been made in the
general area of mixed and integer linear programming, there is still no algorithm that can efficiently solve all
general medium-size integer linear programs in a reasonable amount of time though, for special problems,
adequate computational techniques have been developed. Chapter 9 comments on the various methods
available to solve integer programming problems.
1. Indicate graphically whether each of the following linear programs has a feasible solution. Graphically determine
the optimal solution, if one exists, or show that none exists.
2. Consider the following linear program:
a) Draw a graph of the constraints and shade in the feasible region. Label the vertices of this region with their
b) Using the graph obtained in (a), find the optimal solution and the maximum value of the objective function.
c) What is the slack in each of the constraints?
d) Find the shadow prices on each of the constraints.
e) Find the ranges associated with the two coefficients of the objective function.
f) Find the righthand-side ranges for the three constraints.
3. Consider the bond-portfolio problem formulated in Section 1.3. Reformulate the problem restricting the bonds
available only to bonds A and D. Further add a constraint that the holdings of municipal bonds must be less than or
b) What is the shadow price on the municipal limit?
c) How much can the municipal limit be relaxed before it becomes a nonbinding constraint?
d) Below what interest rate is it favorable to borrow funds to increase the overall size of the portfolio?
e) Why is this rate less than the earnings rate on the portfolio as a whole?
4. A liquor company produces and sells two kinds of liquor: blended whiskey and bourbon. The company purchases
intermediate products in bulk, purifies them by repeated distillation, mixes them, and bottles the final product under
their own brand names. In the past, the firm has always been able to sell all that it produced.
The firm has been limited by its machine capacity and available cash. The bourbon requires 3 machine hours per
bottle while, due to additional blending requirements, the blended whiskey requires 4 hours of machine time per
bottle. There are 20,000 machine hours available in the current production period. The direct operating costs, which
are principally for labor and materials, are $3.00 per bottle of bourbon and $2.00 per bottle of blended whiskey.
The working capital available to finance labor and material is $4000; however, 45% of the bourbon sales revenues
and 30% of the blended-whiskey sales revenues from production in the current period will be collected during the
current period and be available to finance operations. The selling price to the distributor is $6 per bottle of bourbon
a) Formulate a linear program that maximizes contribution subject to limitations on machine capacity and working
b) What is the optimal production mix to schedule?
c) Can the selling prices change without changing the optimal production mix?
d) Suppose that the company could spend $400 to repair some machinery and increase its available machine hours
by 2000 hours. Should the investment be made?
e) What interest rate could the company afford to pay to borrow funds to finance its operations during the current
5. The truck-assembly division of a large company produces two different models: the Aztec and the Bronco. Their
basic operation consists of separate assembly departments: drive-train, coachwork, Aztec final, and Bronco final.
The drive-train assembly capacity is limited to a total of 4000 units per month, of either Aztecs or Broncos, since it
takes the same amount of time to assemble each. The coachwork capacity each month is either 3000 Aztecs or 6000
Broncos. The Aztecs, which are vans, take twice as much time for coachwork as the Broncos, which are pickups.
The final assembly of each model is done in separate departments because of the parts availability system. The
division can do the final assembly of up to 2500 Aztecs and 3000 Broncos each month.
The profit per unit on each model is computed by the firm as follows:
† Allocated according to planned production of 1000 Aztecs and 3000 Broncos per monthfor the coming year.
a) Formulate a linear program to aid management in deciding how many trucks of each type to produce per month.
b) What is the proper objective function for the division?
c) How many Aztecs and Broncos should the division produce each month?
6. Suppose that the division described in Exercise 5 now has the opportunity to increase its drive-train capacity by
subcontracting some of this assembly work to a nearby firm. The drive-train assembly department cost breakdown
The subcontractor will pick up the parts and deliver the assembled drive-trains back to the division. What is the
maximum amount that the division would be willing to pay the subcontractor for assembly of each type of drive-train?
7. Suppose that the division described in Exercises 5 and 6 has decided against subcontracting the assembly of drivetrains but now is considering assembling drive-trains on overtime. If there is a 50% overtime labor premium on each
drive-train assembled on overtime and increased fixed overhead of $150,000 per month, should the division go on
overtime drive-train production? Formulate a linear program to answer this question, but do not solve explicitly.
8. A manufacturer of wire cloth products can produce four basic product lines: (1) industrial wire cloth; (2) insect
screen; (3) roofing mesh; and (4) snow fence. He can sell all that he can produce of each product line for the next
The production process for each product line is essentially the same. Aluminum wire is purchased in large
diameters of approximately 0.375 inches and drawn down to finer diameters of 0.009 to 0.018 inches. Then the fine
wire is woven on looms, in much the same manner as textiles. Various types of different wire meshes are produced,
depending on product line. For example, industrial wire cloth consists of meshes as fine as 30 wires per inch, while
snow fence has approximately 6 wires per inch. The production process is limited by both wire-drawing capacity
and weaving capacity, as well as the availability of the basic raw material, large-diameter aluminum wire.
For the next planning period, there are 600 hours of wire-drawing machine capacity, 1000 hours of loom capacity,
and 15 cwt (hundred weight) of large-diameter aluminum wire. The four product lines require the following inputs
to make a thousand square feet of output:
The contributions from industrial cloth, insect screen, roofing mesh, and snow fence are 2.0, 3.0, 4.2, and 4.0,
respectively, in 100’s of dollars per thousand square feet.
a) Formulate a linear program to maximize the firm’s contribution from the four product lines.
b) Since roofing mesh and snow fence are really new product lines, analyze the problem graphically, considering
only industrial wire cloth and insect screen.
i) What is the optimal solution using only these two product lines?
ii) Over what range of contribution of screen cloth will this solution remain optimal?
iii) Determine the shadow prices on the resources for this solution. Give an economic interpretation of these
iv) Suppose that the manufacturer is considering adding wire-drawing capacity. Over what range of wiredrawing capacity will the shadow price on this constraint remain unchanged? In this range, what happens to
c) Now, considering the full line of four products, answer the following, making use of the information developed
i) Will it pay to transfer resources into the production of roofing mesh or snow fence?
ii) Without performing the calculations, what will be the form of the optimal solution of the full product line?
What is the largest number of product lines that will be produced?
iii) Suppose that in the future some new product line is developed. Is it possible that one of the product lines not
presently included in the optimal solution will then be included? Explain.
9. The Candid Camera Company manufactures three lines of cameras: the Cub, the Quickiematic and the VIP, whose
contributions are $3, $9, and $25, respectively. The distribution center requires that at least 250 Cubs, 375 Quickiematics, and 150 VIPs be produced each week.
Each camera requires a certain amount of time in order to: (1) manufacture the body parts; (2) assemble the
parts (lenses are purchased from outside sources and can be ignored in the production scheduling decision); and (3)
inspect, test, and package the final product. The Cub takes 0.1 hours to manufacture, 0.2 hours to assemble, and 0.1
hours to inspect, test, and package. The Quickiematic needs 0.2 hours to manufacture, 0.35 hours to assemble, and
0.2 hours for the final set of operations. The VIP requires 0.7, 0.1, and 0.3 hours, respectively. In addition, there
are 250 hours per week of manufacturing time available, 350 hours of assembly, and 150 hours total to inspect, test,
Formulate this scheduling problem as a linear program that maximizes contribution.
10. A leather-goods factory manufactures five styles of handbags, whose variable contributions are $30, $40, $45, $25,
and $60 per dozen, respectively. The products must pass through four work centers and the man-hours available
in each are: clicking (700), paring (600), stitching (400), and finishing (900). Hourly requirements for each dozen
To prevent adding to inventory levels already on hand, the production manager, after reviewing the weekly sales
forecasts, has specified that no more than 100, 50, 90, 70, and 30 dozen of each style respectively may be produced.
Each handbag is made from five materials as specified in the following table:
Formulate a linear program for next week’s optimum manufacturing schedule if overall contribution is to be maximized.
11. A corporation that produces gasoline and oil specialty additives purchases three grades of petroleum distillates, A, B,
and C. The company then combines the three according to specifications of the maximum or minimum percentages
Supplies of the three basic additives and their costs are:
Show how to formulate a linear program to determine the production policy that will maximize profits.
12. Universal Aviation currently is investigating the possibility of branching out from its passenger service into the
small-plane air-freight business. With $4,000,000 available to invest in the purchase of new twin-engined cargo
aircraft, Universal is considering three types of planes. Aircraft A, costing $80,000, has a ten-ton payload and is
expected to cruise at 350 knots, while airplane B can haul 20 tons of goods at an average speed of 300 knots. Aircraft
B will cost $130,000. The third aircraft is a modified form of B with provisions for a copilot, a 300-knot cruising
speed, a reduced capacity of 18 tons, and a cost of $150,000.
Plane A requires one pilot and, if flown for three shifts, could average 18 hours a day in the air, as could
aircraft B. While transports B and C both require a crew of two, C could average 21 hours of flying per day on a
three-shift pilot basis due to superior loading equipment. Universal’s operations department currently estimates that
150 pilot-shifts will be available for each day’s cargo operations. Limitations on maintenance facilities indicate that
no more than thirty planes can be purchased. The contributions of planes A, B, and C per ton-mile are, respectively,
$1, $8, and $120. 3,500,000 ton-miles of shipping must be completed each day, but deliveries not completed by the
in-house fleet can still be sub-contracted to outside air carriers at a contribution of $0.20 per ton mile. What ‘‘mix’’
of aircraft should be purchased if the company desires to maximize its contribution per day? (Note. Consider a knot
13. A mobile-home manufacturer in Indiana channels its mobile-home units through distribution centers located in
Elkhart, Ind., Albany, N.Y., Camden, N.J., and Petersburg, Va. An examination of their shipping department records
indicates that, in the upcoming quarter, the distribution centers will have in inventory 30, 75, 60, and 35 mobile
homes, respectively. Quarterly orders submitted by dealerships serviced by the distribution centers require the
following numbers of mobile home units for the upcoming quarter:
Transportation costs (in dollars per unit) between each distribution center and the dealerships are as shown in the
a) Formulate this problem as a linear-programming problem with the objective of minimizing the transportation
costs from the distribution centers to the dealerships.
b) Suppose Dealer E had placed an order for 65 units, assuming all other data remain unchanged. How does this
affect the problem? (Note that total supply is less than total demand.)
14. A strategic planner for an airline that flies to four different cities from its Boston base owns 10 large jets (B707’s),
15 propeller-driven planes (Electra’s), and two small jets (DC9’s).
Assuming constant flying conditions and passenger usage, the following data is available.
Formulate constraints to take into account the following:
i) city D must be served twice daily; cities A, B, and C must be served four times daily;
ii) limitation on number of planes available, assuming that each plane can fly at most 18 hours/day.
Indicate when a continuous linear-programming formulation is acceptable, and when an integer-programming formulation is required.
15. The Temporary Help Company must provide secretaries to its clients over the next year on the following estimated
schedule: spring, 6000 secretary-days; summer, 7500 secretary-days; fall, 5500 secretary-days; and winter, 9000
secretary-days. A secretary must be trained for 5 days before becoming eligible for assignment to clients.
There are 65 working days in each quarter, and at the beginning of the spring season there are 120 qualified
secretaries on the payroll. The secretaries are paid by the company and not the client; they earn a salary of $800 a
month. During each quarter, the company loses 15% of its personnel (including secretaries trained in the previous
Formulate the problem as a linear-programming problem. (Hint: Use xt as the number of secretaries hired at
the beginning of season t, and St as the total number of secretaries at the beginning of season t.)
16. An imaginary economy has six distinct geographic regions; each has its own specific economic functions, as follows:
Manufacturing—Machinery and consumer durables
Manufacturing—Consumer durables and nondurables
The regions also have the following annual requirements (all quantities measured in tons):
Using the national railroad, shipping costs are $1/ton per 100 miles for all hauls over 100 miles. Within 100
miles, all goods are carried by truck at a cost of $1.25/ton per 100 miles ($1/ton minimum charge). The distances
(in miles) between regions are as follows:
Assume producing regions can meet all requirements, but that, due to government regulation, food production in
sector A is restricted to half that of sector E.
Formulate a linear program that will meet the requirements and minimize the total transportation costs in the
17. The Environmental Protection Agency (EPA) wants to restrict the amount of pollutants added by a company to the
river water. The concentrations of phenol and nitrogen in the water are to be restricted to, respectively, P and N
lbs. MG (million gallons) on a daily basis. The river has a flow of M MG/day. The company diverts a portion of
the river water, adds the pollutants, namely, phenol and nitrogen, to it, and sends the water back to the river. The
company has four possible ways to treat the water it uses before returning it to the river. The characteristics of each
treatment are given in the following table:
Assume: (i) that the river is initially free of pollutants; (ii) that addition of pollutants does not affect the amount
of water flow; and (iii) that the company has to process at least K (MG/day) of river water.
a) Set up a linear program to solve for the amount of water to be processed by each treatment, so that total cost of
b) How does the formulation change if the EPA regulations apply not to total river concentration downstream from
the plant, but rather to the concentration of effluent from the plant?
18. Suppose the company of Exercise 17 has three plants, A, B, and C, in a river network as shown below:
River water can be clean enough for (1) swimming, or (2) to support bio-life (but not clean enough for swimming).
Maximum permissible concentrations of pollutants for both cases are given in the table below.
Maximum permissible concentrations (lbs./MG)
Assume again that each plant has four different alternatives for water treatment, as in the table of Exercise 17,
and that A, B, and C must process at least K A , K B , K C MG/day, respectively. It is necessary that water in sections
(1) and (3) be clean enough for swimming and that water in section (2) be clean enough to support bio-life.
Further, assume: (i) that the river is free of pollutants upstream from plants A and B; and (ii) that adding
pollutants does not affect the amount of water flow.
a) Formulate a linear program, including plants A, B, and C, that minimizes total treatment costs.
b) How would the formulation change if all the plants did not necessarily have the same capabilities and cost
structure for each treatment? Indicate modifications only—do not reformulate completely.
19. ‘‘Chemico’’ company produces 3 products from a certain mineral. The production process consists of 2 stages:
mining the crude mineral, and processing the mineral to produce 3 different products.
The crude mineral can be mined by one of 5 methods. The quality of the mineral depends on the method used
and is measured by the percentage of the quantity of the final products that are produced from 1 ton of crude mineral.
Furthermore, the distribution of products obtained from 1 ton of crude mineral depends on the mining method used.
A limited amount of the crude mineral can be mined by each method. In addition, the capacity of the production
process is limited to 850 tons of crude mineral. The following table gives the relevant data.
Note that the mining costs are per 1 ton of final products, and not per 1 ton of crude mineral. The production
capacity of each mining method is in terms of crude material.
There are 2 mines: Mine A uses methods 1 and 2, whereas Mine B uses methods 3, 4, and 5. The total number
of work hours available in Mines A and B are 13,000 and 15,000, respectively (for the planning period). It is possible
to transfer workers from A to B and vice versa, but it costs $2 to transfer 1 work hour, and 10% of the transferred
The company sells its products in 5 markets. The selling price depends on the market, and in each market the
amount that can be sold is limited. The relevant data are given in a second table:
Management wants to plan the production for the next period such that the profit will be maximized. They want
to know how many work hours to assign to each mine, what amount to sell in each market, and what is the expected
profit. Formulate the problem as a linear program.
20. From past data, the production manager of a factory knows that, by varying his production rate, he incurs additional
costs. He estimates that his cost per unit increases by $0.50 when production is increased from one month to the next.
Similarly, reducing production increases costs by $0.25 per unit. A smooth production rate is obviously desirable.
Sales forecasts for the next twelve months are (in thousands):
June’s production schedule already has been set at 4000 units, and the July 1 inventory level is projected to be 2000
units. Storage is available for only 10,000 units at any one time. Ignoring inventory costs, formulate a production
schedule for the coming year that will minimize the cost of changing production rates while meeting all sales
demands. (Hint: Express the change in production from month t to month t + 1 in terms of nonnegative variables
xt+ and xt− as xt+ − xt− . Variable xt+ is the increase in production and xt− the decrease. It is possible for both xt+
and xt− to be positive in the optimal solution?)
21. Videocomp, Inc., a new manufacturer of cathode ray tube (CRT) devices for computer applications, is planning to
enlarge its capacity over the next two years. The company’s primary objective is to grow as rapidly as possible over
these two years to make good on its marketing claims.
The CRT’s are produced in sets of 200 units on modular assembly lines. It takes three months to produce a
set of 200 units from initial chemical coating to final assembly and testing. To ensure quality control, none of the
units in a set is shipped until the entire set has been completed. Videocomp has three modular assembly lines and
thus currently can produce up to 600 units in a quarter. Each set of 200 units requires $15,000 at the beginning of
the quarter when production is initiated for purchasing component parts and paying direct labor expenses. Each set
produces revenue of $35,000, of which 20% is received at the time of shipment and the remaining 80% a full three
Videocomp has negotiated the terms for adding modular assembly lines with a number of contractors and
has selected two possible contractors. The first contractor requires an investment of $60,000 paid in advance and
guarantees that the assembly line will be completed in three months. For the same assembly line, the second
contractor requires an investment of $20,000 in advance and an additional investment of $20,000 upon completion;
however, his completion time is six months.
The present assets of Videocomp for investment in new modular assembly lines and financing current operations
are $150,000. No further funds will be made available except those received from sales of CRT’s. However, as the
market is expanding rapidly, all CRT’s produced can be sold immediately.
Formulate a linear program to maximize Videocomp’s productive capacity at the end of two years using eight
planning periods of three months’ duration each.
22. A rent-a-car company operates a rental-agent training program, which students complete in one month. The teachers
in this program are trained rental agents, at a ratio of one for every fifteen students. Experience has shown that
twenty-five students must be hired for every twenty who successfully complete the program. The demand for rental
cars is seasonal and, for the next six months, requires rental agents as follows:
As of 1 January, 145 trained rental agents are available for counter work or teaching, and the personnel records
indicate that 8% of the trained rental agents leave the company at the end of each month. Payroll costs per month
Company policy forbids firing because of an excess of agents.
Formulate a linear program that will produce the minimum-cost hiring and training schedule that meets the
demand requirements, assuming that average labor turnover rates prevail and ignoring the indivisibility of agents.
Assume also that in June the training school closes for vacation.
23. The Radex Electronics Corporation is a medium-size electronics firm, one division of which specializes in made-toorder radar and ship-to-shore radio equipment. Radex has been awarded an Army contract to assemble and deliver a
number of special radar units that are small enough and light enough to be carried on a man’s back. Radex receives
$500 for each radar unit and the delivery schedule is as follows:
The actual cumulative shipments cannot exceed this schedule, since the Army, in order to have time for effective
testing before accepting all units, will refuse to accept any faster delivery. Further, it is permissible in the terms of
the contract to ship the radar units late; however, a penalty cost of $50 is assessed for each radar unit that is shipped
late. If this division of Radex produces faster than the given schedule, then it must purchase storage space in the
company warehouse at $10 per assembled radar unit on hand on the first of the month (after the shipment is sent
Production requirements are as follows: One radar unit requires 43 standard hours of assembly labor; one
trained man (with more than one month’s experience), working at 100% efficiency, produces 172 standard hours
of output per month, regular time; one new man (with less than one month’s experience), rated at 75% efficiency,
produces 129 standard hours of output per month.
The labor requirements are as follows: Employees are paid $5.00 per hour of regular time and $7.50 per hour
of overtime; a maximum of 35 hours of overtime is allowed per month, but new men may not work overtime; each
man on the payroll is guaranteed 172 regular-time hours (that is, $860 per month); at the end of the month, five
percent of the labor force quits; hiring costs are $200 per man, and all hiring is done on the first of the month.
On 1 March, Radex begins work on the government contract with 90 trained men on the payroll, and new men
can be hired immediately. On completion of the contract 1 June, Radex will begin work on a new contract requiring
Construct the coefficient matrix for a linear program to optimize the operations of this division of the Radex
Electronics Corporation over the indicated time period. Briefly define the variables and explain the significance of
the equations. (Suggestion: Set up the block of the coefficient matrix corresponding to the March decisions first,
then indicate how additional blocks should be constructed.)
24. Construct the coefficient matrix, define each of the variables, and explain briefly the significance of each equation
or inequality in the linear-programming model for optimal operation, during March and April, of the hydroelectric
The system consists of two dams and their associated reservoirs and power plants on a river. The important
flows of power and water are shown in the accompanying diagram.
In the following table, all quantities measuring water are in units of 103 acre-feet (KAF). Power is measured in
Power can be sold at $5.00 per MWH for up to 50,000 MWH each month, and excess power above that figure can
Assume flow rates in and out through the power plants are constant within the month. If the capacity of the
reservoir is exceeded, the excess water runs down the spillway and by-passes the power plant. A consequence of
these assumptions is that the maximum and minimum water-level constraints need to be satisfied only at the end of
the month. (Suggestion: First set up the model for the March operating decisions, then modify it as necessary to
extend the planning horizon to the end of April.)
25. A problem common to many different industries entails ‘‘trim’’ losses in cutting rolls of paper, textiles, foil, or
other material in the process of filling the orders of its customers. The problem arises from the fact that, due to
production economies, a factory normally produces rolls of material in standard widths (for example, 100 inches) of
fixed length (say, 500 feet). Customers who order from the factory, however, usually require rolls of smaller width
for the purposes of their own industrial uses. The rolls are cut on a large cutting machine, the knives of which can
be set for virtually any combination of widths so long as the combined total does not exceed the width of the roll.
Thus the problem becomes one of assigning the orders in such a manner that the number of standard rolls used to fill
the orders is minimized. All wasted material, or ‘‘trim loss,’’ represents a loss to the firm. This loss can sometimes
be alleviated, however, through recycling or selling as ‘‘scrap’’ or ‘‘seconds.’’
For purposes of illustration, assume that a factory produces newsprint in standard rolls, each having a width of
100 inches, and a fixed length of 500 feet. The factory must fill the following orders: 75 rolls of 24-inch width; 50
rolls of 40-inch width; and 110 rolls of 32-inch width. For simplicity, assume that the factory delivers all orders (no
matter what the width) in the standard length of 500 feet. Further, assume that there are on hand as many standard
rolls as necessary, and that only the widths on order are cut. Set up the problem as a linear program with integer
variables that minimizes the trim losses.
(Hint: Completely itemize the number of possible ways n in which a 100-inch roll can be cut into combinations
of 24-, 40-, and 32-inch widths; i.e., one 24-inch roll, one 40-inch roll, one 32-inch roll, with 4 inches of trim waste.
Then let the decision variable xi represent the number of rolls cut as combination i, i = 1, 2, . . . , n. For simplicity
in itemizing the possible combinations, assume that each standard roll is cut into as many smaller rolls as possible.
Thus, if any smaller rolls are produced in excess of the number ordered, they are counted as waste.)
26. For the trim problem described in Exercise 25, assume that the factory has two cutting machines available; machine
#1 is capable of cutting a standard roll of 100 inches, and machine #2 is capable of cutting a standard roll of 90
inches. Each machine can be used to cut no more than 400 rolls. The following orders must be filled: 225 rolls of
40-inch width; 180 rolls of 32-inch width; and 300 rolls of 24-inch width. Using applicable assumptions and hints
given in the statement of Exercise 25, formulate this problem as a linear program to allocate the orders to the two
cutting machines so as to minimize trim losses.
27. The U.S. Supreme Court decision of 1954 on de jure segregation of schools, and recent decisions denying de facto
segregation and barring ‘‘freedom-of-choice’’ pupil assignments, have forced school districts to devise plans for
integrating public schools. Finding a feasible method of achieving racially balanced schools is, at best, difficult. A
great number of factors must be taken into consideration.
For a given school district the following is known. There are G grades and J schools. Each school has a
capacity C jg for grade g. In each of I neighborhoods in the district, there is student population Sig for neighborhood
i and grade g. Let the distance from neighborhood i to school j be represented by di j.
a) Formulate a model to assign all students to schools, minimizing total distance.
b) Now let Sikg = the number of students in neighborhood i of race k and grade g; ak = the maximum percent of
racial group k assigned to a school; and bk = the minimum percent of racial group k. Reformulate the model
while also satisfying the racial-balance constraints.
c) Minimizing total distance might lead to some students having to travel great distances by bus, while others would
be within walking distance. Reformulate the problems in (a) and (b) to minimize the maximum distance traveled
28. The selling prices of a number of houses in a particular section of the city overlooking the bay are given in the
following table, along with the size of the lot and its elevation:
A real-estate agent wishes to construct a model to forecast the selling prices of other houses in this section of
the city from their lot sizes and elevations. The agent feels that a linear model of the form
would be reasonably accurate and easy to use. Here b1 and b2 would indicate how the price varies with lot size and
elevation, respectively, while b0 would reflect a base price for this section of the city.
The agent would like to select the ‘‘best’’ linear model in some sense, but he is unsure how to proceed. It he
knew the three parameters b0 , b1 and b2 , the six observations in the table would each provide a forecast of the selling
However, since b0 , b1 , and b2 cannot, in general, be chosen so that the actual prices Pi are exactly equal to the forecast
prices P̂i for all observations, the agent would like to minimize the absolute value of the residuals Ri = Pi − P̂i.
Formulate mathematical programs to find the ‘‘best’’ values of b0 , b1 , and b2 by minimizing each of the following
(Hint: (b) and (c) can be formulated as linear programs. How should (a) be solved?)
29. A firm wishes to maximize its total funds accumulated after N time periods. It receives di dollars in external
income in period i, where i = 1, 2, . . . , N , and can generate additional income by making any of 10 investments
 investment of $1 in the jth investment in period i produces nonnegative income
ai,i+1 , ai,i+2 , . . . , ai,N in periods i + 1, i + 2, . . . , N respectively. For example, a1,N
N for investing $1 in the third investment opportunity in period 1. The total cash available for investment in each
period equals di, plus yield in period i from previous investments, plus savings of money from previous periods.
Thus, cash can be saved, invested, or partially saved and the rest invested.
a) Formulate a linear program to determine the investment schedule that maximizes the accumulated funds in time period N .
b) How does the formulation change if the investment opportunities vary (in number and kind) from period to
c) What happens if savings earn 5% per time period?
Exercise 4 is based on the Rectified Liquor case, written by V.L. Andrews. Exercises 5, 6, and 7 are
inspired by the Sherman Motor Company case, written by Charles J. Christenson, which in turn is adapted
from an example used by Robert Dorfman in ‘‘Mathematical or ‘Linear’ Programming: a Nonmathematical
Approach,’’ American Economic Review, December 1953. Exercises 17, 18, and 24 are variations of problems
used by Professor C. Roger Glassey of the University of California, Berkeley.
In this chapter, we present a systematic procedure for solving linear programs. This procedure, called the
simplex method, proceeds by moving from one feasible solution to another, at each step improving the value
of the objective function. Moreover, the method terminates after a finite number of such transitions.
Two characteristics of the simplex method have led to its widespread acceptance as a computational tool.
First, the method is robust. It solves any linear program; it detects redundant constraints in the problem
formulation; it identifies instances when the objective value is unbounded over the feasible region; and it
solves problems with one or more optimal solutions. The method is also self-initiating. It uses itself either
to generate an appropriate feasible solution, as required, to start the method, or to show that the problem has
no feasible solution. Each of these features will be discussed in this chapter.
Second, the simplex method provides much more than just optimal solutions. As byproducts, it indicates
how the optimal solution varies as a function of the problem data (cost coefficients, constraint coefficients,
and righthand-side data). This information is intimately related to a linear program called the dual to the
given problem, and the simplex method automatically solves this dual problem along with the given problem.
These characteristics of the method are of primary importance for applications, since data rarely is known
with certainty and usually is approximated when formulating a problem. These features will be discussed in
Before presenting a formal description of the algorithm, we consider some examples. Though elementary,
these examples illustrate the essential algebraic and geometric features of the method and motivate the general
Note that as stated the problem has a very special form. It satisfies the following:
1. All decision variables are constrained to be nonnegative.
2. All constraints, except for the nonnegativity of decision variables, are stated as equalities.
3. The righthand-side coefficients are all nonnegative.
4. One decision variable is isolated in each constraint with a +1 coefficient (x1 in constraint (1) and x2 in
constraint (2)). The variable isolated in a given constraint does not appear in any other constraint, and
appears with a zero coefficient in the objective function.
A problem with this structure is said to be in canonical form. This formulation might appear to be quite
limited and restrictive; as we will see later, however, any linear programming problem can be transformed so
that it is in canonical form. Thus, the following discussion is valid for linear programs in general.
Observe that, given any values for x3 and x4 , the values of x1 and x2 are determined uniquely by the
equalities. In fact, setting x3 = x4 = 0 immediately gives a feasible solution with x1 = 6 and x2 = 4.
Solutions such as these will play a central role in the simplex method and are referred to as basic feasible
solutions. In general, given a canonical form for any linear program, a basic feasible solution is given by
setting the variable isolated in constraint j, called the jth basic-variable, equal to the righthand side of the
jth constraint and by setting the remaining variables, called nonbasic, all to zero. Collectively the basic
In the example above, the basic feasible solution x1 = 6, x2 = 4, x3 = 0, x4 = 0, is optimal. For any
other feasible solution, x3 and x4 must remain nonnegative. Since their coefficients in the objective function
are negative, if either x3 or x4 is positive, z will be less than 20. Thus the maximum value for z is obtained
To summarize this observation, we state the:
Suppose that, in a maximization problem, every nonbasic variable has a nonpositive coefficient in the objective function of a canonical form. Then the basic feasible solution given
by the canonical form maximizes the objective function over the feasible region.
Next consider the example just discussed but with a new objective function:
Since x3 now has a positive coefficient in the objective function, it appears promising to increase the value
of x3 as much as possible. Let us maintain x4 = 0, increase x3 to a value t to be determined, and update x1
and x2 to preserve feasibility. From constraints (1) and (2),
∗ We have introduced the new terms canonical, basis, and basic variable at this early point in our discussion because
these terms have been firmly established as part of linear-programming vernacular. Canonical is a word used in many
contexts in mathematics, as it is here, to mean ‘‘a special or standard representation of a problem or concept,’’ usually
chosen to facilitate study of the problem or concept. Basis and basic are concepts in linear algebra; our use of these
terms agrees with linear-algebra interpretations of the simplex method that are discussed formally in Appendix A.
No matter how large t becomes, x1 and x2 remain nonnegative. In fact, as t approaches +∞, z approaches
+∞. In this case, the objective function is unbounded over the feasible region.
The same argument applies to any linear program and provides the:
Unboundedness Criterion. Suppose that, in a maximization problem, some nonbasic variable has a
positive coefficient in the objective function of a canonical form. If that variable has negative or zero
coefficients in all constraints, then the objective function is unbounded from above over the feasible
Finally, let us consider one further version of the previous problem:
Now as x4 increases, z increases. Maintaining x3 = 0, let us increase x4 to a value t, and update x1 and x2
to preserve feasibility. Then, as before, from constraints (1) and (2),
If x1 and x2 are to remain nonnegative, we require:
Therefore, the largest value for t that maintains a feasible solution is t = 1. When t = 1, the new solution
becomes x1 = 3, x2 = 0, x3 = 0, x4 = 1, which has an associated value of z = 21 in the objective
Note that, in the new solution, x4 has a positive value and x2 has become zero. Since nonbasic variables
have been given zero values before, it appears that x4 has replaced x2 as a basic variable. In fact, it is fairly
simple to manipulate Eqs. (1) and (2) algebraically to produce a new canonical form, where x1 and x4 become
the basic variables. If x4 is to become a basic variable, it should appear with coefficient +1 in Eq. (2), and
with zero coefficients in Eq. (1) and in the objective function. To obtain a +1 coefficient in Eq. (2), we
divide that equation by 4, changing the constraints to read:
Now, to eliminate x4 from the first constraint, we may multiply Eq. (20 ) by 3 and subtract it from constraint
Finally, we may rearrange the objective function and write it as:
and use the same technique to eliminate x4 ; that is, multiply (20 ) by −1 and add to Eq. (1) giving:
Collecting these equations, the system becomes:
Maximize z = 0x1 − 41 x2 − x3 + 0x4 + 21,
Now the problem is in canonical form with x1 and x4 as basic variables, and z has increased from
20 to 21. Consequently, we are in a position to reapply the arguments of this section, beginning with
this improved solution. In this case, the new canonical form satisfies the optimality criterion since all
nonbasic variables have nonpositive coefficients in the objective function, and thus the basic feasible solution
x1 = 3, x2 = 0, x3 = 0, x4 = 1, is optimal.
The procedure that we have just described for generating a new basic variable is called pivoting. It is
the essential computation of the simplex method. In this case, we say that we have just pivoted on x4 in the
second constraint. To appreciate the simplicity of the pivoting procedure and gain some additional insight, let
us see that it corresponds to nothing more than elementary algebraic manipulations to re-express the problem
First, let us use constraint (2) to solve for x4 in terms of x2 and x3 , giving:
Now we will use this relationship to substitute for x4 in the objective equation:
z = 0x1 + 0x2 − 3x3 + 1 − 41 x2 + 2x3 + 20,
Note that the equations determined by this procedure for eliminating variables are the same as those given
by pivoting. We may interpret pivoting the same way, even in more general situations, as merely rearranging
the system by solving for one variable and then substituting for it. We pivot because, for the new basic
variable, we want a +1 coefficient in the constraint where it replaces a basic variable, and 0 coefficients in
all other constraints and in the objective function.
Consequently, after pivoting, the form of the problem has been altered, but the modified equations still
represent the original problem and have the same feasible solutions and same objective value when evaluated
Indeed, the substitution is merely the familiar variable-elimination technique from high-school algebra,
known more formally as Gauss–Jordan elimination.
In summary, the basic step for generating a canonical form with an improved value for the objective
Suppose that, in a maximization problem, some nonbasic variable has a
positive coefficient in the objective function of a canonical form. If that variable has a positive coefficient
in some constraint, then a new basic feasible solution may be obtained by pivoting.
Recall that we chose the constraint to pivot in (and consequently the variable to drop from the basis) by
determining which basic variable first goes to zero as we increase the nonbasic variable x4 . The constraint is
selected by taking the ratio of the righthand-side coefficients to the coefficients of x4 in the constraints, i.e.,
Note, however, that if the coefficient of x4 in the second constraint were −4 instead of +4, the values for
so that as x4 = t increases from 0, x2 never becomes zero. In this case, we would increase x4 to t = 63 = 2.
This observation applies in general for any number of constraints, so that we need never compute ratios for
nonpositive coefficients of the variable that is coming into the basis, and we establish the following criterion:
Ratio and Pivoting Criterion. When improving a given canonical form by introducing variable xs into
the basis, pivot in a constraint that gives the minimum ratio of righthand-side coefficient to corresponding
xs coefficient. Compute these ratios only for constraints that have a positive coefficient for xs .
Observe that the value t of the variable being introduced into the basis is the minimum ratio. This ratio is
zero if the righthand side is zero in the pivot row. In this instance, a new basis will be obtained by pivoting,
but the values of the decision variables remain unchanged since t = 0.
As a final note, we point out that a linear program may have multiple optimal solutions. Suppose that the
optimality criterion is satisfied and a nonbasic variable has a zero objective-function coefficient in the final
canonical form. Since the value of the objective function remains unchanged for increases in that variable,
we obtain an alternative optimal solution whenever we can increase the variable by pivoting.
The three simplex criteria just introduced algebraically may be interpreted geometrically. In order to represent
the problem conveniently, we have plotted the feasible region in Figs. 2.1(a) and 2.1(b) in terms of only the
nonbasic variables x3 and x4 . The values of x3 and x4 contained in the feasible regions of these figures satisfy
the equality constraints and ensure nonnegativity of the basic and nonbasic variables:
Consider the objective function that we used to illustrate the optimality criterion,
For any value of z, say z = 17, the objective function is represented by a straight line in Fig. 2.1(a). As
z increases to 20, the line corresponding to the objective function moves parallel to itself across the feasible
region. At z = 20, it meets the feasible region only at the point x3 = x4 = 0; and, for z > 20, it no longer
touches the feasible region. Consequently, z = 20 is optimal.
The unboundedness criterion was illustrated with the objective function:
which is depicted in Fig.2.1(b). Increasing x3 while holding x4 = 0 corresponds to moving outward from
the origin (i.e., the point x3 = x4 = 0) along the x3 -axis. As we move along the axis, we never meet either
constraint (1) or (2). Also, as we move along the x3 -axis, the value of the objective function is increasing to
The improvement criterion was illustrated with the objective function
which also is shown in Fig. 2.1(b). Starting from x3 = 0, x4 = 0, and increasing x4 corresponds to moving
from the origin along the x4 -axis. In this case, however, we encounter constraint (2) at x4 = t = 1 and
constraint (3) atx4 = t = 2. Consequently, to maintain feasibility in accordance with the ratio test, we move
to the intersection of the x4 -axis and constraint (2), which is the optimal solution.
To this point we have been solving linear programs posed in canonical form with (1) nonnegative variables,
(2) equality constraints, (3) nonnegative righthand-side coefficients, and (4) one basic variable isolated in each
constraint. Here we complete this preliminary discussion by showing how to transform any linear program
In Chapter 1, the blast-furnace example contained the two constraints:
The lefthand side in these constraints is the silicon content of the 1000-pound casting being produced. The
constraints specify the quality requirement that the silicon content must be between 32.5 and 55.0 pounds.
To convert these constraints to equality form, introduce two new nonnegative variables (the blast-furnace
example already includes a variable denoted x4 ) defined as:
Variable x5 measures the amount that the actual silicon content falls short of the maximum content that can
be added to the casting, and is called a slack variable; x6 is the amount of silicon in excess of the minimum
requirement and is called a surplus variable. The constraints become:
Slack or surplus variables can be used in this way to convert any inequality to equality form.
To see how to treat free variables, or variables unconstrained in sign, consider the basic balance equation of
In many applications, we may assume that demand is known and that production xt must be nonnegative.
Inventory It may be positive or negative, however, indicating either that there is a surplus of goods to be stored
or that there is a shortage of goods and some must be produced later. For instance, if dt − xt − It−1 = 3, then
It = −3 units must be produced later to satisfy current demand. To formulate models with free variables,
we introduce two nonnegative variables It+ and It− , and write
as a substitute for It everywhere in the model. The variable It+ represents positive inventory on hand and
It− represents backorders (i.e., unfilled demand). Whenever It ≥ 0, we set It+ = It and It− = 0, and when
It < 0, we set It+ = 0 and It− = −It . The same technique converts any free variable into the difference
between two nonnegative variables. The above equation, for example, is expressed with nonnegative variables
Using these transformations, any linear program can be transformed into a linear program with nonnegative variables and equality constraints. Further, the model can be stated with only nonnegative righthand-side
values by multiplying by −1 any constraint with a negative righthand side. Then, to obtain a canonical form,
we must make sure that, in each constraint, one basic variable can be isolated with a +1 coefficient. Some
constraints already will have this form. For example, the slack variable x5 introduced previously into the
appears in no other equation in the model. It can function as an intial basic variable for this constraint. Note,
however, that the surplus variable x6 in the constraint
does not serve this purpose, since its coefficient is −1.
There are several ways to isolate basic variables in the constraints where one is not readily apparent. One
particularly simple method is just to add a new variable to any equation that requires one. For instance, the
with nonnegative basic variable x7 . This new variable is completely fictitious and is called an artificial
variable. Any solution with x7 = 0 is feasible for the original problem, but those with x7 > 0 are not
feasible. Consequently, we should attempt to drive the artificial variable to zero. In a minimization problem,
this can be accomplished by attaching a high unit cost M (>0) to x7 in th objective function (for maximization,
add the penalty −M x7 to the objective function). For M sufficiently large, x7 will be zero in the final linear
programming solution, so that the solution satisfies the original problem constraint without the artificial
variable. If x7 > 0 in the final tableau, then there is no solution to the original problem where the artificial
variables have been removed; that is, we have shown that the problem is infeasible.
Let us emphasize the distinction between artificial and slack variables. Whereas slack variables have
meaning in the problem formulation, artificial variables have no significance; they are merely a mathematical
convenience useful for initiating the simplex algorithm.
This procedure for penalizing artificial variables, called the big M method, is straightforward conceptually
and has been incorporated in some linear programming systems. There are, however, two serious drawbacks
to its use. First, we don’t know a priori how large M must be for a given problem to ensure that all artificial
variables are driven to zero. Second, using large numbers for M may lead to numerical difficulties on a
computer. Hence, other methods are used more commonly in practice.
An alternative to the big M method that is often used for initiating linear programs is called the phase
I–phase II procedure and works in two stages. Phase I determines a canonical form for the problem by solving
a linear program related to the original problem formulation. The second phase starts with this canonical
To illustrate the technique, consider the linear program:
Maximize z = −3x1 + 3x2 + 2x3 − 2x4 − x5 + 4x6 ,
Assume that x8 is a slack variable, and that the problem has been augmented by the introduction of artificial
variables x9 , x10 , and x11 in the first, third and fourth constraints, so that x8 , x9 , x10 , and x11 form a basis.
The following elementary, yet important, fact will be useful:
Any feasible solution to the augmented system with all artificial variables equal to zero provides a feasible
solution to the original problem. Conversely, every feasible solution to the original problem provides a feasible
solution to the augmented system by setting all artificial variables to zero.
Next, observe that since the artificial variables x9 , x10 , and x11 are all nonnegative, they are all zero only
when their sum x9 + x10 + x11 is zero. For the basic feasible solution just derived, this sum is 5. Consequently,
the artificial variables can be eliminated by ignoring the original objective function for the time being and
minimizing x9 + x10 + x11 (i.e., minimizing the sum of all artificial variables). Since the artificial variables
are all nonnegative, minimizing their sum means driving their sum towards zero. If the minimum sum is 0,
then the artificial variables are all zero and a feasible, but not necessarily optimal, solution to the original
problem has been obtained. If the minimum is greater than zero, then every solution to the augmented system
has x9 + x10 + x11 > 0, so that some artificial variable is still positive. In this case, the original problem has
The essential point to note is that minimizing the infeasibility in the augmented system is a linear program.
Moreover, adding the artificial variables has isolated one basic variable in each constraint. To complete the
canonical form of the phase I linear program, we need to eliminate the basic variables from the phase I objective
function. Since we have presented the simplex method in terms of maximizing an objective function, for the
phase I linear program we will maximize w defined to be minus the sum of the artificial variables, rather than
minimizing their sum directly. The canonical form for the phase I linear program is then determined simply
by adding the artificial variables to the w equation. That is, we add the first, third, and fourth constraints in
w = 2x1 − 2x2 + x3 − x4 − 5x5 + 3x6 − x7 + 0x9 + 0x10 + 0x11 − 5.
The artificial variables now have zero coefficients in the phase I objective.
Note that the initial coefficients for the nonartificial variable x j in the w equation is the sum of the
coefficients of x j from the equations with an artificial variable (see Fig. 2.2).
If w = 0 is the solution to the phase I problem, then all artificial variables are zero. If, in addition, every
artificial variable is nonbasic in this optimal solution, then basic variables have been determined from the
original variables, so that a canonical form has been constructed to initiate the original optimization problem.
(Some artificial variables may be basic at value zero. This case will be treated in Section 2.5.) Observe that
the unboundedness condition is unnecessary. Since the artificial variables are nonnegative, w is bounded
from above by zero (for example, w = −x9 − x10 − x11 ≤ 0) so that the unboundedness condition will never
To recap, artificial variables are added to place the linear program in canonical form. Maximizing w
i) gives max w < 0. The original problem is infeasible and the optimization terminates; or
ii) gives max w = 0. Then a canonical form has been determined to initiate the original problem. Apply
the optimality, unboundedness, and improvement criteria to the original objective function z, starting
In order to reduce a general linear-programming problem to canonical form, it is convenient to perform
the necessary transformations according to the following sequence:
1. Replace each decision variable unconstrained in sign by a difference between two nonnegative variables.
This replacement applies to all equations including the objective function.
2. Change inequalities to equalities by the introduction of slack and surplus variables. For ≥ inequalities,
let the nonnegative surplus variable represent the amount by which the lefthand side exceeds the
righthand side; for ≤ inequalities, let the nonnegative slack variable represent the amount by which the
righthand side exceeds the lefthand side.
3. Multiply equations with a negative righthand side coefficient by −1.
4. Add a (nonnegative) artificial variable to any equation that does not have an isolated variable readily
apparent, and construct the phase I objective function.
To illustrate the orderly application of these rules we provide, in Fig. 2.2, a full example of reduction to
canonical form. The succeeding sets of equations in this table represent the stages of problem transformation
as we apply each of the steps indicated above. We should emphasize that at each stage the form of the given
problem is exactly equivalent to the original problem.
The simplex method for solving linear programs is but one of a number of methods, or algorithms, for solving
optimization problems. By an algorithm, we mean a systematic procedure, usually iterative, for solving a class
of problems. The simplex method, for example, is an algorithm for solving the class of linear-programming
problems. Any finite optimization algorithm should terminate in one, and only one, of the following possible
1. by demonstrating that there is no feasible solution;
2. by determining an optimal solution; or
3. by demonstrating that the objective function is unbounded over the feasible region.
We will say that an algorithm solves a problem if it always satisfies one of these three conditions. As we shall
see, a major feature of the simplex method is that it solves any linear-programming problem.
Most of the algorithms that we are going to consider are iterative, in the sense that they move from one
decision point x1 , x2 , . . . , xn to another. For these algorithms, we need:
i) a starting point to initiate the procedure;
ii) a termination criterion to indicate when a solution has been obtained; and
iii) an improvement mechanism for moving from a point that is not a solution to a better point.
Every algorithm that we develop should be analyzed with respect to these three requirements.
In the previous section, we discussed most of these criteria for a sample linear-programming problem.
Now we must extend that discussion to give a formal and general version of the simplex algorithm. Before
doing so, let us first use the improvement criterion of the previous section iteratively to solve a complete
problem. To avoid needless complications at this point, we select a problem that does not require artificial
Simple Example.∗ The owner of a shop producing automobile trailers wishes to determine the best mix for
his three products: flat-bed trailers, economy trailers, and luxury trailers. His shop is limited to working 24
days/month on metalworking and 60 days/month on woodworking for these products. The following table
indicates production data for the trailers.
Let the decision variables of the problem be:
x1 = Number of flat-bed trailers produced per month,
x2 = Number of economy trailers produced per month,
x3 = Number of luxury trailers produced per month.
Assuming that the costs for metalworking and woodworking capacity are fixed, the problem becomes:
Letting x4 and x5 be slack variables corresponding to unused hours of metalworking and woodworking
capacity, the problem above is equivalent to the linear program:
Excel spreadsheet available at http://web.mit.edu/15.053/www/Sect2.3_Simple_Example.xls
This linear program is in canonical form with basic variables x4 and x5 . To simplify our exposition and to
more nearly parallel the way in which a computer might be used to solve problems, let us adopt a tabular
representation of the equations instead of writing them out in detail. Tableau 1 corresponds to the given
canonical form. The first two rows in the tableau are self-explanatory; they simply represent the constraints,
but with the variables detached. The third row represents the z-equation, which may be rewritten as:
By convention, we say that (−z) is the basic variable associated with this equation. Note that no formal
column has been added to the tableau for the (−z)-variable.
The data to the right of the tableau is not required for the solution. It simply identifies the rows and
summarizes calculations. The arrow below the tableau indicates the variable being introduced into the basis;
the circled element of the tableau indicates the pivot element; and the arrow to the left of the tableau indicates
the variable being removed from the basis.
By the improvement criterion, introducing either x1 , x2 , or x3 into the basis will improve the solution.
The simplex method selects the variable with best payoff per unit (largest objective coefficient), in this case
x2 . By the ratio test, as x2 is increased, x4 goes to zero before x5 does; we should pivot in the first constraint.
After pivoting, x2 replaces x4 in the basis and the new canonical form is as given in Tableau 2.
Next, x3 is introduced in place of x5 (Tableau 3).
Finally, x1 is introduced in place of x2 (Tableau 4).
Tableau 4 satisfies the optimality criterion, giving an optimal contribution of $29,400 with a monthly
production of 36 flat-bed trailers and 6 luxury trailers.
Note that in this example, x2 entered the basis at the first iteration, but does not appear in the optimal
basis. In general, a variable might be introduced into (and dropped from) the basis several times. In fact, it
is possible for a variable to enter the basis at one iteration and drop from the basis at the very next iteration.
The simplex method changes in minor ways if the canonical form is written differently. Since these modifications appear frequently in the management-science literature, let us briefly discuss these variations. We
have chosen to consider the maximizing form of the linear program (max z) and have written the objective
(−z) + c1 x1 + c2 x2 + · · · + cn xn = −z 0 ,
so that the current solution has z = z 0 . We argued that, if all c j ≤ 0, then z = z 0 +c1 x1 +c2 x2 +· · ·+cn xn ≥ z 0
for any feasible solution, so that the current solution is optimal. If instead, the objective equation is written
(z) + c10 x1 + c20 x2 + · · · + cn0 xn = z 0 ,
where c0j = −c j , then z is maximized if each coefficient c0j ≥ 0. In this case, the variable with the most
negative coefficient c0j < 0 is chosen to enter the basis. All other steps in the method are unaltered.
The same type of association occurs for the minimizing objective:
Minimize z = c1 x1 + c2 x2 + · · · + cn xn .
(−z) + c1 x1 + c2 x2 + · · · + cn xn = −z 0 ,
then, since z = z 0 + c1 x1 + · · · + cn xn , the current solution is optimal if every c j ≥ 0. The variable xs to
be introduced is selected from cs = min c j < 0, and every other step of the method is the same as for the
maximizing problem. Similarly, if the objective function is written as:
(z) + c10 x1 + c20 x2 + · · · + cn0 xn = z 0 ,
where c0j = −c j , then, for a minimization problem, we introduce the variable with the most positive c j into
Note that these modifications affect only the way in which the variable entering the basis is determined.
The pivoting computations are not altered.
Given these variations in the selection rule for incoming variables, we should be wary of memorizing
formulas for the simplex algorithm. Instead, we should be able to argue as in the previous example and as in
the simplex preview. In this way, we maintain flexibility for almost any application and will not succumb to
Figure 2.3 summarizes the simplex method in flow-chart form. It illustrates both the computational steps of
the algorithm and the interface between phase I and phase II. The flow chart indicates how the algorithm is
used to show that the problem is infeasible, to find an optimal solution, or to show that the objective function
is unbounded over the feasible region. Figure 2.4 illustrates this algorithm for a phase I–phase II example
by solving the problem introduced in Section 2.2 for reducing a problem to canonical form.∗ The remainder
of this section specifies the computational steps of the flow chart in algebraic terms.
At any intermediate step during phase II of the simplex algorithm, the problem is posed in the following
xm + a m, m+1 xm+1 + · · · + a ms xs + · · · + a mn xn = bm ,
Excel spreadsheet available at http://web.mit.edu/15.053/www/Fig2.4_Pivoting.xls
Figure 2.1 Simplex phase I–phase II maximization procedure.
Originally, this canonical form is developed by using the procedures of Section 2.2. The data a i j , bi , z 0 , w 0 ,
and c j are known. They are either the original data (without bars) or that data as updated by previous steps
of the algorithm. We have assumed (by reindexing variables if necessary) that x1 , x2 , . . . , xm are the basic
variables. Also, since this is a canonical form, bi ≥ 0 for i = 1, 2, . . . , m.
STEP (0) The problem is initially in canonical form and all bi ≥ 0.
STEP (1) If c j ≤ 0 for j = 1, 2, . . . , n, then stop; we are optimal. If we continue then
STEP (2) Choose the column to pivot in (i.e., the variable to introduce into the basis)
If a is ≤ 0 for i = 1, 2, . . . , m, then stop; the primal problem is unbounded.
If we continue, then a is > 0 for some i = 1, 2, . . . , m.
STEP (3) Choose row r to pivot in (i.e., the variable to drop from the basis) by the
STEP (4) Replace the basic variable in row r with variable s and re-establish the
canonical form (i.e., pivot on the coefficient a r s ).
These steps are the essential computations of the simplex method. They apply to either the phase I or
phase II problem. For the phase I problem, the coefficients c j are those of the phase I objective function.
The only computation remaining to be specified formally is the effect that pivoting in step (4) has on the
problem data. Recall that we pivot on coefficient a r s merely to isolate variable xs with a +1 coefficient in
constraint r . The pivot can be viewed as being composed of two steps:
i) normalizing the r th constraint so that xs has a +1 coefficient, and
ii) subtracting multiples of the normalized constraint from the order equations in order to eliminate variable
These steps are summarized pictorially in Fig. 2.5.
The last tableau in Fig. 2.5 specifies the new values for the data. The new righthand-side coefficients,
Observe that the new coefficients for the variable xr being removed from the basis summarize the computations. For example, the coefficient of xr in the first row of the final tableau is obtained from the first tableau
by subtracting a 1s /a r s times the r th row from the first row. The coefficients of the other variables in the
first row of the third tableau can be obtained from the first tableau by performing this same calculation. This
observation can be used to partially streamline the computations of the simplex method. (See Appendix B
The vertical bar within braces is an abbreviation for the phrase ‘‘such that.’’
Figure 2.5 Algebra for a pivot operation.
Note also that the new value for z will be given by:
By our choice of the variable xs to introduce into the basis, cs > 0. Since br ≥ 0 and a r s > 0, this implies
that z new ≥ z old . In addition, if br > 0, then z new is strictly greater than z old .
Though the simplex algorithm has solved each of our previous examples, we have yet to show that it solves
any linear program. A formal proof requires results from linear algebra, as well as further technical material
that is presented in Appendix B. Let us outline a proof assuming these results. We assume that the linear
program has n variables and m equality constraints.
First, note that there are only a finite number of bases for a given problem, since a basis contains m
variables (one isolated in each constraint) and there are a finite number of variables to select from. A standard
result in linear algebra states that, once the basic variables have been selected, all the entries in the tableau,
including the objective value, are determined uniquely. Consequently, there are only a finite number of
canonical forms as well. If the objective value strictly increases after every pivot, the algorithm never repeats
a canonical form and must determine an optimal solution after a finite number of pivots (any nonoptimal
canonical form is transformed to a new canonical form by the simplex method).
This argument shows that the simplex method solves linear programs as long as the objective value strictly
increases after each pivoting operation. As we have just seen, each pivot affects the objective function by
adding a multiple of the pivot equation to the objective function. The current value of the z-equation increases
by a multiple of the righthand-side coefficient; if this coefficient is positive (not zero), the objective value
increases. With this in mind, we introduce the following definition:
A canonical form is called nondegenerate if each righthand-side coefficient is strictly positive. The
linear-programming problem is called nondegenerate if, starting with an initial canonical form, every
canonical form determined by the algorithm is nondegenerate.
In these terms, we have shown that the simplex method solves every nondegenerate linear program using
a finite number of pivoting steps. When a problem is degenerate, it is possible to perturb the data slightly
so that every righthand-side coefficient remains positive and again show that the method works. Details are
given in Appendix B. A final note is that, empirically, the finite number of iterations mentioned here to solve
a problem frequently lies between 1.5 and 2 times the number of constraints (i.e., between 1.5m and 2m).
Applying this perturbation, if required, to both phase I and phase II, we obtain the essential property of
Fundamental Property of the Simplex Method. The simplex method (with perturbation if necessary)
solves any given linear program in a finite number of iterations. That is, in a finite number of iterations,
it shows that there is no feasible solution; finds an optimal solution; or shows that the objective function
Although degeneracy occurs in almost every problem met in practice, it rarely causes any complications.
In fact, even without the perturbation analysis, the simplex method never has failed to solve a practical
problem, though problems that are highly degenerate with many basic variables at value zero frequently take
more computational time than other problems.
Applying this fundamental property to the phase I problem, we see that, if a problem is feasible, the
simplex method finds a basic feasible solution. Since these solutions correspond to corner or extreme points
Fundamental Property of Linear Equations. If a set of linear equations in nonnegative variables is
feasible, then there is an extreme-point solution to the equations.
We have seen that, if an artificial variable is positive at the end of phase I, then the original problem has no
feasible solution. On the other hand, if all artificial variables are nonbasic at value zero at the end of phase
I, then a basic feasible solution has been found to initiate the original optimization problem. Section 2.4
furnishes an example of this case. Suppose, though, that when phase I terminates, all artificial variables are
zero, but that some artificial variable remains in the basis. The following example illustrates this possibility.
Problem. Find a canonical form for x1 , x2 , and x3 by solving the phase I problem (x4 , x5 , and x6 are
To illustrate the various terminal conditions, the coefficient of x3 is unspecified in the third constraint. Later
it will be set to either 0 or 1. In either case, the pivoting sequence will be the same and we shall merely carry
Putting the problem in canonical form by eliminating x4 , x5 , and x6 from the objective function, the
simplex solution to the phase I problem is given in Tableaus 1 through 3.
For a = 0 or 1, phase I is complete since c3 = a − 1 ≤ 0, but with x6 still part of the basis. Note that
in Tableau 2, either x4 or x6 could be dropped from the basis. We have arbitrarily selected x4 . (A similar
First, assume a = 0. Then we can introduce x3 into the basis in place of the artificial variable x6 , pivoting
on the coefficient a − 1 or x3 in the third constraint, giving Tableau 4.
Note that we have pivoted on a negative coefficient here. Since the righthand-side element of the third
equation is zero, dividing by a negative pivot element will not make the resulting righthand-side coefficient
negative. Dropping x4 , x5 , and x6 , we obtain the desired canonical form. Note that x6 is now set to zero and
Next, suppose that a = 1. The coefficient (a − 1) in Tableau 3 is zero, so we cannot pivot x3 into the basis
as above. In this case, however, dropping artificial variables x4 and x5 from the system, the third constraint
of Tableau 3 reads x6 = 0. Consequently, even though x6 is a basic variable, in the canonical form for the
original problem it will always remain at value zero during phase II. Thus, throughout phase II, a feasible
solution to the original problem will be maintained as required. When more than one artificial variable is in
the optimal basis for phase I, these techniques can be applied to each variable.
For the general problem, the transition rule from phase I to phase II can be stated as:
Phase I–Phase II Transition Rule. Suppose that artificial variable xi is the ith basic variable at the
end of Phase I (at value zero). Let a i j be the coefficient of the nonartificial variable x j in the ith constraint
of the final tableau. If some a i j 6 = 0, then pivot on any such a i j , introducing x j into the basis in place of
xi . If all a i j = 0, then maintain xi in the basis throughout phase II by including the ith constraint, which
As a final note, observe that if all a i j = 0 above, then constraint i is a redundant constraint in the original
system, for, by adding multiples of the other equation to constraint i via pivoting, we have produced the
equation (ignoring artificial variables):
For example, when a = 1 for the problem above, (constraint 3) = 2 times (constraint 1)–(constraint 2), and
Adding artificial variables x5 , x6 , and x7 , we first minimize x5 + x6 + x7 or, equivalently, maximize
w = −x5 − x6 − x7 . The iterations are shown in Fig. 2.6.∗ The first tableau is the phase I problem statement.
Basic variables x5 , x6 and x7 appear in the objective function and, to achieve the initial canonical form, we
must add the constraints to the objective function to eliminate these variables.
Tableaus 2 and 3 contain the phase I solution. Tableau 4 gives a feasible solution to the original problem.
Artificial variable x7 remains in the basis and is eliminated by pivoting on the −1 coefficient for x4 . This
pivot replaces x7 = 0 in the basis by x4 = 0, and gives a basis from the original variables to initiate phase II.
Tableaus 5 and 6 give the phase II solution.
Excel spreadsheet available at http://web.mit.edu/15.053/www/Fig2.6_Pivoting.xls
In most linear-programming applications, many of the constraints merely specify upper and lower bounds on
the decision variables. In a distribution problem, for example, variables x j representing inventory levels might
be constrained by storage capacities u j and by predetermined safety stock levels ` j so that ` j ≤ x j ≤ u j .
We are led then to consider linear programs with bounded variables:
The lower bounds ` j may be −∞ and/or the upper bounds u j may be +∞, indicating respectively that
the decision variable x j is unbounded from below or from above. Note that when each ` j = 0 and each
u j = +∞, this problem reduces to the linear-programming form that has been discussed up until now.
The bounded-variable problem can be solved by the simplex method as discussed thus far, by adding
slack variables to the upper-bound constraints and surplus variables to the lower-bound constraints, thereby
converting them to equalities. This approach handles the bounding constraints explicitly. In contrast, the
approach proposed in this section modifies the simplex method to consider the bounded-variable constraints
implicitly. In this new approach, pivoting calculations are computed only for the equality constraints (3) rather
than for the entire system (3) and (4). In many instances, this reduction in pivoting calculations will provide
substantial computational savings. As an extreme illustration, suppose that there is one equality constraint
and 1000 nonnegative variables with upper bounds. The simplex method will maintain 1001 constraints in
the tableau, whereas the new procedure maintains only the single equality constraint.
We achieve these savings by using a canonical form with one basic variable isolated in each of the equality
constraints, as in the usual simplex method. However, basic feasible solutions now are determined by setting
nonbasic variables to either their lower or upper bound. This method for defining basic feasible solutions
extends our previous practice of setting nonbasic variables to their lower bounds of zero, and permits us to
assess optimality and generate improvement procedures much as before.
Suppose, for example, that x2 and x4 are nonbasic variables constrained by:
in the current canonical form. In any feasible solution, x2 ≥ 4, so − 41 x2 ≤ −1; also, x4 ≤ 5, so that
z = 4 − 41 x2 + 21 x4 ≤ 4 − 1 + 2 21 = 5 21
for any feasible solution. Since the current solution with x2 = 4 and x4 = 5 attains this upper bound, it
must be optimal. In general, the current canonical form represents the optimal solution whenever nonbasic
variables at their lower bounds have nonpositive objective coefficients, and nonbasic variables at their upper
bound have nonnegative objective coefficients.
In a maximization problem in canonical form, if every
nonbasic variable at its lower bound has a nonpositive objective coefficient, and every nonbasic variable
at its upper bound has a nonnegative objective coefficient, then the basic feasible solution given by that
canonical form maximizes the objective function over the feasible region.
Improving a nonoptimal solution becomes slightly more complicated than before. If the objective coefficient c j of nonbasic variable x j is positive and x j = ` j , then we increase x j ; if c j < 0 and x j = u j , we
decrease x j . In either case, the objective value is improving.
When changing the value of a nonbasic variable, we wish to maintain feasibility. As we have seen, for
problems with only nonnegative variables, we have to test, via the ratio rule, to see when a basic variable first
becomes zero. Here we must consider the following contingencies:
i) the nonbasic variable being changed reaches its upper or lower bound; or
ii) some basic variable reaches either its upper or lower bound.
In the first case, no pivoting is required. The nonbasic variable simply changes from its lower to upper
bound, or upper to lower bound, and remains nonbasic. In the second case, pivoting is used to remove the
basic variable reaching either its lower or upper bound from the basis.
These ideas can be implemented on a computer in a number of ways. For example, we can keep track of
the lower bounds throughout the algorithm; or every lower bound
can be converted to zero by defining a new variable
and substituting x 00j + ` j for x j everywhere throughout the model. Also, we can always redefine variables
so that every nonbasic variable is at its lower bound. Let x 0j denote the slack variable for the upper-bound
Whenever x j is nonbasic at its upper bound u j , the slack variable x 0j = 0. Consequently, substituting u j − x 0j
for x j in the model makes x 0j nonbasic at value zero in place of x j . If, subsequently in the algorithm, x 0j
becomes nonbasic at its upper bound, which is also u j , we can make the same substitution for x 0j , replacing
it with u j − x j , and x j will appear nonbasic at value zero. These transformations are usually referred to as
The computational steps of the upper-bounding algorithm are very simple to describe if both of these
transformations are used. Since all nonbasic variables (either x j or x 0j ) are at value zero, we increase a variable
for maximization as in the usual simplex method if its objective coefficient is positive. We use the usual ratio
rule to determine at what value t1 for the incoming variable, a basic variable first reaches zero. We also must
ensure that variables do not exceed their upper bounds. For example, when increasing nonbasic variable xs
to value t, in a constraint with x1 basic, such as:
We must perform such a check in every constraint in which the incoming variable has a negative coefficient;
and u k is the upper bound for the basic variable xk in the ith constraint, bi is the current value for this variable,
and a is are the constraint coefficients for variable xs . This test might be called the upper-bounding ratio test.
Note that, in contrast to the usual ratio test, the upper-bounding ratio uses negative coefficients a is < 0 for
the nonbasic variable xs being increased.
In general, the incoming variable xs (or xs0 ) is set to:
i) u s , then the upper bounding substitution is made for xs (or xs0 );
ii) t1 , then a usual simplex pivot is made to introduce xs into the basis;
iii) t2 , then the upper bounding substitution is made for the basic variable xk (or xk0 ) reaching its upper bound
and xs is introduced into the basis in place of xk0 (or xk ) by a usual simplex pivot.
The procedure is illustrated in Fig. 2.7. Tableau 1 contains the problem formulation, which is in canonical
form with x1 , x2 , x3 , and x4 as basic variables and x5 and x6 as nonbasic variables at value zero. In the first
iteration, variable x5 increases, reaches its upper bound, and the upper bounding substitution x50 = 1 − x5
is made. Note that, after making this substitution, the variable x50 has coefficients opposite in sign from the
coefficients of x5 . Also, in going from Tableau 1 to Tableau 2, we have updated the current value of the basic
variables by multiplying the upper bound of x5 , in this case u 5 = 1, by the coefficients of x5 and moving
these constants to the righthand side of the equations.
In Tableau 2, variable x6 increases, basic variable x2 reaches zero, and a usual simplex pivot is performed.
After the pivot, it is attractive to increase x50 in Tableau 3. As x50 increases basic variable x4 reaches its upper
bound at x4 = 5 and the upper-bounding substitution x40 = 5 − x4 is made. Variable x40 is isolated as the basic
variable in the fourth constraint in Tableau 4 (by multiplying the constraint by −1 after the upper-bounding
substitution); variable x50 then enters the basis in place of x40 . Finally, the solution in Tableau 5 is optimal,
since the objective coefficients are nonpositive for the nonbasic variables, each at value zero.
a) What is the optimal solution of this problem?
b) Change the coefficient of x4 in the z-equation to −3. What is the optimal solution now?
c) Change the signs on all x4 coefficients to be negative. What is the optimal solution now?
Find an initial basic feasible solution, specify values of the decision variables, and tell which are basic.
Transform the system of equations to the canonical form for carrying out the simplex routine.
Is your initial basic feasible solution optimal? Why?
How would you select a column in which to pivot in carrying out the simplex algorithm?
Having chosen a pivot column, now select a row in which to pivot and describe the selection rule. How does this
rule guarantee that the new basic solution is feasible? Is it possible that no row meets the criterion of your rule?
If this happens, what does this indicate about the original problem?
f) Without carrying out the pivot operation, compute the new basic feasible solution.
g) Perform the pivot operation indicated by (d) and (e) and check your answer to (f). Substitute your basic feasible
solution in the original equations as an additional check.
3. a) Reduce the following system to canonical form. Identify slack, surplus, and artificial variables.
b) Formulate phase I objective functions for the following systems with x1 ≥ 0 and x2 ≥ 0:
Solve geometrically and also trace the simplex procedure steps graphically.
Suppose that the objective function is changed to z = x1 + cx2 . Graphically determine the values of c for which
the solution found in parts (b) and (c) remains optimal.
e) Graphically determine the shadow price corresponding to the third constraint.
5. The bartender of your local pub has asked you to assist him in finding the combination of mixed drinks that will
maximize his revenue. He has the following bottles available:
1 quart (32 oz.) Old Cambridge (a fine whiskey—cost $8/quart)
1 quart Joy Juice (another fine whiskey—cost $10/quart)
Since he is new to the business, his knowledge is limited to the following drinks:
Use the simplex method to maximize the bar’s profit. (Is the cost of the liquor relevant in this formulation?)
6. A company makes three lines of tires. Its four-ply biased tires produce $6 in profit per tire, its fiberglass belted line
$4 a tire, and its radials $8 a tire. Each type of tire passes through three manufacturing stages as a part of the entire
Each of the three process centers has the following hours of available production time per day:
The time required in each process to produce one hundred tires of each line is as follows:
Determine the optimum product mix for each day’s production, assuming all tires are sold.
7. An electronics firm manufactures printed circuit boards and specialized electronics devices. Final assembly operations are completed by a small group of trained workers who labor simultaneously on the products. Because of
limited space available in the plant, no more then ten assemblers can be employed. The standard operating budget
in this functional department allows a maximum of $9000 per month as salaries for the workers.
The existing wage structure in the community requires that workers with two or more years of experience receive
$1000 per month, while recent trade-school graduates will work for only $800. Previous studies have shown that
experienced assemblers produce $2000 in ‘‘value added" per month while new-hires add only $1800. In order to
maximize the value added by the group, how many persons from each group should be employed? Solve graphically
8. The processing division of the Sunrise Breakfast Company must produce one ton (2000 pounds) of breakfast flakes
per day to meet the demand for its Sugar Sweets cereal. Cost per pound of the three ingredients is:
Government regulations require that the mix contain at least 10% ingredient A and 20% ingredient B. Use of
more than 800 pounds per ton of ingredient C produces an unacceptable taste.
Determine the minimum-cost mixture that satisfies the daily demand for Sugar Sweets. Can the boundedvariable simplex method be used to solve this problem?
9. Solve the following problem using the two phases of the simplex method:
a) Solve this problem by the simplex method. Are there alternative optimal solutions? How can this be determined
b) Solve the problem graphically to verify your answer to part (a).
11. Solve the following problem using the simplex method:
12. a) Set up a linear program that will determine a feasible solution to the following system of equations and inequalities
if one exists. Do not solve the linear program.
b) Formulate a phase I linear program to find a feasible solution to the system:
Show, from the phase I objective function, that the system contains no feasible solution (no pivoting calculations
13. The tableau given below corresponds to a maximization problem in decision variables x j ≥ 0 ( j = 1, 2, . . . , 5):
State conditions on all five unknowns a1 , a2 , a3 , b, and c, such that the following statements are true.
The current solution is optimal. There are multiple optimal solutions.
The current solution is not optimal (assume that b ≥ 0). Indicate the variable that enters the basis, the variable
that leaves the basis, and what the total change in profit would be for one iteration of the simplex method for all
values of the unknowns that are not optimal.
a) Form two new constraints as (10 ) = (1) + (2) and (20 ) = −2(1) + (2). Solve for x1 and x2 from (10 ) and (20 ), and
substitute their values in the objective function. Use these transformations to express the problem in canonical
b) Assume 1 = 0 (constant). For what values of α are x1 and x2 optimal basic variables in the problem?
c) Assume α = 3. For what values of 1 do x1 and x2 form an optimal basic feasible solution?
be the phase I objective function when phase I terminates for maximizing w. Discuss the following two procedures
for making the phase I to II transition when an artificial variable remains in the basis at value zero. Show, using
either procedure, that every basic solution determined during phase II will be feasible for the original problem
a) Multiply each coefficient in (∗) by −1. Initiate phase II with the original objective function, but maintain (∗) in
the tableau as a new constraint with (w) as the basic variable.
b) Eliminate (∗) from the tableau and at the same time eliminate from the problem any variable x j with d j < 0.
Any artificial variable in the optimal phase I basis is now treated as though it were a variable from the original
16. In our discussion of reduction to canonical form, we have replaced variables unconstrained in sign by the difference
between two nonnegative variables. This exercise considers an alternative transformation that does not introduce as
many new variables, and also a simplex-like procedure for treating free variables directly without any substitutions.
For concreteness, suppose that y1 , y2 , and y3 are the only unconstrained variables in a linear program.
a) Substitute for y1 , y2 , and y3 in the model by:
with x0 ≥ 0, x1 ≥ 0, x2 ≥ 0, and x3 ≥ 0. Show that the models are equivalent before and after these
b) Apply the simplex method directly with y1 , y2 , and y3 . When are these variables introduced into the basis
at positive levels? At negative levels? If y1 is basic, will it ever be removed from the basis? Is the equation
containing y1 as a basic variable used in the ratio test? Would the simplex method be altered in any other way?
17. Apply the phase I simplex method to find a feasible solution to the problem:
Does the termination of phase I show that the system contains a redundant equation? How?
18. Frequently, linear programs are formulated with interval constraints of the form:
a) Show that this constraint is equivalent to the constraints
b) Indicate how the general interval linear program
can be formulated as a bounded-variable linear program with m equality constraints.
19. a) What is the solution to the linear-programming problem:
Maximize z = c1 x1 + c2 x2 + · · · + cn xn ,
with bounded variables and one additional constraint? Assume that the constants c j , a j , and u j for j =
1, 2, . . . , n, and b are all positive and that the problem has been formulated so that:
b) What will be the steps of the simplex method for bounded variables when applied to this problem (in what order
do the variables enter and leave the basis)?
20. a) Graphically determine the steps of the simplex method for the problem:
Indicate on the sketch the basic variables at each iteration of the simplex algorithm in terms of the given variables
and the slack variables for the four less-than-or-equal-to constraints.
b) Suppose that the bounded-variable simplex method is applied to this problem. Specify how the iterations in the
solution to part (a) correspond to the bounded-variable simplex method. Which variables from x1 , x2 , and the
slack variable for the first two constraints, are basic at each iteration? Which nonbasic variables are at their upper
c) Solve the problem algebraically, using the simplex algorithm for bounded variables.
We have already been introduced to sensitivity analysis in Chapter 1 via the geometry of a simple example.
We saw that the values of the decision variables and those of the slack and surplus variables remain unchanged
even though some coefficients in the objective function are varied. We also saw that varying the righthandside value for a particular constraint alters the optimal value of the objective function in a way that allows us
to impute a per-unit value, or shadow price, to that constraint. These shadow prices and the shadow prices
on the implicit nonnegativity constraints, called reduced costs, remain unchanged even though some of the
righthand-side values are varied. Since there is always some uncertainty in the data, it is useful to know over
what range and under what conditions the components of a particular solution remain unchanged. Further,
the sensitivity of a solution to changes in the data gives us insight into possible technological improvements
in the process being modeled. For instance, it might be that the available resources are not balanced properly
and the primary issue is not to resolve the most effective allocation of these resources, but to investigate what
additional resources should be acquired to eliminate possible bottlenecks. Sensitivity analysis provides an
invaluable tool for addressing such issues.
There are a number of questions that could be asked concerning the sensitivity of an optimal solution to
changes in the data. In this chapter we will address those that can be answered most easily. Every commercial
linear-programming system provides this elementary sensitivity analysis, since the calculations are easy to
perform using the tableau associated with an optimal solution. There are two variations in the data that
invariably are reported: objective function and righthand-side ranges. The objective-function ranges refer to
the range over which an individual coefficient of the objective function can vary, without changing the basis
associated with an optimal solution. In essence, these are the ranges on the objective-function coefficients
over which we can be sure the values of the decision variables in an optimal solution will remain unchanged.
The righthand-side ranges refer to the range over which an individual righthand-side value can vary, again
without changing the basis associated with an optimal solution. These are the ranges on the righthand-side
values over which we can be sure the values of the shadow prices and reduced costs will remain unchanged.
Further, associated with each range is information concerning how the basis would change if the range were
exceeded. These concepts will become clear if we deal with a specific example.
We will consider for concreteness the custom-molder example from Chapter 1; in order to increase the
complexity somewhat, let us add a third alternative to the production possibilities. Suppose that, besides
the six-ounce juice glasses x1 and the ten-ounce cocktail glasses x2 , our molder is approached by a new
customer to produce a champagne glass. The champagne glass is not difficult to produce except that it must
be molded in two separate pieces—the bowl with stem and then base. As a result, the production time for the
champagne glass is 8 hours per hundred cases, which is greater than either of the other products. The storage
space required for the champagne glasses is 1000 cubic feet per hundred cases; and the contribution is $6.00
per case, which is higher than either of the other products. There is no limit on the demand for champagne
glasses. Now what is the optimal product mix among the three alternatives?
The formulation of the custom-molding example, including the new activity of producing champagne
glasses, is straightforward. We have exactly the same capacity limitations—hours of production capacity,
cubic feet of warehouse capacity, and limit on six-ounce juice-glass demand—and one additional decision
variable for the production of champagne glasses. Letting
x1 = Number of cases of six-ounce juice glasses, in hundreds;
x2 = Number of cases of ten-ounce cocktail glasses, in hundreds;
x3 = Number of cases of champagne glasses, in hundreds;
and measuring the contribution in hundreds of dollars, we have the following formulation of our custommolder example:
If we add one slack variable in each of the less-than-or-equal-to constraints, the problem will be in the
following canonical form for performing the simplex method:
The corresponding initial tableau is shown in Tableau 1.∗ After applying the simplex method as described
in Chapter 2, we obtain the final tableau shown in Tableau 2.∗
Since the final tableau is in canonical form and all objective-function coefficients of the nonbasic variables
are currently nonpositive, we know from Chapter 2 that we have the optimal solution, consisting of x1 =
6 37 , x2 = 4 27 , x6 = 1 47 , and z = 51 37 .
In this chapter we present results that depend only on the initial and final tableaus of the problem.
Specifically, we wish to analyze the effect on the optimal solution of changing various elements of the
problem data without re-solving the linear program or having to remember any of the intermediate tableaus
Excel spreadsheet available at http://web.mit.edu/15.053/www/Sect3.1_Tableaus.xls
generated in solving the problem by the simplex method. The type of results that can be derived in this way are
conservative, in the sense that they provide sensitivity analysis for changes in the problem data small enough
so that the same decision variables remain basic, but not for larger changes in the data. The example presented
in this section will be used to motivate the discussions of sensitivity analysis throughout this chapter.
SHADOW PRICES, REDUCED COSTS, AND NEW ACTIVITIES
In our new variation of the custom-molder example, we note that the new activity of producing champagne
glasses is not undertaken at all. An immediate question arises, could we have known this without performing
the simplex method on the entire problem? It turns out that a proper interpretation of the shadow prices in
the Chapter 1 version of the problem would have told us that producing champagne glasses would not be
economically attractive. However, let us proceed more slowly. Recall the definition of the shadow price
Definition. The shadow price associated with a particular constraint is the change in the optimal value
of the objective function per unit increase in the righthand-side value for that constraint, all other problem
In Chapter 1 we implied that the shadow prices were readily available when a linear program is solved.
Is it then possible to determine the shadow prices from the final tableau easily? The answer is yes, in general,
but let us consider our example for concreteness.
Suppose that the production capacity in the first constraint of our model
is increased from 60 to 61 hours. We then essentially are procuring one additional unit of production capacity
at no cost. We can obtain the same result algebraically by allowing the slack variable x4 to take on negative
values. If x4 is replaced by x4 − 1 (i.e., from its optimal value x4 = 0 to x4 = −1), Eq.(6) becomes:
Since x4 is a slack variable, it does not appear in any other constraint of the original model formulation,
nor does it appear in the objective function. Therefore, this replacement does not alter any other righthandside value in the original problem formulation. What is the contribution to the optimal profit of this additional
unit of capacity? We can resolve this question by looking at the objective function of the final tableau, which
The optimality conditions of the simplex method imply that the optimal solution is determined by setting the
nonbasic variables x3 = x4 = x5 = 0, which results in a profit of 51 37 . Now, if we are allowed to make
hundred dollars for each additional unit of capacity available. This, then,
is the marginal value, or shadow price, for production hours.
Shadow Prices, Reduced Costs, and New Activities
The righthand side for every constraint can be analyzed in this way, so that the shadow price for a
particular constraint is merely the negative of the coefficient of the appropriate slack (or artificial) variable
in the objective function of the final tableau. For our example, the shadow prices are 14
hour of production capacity, 35 hundred dollars per hundred cubic feet of storage capacity, and zero for the
limit on six-ounce juice-glass demand. It should be understood that the shadow prices are associated with
the constraints of the problem and not the variables. They are in fact the marginal worth of an additional unit
So far, we have discussed shadow prices for the explicit structural constraints of the linear-programming
model. The nonnegativity constraints also have a shadow price, which, in linear-programming terminology,
is given the special name of reduced cost.
Definition. The reduced cost associated with the nonnegativity constraint for each variable is the shadow
price of that constraint (i.e., the corresponding change in the objective function per unit increase in the
The reduced costs can also be obtained directly from the objective equation in the final tableau. In our
Increasing the righthand side of x3 ≥ 0 by one unit to x3 ≥ 1 forces champagne glasses to be used in the final
solution. From (8), the optimal profit decreases by − 47 . Since the basic variables have values x1 = 6 73 and
x2 = 4 27 , increasing the righthand sides of x1 ≥ 0 and x2 ≥ 0 by a small amount does not affect the optimal
solution, so their reduced costs are zero. Consequently, in every case, the shadow price for the nonnegativity
constraint on a variable is the objective coefficient for this variable in the final canonical form. For basic
Alternatively, the reduced costs for all decision variables can be computed directly from the shadow
prices on the structural constraints and the objective-function coefficients. In this view, the shadow prices
are thought of as the opportunity costs associated with diverting resources away from the optimal production
mix. For example, consider x3 . Since the new activity of producing champagne glasses requires 8 hours of
production capacity per hundred cases, whose opportunity cost is 14
cubic feet of storage capacity per hundred cases, whose opportunity cost is 35
cubic feet, the resulting total opportunity cost of producing one hundred cases of champagne glasses is:
Now the contribution per hundred cases is only 6 hundred dollars so that producing any champagne glasses
is not as attractive as producing the current levels of six-ounce juice glasses and ten-ounce cocktail glasses.
In fact, if resources were diverted from the current optimal production mix to produce champagne glasses,
the optimal value of the objective function would be reduced by 47 hundred dollars per hundred cases of
champagne glasses produced. This is exactly the reduced cost associated with variable x3 . This operation
of determining the reduced cost of an activity from the shadow price and the objective function is generally
Given the reduced costs, it becomes natural to ask how much the contribution of the new activity would
have to increase to make producing champagne glasses attractive? Using the opportunity-cost interpretation,
the contribution clearly would have to be $6 47 in order for the custom-molder to be indifferent to transferring
resources to the production of champagne glasses. Since the reduced cost associated with the new activity
6 − 6 47 = − 47 is negative, the new activity will not be introduced into the basis. If the reduced cost had been
positive, the new activity would have been an attractive candidate to introduce into the basis.
The shadow prices determined for the Chapter 1 version of the custom-molder example are the same
as those determined here, since the optimal solution is unchanged by the introduction of the new activity
of producing champagne glasses. Had the new activity been priced out at the outset, using the shadow
prices determined in Chapter 1, we would have immediately discovered that the opportunity cost of diverting
resources from the current solution to the new activity exceeded its potential contribution. There would have
been no need to consider the new activity further. This is an important observation, since it implies that the
shadow prices provide a mechanism for screening new activities that were not included in the initial model
formulation. In a maximization problem, if any new activity prices out negatively using the shadow prices
associated with an optimal solution, it may be immediately dropped from consideration. If, however, a new
activity prices out positively with these shadow prices, it must be included in the problem formulation and
the new optimal solution determined by pivoting.
The concepts presented in the context of the custom-molder example can be applied to any linear program.
Consider a problem in initial canonical form:
+· · · + cn xn + 0xn+1 +0xn+2 + · · · +0xn+m = 0
The variables xn+1 , xn+2 , . . . , xn+m are either slack variables or artificial variables that have been introduced
in order to transform the problem into canonical form.
Assume that the optimal solution to this problem has been foundand the corresponding final form of the
(−z) + c̄1 x1 + c̄2 x2 + · · · + c̄n xn + c̄n+1 xn+1
+ c̄n+2 xn+2 + · · · + c̄n+m xn+m = −z̄ 0 .
As we have indicated before, c̄ j is the reduced cost associated with variable x j . Since (9) is in canonical form,
c̄ j = 0 if x j is a basic variable. Let yi denote the shadow price for the ith constraint. The arguments from
the example problem show that the negative of the final objective coefficient of the variable xn+i corresponds
to the shadow price associated with the ith constraint. Therefore:
Note that this result applies whether the variable xn+i is a slack variable (i.e., the ith constraint is a less-thanor-equal-to constraint), or whether xn+i is an artificial variable (i.e., the ith constraint is either an equality or
We now shall establish a fundamental relationship between shadow prices, reduced costs, and the problem data. Recall that, at each iteration of the simplex method, the objective function is transformed by
subtracting from it a multiple of the row in which the pivot was performed. Consequently, the final form of
the objective function could be obtained by subtracting multiples of the original constraints from the original
objective function. Consider first the final objective coefficients associated withthe original basic variables
xn+1 , xn+2 , . . . , xn+m . Let π1 , π2 , . . . , πn be the multiples of each row that are subtracted from the original
objective function to obtain its final form (9). Since xn+i appears only in the ith constraint and has a +1
Combining this expression with (10), we obtain:
Thus the shadow prices yi are the multiples πi .
Since these multiples can be used to obtain every objective coefficient in the final form (9), the reduced
and the current value of the objective function is:
Expression (11) links the shadow prices to the reduced cost of each variable, while (12) establishes the
relationship between the shadow prices and the optimal value of the objectivefunction.
Expression (11) also can be viewed as a mathematical definition of the shadow prices. Since c̄ j = 0 for
the m basic variables of the optimal solution, we have:
This is a system of m equations in m unknowns that uniquely determines the values of the shadow prices yi .
Now let us consider the question of how much the objective-function coefficients can vary without changing
the values of the decision variables in the optimal solution. We will make the changes one at a time, holding
all other coefficients and righthand-side values constant. The reason for this is twofold: first, the calculation
of the range on one coefficient is fairly simple and therefore not expensive; and second, describing ranges
when more than two coefficients are simultaneously varied would require a system of equations instead of a
We return to consideration of the objective coefficient of x3 , a nonbasic variable in our example. Clearly,
if the contribution is reduced from $6 per case to something less it would certainly not become attractive
to produce champagne glasses. If it is now not attractive to produce champagne glasses, then reducing the
contribution from their production only makes it less attractive. However, if the contribution from production
of champagne glasses is increased, presumably there is some level of contribution such that it becomes
attractive to produce them. In fact, it was argued above that the opportunity cost associated with diverting
resources from the optimal production schedule was merely the shadow price associated with a resource
multiplied by the amount of the resource consumed by the activity. For this activity, the opportunity cost
is $6 47 per case compared to a contribution of $6 per case. If the contribution were increased above the
break-even opportunity cost, then it would become attractive to produce champagne glasses.
Let us relate this to the procedures of the simplex method. Suppose that we increase the objective function
coefficient of x3 in the original problem formulation (5) by 1c3 , giving us:
In applying the simplex method, multiples of the rows were subtracted from the objective function to yield
the final system of equations. Therefore, the objective function in the final tableau will remain unchanged
except for the addition of 1c3 x3 . The modified final tableau is given in Tableau 3 .
Now x3 will become a candidate to enter the optimal solution at a positive level, i.e., to enter the basis,
only when its objective-function coefficient is positive. The optimal solution remains unchanged so long as:
Equivalently, we know that the range on the original objective-function coefficient of x3 , say c3new , must
if the optimal solution is to remain unchanged.
Next, let us consider what happens when the objective-function coefficient of a basic variable is varied.
Consider the range of the objective-function coefficient of variable x1 . It should be obvious that if the
contribution associated with the production of six-ounce juice glasses is reduced sufficiently, we will stop
producing them. Also, a little thought tells us that if the contribution were increased sufficiently, we might
end up producing only six-ounce juice glasses. To understand this mathematically, let us start out as we did
before by adding 1c1 to the objective-function coefficient of x1 in the original problem formulation (5) to
yield the following modified objective function:
If we apply the same logic as in the case of the nonbasic variable, the result is Tableau 4.
However, the simplex method requires that the final system of equations be in canonical form with respect
to the basic variables. Since the basis is to be unchanged, in order to make the coefficient of x1 zero in the
final tableau we must subtract 1c1 times row 3 from row 4 in Tableau 4. The result is Tableau 5.
By the simplex optimality criterion, all the objective-function coefficients in the final tableau must be
nonpositive in order to have the current solution remain unchanged. Hence, we must have:
and, taking the most limiting inequalities, the bounds on 1c1 are:
If we let c1new = c1 + 1c1 be the objective-function coefficient of x1 in the initial tableau, then:
It is easy to determine which variables will enter and leave the basis when the new cost coefficient reaches
either of the extreme values of the range. When c1new = 5 25 , the objective coefficient of x5 in the final tableau
becomes 0; thus x5 enters the basis for any further increase of c1new . By the usual ratio test of the simplex
and the variable x6 , which is basic in row 2, leaves the basis when x5 is introduced. Similarly, when
, the objective coefficient of x3 in the final tableau becomes 0, and x3 is the entering variable. In
this case, the ratio test shows that x1 leaves the basis.
To determine the ranges of the cost coefficients in the optimalsolution of any linear program, it is useful to
distinguish between nonbasic variables and basic variables.
If x j is a nonbasic variable and we let its objective-function coefficient c j be changed by an amount 1c j
with all other data held fixed, then the current solution remains unchanged so long as the new reduced cost
The range on the variation of the objective-function coefficient of a nonbasic variable is then given by:
so that the range on the objective-function coefficient cnew
If xr is a basic variable in row k and we let its original objective-function coefficient cr be changed by an
amount 1cr with all other data held fixed, then the coefficient of the variable xr in the final tableau changes
Since xr is a basic variable, c̄r = 0; so, to recover a canonical form with c̄rnew = 0, we subtract 1cr times the
kth constraint in the final tableau from the final form of the objective function, to give new reduced costs for
Here āk j is the coefficient of variable x j in the kth constraint of the final tableau. Note that c̄new
The current basis remains optimal if c̄new
≤ 0. Using this condition and (14), we obtain the range on the
variation of the objective-function coefficient:
The range on the objective-function coefficient crnew = cr + 1cr of the basic variable xr is determined by
The variable transitions that occur at the limits of the cost ranges are easy to determine. For nonbasic
variables, the entering variable is the one whose cost is being varied. For basic variables, the entering
variable is the one giving the limiting value in (15). The variable that leaves the basis is then determined by
the minimum-ratio rule of the simplex method. If xs is the entering variable, then the basic variable in row
Since the calculation of these ranges and the determination of the variables that will enter and leave
the basis if a range is exceeded are computationally inexpensive to perform, this information is invariably
reported on any commercially available computer package. These computations are easy since no iterations
of the simplex method need be performed. It is necessary only (1) to check the entering variable conditions
of the simplex method to determine the ranges, as well as the variable that enters the basis, and (2) to check
the leaving variable condition (i.e., the minimum-ratio rule) of the simplex method to compute the variable
Now let us turn to the questions related to the righthand-side ranges. We already have noted that a righthandside range is the interval over which an individual righthand-side value can be varied, all the other problem
data being held constant, such that variables that constitute the basis remain the same. Over these ranges,
the values of the decision variables are clearly modified. Of what use are these righthand-side ranges? Any
change in the righthand-side values that keep the current basis, and therefore the canonical form, unchanged
has no effect upon the objective-function coefficients. Consequently, the righthand-side ranges are such that
the shadow prices (which are the negative of the coefficients of the slack or artificial variables in the final
tableau) and the reduced costs remain unchanged for variations of a single value within the stated range.
We first consider the righthand-side value for the demand limit on six-ounce juice glasses in our example.
Since this constraint is not binding, the shadow price associated with it is zero and it is simple to determine
the appropriate range. If we add an amount 1b3 to the righthand side of this constraint (4), the constraint
In the original problem formulation, it should be clear that, since x6 , the slack in this constraint, is a basic
variable in the final system of equations, x6 is merely increased or decreased by 1b3 . In order to keep the
current solution feasible, x6 must remain greater than or equal to zero. From the final tableau, we see that the
current value of x6 = 1 47 ; therefore x6 remains in the basis if the following condition is satisfied:
Now let us consider changing the righthand-side value associated with the storage-capacity constraint of
our example. If we add 1b2 to the righthand-side value of constraint (3), this constraint changes to:
In the original problem formulation, as was previously remarked, changing the righthand-side value is essentially equivalent to decreasing the value of the slack variable x5 of the corresponding constraint by 1b2 ; that
is, substituting x5 − 1b2 for x5 in the original problem formulation. In this case, x5 , which is zero in the final
solution, is changed to x5 = −1b2 . We can analyze the implications of this increase in the righthand-side
value by using the relationships among the variables represented by the final tableau. Since we are allowing
only one value to change at a time, we will maintain the remaining nonbasic variables, x3 and x4 , at zero level,
and we let x5 = −1b2 . Making these substitutions in the final tableau provides the following relationships:
In order for the current basis to remain optimal, it need only remain feasible, since the reduced costs will
be unchanged by any such variation in the righthand-side value. Thus,
where the current value of b2 = 150 and b2new = 150 + 1b2 .
Observe that these computations can be carried out directly in terms of the final tableau. When changing
the ith righthand side by 1bi , we simply substitute −1bi for the slack variable in the corresponding constraint
and update the current values of the basic variables accordingly. For instance, the change of storage capacity
just considered is accomplished by setting x5 = −1b2 in the final tableau to produce Tableau 6 with modified
Note that the change in the optimal value of the objective function is merely the shadow price on the
storage-capacity constraint multiplied by the increased number of units of storage capacity.
We have just seen how to compute righthand-side ranges so that the current basis remains optimal. For
example, when changing demand on six-ounce juice glasses, we found that the basis remains optimal if
and that for b3new < 6 73 , the basic variable x6 becomes negative. If b3new were reduced below 6 37 , what change
would take place in the basis? First, x6 would have to leave the basis, since otherwise it would become
the basis to take its place? In order to have the new basis be an optimal solution, the entering variable
must be chosen so that the reduced costs are not allowed to become positive.
Regardless of which variable enters the basis, the entering variable will be isolated in row 2 of the final
tableau to replace x6 , which leaves the basis. To isolate the entering variable, we must perform a pivot
operation, and a multiple, say t, of row 2 in the final tableau will be subtracted from the objective-function
row. Assuming that b3new were set equal to 6 73 in the initial tableau, the results are given in Tableau 7.
In order that the new solution be an optimal solution, the coefficients of the variables in the objective
function of the final tableau must be nonpositive; hence,
Since the coefficient of x3 is most constraining on t, x3 will enter the basis. Note that the range on the righthandside value and the variable transitions that would occur if that range were exceeded by a small amount are
easily computed. However, the pivot operation actually introducing x3 into the basis and eliminating x6 need
As another example, when the change 1b2 in storage capacity reaches −22 in Tableau 6, then x6 , the
slack on six-ounce juice glasses, reaches zero and will drop from the basis, and again x3 enters the basis.
When 1b2 = 90, though, then x1 , the production of six-ounce glasses, reaches zero and will drop from
the basis. Since x1 is a basic variable in the third constraint of Tableau 6, we must pivot in the third row,
subtracting t times this row from the objective function. The result is given in Tableau 8.
The new objective-function coefficients must be nonpositive in order for the new basis to be optimal;
which implies 0 ≤ t ≤ 25 . Consequently, x5 enters the basis. The implication is that, if the storage capacity
were increased from 150 to 240 cubic feet, then we would produce only the ten-ounce cocktail glasses, which
have the highest contribution per hour of production time.
In the process of solving linear programs by the simplex method, the initial canonical form:
ā11 x1 + ā12 x2 + · · · + ā1n xn + β11 xn+1 + β12 xn+2 + · · · + β1m xn+m = b̄1 ,
ā21 x1 + ā22 x2 + · · · + ā2n xn + β21 xn+1 + β22 xn+2 + · · · + β2m xn+m = b̄2 ,
ām1 x1 + ām2 x2 + · · · + āmn xn + βm1 xn+1 + βm2 xn+2 + · · · + βmn xn+m = b̄m .
Of course, because this is a canonical form, the updated data āi j and βi j will be structured so that one basic
variable is isolated in each constraint. Since the updated coefficients of the initial basic (slack or artificial)
variables xn+1 , xn+2 , . . . , xn+m in the final tableau play such an important role in sensitivity analysis, we
specifically denote these values as βi j .
We can change the coefficient bk of the kth righthand side in the initial tableau by 1bk with all the other data
held fixed, simply by substituting xn+k − 1bk for xn+k in the original tableau. To see how this change affects
the updated righthand-side coefficients, we make the same substitution in the final tableau. Only the terms
βik xn+k for i = 1, 2, . . . , m change in the final tableau. They become βik (xn+k − 1bk ) = βik xn+k − βik 1bk .
Since βik 1bk is a constant, we move it to the righthand side to give modified righthand-side values:
As long as all of these values are nonnegative, the basis specified by the final tableau remains optimal, since
the reduced costs have not been changed. Consequently, the current basis is optimal whenever b̄i +βik 1bk ≥ 0
for i = 1, 2, . . . , m or, equivalently,
The lower bound disappears if all βik ≤ 0, and the upper bound disappears if all βik ≥ 0.
When 1bk reaches either its upper or lower bound in Eq. (16), any further increase (or decrease) in its
value makes one of the updated righthand sides, say b̄r + βr k 1bk , negative. At this point, the basic variable
in row r leaves the basis, and we must pivot in row r in the final tableau to find the variable to be introduced in
its place. Since pivoting subtracts a multiple t of the pivot row from the objective equation, the new objective
For the new basis to be optimal, each of these coefficients must be nonpositive. Since c̄ j = 0 for the basic
variable being dropped and its coefficient in constraint r is ār j = 1, we must have t ≥ 0. For any nonnegative
t, the updated coefficient c̄ j − t ār j for any other variable remains nonpositive if ār j ≥ 0. Consequently we
need only consider ār j < 0, and t is given by
The index s giving this minimum has c̄s − t ār s = 0, and the corresponding variable xs can become the new
basic variable in row r by pivoting on ār s . Note that this pivot is made on a negative coefficient.
Since the calculation of the righthand-side ranges and the determination of the variables that will enter
and leave the basis when a range is exceeded are computationally easy to perform, this information is reported
by commercially available computer packages. For righthand-side ranges, it is necessary to check only the
feasibility conditions to determine the ranges as well as the variable that leaves, and it is necessary to check
only the entering variable condition (18) to complete the variable transitions. This condition will be used
again in Chapter 4, since it is the minimum-ratio rule of the so-called dual simplex method.
ALTERNATIVE OPTIMAL SOLUTIONS AND SHADOW PRICES
In many applied problems it is important to identify alternative optimal solutions when they exist. When
there is more than one optimal solution, there are often good external reasons for preferring one to the other;
therefore it is useful to be able to easily determine alternative optimal solutions.
As in the case of the objective function and righthand-side ranges, the final tableau of the linear program
tells us something conservative about the possibility of alternative optimal solutions. First, if all reduced
costs of the nonbasic variables are strictly negative (positive) in a maximization (minimization) problem,
then there is no alternative optimal solution, because introducing any variable into the basis at a positive level
would reduce (increase) the value of the objective function. On the other hand, if one or more of the reduced
costs are zero, there may exist alternative optimal solutions. Suppose that, in our custom-molder example,
Alternative Optimal Solutions and Shadow Prices
the contribution from champagne glasses, x3 , had been 6 47 . From Section 3.1 we know that the reduced cost
associated with this activity would be zero. The final tableau would look like Tableau 9.
This would imply that x3 , production of champagne glasses, could be introduced into the basis without
changing the value of the objective function. The variable that would be dropped from the basis would be
determined by the usual minimum-ratio rule:
In this case, the minimum ratio occurs for row 3 so that x1 leaves the basis. The alternative optimal solution
is then found by completing the pivot that introduces x3 and eliminates x1 . The values of the new basic
variables can be determined from the final tableau as follows:
Under the assumption that the contribution from champagne-glass production is 6 47 , we have found an
alternative optimal solution. It should be pointed out that any weighted combination of these two solutions
is then also an alternative optimal solution.
In general, we can say that there may exist an alternative optimal solution to a linear program if one or
more of the reduced costs of the nonbasic variables are zero. There does exist an alternative optimal solution
if one of the nonbasic variables with zero reduced cost can be introduced into the basis at a positive level.
In this case, any weighted combination of these solutions is also an alternative optimal solution. However,
if it is not possible to introduce a new variable at a positive level, then no such alternative optimal solution
exists even though some of the nonbasic variables have zero reduced costs. Further, the problem of finding
all alternative optimal solutions cannot be solved by simply considering the reduced costs of the final tableau,
since there can in general exist alternative optimal solutions that cannot be reached by a single pivot operation.
Independent of the question of whether or not alternative optimal solutions exist in the sense that different
values of the decision variables yield the same optimal value of the objective function, there may exist
alternative optimal shadow prices. The problem is completely analogous to that of identifying alternative
optimal solutions. First, if all righthand-side values in the final tableau are positive, then there do not exist
alternative optimal shadow prices. Alternatively, if one or more of these values are zero, then there may exist
alternative optimal shadow prices. Suppose, in our custom-molder example, that the value of storage capacity
had been 128 hundred cubic feet rather than 150. Then from Tableau 6 in Section 3.4, setting 1b2 = −22,
we illustrate this situation in Tableau 10.
Since the righthand-side value in row 2 of Tableau 10 is zero, it is possible to drop x6 , the basic variable
in row 2 of the final tableau, from the basis as long as there is a variable to introduce into the basis. The
variable to be introduced into the basis can be determined from the entering variable condition, Eq. (18):
In this case the minimum ratio implies that the production of champagne glasses, x3 , enters the basis. The
values of the reduced costs for the new basis can be determined by subtracting 11
tableau from the objective function in the final tableau. Thus we have:
Since the shadow prices are the negative of the objective-function coefficients of the slack variables in the
final tableau, the alternative optimal shadow prices in this case are 22
In general we can say that there may exist alternative optimal shadow prices for a linear program if one
or more of the righthand-side values in the final tableau are zero. There does exist an alternative set of
optimal shadow prices if the variable to enter the basis determined by the minimum-ratio rule has a strictly
negative reduced cost. As in the case of alternative optimal solutions, any weighted combination of these
sets of shadow prices is also an alternative set of optimal shadow prices. Finding all such sets of alternative
optimal shadow prices is of the same degree of complexity as finding all alternative optimal solutions, since
in general there can exist alternative sets of shadow prices that cannot be reached in a single pivot. Finally, it
should be pointed out that all four cases can take place: unique solution with unique shadow prices; unique
solution with alternative optimal shadow prices; alternative optimal solutions with unique shadow prices; and
alternative optimal solutions and alternative shadow prices simultaneously.
We have remarked that any commercially available linear-programming package routinely reports a great
deal of information besides the values of the decision variables at the optimal solution. In this section we
illustrate the typical computer output for the variation of the custom-molder example presented in the first few
sections of this chapter. The results shown in Fig. 3.1 were obtained on a commercial time-sharing system.∗
Note that the output includes a tabular display of the problem as stated in Eq. (1).
The first four numbered sections of this output should be compared to Tableau 12 for this example, given
in Section 3.1. The optimal value of the objective function is z = 51 37 hundred dollars, while the associated
values of the decision variables are as follows: production of six-ounce juice glasses x1 = 6 73 hundred cases,
and production of ten-ounce cocktail glasses x2 = 4 27 hundred cases. Note that there is slack in the constraint
on demand for six-ounce juice glasses of 1 47 hundred cases, which corresponds to variable x6 . Finally,
champagne glasses are not produced, and hence x3 = 0. Note that the reduced cost associated with production
of champagne glasses is − 47 , which is the amount the objective function would decrease per hundred cases if
In our discussion of shadow prices in Section 3.2, it is pointed out that the shadow prices are the negative
of the reduced costs associated with the slack variables. Thus the shadow price on production capacity is 14
hundred dollars per hour of production time, and the shadow price on storage capacity is 35
per hundred square feet of storage space. The shadow price on six-ounce juice glasses demand is zero, since
there remains unfulfilled demand in the optimal solution. It is intuitive that, in general, either the shadow
price associated with a constraint is nonzero or the slack (surplus) in that constraint is nonzero, but both will
not simultaneously be nonzero. This property is referred to as complementary slackness, and is discussed in
Sections ∗5∗ and ∗7∗ of the computer output give the ranges on the coefficients of the objective function
and the variable transitions that take place. (This material is discussed in Section 3.3.) Note that the range
on the nonbasic variable x3 , production of champagne glasses, is one-sided. Champagne glasses are not
currently produced when their contribution is $6 per case, so that, if their contribution were reduced, we
would certainly not expect this to change. However, if the contribution from the production of champagne
glasses is increased to $6 47 per case, their production becomes attractive, so that variable x3 would enter the
basis and variable x1 , production of six-ounce juice glasses, would leave the basis. Consider now the range
on the coefficient of x1 , production of six-ounce juice glasses, where the current contribution is $5 per case. If
this contribution were raised to $5 25 per case, the slack in storage capacity would enter the basis, and the slack
in juice glass, demand would leave. This means we would meet all of the juice-glass demand and storage
capacity would no longer be binding. On the other hand, if this contribution were reduced to $4 47 per case,
variable x3 , production of champagne glasses, would enter the basis and variable x1 , production of six-ounce
juice-glasses, would leave. In this instance, juice glasses would no longer be produced.
Sections ∗6∗ and ∗8∗ of the computer output give the ranges on the righthand-side values and the variable
transitions that result. (This material is discussed in Section 3.4.) Consider, for example, the range on the
righthand-side value of the constraint on storage capacity, where the current storage capacity is 150 hundred
square feet. If this value were increased to 240 hundred square feet, the slack in storage capacity would enter
the basis and variable x1 , production of six-ounce glasses, would leave. This means we would no longer
produce six-ounce juice glasses, but would devote all our production capacity to ten-ounce cocktail glasses. If
the storage capacity were reduced to 128 hundred square feet, we would begin producing champagne glasses
and the slack in the demand for six-ounce juice glasses would leave the basis. The other ranges have similar
Thus far we have covered information that is available routinely when a linear program is solved. The
format of the information varies from one computer system to another, but the information available is always
the same. The role of computers in solving linear-programming problems is covered more extensively in
∗ Excel spreadsheets available at http://web.mit.edu/15.053/www/Sect3.6_Glasses.xls and
http://web.mit.edu/15.053/www/Sect3.6_Sensitivity.xls
Figure 3.1 Solution of the custom-molder example.
Simultaneous Variations Within the Ranges
SIMULTANEOUS VARIATIONS WITHIN THE RANGES
Until now we have described the sensitivity of an optimal solution in the form of ranges on the objectivefunction coefficients and righthand-side values. These ranges were shown to be valid for changes in one
objective-function coefficient or righthand-side value, while the remaining problem data are held fixed. It is
then natural to ask what can be said about simultaneously changing more than one coefficient or value within
the ranges. In the event that simultaneous changes are made only in objective-function coefficients of nonbasic
variables and righthand-side values of nonbinding constraints within their appropriate ranges, the basis will
remain unchanged. Unfortunately, it is not true, in general, that when the simultaneous variations within the
ranges involve basic variables or binding constraints the basis will remain unchanged. However, for both the
ranges on the objective-function coefficients when basic variables are involved, and the righthand-side values
when binding constraints are involved, there is a conservative bound on these simultaneous changes that we
Let us consider first, simultaneous changes in the righthand-side values involving binding constraints for
which the basis, and therefore the shadow prices and reduced costs, remain unchanged. The righthand-side
ranges, as discussed in Section 3.4, give the range over which one particular righthand-side value may be
varied, with all other problem data being held fixed, such that the basis remains unchanged. As we have
indicated, it is not true that simultaneous changes of more than one righthand-side value within these ranges
will leave the optimal basis unchanged. However, it turns out that if these simultaneous changes are made in
such a way that the sum of the fractions of allowable range utilized by these changes is less than or equal to
one, the optimal basis will be unchanged.
Let us consider our custom-molder example, and make simultaneous changes in the binding production
and storage capacity constraints. The righthand-side range on production capacity is 37.5 to 65.5 hundred
hours, with the current value being 60. The righthand-side range on storage capacity is 128 to 240 hundred
cubic feet, with the current value being 150. Although it is not true that the optimal basis remains unchanged
for simultaneous changes in the current righthand-side values anywhere within these ranges, it is true that the
optimal basis remains unchanged for any simultaneous change that is a weighted combination of values within
these ranges. Figure 3.2 illustrates this situation. The horizontal and vertical lines in the figure are the ranges
for production and storage capacity, respectively. The four-sided figure includes all weighted combinations
of these ranges and is the space over which simultaneous variations in the values of production and storage
capacity can be made while still ensuring that the basis remains unchanged. If we consider moving from the
current righthand-side values of 60 and 150 to b1new and b2new respectively, where b1new ≤ 60 and b2new ≥ 150,
we can ensure that the basis remains unchanged if
As long as the sum of the fractions formed by the ratio of the change to the maximum possible change in
that direction is less than or equal to one, the basis remains unchanged. Hence, we have the 100 percent rule.
Since the basis remains unchanged, the shadow prices and reduced costs also are unchanged.
A similar situation exists in the case of simultaneous variations in the objective-function coefficients
when basic variables are involved. It is not true that the basis remains unchanged for simultaneous changes in
these coefficients anywhere within their individual ranges. However, it is true that the optimal basis remains
unchanged for any simultaneous change in the objective-function coefficients that is a weighted combination
of the values within these ranges. If, for example, we were to increase all cost coefficients simultaneously,
the new optimal basis would remain unchanged so long as the new values c1new , c2new , and c3new satisfy:
Again, the sum of the fractions formed by the ratio of the change in the coefficient to the maximum possible
change in that direction must be less than or equal to one.
Figure 3.2 Simultaneous variation of righthand-side values.
Let us analyze the 100 percent rule more formally. If we first consider simultaneous variations in the righthandside values, the 100 percent rule states that the basis remains unchanged so long as the sum of the fractions,
corresponding to the percent of maximum change in each direction, is less than or equal to one. To see
that this must indeed be true, we look at weighted combinations of the solution for the current values and
the solutions corresponding to particular boundaries of the ranges. In Fig. 3.2, the shaded area contains all
weighted combinations of the current values, the lower bound on b1 , and the upper bound on b2 .
Let x 0j , j = 1, 2, . . . , n, be an optimal solution to the given linear program, and let ai j be the coefficients
of the initial tableau corresponding to the basic variables. Then,
where j B indicates that the sum is taken only over basic variables. Further, let x kj , j = 1, 2, . . . , n, be the
optimal solution at either the upper or lower limit of the range when changing bk alone, depending on the
direction of the variation being considered. Since the basis remains unchanged for these variations, these
It is now easy to show that any nonnegative, weighted combination of these solutions must be an optimal
feasible solution to the problem with simultaneous variations. Let λ0 be the weight associated with the
Simultaneous Variations Within the Ranges
optimal solution corresponding to the current values, Eq. (19), and let λk be the weight associated with the
optimal solution corresponding to the variation in bk in Eq. (20). Consider all solutions that are nonnegative
weighted combinations of these solutions, such that:
The corresponding weighted solution must be nonnegative; that is,
since both λk and x j are nonnegative. By multiplying the ith constraint of Eq.
λk bk + λi (bi + 1bimax ) = bi + λi 1bimax ,
we can rewrite this expression by changing the order of summation as:
Expressions (22) and (23) together show that the weighted solution x j , j = 1, 2, . . . , n, is a feasible solution to
the righthand-side variations indicated in Eq. (20) and has the same basis as the optimal solution corresponding
to the current values in Eq. (19). This solution must also be optimal, since the operations carried out do not
change the objective-function coefficients.
Hence, the basis remains optimal so long as the sum of the weights is one, as in Eq. (21). However,
this is equivalent to requiring that the weights λk , k = 1, 2, . . . , m, corresponding to the solutions associated
with the ranges, while excluding the solution associated with the current values, satisfy:
The weight λ0 on the solution corresponding to the current values is then determined from Eq. (21). Expression (24) can be seen to be the 100 percent rule by defining:
which, when substituted in Eq. (24) yields:
Since it was required that λk ≥ 0, 1bk and 1bkmax must have the same sign. Hence, the fractions in the 100
percent rule are the ratio of the actual change in a particular direction to the maximum possible change in
A similar argument can be made to establish the 100 percent rule for variations in the objective-function
coefficients. The argument will not be given, but the form of the rule is:
In the sensitivity analysis discussed thus far, we have restricted our presentation to changes in the problem
data that can be made without changing the optimal basis. Consequently, what we have been able to say is
fairly conservative. We did go so far as to indicate the variable that would enter the basis and the variable
that would leave the basis when a boundary of a range was encountered. Further, in the case of alternative
optimal solutions and alternative optimal shadow prices, the indicated pivot was completed at least far enough
to exhibit the particular alternative. One important point in these discussions was the ease with which we
could determine the pivot to be performed at a boundary of a range. This seems to indicate that it is relatively
easy to make systematic calculations beyond the indicated objective-function or righthand-side ranges. This,
in fact, is the case; and the procedure by which these systematic calculations are made is called parametric
Consider once again our custom-molder example, and suppose that we are about to negotiate a contract for
storage space and are interested in knowing the optimal value of the objective function for all values of
storage capacity. We know from Section 3.2 that the shadow price on storage capacity is 35
per hundred cubic feet, and that this shadow price holds over the range of 128 to 240 hundred cubic feet.
As long as we are negotiating within this range, we know the worth of an additional hundred cubic feet of
storage capacity. We further know that if we go above a storage capacity of 240, x5 , the slack variable in
the storage-capacity constraint, enters the basis and x1 , the production of six-ounce juice glasses, leaves the
basis. Since slack in storage capacity exists beyond 240, the shadow price beyond 240 must be zero. If we go
below 128, we know that x3 , production of champagne glasses, will enter the basis and the slack in six-ounce
juice-glass demand leaves the basis. However, we do not know the shadow price on storage capacity below
To determine the shadow price on storage capacity below 128, we need to perform the indicated pivot
and exhibit the new canonical form. Once we have the new canonical form, we immediately know the new
shadow prices and can easily compute the new righthand-side ranges such that these shadow prices remain
unchanged. The new shadow price on storage capacity turns out to be 55
128. We can continue in this manner until the optimal value of the objective function for all possible values
Since the shadow price on a particular constraint is the change in the optimal value of the objective
function per unit increase in the righthand-side value of that constraint, the
optimal value of the objective function within some range must be a linear function of the righthand-side value
with a slope equal to the corresponding shadow price. In Fig. 3.3, the optimal value of the objective function
is plotted versus the available storage capacity. Note that this curve consists of a number of straight-line
segments. The slope of each straight-line segment is equal to the shadow price on storage capacity, and the
corresponding interval is the righthand-side range for storage capacity. For example, the slope of this curve
over the interval 128 to 240 hundred cubic feet.
In order to determine the curve given in Fig. 3.3, we essentially need to compute the optimal solution for
all possible values of storage capacity. It is intuitive that this may be done efficiently since the breakpoints
in the curve correspond to changes in the basis, and the optimal solution need only be calculated at these
breakpoints. From a given solution the next breakpoint may be determined, since this is the same as computing
Now let us fix the storage capacity again at 150 hundred cubic feet and consider solving our custom-molder
example as a function of the contribution from six-ounce juice glasses. Since the basis will remain unchanged
for variations within the objective-function ranges, we might expect results similar to those obtained by varying
a righthand-side value. In Fig. 3.4, the optimal value of the objective function is plotted versus the contribution
from six-ounce juice glasses. Note that this curve also consists of a number of straight-line segments. These
segments correspond to ranges on the objective-function coefficient of six-ounce juice glasses such that the
optimal basis does not change. Since the curve is a function of the contribution from production of six-ounce
juice glasses, and the basis remains unchanged over each interval, the slope of the curve is given by the value
In general then, it is straightforward to find the optimal solution to a linear program as a function of
any one parameter: hence, the name parametric programming. In the above two examples, we first found
the optimal solution as a function of the righthand-side value b2 , and then found the optimal solution as a
function of the objective-function coefficient c1 . The procedure used in these examples is easily generalized
to include simultaneous variation of more than one coefficient, as long as the variation is made a function of
To illustrate the general procedure in detail, consider the trailer-production problem introduced in Chapter
2. That example included two constraints, a limit of 24 days/month on metalworking capacity and a limit
of 60 days/month on woodworking capacity. Suppose that, by reallocating floor space and manpower in
the workshop, we can exchange any number of days of woodworking capacity for the same number of days
of metalworking capacity. After such an exchange, the capacities will become (24 + θ) days/month for
metalworking capacity and (60 − θ ) days/month for woodworking. The initial tableau for this problem is
then given in Tableau 11. What is the optimal contribution to overhead that the firm can obtain for each value
of θ ? In particular, what value of θ provides the greatest contribution to overhead?
We can answer these questions by performing parametric righthand-side analysis, starting with the final
linear-programming tableau that was determined in Chapter 2 and is repeated here as Tableau 12.
In Tableau 12 we have introduced the changes in the current values of the basic variables implied by the
parametric variation. These are obtained in the usual way. Increasing metalworking capacity by θ units is
equivalent to setting its slack variable x4 = −θ , and decreasing woodworking capacity by θ is equivalent to
setting its slack variable x5 = +θ . Making these substitutions simultaneously in the tableau and moving the
parameter θ to the righthand side gives the current values specified in Tableau 12.
Since the reduced costs are not affected by the value of θ , we see that the basis remains optimal in the
final tableau so long as the basic variables x1 and x2 remain nonnegative. Hence,
which implies that the optimal contribution is given by
At θ = 4, variable x3 becomes zero, while at θ = −7 15 , variable x1 becomes zero, and in each case a pivot
operation is indicated. As we saw in Section 5 on variable transitions associated with righthand-side ranges,
the variable to be introduced at these values of θ is determined by pivoting on the negative coefficient in the
appropriate pivot row r that gives the minimum ratio as follows:
At θ = −7 51 , only variable x5 has a negative coefficient in the pivot row, so we pivot to introduce x5 into
the basis in place of x1 . The result is given in Tableau 13.
At θ = −24, x3 is zero and becomes a candidate to drop from the basis. We would like to replace x3 in
the basis with another decision variable for θ < −24. We cannot perform any such pivot, however, because
there is no negative constraint coefficient in the pivot row. The row reads:
For θ < −24, the righthand side is negative and the constraint cannot be satisfied by the nonnegative variables
x1 , x2 , x3 , and x4 . Consequently, the problem is infeasible for θ < −24. This observation reflects the obvious
fact that the capacity (24 + θ ) in the first constraint of the original problem formulation becomes negative
for θ < −24 and so the constraint is infeasible.
Having now investigated the problem behavior for θ ≤ 4, let us return to Tableau 12 with θ = 4. At this
value, x2 replaces x3 in the basis. Performing the pivot gives Tableau 14.
The basic variables are nonegative in Tableau 14 for 4 ≤ θ ≤ 18 with optimal objective value z = 348−3θ .
At θ = 18, we must perform another pivot to introduce x4 into the basis in place of x1 , giving Tableau 15.
The basic variables are nonnegative in Tableau 15 for 18 ≤ θ ≤ 60 with optimal objective value
z = 420 − 7θ . At θ = 60, no variable can be introduced into the basis for the basic variable x2 , which reaches
Figure 3.5 Parametric righthand-side analysis.
zero. This is caused by an infeasibility in the original problem formulation, since the woodworking capacity
60 − θ becomes negative for any value of θ in excess of 60.
By collecting the various pieces of the optimal contribution as a function of the parameter θ, we determine
the graph given in Fig. 3.5. The highest contribution that can be obtained is $33,600 per month, which occurs
24 + θ = 28 days/month of metalworking capacity,
60 − θ = 56 days/month of woodworking capacity.
By exchanging 4 days of capacity, we can increase contribution by more than 15 percent from its original
value of $29,400 permonth. This increase must be weighed against the costs incurred in the changeover.
To illustrate parametric programming of the objective-function coefficients, we will consider the trailerproduction example once again. However, this time we will keep the capacities unchanged and vary the
contribution coefficients in the objective function. Suppose that our trailer manufacturer is entering a period
of extreme price competition and is considering changing his prices in such a way that his contribution would
How does the optimal production strategy change when the contribution is reduced (i.e., as θ becomes more
The initial tableau for this example is then Tableau 16, and the final tableau, assuming θ = 0, is Tableau 17.
As θ is allowed to decrease, the current solution remains optimal so long as θ ≥ − 29 . At this value of θ ,
the reduced cost of x2 becomes zero, indicating that there may be alternative optimal solutions. In fact, since
a pivot is possible in the first row, we can determine an alternative optimal solution where x2 enters the basis
and x1 leaves. The result is given in Tableau 18.
The new basis, consisting of variables x2 and x3 , remains optimal so long as −6 ≤ θ ≤ −4 21 . Once
θ = −6, the reduced cost of x5 is zero, so that x5 becomes a candidate to enter the basis. A pivot can be
performed so that x5 replaces x3 in the basis. The result is given in Tableau 19.
The new basis, consisting of the variables x2 , and x5 , remains optimal so long as −7 ≤ θ ≤ −6. At
θ = −7, x4 enters the basis, replacing x2 , and the resulting tableau is identical to Tableau 16 that has the
slack basis x4 and x5 and so will not be repeated here.
Figure 3.6 Parametric objective-function analysis.
In Fig. 3.6, we plot the optimal value of the objective function as a function of θ . As θ is decreased to
−4 21 , the contributions of the three products become 1 21 , 5, and 4, respectively, and x1 is replaced in the basis
by x2 . As we continue to decrease θ to −6, the contributions become 0, 2, and 1, and x2 replaces x3 in the
basis. It is interesting to note that x2 is not in the optimal basis with θ = 0, but eventually is the only product
produced. At θ = 0, even though x2 has the highest contribution, it is not produced because a combination of
x1 and x3 is a better match with the productive resources available. As the relative contributions are reduced,
x2 eventually becomes more attractive than x1 and finally is the only product manufactured.
The algorithm for objective-function parametrics is clearly straightforward to apply and consists of
computing a sequence of optimal bases by the primal simplex method. At each stage, a range is computed on
the parameter θ such that the current basis remains optimal. The variable transition at the boundary of this
range is easily determined, and one pivot operation determines a new basis that is optimal for some adjacent
1. [Excel spreadsheet available at http://web.mit.edu/15.053/www/Exer3.1.xls] Outdoors, Inc. has,
as one of its product lines, lawn furniture. They currently have three items in that line: a lawn chair, a standard
bench, and a table. These products are produced in a two-step manufacturing process involving the tube-bending
department and the welding department. The time required by each item in each department is as follows:
The contribution that Outdoors, Inc. receives from the manufacture and sale of one unit of each product is $3
for a chair, $3 for a bench, and $5 for a table.
The company is trying to plan its production mix for the current selling season. It feels that it can sell any
number it produces, but unfortunately production is further limited by available material, because of a prolonged
strike. The company currently has on hand 2000 lbs. of tubing. The three products require the following amounts
of this tubing: 2 lbs. per chair, 3 lbs. per bench, and 4.5 lbs. per table.
In order to determine the optimal product mix, the production manager has formulated the linear program shown
in Fig. E3.1 and obtained the results shown in Fig. E3.2.
Figure E3.1 Formulation of Outdoors, Inc.
a) What is the optimal production mix? What contribution can the firm anticipate by producing this mix?
b) What is the value of one unit more of tube-bending time? of welding time? of metal tubing?
c) A local distributor has offered to sell Outdoors, Inc. some additional metal tubing for $0.60/lb. Should Outdoors
buy it? If yes, how much would the firm’s contribution increase if they bought 500 lbs. and used it in an optimal
d) If Outdoors, Inc. feels that it must produce at least 100 benches to round out its product line, what effect will
e) The R&D department has been redesigning the bench to make it more profitable. The new design will require
1.1 hours of tube-bending time, 2.0 hours of welding time, and 2.0 lbs. of metal tubing. If it can sell one unit of
this bench with a unit contribution of $3, what effect will it have on overall contribution?
f) Marketing has suggested a new patio awning that would require 1.8 hours of tube-bending time, 0.5 hours of
welding time, and 1.3 lbs. of metal tubing. What contribution must this new product have to make it attractive
g) Outdoors, Inc. has a chance to sell some of its capacity in tube bending at cost + $1.50/hour. If it sells 200 hours
at that price, how will this affect contribution?
h) If the contribution on chairs were to decrease to $2.50, what would be the optimal production mix and what
contribution would this production plan give?
2. [Excel spreadsheet available at http://web.mit.edu/15.053/www/Exer3.2.xls] A commercial printing firm is trying to determine the best mix of printing jobs it should seek, given its current capacity constraints in
its four capital-intensive departments: typesetting, camera, pressroom, and bindery. It has classified its commercial
work into three classes: A, B, and C, each requiring different amounts of time in the four major departments.
The production requirements in hours per unit of product are as follows:
Assuming these units of work are produced using regular time, the contribution to overhead and profit is $200
for each unit of Class A work, $300 for each unit of Class B work, and $100 for each unit of Class C work.
The firm currently has the following regular-time capacity available in each department for the next time period:
typesetting, 40 hours; camera, 60 hours; pressroom, 200 hours; bindery, 160 hours. In addition to this regular time,
the firm could utilize an overtime shift in typesetting, which would make available an additional 35 hours in that
department. The premium for this overtime (i.e., incremental costs in addition to regular time) would be $4/hour.
Since the firm wants to find the optimal job mix for its equipment, management assumes it can sell all it produces.
However, to satisfy long-established customers, management decides to produce at least 10 units of each class of
Assuming that the firm wants to maximize its contribution to profit and overhead, we can formulate the above
situation as a linear program, as follows:
X AR = Number of units of Class A work produced on regular time;
X BR = Number of units of Class B work produced on regular time;
X CR = Number of units of Class C work produced on regular time;
X BO = Number of units of Class B work produced on overtime typesetting;
X CO = Number of units of Class C work produced on overtime typesetting.
Maximize z = 200X AR + 300X BR + 100X CR + 292X BO + 88X CO ,
X AR ≥ 0, X BR ≥ 0, X CR ≥ 0, X BO ≥ 0, X CO ≥ 0.
The solution of the firm’s linear programming model is given in Fig. E3.3.
Why is the shadow price of regular typesetting different from the shadow price of overtime typesetting?
If the printing firm has a chance to sell a new type of work that requires 0 hours of typesetting, 2 hours of camera,
2 hours of pressroom, and 1 hour of bindery, what contribution is required to make it attractive?
f) Suppose that both the regular and overtime typesetting capacity are reduced by 4 hours. How does the solution
change? (Hint: Does the basis change in this situation?)
3. Jean-Pierre Leveque has recently been named the Minister of International Trade for the new nation of New France.
In connection with this position, he has decided that the welfare of the country (and his performance) could best be
served by maximizing the net dollar value of the country’s exports for the coming year. (The net dollar value of
exports is defined as exports less the cost of all materials imported by the country.)
The area that now constitutes New France has traditionally made three products for export: steel, heavy
machinery, and trucks. For the coming year, Jean-Pierre feels that they could sell all that they could produce of
these three items at existing world market prices of $900/unit for steel, $2500/unit for machinery, and $3000/unit
In order to produce one unit of steel with the country’s existing technology, it takes 0.05 units of machinery,
0.08 units of trucks, two units of ore purchased on the world market for $100/unit, and other imported materials
costing $100. In addition, it takes .5 man-years of labor to produce each unit of steel. The steel mills of New France
have a maximum usable capacity of 300,000 units/year.
To produce one unit of machinery requires .75 units of steel, 0.12 units of trucks, and 5 man-years of labor. In
addition, $150 of materials must be imported for each unit of machinery produced. The practical capacity of the
country’s machinery plants is 50,000 units/year.
In order to produce one unit of trucks, it takes one unit of steel, 0.10 units of machinery, three man-years of
labor, and $500 worth of imported materials. Existing truck capacity is 550,000 units/year.
The total manpower available for production of steel, machinery, and trucks is 1,200,000 men/year.
To help Jean-Pierre in his planning, he had one of his staff formulate the model shown in Fig. E3.4 and solved
in Fig. E3.5. Referring to these two exhibits, he has asked you to help him with the following questions:
a) What is the optimal production and export mix for New France, based on Fig.E3.5? What would be the net dollar
b) What do the first three constraint equations (STEEL, MACHIN, and TRUCK) represent? Why are they equality
c) The optimal solution suggests that New France produce 50,000 units of machinery. How are those units to be
d) What would happen to the value of net exports if the world market price of steel increased to $1225/unit and the
country chose to export one unit of steel?
Figure E3.3 Solution for commericial printing firm.
e) If New France wants to identify other products it can profitably produce and export, what characteristics should
f) There is a chance that Jean-Pierre may have $500, 000 to spend on expanding capacity. If this investment will
buy 500 units of truck capacity, 1000 units of machine capacity, or 300 units of steel capacity, what would be the
g) If the world market price of the imported materials needed to produce one unit of trucks were to increase by
$400, what would be the optimal export mix for New France, and what would be the dollar value of their net
= Machinery production for export (EXMACH),
Figure E3.4 Formulation of optimal production and export for New France.
h) The Minister of Defense has recently come to Jean-Pierre and said that he would like to stockpile (inventory) an
additional 10,000 units of steel during the coming year. How will this change the constraint equation STEEL,
and what impact will it have on net dollar exports?
i) A government R&D group has recently come to Jean-Pierre with a new product, Product X , that can be produced
for export with 1.5 man-years of labor and 0.3 units of machinery for each unit produced. What must Product X
sell for on the world market to make it attractive for production?
j) How does this particular formulation deal with existing inventories at the start of the year and any desired
4. Another member of Jean-Pierre’s staff has presented an alternative formulation of New France’s planning problem
Figure E3.5 Solution of New France model.
as described in Exercise 3, which involves only three variables. This formulation is as follows:
Maximize z = 900(Y1 − 0.75Y2 − Y3 ) − 300Y1 + 2500(Y2 − 0.05Y1 − 0.10Y3 )
−150Y2 + 3000(Y3 − 0.80Y1 − 0.12Y2 ) − 500Y3 ,
a) Is this formulation equivalent to the one presented in Fig. E3.4 of Exercise 3? How would the optimal solution
here compare with that found in Fig. E3.5?
b) If we had the optimal solution to this formulation in terms of total production, how would we find the optimal
c) What assumption does this formulation make about the quantities and prices of products that can be exported
d) New France is considering the production of automobiles. It will take 0.5 units of steel, 0.05 units of machinery,
and 2.0 man-years to produce one unit of automobiles. Imported materials for this unit will cost $250 and the
finished product will sell on world markets at a price of $2000. Each automobile produced will use up .75 units of
the country’s limited truck capacity. How would you alter this formulation to take the production of automobiles
5. Returning to the original problem formulation shown in Fig. E3.4 of Exercise 3, Jean-Pierre feels that, with existing
uncertainties in international currencies, there is some chance that the New France dollar will be revalued upward
relative to world markets. If this happened, the cost of imported materials would go down by the same percent as
the devaluation, and the market price of the country’s exports would go up by the same percent as the revaluation.
Assuming that the country can always sell all it wishes to export how much of a revaluation could occur before the
optimal solution in Fig. E3.5 would change?
6. After paying its monthly bills, a family has $100 left over to spend on leisure. The family enjoys two types of
activities: (i) eating out; and (ii) other entertainment, such as seeing movies and sporting events. The family has
determined the relative value (utility) of these two activities—each dollar spend on eating out provides 1.2 units
of value for each dollar spent on other entertainment. Suppose that the family wishes to determine how to spend
this money to maximize the value of its expenditures, but that no more than $70 can be spent on eating out and no
more than $50 on other entertainment (if desired, part of the money can be saved). The family also would like to
a) How the total value of its expenditures for leisure would change if there were only $99 to spend.
b) How the total value would change if $75 could be spend on eating out.
c) Whether it would save any money if each dollar of savings would provide 1.1 units of value for each dollar spent
Formulate the family’s spending decision as a linear program. Sketch the feasible region, and answer each of
the above questions graphically. Then solve the linear program by the simplex method, identify shadow prices on
the constraints, and answer each of these questions, using the shadow prices.
7. [Excel spreadsheet available at http://web.mit.edu/15.053/www/Exer3.7.xls] Consider the linear
ii) the shadow prices on the three constraints;
iii) the range on the objective coefficient of each variable, holding the coefficient of the other variable at its current
value, for which the solution to part (i) remains optimal;
iv) the range on the availability of each resource, holding the availability of the other resources at their current
values, for which the shadow prices in part (ii) remain optimal.
b) Answer the same question, using the following optimal tableau determined by the simplex method:
8. Determine the variable transitions for the previous problem, when each objective coefficient or righthand-side value
is varied by itself to the point where the optimal basis no longer remains optimal. Carry out this analysis using the
optimal tableau, and interpret the transitions graphically on a sketch of the feasible region.
9. [Excel spreadsheet available at http://web.mit.edu/15.053/www/Exer3.9.xls] A wood-products
company produces four types of household furniture. Three basic operations are involved: cutting, sanding, and
finishing. The plant’s capacity is such that there is a limit of 900 machine hours for cutting, 800 hours for sanding,
and 480 hours for finishing. The firm’s objective is to maximize profits. The initial tableau is as follows:
Using the simplex algorithm, the final tableau is found to be:
What are the shadow prices on each of the constraints?
What profit for x3 would justify its production?
What are the limits on sanding capacity that will allow the present basic variables to stay in the optimal solution?
Suppose management had to decide whether or not to introduce a new product requiring 20 hours of cutting, 3
hours of sanding, and 2 hours of finishing, with an expected profit of $120. Should the product be produced?
e) If another saw to perform cutting can be rented for $10/hour, should it be procured? What about a finisher at the
same price? If either is rented, what will be the gain from the first hour’s use?
10. [Excel spreadsheet available at http://web.mit.edu/15.053/www/Exer3.10.xls] The Reclamation
Machining Company makes nuts and bolts from scrap material supplied from the waste products of three steel-using
firms. For each 100 pounds of scrap material provided by firm A, 10 cases of nuts and 4 cases of bolts can be made,
with a contribution of $46. 100 pounds from firm B results in 6 cases of nuts, 10 cases of bolts, and a contribution
of $57. Use of 100 pounds of firm C’s material will produce 12 cases of nuts, 8 of bolts, and a contribution of
$60. Assuming Reclamation can sell only a maximum of 62 cases of nuts and 60 of bolts, the final tableau for a
linear-programming solution of this problem is as follows:
c) For each of the three sources, determine the interval of contribution for which the solution in part (a) remains
d) What are the shadow prices associated with the optimal solution in (a), and what do they mean?
e) Give an interval for each sales limitation such that the shadow prices in (d) remain unchanged.
11. [Excel spreadsheet available at http://web.mit.edu/15.053/www/Exer3.11.xls] Consider the linear
a) What are the optimal shadow prices for the two constraints? Can the optimal shadow price for the first constraint
be determined easily from the final objective coefficient for x1 ? (Hint: The initial problem formulation is in
canonical form if the objective coefficient of x1 is changed to 0x1 .)
b) Suppose that the initial righthand-side coefficient of the first constraint is changed to 10 + δ. For what values
of δ do x2 and x3 form an optimal basis for the problem?
12. [Excel spreadsheet available at http://web.mit.edu/15.053/www/Exer3.12.xls] Consider the following linear program:
After several iterations of the simplex algorithm, the following tableau has been determined:
a) What are the values of the decision variables? How do you know this is the optimal solution?
b) For each nonbasic variable of the solution, find the interval for its objective-function coefficient such that the
d) Determine the interval for each righthand-side value such that the optimal basis determined remains unchanged.
What does this imply about the shadow prices? reduced costs?
13. A cast-iron foundry is required to produce 1000 lbs. of castings containing at least 0.35 percent manganese and
not more than 3.2 percent silicon. Three types of pig iron are available in unlimited amounts, with the following
Assuming that pig iron is melted with other materials to produce cast iron, a linear-programming formulation that
a) At what cost does pig type A become a candidate for entry into the optimal basis? What activity would it replace?
b) How much can we afford to pay for pure manganese to add to the melt?
c) How much can the manganese requirement be reduced without changing the basis? What are the values of the
d) How much can the cost of pig type B change without changing the optimal basis? What are the new basic
e) How can the final tableau be optimal if the reduced cost of v1 is −10?
14. [Excel spreadsheet available at http://web.mit.edu/15.053/www/Exer3.14.xls] The Classic Stone
Cutter Company produces four types of stone sculptures: figures, figurines, free forms, and statues. Each product
requires the following hours of work for cutting and chiseling stone and polishing the final product:
The last row in the above table specifies the contribution to overhead for each product.
Classic’s current work force has production capacity to allocate 300 hours to cutting, 180 hours to chiseling,
and 300 hours to polishing in any week. Based upon these limitations, it finds its weekly production schedule from
the linear-programming solution given by the following tableau.
Current Figures Figurines Forms Statues hours
a) Determine a range on the cutting capacity such that the current solution remains optimal.
b) Busts have the following characteristics:
Should Classic maintain its present line or expand into busts?
c) Classic can buy 5 hours of cutting capacity and 5 hours of chiseling capacity from an outside contractor at a total
cost of $75. Should Classic make the purchase or not?
d) By how much does the contribution from free forms have to be increased to make free forms profitable to produce?
e) Give a range on the contribution from figures such that the current solution remains optimal. What activities
enter the basis at the bounds of this range?
15. [Excel spreadsheet available at http://web.mit.edu/15.053/www/Exer3.15.xls] The Concrete Products Corporation has the capability of producing four types of concrete blocks. Each block must be subjected to
four processes: batch mixing, mold vibrating, inspection, and yard drying. The plant manager desires to maximize
profits during the next month. During the upcoming thirty days, he has 800 machine hours available on the batch
mixer, 1000 hours on the mold vibrator, and 340 man-hours of inspection time. Yard-drying time is unconstrained.
The production director has formulated his problem as a linear program with the following initial tableau:
where x1 , x2 , x3 , x4 represent the number of pallets of the four types of blocks. After solving by the simplex method,
a) By how much must the profit on a pallet of number 3 blocks be increased before it would be profitable to
b) What minimum profit on x2 must be realized so that it remains in the production schedule?
c) If the 800 machine-hours capacity on the batch mixer is uncertain, for what range of machine hours will it remain
d) A competitor located next door has offered the manager additional batch-mixing time at a rate of $4.00 per hour.
e) The owner has approached the manager with a thought about producing a new type of concrete block that would
require 4 hours of batch mixing, 4 hours of molding, and 1 hour of inspection per pallet. What should be the
profit per pallet if block number 5 is to be included in the optimal schedule?
16. [Excel spreadsheet available at http://web.mit.edu/15.053/www/Exer3.16.xls] The linear-programming
Answer the following questions. All parts are independent and refer to changes in the original problem
formulation as stated above. That is, do not consider parts (a), (b), and (c) together, but refer to the original problem
a) Suppose that the objective function changes to
Find the new optimal solution. Is the solution to the new problem unique? Explain your answer.
b) Consider the parametric-programming problem with the objective function:
Maximize z = (4 + 2θ)x4 + (2 − 4θ )x5 + (−3 + θ )x6 .
For what values θ ≤ θ ≤ θ of θ do the variables x4 , x5 , and x3 remain in the optimal basis (e.g., if θ = −1 and
θ = 2, then the interval is −1 ≤ θ ≤ 2). What are the variable transitions at θ = θ and θ = θ?
c) Consider the parametric programming problem with the righthand sides
For what values θ ≤ θ ≤ θ of θ do the variables x4 , x5 , and x3 remain in the optimal basis? What are the variable
17. The Massachusetts Electric Company is planning additions to its mix of nuclear and conventional electric power
plants to cover a ten-year horizon. It measures the output of plants in terms of equivalent conventional plants.
Production of electricity must satisfy the state’s additional requirements over the planning horizon for guaranteed
power (kW), peak power (kW), and annual energy (MWh). The state’s additional requirements, and the contribution
of each type of plant to these requirements, are as follows:
The costs for each type of plant include fixed investment costs and variable operating costs per year. The
conventional plants have very high operating costs, since they burn fossil fuel, while the nuclear plants have very
high investment costs. These costs are as follows:
For simplicity, we will assume that the annual operating costs are an infinite stream discounted at a rate of (1/(1+r ))
per year. The present value of this infinite stream of operating costs is:
and the term 1/r is sometimes referred to as the coefficient of capitalization.
a) Formulate a linear program to decide what mix of conventional and nuclear power plants to build, assuming
that you must meet or exceed the state’s three requirements and you want to minimize the total investment plus
b) There has been a debate at Massachusetts Electric as to what discount rate r to use in making this calculation.
Some have argued for a low ‘‘social’’ rate of about 2 or 3 percent, while others have argued for the private ‘‘cost
of capital’’ rate of from 10 to 15 percent. Graphically determine the optimal solution for all values of the discount
rate r , to aid in settling this question. Comment on the implications of the choice of discount rate.
c) Another difficulty is that there may not be sufficient investment funds to make the decisions independently of
an investment limitation. Assuming the ‘‘social’’ discount rate of 2 percent, find the optimal solution for all
conceivable budget levels for total investment. What is the impact of limiting the budget for investment?
18. [Excel spreadsheet available at http://web.mit.edu/15.053/www/Exer3.18.xls] Consider the parametricprogramming problem:
Letting x3 , x4 , and x5 be slack variables for the constraints, we write the optimal canonical form at θ = 0 as:
a) Place the objective function in this tableau in canonical form for values of θ other than 0. For what values of θ
b) What are the variable transitions when this canonical form is no longer optimal? Does the problem become
unbounded at either of the transition points?
c) Use the parametric programming algorithm to find the optimal solution for all values of θ. Plot the optimal
d) Graph the feasible region and interpret the parametric algorithm on the graph.
19. [Excel spreadsheet available at http://web.mit.edu/15.053/www/Exer3.19.xls] Consider the following parametric linear program:
a) Graph the feasible region and indicate the optimal solution for θ = 0, θ = 1, and θ = 2.
b) For what values of θ is this problem feasible?
c) From the graphs in part (a), determine the optimal solution for all values of θ. Graph the optimal objective value
d) Starting with the optimal canonical form given below for θ = 0, use the parametric simplex algorithm to solve
iii) Suppose that the constant on the righthand side of the second inequality is changed from 4 to 6. What is the
b) For what values of θ does the optimal basis to part a(i) remain optimal?
c) Solve the linear program for all values of θ.
21. When discussing parametric analysis in Section 3.8, we considered reallocating floor space for a trailer-production
problem to trade off woodworking capacity for metalworking capacity. The trade-off was governed by the parameter
We found that the following tableau was optimal for values of θ in the range 0 ≤ θ ≤ 4:
The optimal solution at θ = 4 is x1 = 56, x2 = x3 = x4 = x5 = 0, and z = 336. At θ = 5, we found that
the optimal basic variables are x1 = 52, x2 = 1.5, and that the optimal objective value is z = 348 − 3(5) = 333.
The previous optimal tableau tells us that for 0 ≤ θ ≤ 4, woodworking capacity is worth $11/day and
metalworking capacity is worth $0.50/day. Increasing θ from 4 to 5 increases woodworking capacity by one
day. Using the prices $11/day and $0.50/day, the change in the optimal objective value should be:
We have obtained two different values for the change in the optimal objective value, 1z = −3 and 1z = 10.50.
Reconcile the difference between these values.
22. An investor has $5000 and two potential investments. Let x j for j = 1 and j = 2 denote her allocation to investment
j in thousands of dollars. From historical data, investments 1 and 2 are known to have an expected annual return of
20 and 16 percent, respectively. Also, the total risk involved with investments 1 and 2, as measured by the variance
of total return, is known to be given by 2x1 + x2 + (x1 + x2 ), so that risk increases with total investment (x1 + x2 )
and with the amount of each individual investment. The investor would like to maximize her return and at the same
time minimize her risk. Figure E3.6 illustrates the conflict between these two objectives. Point A in this figure
corresponds to investing nothing, point B to investing all $5000 in the second alternative, and point C to investing
completely in the first alternative. Every other point in the shaded region of the figure corresponds to some other
investment strategy; that is, to a feasible solution to the constraints:
To deal with the conflicting objectives, the investor decides to combine return and risk into a single objective
= 20x1 + 16x2 − θ[2x1 + x2 + (x1 + x2 )].
She uses the parameter θ in this objective function to weigh the trade-off between the two objectives.
Because the ‘‘most appropriate’’ trade-off parameter is difficult to assess, the investor would like to maximize
the objective function (28) subject to the constraints (27), for all values of θ, and then use secondary considerations,
not captured in this simple model, to choose from the alternative optimal solutions.
Use parametric linear programming to solve the problem for all nonnegative values of θ.
Plot the optimal objective value, the expected return, and the risk as a function of θ.
Suppose that the investor can save at 6% with no risk. For what values of θ will she save any money using the
23. An alternative model for the investment problem discussed in the previous exercise is:
In this model, the investor maximizes her expected return, constraining the risk that she is willing to incur by the
a) Use parametric linear programming to solve the problem for all nonnegative values of γ .
b) Plot the expected return and risk as a function of γ .
c) Interpret the solutions on Fig. E3.6 of Exercise 22.
24. The shadow-price concept has been central to our development of sensitivity analysis in this chapter. In this exercise, we consider how changing the initial problem formulation alters the development. Suppose that the initial
Solving this problem by the simplex method determines the shadow prices for the constraints as y1 , y2 , . . . , ym .
a) Suppose that the first constraint were multiplied by 2 and stated instead as:
Let ŷ1 denote the value of the shadow price for this constraint. How is ŷ1 related to y1 ?
b) What happens to the value of the shadow prices if every coefficient c j is multiplied by 2 in the original problem
c) Suppose that the first variable x1 in the model is rescaled by a factor of 3. That is, let x10 = 3x1 and replace x1
everywhere in the model by (x10 /3). Do the shadow prices change? Would it be possible for x10 to appear in an
optimal basis, if x1 could not appear in an optimal basis of the original formulation for the problem?
d) Do the answers to parts (a), (b), and (c) change if the original problem is stated with all equality constraints:
25. [Excel spreadsheet available at http://web.mit.edu/15.053/www/Exer3.25.xls] Shortly after the
beginning of the oil embargo, the Eastern District Director of the Government Office of Fuel Allocation was
concerned that he would soon have to start issuing monthly allocations specifying the amounts of heating oil that
each refinery in the district would send to each city to ensure that every city would receive its quota.
Since different refineries used a variety of alternative sources of crude oil, both foreign and domestic, the cost
of products at each refinery varied considerably. Consequently, under current government regulations, the prices
that could be charged for heating oil would vary from one refinery to another. To avoid political criticism, it was
felt that, in making allocations of supplies from the refineries to the cities, it was essential to maintain a reasonably
uniform average refinery price for each city. In fact, the Director felt that the average refinery price paid by any city
should not be more than 3% above the overall average.
Another complication had arisen in recent months, since some of the emergency allocations of supplies to certain
cities could not be delivered due to a shortage in tanker capacity. If deliveries of the allocated supplies were to be
feasible, the limited transportation facilities on some of the shipping routes would have to be recognized. Finally,
it would be most desirable to maintain distribution costs as low as possible under any allocation plan, if charges of
government inefficiency were to be avoided.
Data for a simplified version of the problem, with only three refineries and four cities, are given in Fig. E3.7.
The allocation problem can be formulated as the linear program shown in Fig. E3.8. The decision variables are
A − n = Barrels of heating oil (in thousands) to be supplied from Refinery A to
B − n = Barrels of heating oil (in thousands) to be supplied from Refinery B to
C − n = Barrels of heating oil (in thousands) to be supplied by Refinery C to
PMAX = A value higher than the average refinery price paid by any of the four
There are four types of constraints that must be satisfied:
3. Average price restrictions which impose an upper limit to the average refinery price which will be paid by any
4. Shipping capacity limits on some of the routes.
All the constraints are straightforward except possibly the average price reductions. To restrict the average refinery
price paid by City 1 to be less than the variable PMAX, the following expression is used:
(10.53)(A − 1) + (9.39)(B − 1) + (12.43)(C − 1)
0.1915(A − 1) + 0.1701(B − 1) + 0.2260(C − 1) − PMAX ≤ 0.
Such a restriction is included for each city, to provide a uniform upper bound on average prices. The value of PMAX
is limited by the prescribed maximum of 11.40 = 11.07 × 1.03 by the constraint
The computer analysis of the linear programming model is given in Fig. E3.9
Determine the detailed allocations that might be used for December.
Evaluate the average refinery prices paid by each city under these allocations.
Determine the best way to utilize an additional tanker-truck capacity of 10,000 barrels per month.
Discuss the inefficiency in distribution costs resulting from the average refinery price restrictions.
Evaluate the applicability of the model in the context of a full allocation system.
Figure E3.7 Data for heating oil allocation problem.
f) Discuss any general insights into the fuel allocation problem provided by this model.
26. The Krebs Wire Company is an intermediate processor that purchases uncoated wire in standard gauges and then
applies various coatings according to customer specification. Krebs Wire has essentially two basic products—
standard inexpensive plastic and the higher quality Teflon. The two coatings come in a variety of colors but these
are changed easily by introducing different dyes into the basic coating liquid.
The production facilities at Krebs Wire consist of two independent wire trains, referred to as the Kolbert and
Loomis trains. Both the standard plastic-coated and the quality Teflon-coated wire can be produced on either
process train; however, production of Teflon-coated wire is a slower process due to drying requirements. The
different production rates in tons per day are given below:
It has been traditional at Krebs Wire to view production rates in terms of daily tonnage, as opposed to reels per day
or other production measures. The respective contributions in dollars per day are:
Planning at Krebs Wire is usually done on a monthly basis. However, since most employee vacations are
scheduled over the two summer months, management feels that production planning for the two summer months
should be combined to facilitate vacation scheduling. Each month the process trains must be shut down for scheduled
maintenance, so that the total days available for production per month are as follows:
Figure E3.8 Formulation of the heating-oil allocation model.
The scheduling process is further complicated by the fact that, over the two summer months, the total amount of
time available for production is limited to 102 machine days due to vacation schedules.
The amounts of wire that the management feels it can sell in the coming two months are:
Both types of wire may be stored for future delivery. Space is available in Krebs’ own warehouse, which has a
capacity of 20 tons. The inventory and carrying costs in dollars per ton for wire produced in July and delivered in
Due to a commitment of warehouse capacity to other products in September, it is not possible to stock any wire
To help in planning production for the two summer months, Krebs Wire management has formulated and solved
a linear program (see Figs. E3.10 and E3.11) in order to determine the production schedule that will maximize
a) What does the output in Fig. E3.12 tell the production manager about the details of scheduling his machines?
b) There is the possibility that some employees might be persuaded to take their vacations in June or September.
c) The solution in Fig. E3.12 suggests that Teflon should be made only on the Loomis train in July and only on the
d) Should Krebs Wire lease additional warehouse capacity at a cost of $2.00 above the inventory and carrying costs?
If so, how would the optimal solution change?
e) The sales manager feels that future sales might be affected if the firm could not meet demand for plastic-coated
wire in August. What, if anything, should be done?
f) One of Krebs’ customers has requested a special run of twenty tons of corrosion-resistant wire to be delivered
at the end of August. Krebs has made this product before and found that it can be produced only on the Loomis
machine, due to technical restrictions. The Loomis machine can produce this special wire at a rate of 40 tons
per day, and the customer will pay $12 per ton. Krebs cannot start production before the 1st of August due to a
shortage of raw materials. Should the firm accept the order?
27. Consider the computer output for the Krebs Wire case in Exercise 26. What does the ‘‘100 percent rule’’ tell us in
Figure E3.9 Solution of the allocation model. (Continued on next page.)
a) The objective-function coefficients changed as follows:
b) The objective-function coefficients changed as follows:
c) The objective-function coefficients changed as follows:
d) The righthand-side values changed as follows:
e) The righthand-side values changed as follows:
28. [Excel spreadsheet available at http://web.mit.edu/15.053/www/Exer3.28.xls] Mr. Watson has
100 acres that can be used for growing corn or soybeans. His yield is 95 bushels per acre per year of corn of 60
bushels of soybeans. Any fraction of the 100 acres can be devoted to growing either crop. Labor requirements are
4 hours per acre per year, plus 0.70 hour per bushel of corn and 0.15 hour per bushel of soybeans. Cost of seed,
fertilizer, and so on is 24 cents per bushel of corn and 40 cents per bushel of soybeans. Corn can be sold for $1.90
per bushel, and soybeans for $3.50 per bushel. Corn can be purchased for $3.00 per bushel, and soybeans for $5.00
Figure E3.10 Formulation of the Krebs Wire linear program.
In the past, Mr. Watson has occasionally raised pigs and calves. He sells the pigs or calves when they reach
the age of one year. A pig sells for $80 and a calf for $160. One pig requires 20 bushels of corn or 25 bushels
of soybeans, plus 25 hours of labor and 25 square feet of floor space. One calf requires 50 bushels of corn or 20
bushels of soybeans, 80 hours of labor, and 30 square feet of floor space.
Mr. Watson has 10,000 square feet of floor space. He has available per year 2000 hours of his own time and
another 4000 hours from his family. He can hire labor at $3.00 per hour. However, for each hour of hired labor,
0.15 hour of his time is required for supervision.
Mr. Watson’s son is a graduate student in business, and he has formulated a linear program to show his father how
much land should be devoted to corn and soybeans and in addition, how many pigs and/or calves should be raised
In Fig. 3.12, Tableau 1 shows an initial simplex tableau for Watson’s farm using the definitions of variables and
constraints given below, and Tableau 2 shows the results of several iterations of the simplex algorithm.
Figure E3.11 Solution of the Krebs Wire model.
Figure E3.12 Initial and final tableaus for Watson’s model.
a) What is the optimal solution to the farmer’s problem?
b) What are the binding constraints and what are the shadow prices on these constraints? [Hint: The initial tableau
c) At what selling price for corn does the raising of corn become attractive? At this price +$0.05, what is an optimal
d) The farmer’s city nephew wants a summer job, but because of his inexperience he requires 0.2 hours of supervision
for each hour he works. How much can the farmer pay him and break even? How many hours can the nephew
work without changing the optimal basis? What activity leaves the basis if he works more than that amount?
e) One of the farmer’s sons wants to leave for the city. How much can the old man afford to pay him to stay? Since
that is not enough, he goes, reducing the family labor pool by 2000 hours/year. What is the optimal program
f) How much can the selling price of soybeans increase without changing the basis? Decrease? For both of these
basis changes, what activity leaves the basis? Are these basis changes intuitively obvious?
g) Does there exist an alternative optimal solution to the linear program? Alternative optimal shadow prices? If so,
29. The initial data tableau, in canonical form, for a linear program to be minimized is given below:
A standard commercial linear-programming code employing the revised simplex method would have the following
information at its disposal: (1) the above initial data tableau; (2) the current values of the basic variables and the
row in which each is basic; and (3) the current coefficients of the initial unit columns. Items (2) and (3) are given
a) What is the current basic feasible solution?
b) We can define simplex multipliers to be the shadow prices associated with the current basic solution even if the
solution is not optimal. What are the values of the simplex multipliers associated with the current solution?
c) The current solution is optimal if the reduced costs of the nonbasic variables are nonnegative. Which variables
are nonbasic? Determine the reduced cost of the nonbasic variables and show that the current solution is not
d) Suppose that variable x4 should now be introduced into the basis. To determine the variable to drop from the
basis, we use the minimum-ratio rule, which requires that we know not only the current righthand-side values
but also the coefficients of x4 in the current tableau. These coefficients of x4 need to be computed.
In performing the simplex method, multiples of the initial tableau have been added to and subtracted from one
another to produce the final tableau. The coefficients in the current tableau of the initial unit columns summarize
i) What multiple of rows 1, 2, and 3, when added together, must produce the current row 1 (even though we do
not know all the current coefficients in row 1)? The current row 2? The current row 3?
ii) Using the rationale of (i) determine the coefficients of x4 in the current tableau. Note that it is unnecessary to
determine any of the other unknown columns.
iii) How should the pivot operation be performed to update the tableau consisting of only x5 , x6 , and x7 ?
You have now completed an iteration of the simplex algorithm using only (1) the initial data, (2) the current
values of the basic variables and the row in which each is basic, and (3) the current coefficients of the initial unit
columns. This is the essence of the revised simplex method. (See Appendix B for further details.)
Exercises 1 and 2 are due to Steven C. Wheelwright of the Harvard Business School. Exercises 3, 4, and 5
are based on the Land of Milk and Honey case, written by Steven Wheelwright, which in turn is based on a
formulation exercise from Quantitative Analysis of Business Decisions, by H. Bierman, C. P. Bonnini, and
W. H. Hausman, Third Edition, Richard D. Irwin, Inc., 1969.
Exercises 13 and 28 are variations of problems used by C. Roger Glassey of the University of California,
Berkeley, and Exercise 28 is in turn based on a formulation exercise from Linear Programming, by G. Hadley,
Addison-Wesley Pyblishing Company, Inc., 1963.
Exercise 17 is inspired by the French Electric Power Industry case written by John E. Bishop, based on
‘‘Application of Linear Programming to Investments in the Electric Power Industry,’’ by P. Massé and R.
Gibrat, which appeared in Management Science, 1957.
Exercise 25 is based on the Holden Consulting Company case written by Basil A. Kalyman.
Exercise 26 is based on the Krebs Wire Company case written by Ronald S. Frank, based on a case of one of
In the preceding chapter on sensitivity analysis, we saw that the shadow-price interpretation of the optimal
simplex multipliers is a very useful concept. First, these shadow prices give us directly the marginal worth
of an additional unit of any of the resources. Second, when an activity is ‘‘priced out’’ using these shadow
prices, the opportunity cost of allocating resources to that activity relative to other activities is determined.
Duality in linear programming is essentially a unifying theory that develops the relationships between a
given linear program and another related linear program stated in terms of variables with this shadow-price
interpretation. The importance of duality is twofold. First, fully understanding the shadow-price interpretation
of the optimal simplex multipliers can prove very useful in understanding the implications of a particular
linear-programming model. Second, it is often possible to solve the related linear program with the shadow
prices as the variables in place of, or in conjunction with, the original linear program, thereby taking advantage
of some computational efficiencies. The importance of duality for computational procedures will become
more apparent in later chapters on network-flow problems and large-scale systems.
We can motivate our discussion of duality in linear programming by considering again the simple example
given in Chapter 2 involving the firm producing three types of automobile trailers. Recall that the decision
x1 = number of flat-bed trailers produced per month,
x2 = number of economy trailers produced per month,
x3 = number of luxury trailers produced per month.
The constraining resources of the production operation are the metalworking and woodworking capacities
measured in days per month. The linear program to maximize contribution to the firm’s overhead (in hundreds
After adding slack variables, the initial tableau is stated in canonical form in Tableau 1.
In Chapter 2, the example was solved in detail by the simplex method, resulting in the final tableau,
As we saw in Chapter 3, the shadow prices, y1 for metalworking capacity and y2 for woodworking
capacity, can be determined from the final tableau as the negative of the reduced costs associated with the
slack variables x4 and x5 . Thus these shadow prices are y1 = 11 and y2 = 21 , respectively.
We can interpret the shadow prices in the usual way. One additional day of metalworking capacity is worth
$1100, while one additional day of woodworking capacity is worth only $50. These values can be viewed as
the breakeven rents that the firm could pay per day for additional capacity of each type. If additional capacity
could be rented for less than its corresponding shadow price, it would be profitable to expand capacity in
this way. Hence, in allocating the scarce resources to the production activities, we have determined shadow
prices for the resources, which are the values imputed to these resources at the margin.
Let us examine some of the economic properties of the shadow prices associated with the resources.
Recall, from Chapter 3, Eq. (11), that the reduced costs are given in terms of the shadow prices as follows:
Since ai j is the amount of resource i used per unit of activity j, and yi is the imputed value of that resource,
is the total value of the resources used per unit of activity j. It is thus the marginal resource cost for using
that activity. If we think of the objective coefficients c j as being marginal revenues, the reduced costs c j are
simply net marginal revenues (i.e., marginal revenue minus marginal cost).
For the basic variables x1 and x3 , the reduced costs are zero,
The values imputed to the resources are such that the net marginal revenue is zero on those activities operated
at a positive level. That is, for any production activity at positive level, marginal revenue must equal marginal
The situation is much the same for the nonbasic variables x2 , x4 , and x5 , with corresponding reduced
The reduced costs for all nonbasic variables are negative. The interpretation is that, for the values imputed
to the scarce resources, marginal revenue is less than marginal cost for these activities, so they should not be
pursued. In the case of x2 , this simply means that we should not produce any economy trailers. The cases of
x4 and x5 are somewhat different, since slack variables represent unused capacity. Since the marginal revenue
of a slack activity is zero, its reduced cost equals minus its marginal cost, which is just the shadow price of
the corresponding capacity constraint, as we have seen before.
The above conditions interpreted for the reduced costs of the decision variables are the familiar optimality
conditions of the simplex method. Economically we can see why they must hold. If marginal revenue exceeds
marginal cost for any activity, then the firm would improve its contribution to overhead by increasing that
activity. If, however, marginal cost exceeds marginal revenue for an activity operated at a positive level, then
the firm would increase its contribution by decreasing that activity. In either case, a new solution could be
found that is an improvement on the current solution. Finally, as we have seen in Chapter 3, those nonbasic
variables with zero reduced costs represent possible alternative optimal solutions.
Until now we have used the shadow prices mainly to impute the marginal resource cost associated with
each activity. We then selected the best activities for the firm to pursue by comparing the marginal revenue of
an activity with its marginal resource cost. In this case, the shadow prices are interpreted as the opportunity
costs associated with consuming the firm’s resources. If we now value the firm’s total resources at these
is exactly equal to the optimal value of the objective function of the firm’s decision problem. The implication
of this valuation scheme is that the firm’s metalworking and woodworking capacities have an imputed worth
of $264 and $30, respectively. Essentially then, the shadow prices constitute an internal pricing system for
1. permits the firm to select which activity to pursue by considering only the marginal profitability of its
2. allocates the contribution of the firm to its resources at the margin.
Suppose that we consider trying to determine directly the shadow prices that satisfy these conditions,
without solving the firm’s production-decision problem. The shadow prices must satisfy the requirement
that marginal revenue be less than or equal to marginal cost for all activities. Further, they must be nonnegative since they are associated with less-than-or-equal-to constraints in a maximization decision problem.
Therefore, the unknown shadow prices y1 on metalworking capacity and y2 on woodworking capacity must
These constraints require that the shadow prices be chosen so that the net marginal revenue for each activity
is nonpositive. If this were not the case, an improvement in the firm’s total contribution could be made by
changing the choice of production activities.
Recall that the shadow prices were interpreted as breakeven rents for capacity at the margin. Imagine for
the moment that the firm does not own its productive capacity but has to rent it. Now consider any values for
the shadow prices, or rental rates, that satisfy the above constraints, say y1 = 4 and y2 = 4. The total worth
of the rented capacities evaluated at these shadow prices is v = 24(4) + 60(4) = 336, which is greater than
the maximum contribution of the firm. Since the imputed value of the firm’s resources is derived solely from
allocating the firm’s contribution to its resources, v = 336 is too high a total worth to impute to the firm’s
resources. The firm clearly could not break even if it had to rent its production capacity at such rates.
If we think of the firm as renting all of its resources, then surely it should try to rent them at least cost.
This suggests that we might determine the appropriate values of the shadow prices by minimizing the total
rental cost of the resources, subject to the above constraints. That is, solve the following linear program:
If we solve this linear program by the simplex method, the resulting optimal solution is y1 = 11, y2 = 21 ,
and v = 294. These are exactly the desired values of the shadow prices, and the value of v reflects that
the firm’s contribution is fully allocated to its resources. Essentially, the linear program (2), in terms of the
shadow prices, determines rents for the resources that would allow the firm to break even, in the sense that its
total contribution would exactly equal the total rental value of its resources. However, the firm in fact owns
its resources, and so the shadow prices are interpreted as the breakeven rates for renting additional capacity.
Thus, we have observed that, by solving (2), we can determine the shadow prices of (1) directly. Problem
(2) is called the dual of Problem (1). Since Problem (2) has a name, it is helpful to have a generic name for
the original linear program. Problem (1) has come to be called the primal.
In solving any linear program by the simplex method, we also determine the shadow prices associated
with the constraints. In solving (2), the shadow prices associated with its constraints are u 1 = 36, u 2 = 0,
and u 3 = 6. However, these shadow prices for the constraints of (2) are exactly the optimal values of the
decision variables of the firm’s allocation problem. Hence, in solving the dual (2) by the simplex method,
we apparently have solved the primal (1) as well. As we will see later, this will always be the case since ‘‘the
dual of the dual is the primal.’’ This is an important result since it implies that the dual may be solved instead
of the primal whenever there are computational advantages.
Let us further emphasize the implications of solving these problems by the simplex method. The optimality conditions of the simplex method require that the reduced costs of basic variables be zero. Hence,
These equations state that, if a decision variable of the primal is positive, then the corresponding constraint
in the dual must hold with equality. Further, the optimality conditions require that the nonbasic variables be
zero (at least for those variables with negative reduced costs); that is,
These observations are often referred to as complementary slackness conditions since, if a variable is positive,
its corresponding (complementary) dual constraint holds with equality while, if a dual constraint holds with
strict inequality, then the corresponding (complementary) primal variable must be zero.
These results are analogous to what we have seen in Chapter 3. If some shadow price is positive, then
the corresponding constraint must hold with equality; that is,
Further, if a constraint of the primal is not binding, then its corresponding shadow price must be zero. In
our simple example there do not happen to be any nonbinding constraints, other than the implicit nonnegativity constraints. However, the reduced costs have the interpretation of shadow prices on the nonnegativity
constraints, and we see that the reduced costs of x1 and x3 are appropriately zero.
In this chapter we develop these ideas further by presenting the general theory of duality in linear
The duality principles we have illustrated in the previous sections can be stated formally in general terms.
Associated with this primal problem there is a corresponding dual problem given by:
These primal and dual relationships can be conveniently summarized as in Fig. 4.1.
Without the variables y1 , y2 , . . . , ym , this tableau is essentially the tableau form utilized in Chapters 2
and 3 for a linear program. The first m rows of the tableau correspond to the constraints of the primal problem,
while the last row corresponds to the objective function of the primal problem. If the variables x1 , x2 , . . . xn ,
are ignored, the columns of the tableau have a similar interpretation for the dual problem. The first n columns
of the tableau correspond to the constraints of the dual problem, while the last column corresponds to the
objective function of the dual problem. Note that there is one dual variable for each explicit constraint in the
primal, and one primal variable for each explicit constraint in the dual. Moreover, the dual constraints are the
familiar optimality condition of ‘‘pricing out’’ a column. They state that, at optimality, no activity should
appear to be profitable from the standpoint of its reduced cost; that is,
Figure 4.1 Primal and dual relationships.
To illustrate some of these relationships, let us consider an example formulated in Chapter 1. Recall the
portfolio-selection problem, where the decision variables are the amounts to invest in each security type:
Maximize z = 0.043xA + 0.027xB + 0.025xC + 0.022xD + 0.045xE ,
The dual of this problem can be found easily by converting it to the standard primal formulation given in (3).
This is accomplished by multiplying the second constraint by −1, thus changing the ‘‘greater than or equal
to’’ constraint to a ‘‘less than or equal to’’ constraint. The resulting primal problem becomes:
Maximize z = 0.043xA + 0.027xB + 0.025xC + 0.022xD + 0.045xE ,
0.6xA + 0.6xB − 0.4xC − 0.4xD + 3.6xE ≤ 0,
According to expression (4), the corresponding dual problem is:
By applying the simplex method, the optimal solution to both primal and dual problems can be found to be:∗
As we have seen before, the optimal values of the objective functions of the primal and dual solutions
are equal. Furthermore, an optimal dual variable is nonzero only if its associated constraint in the primal is
binding. This should be intuitively clear, since the optimal dual variables are the shadow prices associated with
the constraints. These shadow prices can be interpreted as values imputed to the scarce resources (binding
constraints), so that the value of these resources equals the value of the primal objective function.
To further develop that the optimal dual variables are the shadow prices discussed in Chapter 3, we note
that they satisfy the optimality conditions of the simplex method. In the final tableau of the simplex method,
the reduced costs of the basic variables must be zero. As an example, consider basic variable xA . The reduced
cost of xA in the final tableau can be determined as follows:
= 0.043 − 1(0.0294) − 0(0) − 0.6(0.00636) − 4(0.00244) = 0.
For nonbasic variables, the reduced cost in the final tableau must be nonpositive in order to ensure that no
improvements can be made. Consider nonbasic variable xB , whose reduced cost is determined as follows:
= 0.027 − 1(0.0294) − 1(0) − 0.6(0.00636) − 10(0.00244) = −0.0306.
The remaining basic and nonbasic variables also satisfy these optimality conditions for the simplex method.
Therefore, the optimal dual variables must be the shadow prices associated with an optimal solution.
Since any linear program can be put in the form of (3) by making simple transformations similar to those
used in this example, then any linear program must have a dual linear program. In fact, since the dual problem
(4) is a linear program, it must also have a dual. For completeness, one would hope that the dual of the dual
is the primal (3), which is indeed the case. To show this we need only change the dual (4) into the form of
(3) and apply the definition of the dual problem. The dual may be reformulated as a maximization problem
with less-than-or-equal-to constraints, as follows:
Excel spreadsheet available at http://web.mit.edu/15.053/www/Sect4.2_Primal_Dual.xls
Applying the definition of the dual problem and letting the dual variables be x j , j = 1, 2, . . . , n, we have
which, by multiplying the constraints by minus one and converting the objective function to maximization,
is clearly equivalent to the primal problem. Thus, the dual of the dual is the primal.
Very often linear programs are encountered in equality form with nonnegative variables. For example, the
canonical form, which is used for computing a solution by the simplex method, is in equality form. It is of
interest, then, to find the dual of the equality form:
A problem in equality form can be transformed into inequality form by replacing each equation by two
inequalities. Formulation (7) can be rewritten as
The dual of the equality form can then be found by applying the definition of the dual to this problem. Letting
yi+ and yi− (i = 1, 2, . . . , m) be the dual variables associated with the first m and second m constraints,
respectively, from expression (4), we find the dual to be:
Letting yi = yi+ − yi− , and noting that yi is unrestricted in sign, gives us the dual of the equality form (7):
Note that the dual variables associated with equality constraints are unrestricted.
There are a number of relationships between primal and dual, depending upon whether the primal problem
is a maximization or a minimization problem and upon the types of constraints and restrictions on the variables.
To illustrate some of these relationships, let us consider a general maximization problem as follows:
We can change the general primal problem to equality form by adding the appropriate slack and surplus
Letting yi , yi0 , and yi00 be dual variables associated respectively with the three sets of equations, the dual of
where yi00 is unrestricted in sign and the last inequality could be written yi0 ≤ 0. Thus, if the primal problem
is a maximization problem, the dual variables associated with the less-than-or-equal-to constraints are nonnegative, the dual variables associated with the greater-than-or-equal-to constraints are nonpositive, and the
dual variables associated with the equality constraints are unrestricted in sign.
These conventions reflect the interpretation of the dual variables as shadow prices of the primal problem.
A less-than-or-equal-to constraint, normally representing a scarce resource, has a positive shadow price,
since the expansion of that resource generates additional profits. On the other hand, a greater-than-orequal-to constraint usually represents an external requirement (e.g., demand for a given commodity). If that
requirement increases, the problem becomes more constrained; this produces a decrease in the objective
function and thus the corresponding constraint has a negative shadow price. Finally, changes in the righthand
side of an equality constraint might produce either negative or positive changes in the value of the objective
function. This explains the unrestricted nature of the corresponding dual variable.
Let us now investigate the duality relationships when the primal problem is cast in minimization, rather
Since the dual of the dual is the primal, we know that the dual of a minimization problem will be a maximization
problem. The dual of (11) can be found by performing transformations similar to those conducted previously.
The resulting dual of (11) is the following maximization problem:
Observe that now the sign of the dual variables associated with the inequality constraints has changed,
as might be expected from the shadow-price interpretation. In a cost-minimization problem, increasing the
available resources will tend to decrease the total cost, since the constraint has been relaxed. As a result, the
dual variable associated with a less-than-or-equal-to constraint in a minimization problem is nonpositive. On
the other hand, increasing requirements could only generate a cost increase. Thus, a greater-than-or-equal-to
constraint in a minimization problem has an associated nonnegative dual variable.
The primal and dual problems that we have just developed illustrate one further duality correspondence.
If (12) is considered as the primal problem and (11) as its dual, then unrestricted variables in the primal are
associated with equality constraints in the dual.
We now can summarize the general duality relationships. Basically we note that equality constraints in the
primal correspond to unrestricted variables in the dual, while inequality constraints in the primal correspond
to restricted variables in the dual, where the sign of the restriction in the dual depends upon the combination of
objective-function type and constraint relation in the primal. These various correspondences are summarized
in Table 4.1. The table is based on the assumption that the primal is a maximization problem. Since the dual
of the dual is the primal, we can interchange the words primal and dual in Table 4.1 and the correspondences
In the previous sections of this chapter we have illustrated many duality properties for linear programming. In
this section we formalize some of the assertions we have already made. The reader not interested in the theory
should skip over this section entirely, or merely read the statements of the properties and ignore the proofs.
We consider the primal problem in inequality form so that the primal and dual problems are symmetric. Thus,
any statement that is made about the primal problem immediately has an analog for the dual problem, and
conversely. For convenience, we restate the primal and dual problems.
The first property is referred to as ‘‘weak duality’’ and provides a bound on the optimal value of the
objective function of either the primal or the dual. Simply stated, the value of the objective function for any
feasible solution to the primal maximization problem is bounded from above by the value of the objective
function for any feasible solution to its dual. Similarly, the value of the objective function for its dual is
bounded from below by the value of the objective function of the primal. Pictorially, we might represent the
The sequence of properties to be developed will lead us to the ‘‘strong duality" property, which states
that the optimal values of the primal and dual problems are in fact equal. Further, in developing this result,
we show how the solution of one of these problems is readily available from the solution of the other.
Weak Duality Property. If x j , j = 1, 2, . . . , n, is a feasible solution to the primal problem and
y i , i = 1, 2, . . . , m, is a feasible solution to the dual problem, then
The weak duality property follows immediately from the respective feasibility of the two solutions. Primal
Hence, multiplying the ith primal constraint by y i and adding yields:
while multiplying the jth dual constraint by x j and adding yields:
Since the lefthand sides of these two inequalities are equal, together they imply the desired result that
There are a number of direct consequences of the weak duality property. If we have feasible solutions
to the primal and dual problems such that their respective objective functions are equal, then these solutions
are optimal to their respective problems. This result follows immediately from the weak duality property,
since a dual feasible solution is an upper bound on the optimal primal solution and this bound is attained
by the given feasible primal solution. The argument for the dual problem is analogous. Hence, we have an
optimality property of dual linear programs.
Optimality Property. If x̂ j , j = 1, 2, . . . , n, is a feasible solution to the primal problem and ŷi , i =
1, 2, . . . , m, is a feasible solution to the dual problem, and, further,
then x̂ j , j = 1, 2, . . . , n, is an optimal solution to the primal problem and ŷi , i = 1, 2, . . . , m, is an
Furthermore, if one problem has an unbounded solution, then the dual of that problem is infeasible. This
must be true for the primal since any feasible solution to the dual would provide an upper bound on the primal
objective function by the weak duality theorem; this contradicts the fact that the primal problem is unbounded.
Again, the argument for the dual problem is analogous. Hence, we have an unboundedness property of dual
Unboundedness Property. If the primal (dual) problem has an unbounded solution, then the dual (primal) problem is infeasible.
We are now in a position to give the main result of this section, the ‘‘strong duality’’ property. The
importance of this property is that it indicates that we may in fact solve the dual problem in place of or
in conjunction with the primal problem. The proof of this result depends merely on observing that the
shadow prices determined by solving the primal problem by the simplex method give a dual feasible solution,
satisfying the optimality property given above.
Strong Duality Property. If the primal (dual) problem has a finite optimal solution, then so does the
dual (primal) problem, and these two values are equal. That is, ẑ = v̂ where
Let us see how to establish this property. We can convert the primal problem to the equivalent equality
form by adding slack variables as follows:
Suppose that we have applied the simplex method to the linear program and x̂ j , j = 1, 2, . . . , n, is the resulting
optimal solution. Let ŷi , i = 1, 2, . . . , m, be the shadow prices associated with the optimal solution. Recall
that the shadow prices associated with the original constraints are the multiples of those constraints which,
when subtracted from the original form of the objective function, yield the form of the objective function in
the final tableau [Section 3.2, expression (11)]. Thus the following condition holds:
where, due to the optimality criterion of the simplex method, the reduced costs satisfy:
Conditions (16) and (17) imply that ŷi , for i = 1, 2, . . . , m, constitutes a feasible solution to the dual problem.
When x j is replaced by the optimal value x̂ j in expression (15), the term
is equal to zero, since c j = 0 when x̂ j is basic, and x̂ j = 0 when x̂ j is nonbasic. Therefore, the maximum
Moreover, since x̂ j , for j = 1, 2, . . . , n, is an optimal solution to the primal problem,
This is the optimality property for the primal feasible solution x̂ j , j = 1, 2, . . . , n, and the dual feasible
solution ŷi , i = 1, 2, . . . , m, so they are optimal for their respective problems. (The argument in terms of
It should be pointed out that it is not true that if the primal problem is infeasible, then the dual problem
is unbounded. In this case the dual problem may be either unbounded or infeasible. All four combinations
of feasibility and infeasibility for primal and dual problems may take place. An example of each is indicated
In example (2) of Table 4.2 it should be clear that x2 may be increased indefinitely without violating
feasibility while at the same time making the objective function arbitrarily large. The constraints of the dual
problem for this example are clearly infeasible since y1 + y2 ≥ 2 and y1 + y2 ≤ −1 cannot simultaneously
hold. A similar observation is made for example (3), except that the primal problem is now infeasible while
the dual variable y1 may be increased indefinitely. In example (4), the fact that neither primal nor dual
problem is feasible can be checked easily by multiplying the first constraint of each by minus one.
We have remarked that the duality theory developed in the previous section is a unifying theory relating the
optimal solution of a linear program to the optimal solution of the dual linear program, which involves the
shadow prices of the primal as decision variables. In this section we make this relationship more precise by
defining the concept of complementary slackness relating the two problems.
Complementary Slackness Property. If, in an optimal solution of a linear program, the value of the dual
variable (shadow price) associated with a constraint is nonzero, then that constraint must be satisfied with
equality. Further, if a constraint is satisfied with strict inequality, then its corresponding dual variable
For the primal linear program posed as a maximization problem with less-than-or-equal-to constraints,
We can show that the complementary-slackness conditions follow directly from the strong duality property
just presented. Recall that, in demonstrating the weak duality property, we used the fact that:
for any x̂ j , j = 1, 2, . . . , n, and ŷi , i = 1, 2, . . . , m, feasible to the primal and dual problems, respectively.
Now, since these solutions are not only feasible but optimal to these problems, equality must hold throughout.
Hence, considering the righthand relationship in (18), we have:
Since the dual variables ŷi are nonnegative and their coefficients
are nonpositive by primal feasibility, this condition can hold only if each of its terms is equal to zero; that is,
These latter conditions are clearly equivalent to (i) and (ii) above.
For the dual linear program posed as a minimization problem with greater-than-or-equal-to constraints,
the complementary-slackness conditions are the following:
These conditions also follow directly from the strong duality property by an argument similar to that given
above. By considering the lefthand relationship in (18), we can easily show that
The complementary-slackness conditions of the primal problem have a fundamental economic interpretation. If the shadow price of the ith resource (constraint) is strictly positive in the optimal solution ŷi > 0,
then we should require that all of this resource be consumed by the optimal program; that is,
If, on the other hand, the ith resource is not fully used; that is,
then its shadow price should be zero, ŷi = 0.
The complementary-slackness conditions of the dual problem are merely the optimality conditions for
the simplex method, where the reduced cost c j associated with any variable must be nonpositive and is given
If x̂ j > 0, then x̂ j must be a basic variable and its reduced cost is defined to be zero. Thus,
then x̂ j must be nonbasic and set equal to zero in the optimal solution; x̂ j = 0.
We have shown that the strong duality property implies that the complementary-slackness conditions
must hold for both the primal and dual problems. The converse of this also is true. If the complementaryslackness conditions hold for both problems, then the strong duality property holds. To see this, let x̂ j , j =
1, 2, . . . , n, and ŷi , i = 1, 2, . . . , m, be feasible solutions to the primal and dual problems, respectively. The
complementary-slackness conditions (i) and (ii) for the primal problem imply:
while the complementary-slackness conditions (iii) and (iv) for the dual problem imply:
and hence the values of the primal and dual objective functions are equal. Since these solutions are feasible
to the primal and dual problems respectively, the optimality property implies that these solutions are optimal
to the primal and dual problems. We have, in essence, shown that the complementary-slackness conditions
holding for both the primal and dual problems is equivalent to the strong duality property. For this reason,
the complementary-slackness conditions are often referred to as the optimality conditions.
Optimality Conditions. If x̂ j , j = 1, 2, . . . , n, and ŷi , i = 1, 2, . . . , m, are feasible solutions to the
primal and dual problems, respectively, then they are optimal solutions to these problems if, and only if,
the complementary-slackness conditions hold for both the primal and the dual problems.
One of the most important impacts of the general duality theory presented in the previous section has been
on computational procedures for linear programming. First, we have established that the dual can be solved
in place of the primal whenever there are advantages to doing so. For example, if the number of constraints
of a problem is much greater than the number of variables, it is usually wise to solve the dual instead of the
primal since the solution time increases much more rapidly with the number of constraints in the problem
than with the number of variables. Second, new algorithms have been developed that take advantage of the
duality theory in more subtle ways. In this section we present the dual simplex method. We have already
seen the essence of the dual simplex method in Section 3.5, on righthand-side ranging, where the variable
transitions at the boundaries of each range are essentially computed by the dual simplex method. Further, in
Section 3.8, on parametric programming of the righthand side, the dual simplex method is the cornerstone of
the computational approach. In this section we formalize the general algorithm.
Recall the canonical form employed in the simplex method:
xm + a m,m+1 xm+1 + · · · + a m,n xn = bm ,
The conditions for x1 , x2 , . . . , xm to constitute an optimal basis for a maximization problem are:
We could refer to condition (i) as primal optimality (or equivalently, dual feasibility) and condition (ii) as
primal feasibility. In the primal simplex method, we move from basic feasible solution to adjacent basic
feasible solution, increasing (not decreasing) the objective function at each iteration. Termination occurs
when the primal optimality conditions are satisfied. Alternatively, we could maintain primal optimality (dual
feasibility) by imposing (i) and terminating when the primal feasibility conditions (ii) are satisfied. This latter
procedure is referred to as the dual simplex method and in fact results from applying the simplex method
to the dual problem. In Chapter 3, on sensitivity analysis, we gave a preview of the dual simplex method
when we determined the variable to leave the basis at the boundary of a righthand-side range. In fact, the
dual simplex method is most useful in applications when a problem has been solved and a subsequent change
on the righthand side makes the optimal solution no longer primal feasible, as in the case of parametric
programming of the righthand-side values.
The rules of the dual simplex method are identical to those of the primal simplex algorithm, except for
the selection of the variable to leave and enter the basis. At each iteration of the dual simplex method, we
and since yi ≥ 0 for i = 1, 2, . . . , m, these variables are a dual feasible solution. Further, at each iteration
of the dual simplex method, the most negative bi is chosen to determine the pivot row, corresponding to
choosing the most positive c j to determine the pivot column in the primal simplex method.
Prior to giving the formal rules of the dual simplex method, we present a simple example to illustrate the
essence of the procedure. Consider the following maximization problem with nonnegative variables given
in Tableau 3. This problem is in ‘‘dual canonical form" since the optimality conditions are satisfied, but the
In the dual simplex algorithm, we are attempting to make all variables nonnegative. The procedure is
the opposite of the primal method in that it first selects the variable to drop from the basis and then the new
variable to introduce into the basis in its place. The variable to drop is the basic variable associated with
the constraint with the most negative righthand-side value; in this case x4 . Next we have to determine the
entering variable. We select from only those nonbasic variables that have a negative coefficient in the pivot
row, since then, after pivoting, the righthand side becomes positive, thus eliminating the primal infeasibility
in the constraint. If all coefficients are positive, then the primal problem is clearly infeasible, because the
sum of nonnegative terms can never equal the negative righthand side.
In this instance, both nonbasic variables x1 and x2 are candidates. Pivoting will subtract some multiple,
say t, of the pivot row containing x4 from the objective function, to give:
(−3 + 2t)x1 + (−1 + 3t)x2 − t x4 − z = 2t.
Since we wish to maintain the optimality conditions, we want the coefficient of each variable to remain
Setting t = 31 preserves the optimality conditions and identifies the new basic variable with a zero coefficient
in the objective function, as required to maintain the dual canonical form.
These steps can be summarized as follows: the variable to leave the basis is chosen by:
The variable to enter the basis is determined by the dual ratio test:
Pivoting in x2 in the second constraint gives the new canonical form in Tableau 4.
Clearly, x3 is the leaving variable since b1 = − 13 is the only negative righthand-side coefficient; and x4 is
the entering variable since c4 /a 14 is the minimum dualratio in the first row. After pivoting, the new canonical
Since bi ≥ 0 for i = 1, 2, and c j ≤ 0 for j = 1, 2, . . . , 4, we have the optimal solution.
Following is a formal statement of the procedure. The proof of it is analogous to that of the primal
STEP (0) The problem is initially in canonical form and all c j ≤ 0.
STEP (1) If bi ≥ 0, i = 1, 2, . . . , m, then stop, we are optimal. If we continue, then
STEP (2) Choose the row to pivot in (i.e., variable to drop from the basis) by:
If a r j ≥ 0, j = 1, 2, . . . , n, then stop; the primal problem is infeasible (dual
unbounded). If we continue, then there exists a r j < 0 for some j = 1, 2, . . . , n.
STEP (3) Choose column s to enter the basis by:
STEP (4) Replace the basic variable in row r with variable s and reestablish the canonical
form (i.e., pivot on the coefficient a r s ).
Step (3) is designed to maintain c j ≤ 0 at each iteration, and Step (2) finds the most promising candidate for
There are many other variants of the simplex method. Thus far we have discussed only the primal and dual
methods. There are obvious generalizations that combine these two methods. Algorithms that perform both
primal and dual steps are referred to as primal-dual algorithms and there are a number of such algorithms. We
present here one simple algorithm of this form called the parametric primal-dual. It is most easily discussed
The above example can easily be put in canonical form by addition of slack variables. However, neither
primal feasibility nor primal optimality conditions will be satisfied. We will arbitrarily consider the above
example as a function of the parameter θ in Tableau 6.
Clearly, if we choose θ large enough, this system of equations satisfies the primal feasibility and primal
optimality conditions. The idea of the parametric primal-dual algorithm is to choose θ large initially so
that these conditions are satisfied, and attempt to reduce θ to zero through a sequence of pivot operations.
If we start with θ = 4 and let θ approach zero, primal optimality is violated when θ < 3. If we were to
reduce θ below 3, the objective-function coefficient of x2 would become positive. Therefore we perform a
primal simplex pivot by introducing x2 into the basis. We determine the variable to leave the basis by the
minimum-ratio rule of the primal simplex method:
x4 leaves the basis and the new canonical form is then shown in Tableau 7.
, the righthandThe optimality conditions are satisfied for
side value of the third constraint would become negative. Therefore, we perform a dual simplex pivot by
dropping x5 from the basis. We determine the variable to enter the basis by the rules of the dual simplex
After the pivot is performed the new canonical form is given in Tableau 8.
As we continue to decrease θ to zero, the optimality conditions remain satisfied. Thus the optimal final
tableau for this example is given by setting θ equal to zero.
Primal-dual algorithms are useful when simultaneous changes of both righthand-side and cost coefficients
are imposed on a previous optimal solution, and a new optimal solution is to be recovered. When parametric
programming of both the objective-function coefficients and the righthand-side values is performed simultaneously, a variation of this algorithm is used. This type of parametric programming is usually referred to as
the rim problem. (See Appendix B for further details.)
As we have seen in the two previous sections, duality theory is important for developing computational
procedures that take advantage of the relationships between the primal and dual problems. However, there is
another less obvious area that also has been heavily influenced by duality, and that is mathematical economics.
In the beginning of this chapter, we gave a preview of duality that interpreted the dual variables as shadow
prices imputed to the firm’s resources by allocating the profit (contribution) of the firm to its resources at
the margin. In a perfectly competitive economy, it is assumed that, if a firm could make profits in excess
of the value of its resources, then some other firm would enter the market with a lower price, thus tending
to eliminate these excess profits. The duality theory of linear programming has had a significant impact on
mathematical economics through the interpretation of the dual as the price-setting mechanism in a perfectly
competitive economy. In this section we will briefly sketch this idea.
Suppose that a firm may engage in any n production activities that consume and/or produce m resources
in the process. Let x j ≥ 0 be the level at which the jth activity is operated, and let c j be the revenue per
unit (minus means cost) generated from engaging in the jth activity. Further, let ai j be the amount of the
ith resource consumed (minus means produced) per unit level of operation of the jth activity. Assume that
the firm starts with a position of bi units of the ith resource and may buy or sell this resource at a price
yi ≥ 0 determined by an external market. Since the firm generates revenues and incurs costs by engaging in
production activities and by buying and selling resources, its profit is given by:
where the second term includes revenues from selling excess resources and costs of buying additional resources.
Note that if bi > nj=1 ai j x j , the firm sells bi − nj=1 ai j x j units of resources i to the marketplace at
a price yi . If, however, bi < nj=1 ai j x j , then the firm buys nj=1 ai j x j − bi units of resource i from the
Now assume that the market mechanism for setting prices is such that it tends to minimize the profits of
the firm, since these profits are construed to be at the expense of someone else in the market. That is, given
x j for j = 1, 2, . . . , n, the market reacts to minimize (19). Two consequences immediately follow. First,
consuming any resource that needs to be purchased from the marketplace, that is,
is clearly uneconomical for the firm, since the market will tend to set the price of the resource arbitrarily high
so as to make the firm’s profits arbitrarily small (i.e., the firm’s losses arbitrarily large). Consequently, our
imaginary firm will always choose its production activities such that:
Second, if any resource were not completely consumed by the firm in its own production and therefore became
available for sale to the market, that is,
this ‘‘malevolent market" would set a price of zero for that resource in order to minimize the firm’s profit.
Therefore, the second term of (19) will be zero and the firm’s decision problem of choosing production
activities so as to maximize profits simply reduces to:
Now let us look at the problem from the standpoint of the market. Rearranging (19) as follows:
we can more readily see the impact of the firm’s decision on the market. Note that the term i=1
the market opportunity cost for the firm using the resources a1 j , a2 j , . . . , am j , in order to engage in the jth
activity at unit level. Again, two consequences immediately follow. First, if the market sets the prices so that
the revenue from engaging in an activity exceeds the market cost, that is,
then the firm would be able to make arbitrarily large profits by engaging in the activity at an arbitrarily high
level, a clearly unacceptable situation from the standpoint of the market. The market instead will always
Second, if the market sets the price of a resource so that the revenue from engaging in that activity does not
exceed the potential revenue from the sale of the resources directly to the market, that is,
then the firm will not engage in that activity at all. In this latter case, the opportunity cost associated with
engaging in the activity is in excess of the revenue produced by engaging in the activity. Hence, the first term
of (21) will always be zero, and the market’s ‘‘decision" problem of choosing the prices for the resources so
as to minimize the firm’s profit reduces to:
The linear program (22) is the dual of (20).
The questions that then naturally arise are ‘‘When do these problems have solutions?" and ‘‘What is the
relationship between these solutions?" In arriving at the firm’s decision problem and the market’s ‘‘decision"
problem, we assumed that the firm and the market would interact in such a manner that an equilibrium would
These equations are just the complementary-slackness conditions of linear programming. The first condition
implies that either the amount of resource i that is unused (slack in the ith constraint of the primal) is zero, or
the price of resource i is zero. This is intuitively appealing since, if a firm has excess of a particular resource,
then the market should not be willing to pay anything for the surplus of that resource since the maket wishes
to minimize the firm’s profit. There may be a nonzero market price on a resource only if the firm is consuming
all of that resource that is available. The second condition implies that either the amount of excess profit on
the jth activity (slack in the jth constraint of the dual) is zero or the level of activity j is zero. This is also
appealing from the standpoint of the perfectly competitive market, which acts to eliminate any excess profits.
If we had an equilibrium satisfying (23), then, by equating (19) and (21) for this equilibrium, we can
quickly conclude that the extreme values of the primal and dual problems are equal; that is,
Observe that this condition has the usual interpretation for a firm operating in a perfectly competitive market.
It states that the maximum profit that the firm can make equals the market evaluation of its initial endowment
of resources. That is, the firm makes no excess profits. The important step is to answer the question of when
such equilibrium solutions exist. As we have seen, if the primal (dual) has a finite optimal solution, then so
does the dual (primal), and the optimal values of these objective functions are equal. This result is just the
strong duality property of linear programming.
The example of the perfectly competitive economy given in the previous section appears to be a game of
some sort between the firm and the malevolent market. The firm chooses its strategy to maximize its profits
while the market behaves (‘‘chooses" its strategy) in such a way as to minimize the firm’s profits. Duality
theory is, in fact, closely related to game theory, and in this section we indicate the basic relationships.
In many contexts, a decision-maker does not operate in isolation, but rather must contend with other
decision-makers with conflicting objectives. Consider, for example, advertising in a competitive market,
portfolio selection in the presence of other investors, or almost any public-sector problem with its multifaceted
implications. Each instance contrasts sharply with the optimization models previously discussed, since they
concern a single decision-maker, be it an individual, a company, a government, or, in general, any group
acting with a common objective and common constraints.
Game theory is one approach for dealing with these ‘‘multiperson" decision problems. It views the
decision-making problem as a game in which each decision-maker, or player, chooses a strategy or an action
to be taken. When all players have selected a strategy, each individual player receives a payoff. As an
example, consider the advertising strategies of a two-firm market. There are two players firm R (row player)
and firm C (column player). The alternatives open to each firm are its advertising possibilities; payoffs are
market shares resulting from the combined advertising selections of both firms. The payoff table in Tableau
Since we have assumed a two-firm market, firm R and firm C share the market, and firm C receives
whatever share of the market R does not. Consequently, firm R would like to maximize the payoff entry from
the table and firm B would like to minimize this payoff. Games with this structure are called two-person,
zero-sum games. They are zero-sum, since the gain of one player is the loss of the other player.
To analyze the game we must make some behavioral assumptions as to how the players will act. Let us
suppose, in this example, that both players are conservative, in the sense that they wish to assure themselves
of their possible payoff level regardless of the strategy adopted by their opponent. It selecting its alternative,
firm R chooses a row in the payoff table. The worst that can happen from its viewpoint is for firm C to select
the minimum column entry in that row. If firm R selects its first alternative, then it can be assured of securing
30% of the market, but no more, whereas if it selects its second alternative it is assured of securing 10%, but
no more. Of course, firm R, wishing to secure as much market share as possible, will select alternative 1,
to obtain the maximum of these security levels. Consequently, it selects the alternative giving the maximum
of the column minimum, known as a maximin strategy. Similarly, firm C’s security levels are given by the
maximum row entries; if it selects alternative 1, it can be assured of losing only 30% of the market, and no
more, and so forth. In this way, firm C is led to a minimax strategy of selecting the alternative that minimizes
its security levels of maximum row entries (see Tableau 10).
For the problem at hand, the maximin and minimax are both 30 and we say that the problem has a
saddlepoint. We might very well expect both players to select the alternatives that lead to this common
value—both selecting alternative 1. Observe that, by the way we arrived at this value, the saddlepoint is an
equilibrium solution in the sense that neither player will move unilaterally from this point. For instance, if
firm R adheres to alternative 1, then firm C cannot improve its position by moving to either alternative 2 or 3
since then firm R’s market share increases to either 40% or 60%. Similarly, if firm C adheres to alternative 1,
then firm R as well will not be induced to move from its saddlepoint alternative, since its market share drops
The situation changes dramatically if we alter a single entry in the payoff table (see Tableau 11).
Now the security levels for the two players do not agree, and moreover, given any choice of decisions
by the two firms, one of them can always improve its position by changing its strategy. If, for instance, both
firms choose alternative 1, then firm R increases its market share from 30% to 60% by switching to alternative
2. After this switch though, it is attractive for firm C then to switch to its second alternative, so that firm R’s
market share decreases to 10%. Similar movements will continue to take place as indicated by the arrows in
the table, and no single choice of alternatives by the players will be ‘‘stable".
Is there any way for the firms to do better in using randomized strategies? That is, instead of choosing
a strategy outright, a player selects one according to some preassigned probabilities. For example, suppose
that firm C selects among its alternatives with probabilities x1 , x2 , and x3 , respectively. Then the expected
Since any gain in market share by firm R is a loss to firm C, firm C wants to make the expected market
share of firm R as small as possible, i.e., maximize its own expected market share. Firm C can minimize the
maximum expected market share of firm R by solving the following linear program.
The first two constraints limit firm R’s expected market share to be less than or equal to v for each of firm
R’s pure strategies. By minimizing v, from C limits the expected market share of firm R as much as possible.
The third constraint simply states that the chosen probabilities must sum to one. The solution to this linear
program is x1 = 21 , x2 = 21 , x3 = 0, and v = 35. By using a randomized strategy (i.e., selecting among
the first two alternatives with equal probability), firm C has improved its security level. Its expected market
share has increased, since the expected market share of firm R has decreased from 40 percent to 35 percent.
Let us now see how firm R might set probabilities y1 and y2 on its alternative selections to achieve its
best security level. When firm R weights its alternatives by y1 and y2 , it has an expected market share of:
Firm R wants its market share as large as possible, but takes a conservative approach in maximizing its
minimum expected market share from these three expressions. In this case, firm R solves the following linear
The first three constraints require that, regardless of the alternative selected by firm C, firm R’s market share
will be at least w, which is then maximized. The fourth constraint again states that the probabilities must
sum to one. In this case, firm R acts optimally by selecting its first alternative with probability y1 = 56 and
its second alternative with probability y2 = 61 , giving an expected market share of 35 percent.
Note that the security levels resulting from each linear program are identical. On closer examination
we see that (25) is in fact the dual of (24)! To see the duality correspondence, first convert the inequality
constraints in (24) to the standard (≥) for a minimization problem by multiplying by −1. Then the dual
constraint derived from ‘‘pricing-out" x1 , for example, will read −30y1 − 60y2 + w ≤ 0, which is the first
constraint in (25). In this simple example, we have shown that two-person, zero-sum games reduce to primal
and dual linear programs. This is true in general, so that the results presented for duality theory in linear
programming may be used to draw conclusions about two-person, zero-sum games. Historically, this took
place in the reverse, since game theory was first developed by John von Neumann in 1928 and then helped
motivate duality theory in linear programming some twenty years later.
The general situation for a two-person, zero-sum game has the same characteristics as our simple example.
The payoff table in Tableau 12 and the conservative assumption on the player’s behavior lead to the primal
and dual linear programs discussed below.
The column player must solve the linear program:
and the row player the dual linear program:
a1 j y1 + a2 j y2 + · · · + amn ym −w ≥ 0
The optimal values for x1 , x2 , . . . , xn , and y1 , y2 , . . . , ym , from these problems are the probabilities that
the players use to select their alternatives. The optimal solutions give (min v) = (max w) and, as before,
these solutions provide a stable equilibrium, since neither player has any incentive for improved value by
unilaterally altering its optimal probabilities.
More formally, if the row player uses probabilities yi and the column player uses probabilities x j , then
the expected payoff of the game is given by:
By complementary slackness, the optimal probabilities
ŷi and x̂ j of the dual linear programs satisfy:
Consequently, multiplying the ith inequality in the primal by ŷi , and adding gives
showing that the primal and dual solutions x̂ j and ŷi lead to the payoff v̂. The last equality uses the fact that
Next, consider any other probabilities yi for the row player. Multiplying the ith primal equation
Similarly, multiplying the jth dual constraint
by any probabilities x j and adding gives:
Since v̂ = ŵ by linear programming duality theory, Eqs. (26), (27), and (28) imply that:
This expression summarizes the equilibrium condition. By unilaterally altering its selection of probabilities
ŷi to yi , the row player cannot increase its payoff beyond v̂.
Similarly, the column player cannot reduce the row player’s payoff below v̂ by unilaterally changing its
selection of probabilities x̂ j to x j . Therefore, the probabilities ŷi and x̂ j acts as an equilibrium, since neither
player has an incentive to move from these solutions.
1. Find the dual associated with each of the following problems:
2. Consider the linear-programming problem:
a) State this problem with equality constraints and nonnegative variables.
b) Write the dual to the given problem and the dual to the transformed problem found in part (a). Show that these
3. The initial and final tableaus of a linear-programming problems are as follows:
a) Find the optimal solution for the dual problem.
b) Verify that the values of the shadow prices are the dual feasible, i.e., that they satisfy the following relationship:
where the terms with bars refer to data in the final tableau and the terms without bars refer to data in the initial
c) Verify the complementary-slackness conditions.
4. In the second exercise of Chapter 1, we graphically determined the shadow prices to the following linear program:
a) Formulate the dual to this linear program.
b) Show that the shadow prices solve the dual problem.
5. Solve the linear program below as follows: First, solve the dual problem graphically. Then use the solution to the
dual problem to determine which variables in the primal problem are zero in the optimal primal solution. [Hint:
Invoke complementary slackness.] Finally, solve for the optimal basic variables in the primal, using the primal
6. A dietician wishes to design a minimum-cost diet to meet minimum daily requirements for calories, protein, carbohydrate, fat, vitamin A and vitamin B dietary needs. Several different foods can be used in the diet, with data as
a) Formulate a linear program to determine which foods to include in the minimum cost diet. (More than the
minimum daily requirements of any dietary need can be consumed.)
b) State the dual to the diet problem, specifying the units of measurement for each of the dual variables. Interpret
the dual problem in terms of a druggist who sets prices on the dietary needs in a manner to sell a dietary pill with
b1 , b2 , b3 , b4 , b5 , and b6 units of the given dietary needs at maximum profit.
7. In order to smooth its production scheduling, a footwear company has decided to use a simple version of a linear
cost model for aggregate planning. The model is:
vi = Unit production cost for product i in each period,
ci = Inventory-carrying cost per unit of product i in each period,
ki = Man-hours required to produce one unit of product i,
(r m) = Total man-hours of regular labor available in each period,
p = Fraction of labor man-hours available as overtime,
X it = Units of product i to be produced in period t,
Iit = Units of product i to be left over as inventory at the end of period t,
Wt = Man-hours of regular labor used during period (fixed work force),
Ot = Man-hours of overtime labor used during peirod t.
The company has two major products, boots and shoes, whose production it wants to schedule for the next three
periods. It costs $10 to make a pair of boots and $5 to make a pair of shoes. The company estimates that it costs $2
to maintain a pair of boots as inventory through the end of a period and half this amount for shoes. Average wage
rates, including benefits, are three dollars an hour with overtime paying double. The company prefers a constant
labor force and estimates that regular time will make 2000 man-hours available per period. Workers are willing
to increase their work time up to 25% for overtime compensation. The demand for boots and shoes for the three
a) Set up the model using 1 man-hour and 21 man-hour as the effort required to produce a pair of boots and shoes,
c) Define the physical meaning of the dual objective function and the dual constraints.
8. In capital-budgeting problems within the firm, there is a debate as to whether or not the appropriate objective function
should be discounted. The formulation of the capital-budgeting problem without discounting is as follows:
where ci j is the cash outflow (ci j < 0) or inflow (ci j > 0) in period i for project j; the righthand-side constant f i
is the net exogenous funds made available to ( f i > 0) or withdrawn from ( f i < 0) a division of the firm in period
i; the decision variable x j is the level of investment in project j; u j is an upper bound on the level of investment in
project j; and v N is a variable measuring the value of the holdings of the division at the end of the planning horizon.
If the undiscounted problem is solved by the bounded variable simplex method, the optimal solution is x ∗j for
j = 1, 2, . . . , J with associated shadow prices (dual variables) yi∗ for i = 0, 1, 2, . . . , N .
b) The discount factor for time i is defined to be the present value (time i = 0) of one dollar received at time i.
Show that the discount factor for time i, ρi∗ is given by:
(Assume that the initial budget constraint is binding so that y0∗ > 0.)
9. The discounted formulation of the capital-budgeting problem described in the previous exercise can be stated as:
represents the discounted present value of the cash flows from investing at unit level in project j, and λi for
i = 1, 2, . . . , N are the shadow prices associated with the funds-flow constraints.
Suppose that we wish to solve the above discounted formulation of the capital-budgeting problem, using the
discount factors determined by the optimal solution of the previous exercise, that is, setting:
Show that the optimal solution x ∗j for j = 1, 2, . . . , J , determined from the undiscounted case in the previous
exercise, is also optimal to the above discounted formulation, assuming:
[Hint: Write the optimality conditions for the discounted problem, using shadow-price values λi∗ = 0 for i =
1, 2, . . . , N . Does x ∗j ( j = 1, 2, . . . , J ) satisfy these conditions? Do the shadow prices on the upper bounding
constraints for the discounted model differ from those of the undiscounted model?]
10. An alternative formulation of the undiscounted problem developed in Exercise 8 is to maximize the total earnings
on the projects rather than the horizon value. Earnings of a project are defined to be the net cash flow from a project
over its lifetime. The alternative formulation
Let for j = 1, 2, . . . , J solve this earnings formulation, and suppose that the funds constraints are binding at all
times i = 0, 1, . . . , N for this solution.
a) Show that x ∗j for j = 1, 2, . . . , J also solves the horizon formulation given in Exercise 8.
b) Denote the optimal shadow prices of the funds constraints for the earnings formulation as yi0 for i = 0, 1, 2, . . . , N .
Show that yi = 1 + yi0 for i = 0, 1, 2, . . . , N are optimal shadow prices for the funds constraints of the horizon
11. Suppose that we now consider a variation of the horizon model given in Exercise 8, that explicitly includes one-period
borrowing bi at rate rb and one-period lending `i at rate r` . The formulation is as follows:
(−ci j x j ) − (1 + r` )`i−1 + `i + (1 + rb )bi−1 − bi ≤ f i
(−c N j x j ) − (1 + r` )` N −1 + (1 − rb )b N −1 + v N
a) Suppose that the optimal solution includes lending in every time period; that is, `i∗ > 0 for i = 0, 1, . . . , N − 1.
Show that the present value of a dollar in period i is
b) Suppose that there is no upper bound on borrowing; that is, Bi = +∞ for i = 0, 1, . . . , N − 1, and that the
borrowing rate equals the lending rate, r = rb = r` . Show that
and that the present value of a dollar in period i is
c) Let wi be the shadow prices on the upper-bound constraints bi ≤ Bi , and let r = rb = r` . Show that the shadow
d) Assume that the borrowing rate is greater than the lending rate, rb > r` ; show that the firm will not borrow and
lend in the same period if it uses this linear-programming model for its capital budgeting decisions.
12. As an example of the present-value analysis given in Exercise 8, consider four projects with cash flows and upper
A negative entry in this table corresponds to a cash outflow and a positive entry to a cash inflow.
The horizon-value model is formulated below, and the optimal solution and associated shadow prices are given:
a) Explain exactly how one additional dollar at the end of year 2 would be invested to return the shadow price 1.25.
Similarly, explain how to use the projects in the portfolio to achieve a return of 1.35 for an additional dollar at
each year, from the shadow prices on the constraints.
ρi ci j of each of the four projects. How does the sign of the discounted
present value of a project compare with the sign of the reduced cost for that project? What is the relationship
between the two? Can discounting interpreted in this way be used for decision-making?
d) Consider the two additional projects with cash flows and upper bounds as follows:
What is the discounted present value of each project? Both appear promising. Suppose that fun ds are transferred
from the current portfolio into project E, will project F still appear promising? Why? Do the discount factors
13. In the exercises following Chapter 1, we formulated the absolute-value regression problem:
xi1 β1 + xi2 β2 + · · · + xin βn + Pi − Ni = yi s for i = 1, 2, . . . , m,
In this formulation, the yi are measurements of the dependent variable (e.g., income), which is assumed to be
explained by independent variables (e.g., level of education, parents’ income, and so forth), which are measured as
xi1 , xi2 , . . . , xin . A linear model assumes that y depends linearly upon the β’s, as:
Given any choice of the parameters β1 , β2 , . . . , βn , ŷi is an estimate of yi . The above formulation aims to minimize
the deviations of the estimates of ŷi from yi as measured by the sum of absolute values of the deviations. The
variables in the linear-programming model are the parameters β1 , β2 , . . . , βn as well as the Pi and Ni . The quantities
yi , xi1 , xi2 , . . . , xin are known data found by measuring several values for the dependent and independent variables
In practice, the number of observations m frequently is much larger than the number of parameters n. Show
how we can take advantage of this property by formulating the dual to the above linear program in the dual variables
u 1 , u 2 , . . . , u m . How can the special structure of the dual problem be exploited computationally?
14. The following tableau is in canonical form for maximizing z, except that one righthand-side value is negative.
However, the reduced costs of the nonbasic variables all satisfy the primal optimality conditions. Find the optimal
solution to this problem, using the dual simplex algorithm to find a feasible canonical form while maintaining the
15. In Chapter 2 we solved a two-constraint linear-programming version of a trailer-production problem:
Suppose that, in formulating this problem, we ignored a constraint limiting the time available in the shop for
a) If the solution x1 = 36, x2 = 0, and x3 = 6 to the original problem satisfies the inspection constraint, is it
necessarily optimal for the problem when we impose the inspection constraint?
b) Suppose that the inspection constraint is
where x6 is a nonnegative slack variable. Add this constraint to the optimal tableau with x6 as its basic variable
and pivot to eliminate the basic variables x1 and x3 from this constraint. Is the tableau now in dual canonical
c) Use the dual simplex method to find the optimal solution to the trailer-production problem with the inspection
d) Can the ideas used in this example be applied to solve a linear program whenever a new constraint is added after
16. Apply the dual simplex method to the following tableau for maximizing z with nonnegative decision variables
Is the problem feasible? How can you tell?
b) Solve the primal problem, using the dual simplex algorithm.
c) Utilizing the final tableau from part (b), find optimal values for the dual variables y1 and y2 . What is the
corresponding value of the dual objective function?
18. For what values of the parameter θ is the following tableau in canonical form for maximizing the objective value z?
Starting with this tableau, use the parametric primal-dual algorithm to solve the linear program at θ = 0.
we discover that the problem was formulated improperly. The objective coefficient for x2 should have been 11 (not
7) and the righthand side of the first constraint should have been 2 (not 5).
a) How do these modifications in the problem formulation alter the data in the tableau above?
b) How can we use the parametric primal-dual algorithm to solve the linear program after these data changes,
starting with x1 and x3 as basic variables?
c) Find an optimal solution to the problem after the data changes are made, using the parametric primal-dual
20. Rock, Paper, and Scissors is a game in which two players simultaneously reveal no fingers (rock), one finger (paper),
or two fingers (scissors). The payoff to player 1 for the game is governed by the following table:
Note that the game is void if both players select the same alternative: otherwise, rock breaks scissors and wins,
scissors cut paper and wins, and paper covers rock and wins.
Use the linear-programming formulation of this game and linear-programming duality theory, to show that both
players’ optimal strategy is to choose each alternative with probability 13 .
21. Solve for an optimal strategy for both player 1 and player 2 in a zero-sum two-person game with the following
Is the optimal strategy of each player unique?
22. In a game of tic-tac-toe, the first player has three different choices at the first move: the center square, a corner
square, or a side square. The second player then has different alternatives depending upon the move of the first
player. For instance, if the first player chooses a corner square, the second player can select the center square, the
opposite corner, an adjacent corner, an opposite side square, or an adjacent side square. We can picture the possible
outcomes for the game in a decision tree as follows:
Nodes 1hcorrespond to decision points for the first player; nodes 2hare decision points for the second player.
The tree is constructed in this manner by considering the options available to each player at a given turn, until either
one player has won the game (i.e., has selected three adjacent horizontal or vertical squares or the squares along one
of the diagonals), or all nine squares have been selected. In the first case, the winning player receives 1 point; in the
second case the game is a draw and neither player receives any points.
The decision-tree formulation of a game like that illustrated here is called an extensive form formulation. Show
how the game can be recast in the linear-programming form (called a normal form) discussed in the text. Do not
attempt to enumerate every strategy for both players. Just indicate how to construct the payoff tables.
[Hint: Can you extract a strategy for player 1 by considering his options at each decision point? Does his
strategy depend upon how player 2 reacts to player 1’s selections?]
The remaining exercises extend the theory developed in this chapter, providing new results and relating some of the
duality concepts to other ideas that arise in mathematical programming.
23. Consider a linear program with bounded variables:
where the upper bounds u j are positive constants. Let yi for i = 1, 2, . . . , m and w j for j = 1, 2, . . . , m be variables
a) Formulate the dual to this bounded-variable problem.
b) State the optimality conditions (that is, primal feasibility, dual feasibility, and complementary slackness) for the
yi ai j denote the reduced costs for variable x j determined by pricing out the ai j constraints and
not the upper-bounding constraints. Show that the optimality conditions are equivalent to the bounded-variable
given in Section 2.6 of the text, for any feasible solution x j ( j = 1, 2, . . . , n) of the primal problem.
24. Let x ∗j for j = 1, 2, . . . , n be an optimal solution to the linear program with
two groups of constraints, the ai j constraints and the ei j constraints. Let yi for i = 1, 2, . . . , m and wi for
i = 1, 2, . . . , q denote the shadow prices (optimal dual variables) for the constraints.
a) Show that x ∗j for j = 1, 2, . . . , n also solves the linear program:
in which the ai j constraints have been incorporated into the objective function as in the method of Lagrange
multipliers. [Hint: Apply the optimality conditions developed in Section 4.5 to the original problem and this
b) Illustrate the property from part (a) with the optimal solution x1∗ = 2, x2∗ = 1, and shadow prices y1 = 21 , w1 =
c) Show that an optimal solution x j for j = 1, 2, . . . , n for the ‘‘Lagrangian problem’’ from part (a) need not be
optimal for the original problem [see the example in part (b)]. Under what conditions is an optimal solution to
the Lagrangian problem optimal in the original problem?
d) We know that if the ‘‘Lagrangian problem’’ has an optimal solution, then it has an extreme-point solution. Does
this imply that there is an extreme point to the Lagrangian problem that is optimal in the original problem?
25. The payoff matrix (ai j ) for a two-person zero-sum game is said to be skew symmetric if the matrix has as many rows
as columns and ai j = −a ji for each choice of i and j. The payoff matrix for the game Rock, Paper and Scissors
discussed in Exercise 20 has this property.
a) Show that if players 1 and 2 use the same strategy,
b) Given any strategy x1 , x2 , . . . , xn for player 2, i.e., satisfying:
multiply the first n constraints by y1 = x1 , y2 = x2 , . . . , and yn = xn , respectively, and add. Use this
manipulation, together with part (a), to show that w ≤ 0. Similarly, show that the value to the player 1 problem
satisfies v ≥ 0. Use linear-programming duality to conclude that v = w = 0 is the value of the game.
26. In Section 4.9 we showed how to use linear-programming duality theory to model the column and row players’
decision-making problems in a zero-sum two-person game. We would now like to exhibit a stronger connection
between linear-programming duality and game theory.
Consider the linear-programming dual problems
where the inequalities apply for i = 1, 2, . . . , m and j = 1, 2, . . . , n; in addition, consider a zero-sum two-person
The quantities x j , y i , and t shown above the table are the column players’ selection probabilities.
a) Is this game skew symmetric? What is the value of the game? (Refer to the previous exercise.)
b) Suppose that x j for j = 1, 2, . . . , n and yi for i = 1, 2, . . . , m solve the linear-programming primal and dual
let x j = t x j for j = 1, 2, . . . , n, and let y i = t yi for i = 1, 2, . . . , m. Show that x j , y i , and t solve the given
c) Let x j for j = 1, 2, . . . , n, y i for i = 1, 2, . . . , m, and t solve the game, and suppose that t > 0. Show that
solve the primal and dual linear programs. (See Hint.)
[Hint: Use the value of the game in parts (b) and (c), together with the conditions for strong duality in linear
27. Suppose we approach the solution of the usual linear program:
by the method of Lagrange multipliers. Define the Lagrangian maximization problem as follows:
[Note: The Lagrangian function L(λ1 , λ2 , . . . , λm ) may equal +∞ for certain choices of the Lagrange multipliers
λ1 , λ2 , . . . , λm . Would these values for the Lagrange multipliers ever be selected when minimizing L(λ1 , λ2 , . . . , λm )?]
28. Consider the bounded-variable linear program:
Define the Lagrangian maximization problem by:
Show that the primal problem is bounded above by L(λ1 , λ2 , . . . , λm ) so long as λi ≥ 0 for i = 1, 2, . . . , m.
29. Consider the bounded-variable linear program and the corresponding Lagrangian maximization problem defined in
b) Why is it that L(λ1 , λ2 , . . . , λm ) in this case does not reduce to the usual linear-programming dual problem?
f (x1 , x2 , . . . , xn ; y1 , y2 , . . . , ym ) =
Max Min f (x1 , . . . , xn ; y1 , . . . , ym ) = Min Max f (x1 , . . . , xn ; y1 , . . . , ym )
In Exercise 6, the pill interpretation of the diet problem appears in The Theory of Linear Economic Models,
by David Gale, McGraw-Hill Book Company, Inc., 1960.
Exercises 8 and 11 are based on material contained in Mathematical Programming and the Analysis of Capital
Budgeting Problems, by H. Martin Weingartner, Prentice-Hall, Inc. 1963.
Exercise 12 is based on the Gondon Enterprises case written by Paul W. Marshall and Colin C. Blaydon.
In management science, as in most sciences, there is a natural interplay between theory andpractice. Theory
provides tools for applied work and suggests viable approaches to problem solving, whereas practice adds
focus to the theory by suggesting areas for theoretical development in its continual quest for problem-solving
capabilities. It is impossible, then, to understand fully either theory or practice in isolation. Rather, they need
to be considered as continually interacting with one another.
Having established linear programming as a foundation for mathematical programming theory, we now
are in a position to appreciate certain aspects of implementing mathematical programming models. In the
next three chapters, we address several issues of mathematical-programming applications, starting with a
general discussion and followed by specific applications. By necessity, at this point, the emphasis is on linear
programming; however, most of our comments apply equally to other areas of mathematical programming,
and we hope they will provide a useful perspective from which to view forthcoming developments in the text.
This chapter begins by presenting two frameworks that characterize the decision-making process. These
frameworks suggest how modeling approaches to problem solving have evolved; specify those types of
problems for which mathematical programming has had most impact; and indicate how other techniques
can be integrated with mathematical-programming models. The remainder of the chapter concentrates on
mathematical programming itself in terms of problem formulation and implementation, including the role of
the computer. Finally, an example is presented to illustrate much of the material.
Since management science basically aims to improve the quality of decision-making by providing managers
with a better understanding of the consequences of their decisions, it is important to spend some time reflecting
upon the nature of the decision-making process and evaluating the role that quantitative methods, especially
mathematical programming, can play in increasing managerial effectiveness.
There are several ways to categorize the decisions faced by managers. We would like to discuss two
frameworks, in particular, since they have proved to be extremely helpful in generating better insights into
the decision-making process, and in defining the characteristics that a sound decision-support system should
possess. Moreover, each framework leads to new perceptions concerning model formulation and the role of
Anthony’s Framework: Strategic, Tactical, and Operational Decisions
The first of these frameworks was proposed by Robert N. Anthony.∗ He classified decisions in three categories:
strategic planning, tactical planning, and operations control. Let us briefly comment on the characteristics of
each of these categories and review their implications for a model-based approach to support management
The examples given to illustrate specific decisions belonging to each category are based primarily on
the production and distribution activities of a manufacturing firm. This is done simply for consistency and
convenience; the suggested framework is certainly appropriate for dealing with broader kinds of decisions.
Strategic planning is concerned mainly with establishing managerial policies and with developing the necessary resources the enterprise needs to satisfy its external requirements in a manner consistent with its specific
goals. Examples of strategic decisions are major capital investments in new production capacity and expansions of existing capacity, merger and divestiture decisions, determination of location and size of new plants
and distribution facilities, development and introduction of new products, and issuing of bonds and stocks to
These decisions are extremely important because, to a great extent, they are responsible for maintaining
the competitive capabilities of the firm, determining its rate of growth, and eventually defining its success
or failure. An essential characteristic of these strategic decisions is that they have long-lasting effects, thus
mandating long planning horizons in their analysis. This, in turn, requires the consideration of uncertainties
and risk attitudes in the decision-making process. Moreover, strategic decisions are resolved at fairly high
managerial levels, and are affected by information that is both external and internal to the firm. Thus, any
form of rational analysis of these decisions necessarily has a very broad scope, requiring information to be
processed in a very aggregate form so that all the dimensions of the problem can be included and so that top
managers are not distracted by unnecessary operational details.
Once the physical facilities have been decided upon, the basic problem to be resolved is the effective allocation of resources (e.g., production, storage, and distribution capacities; work-force availabilities; marketing,
financial, and managerial resources) to satisfy demand and technologicalrequirements, taking into account
the costs and revenues associated with the operation of the resources available to the firm. When we are
dealing with several plants, many distribution centers, and regional and local warehouses, having products
that require complex multistage fabrication and assembly processes, and serving broad market areas affected
by strong randomness and seasonalities in their demand patterns, these decisions are far from simple. They
usually involve the consideration of a medium-range time horizon divided into several periods, and require
significant aggregation of the information to be processed. Typical decisions to be made within this context are utilization of regular and overtime work force, allocation of aggregate capacity resources to product
families, definition of distribution channels, selection of transportation and transshipment alternatives, and
allocation of advertising and promotional budgets.
After making an aggregate allocation of the resources of the firm, it is necessary to deal with the day-to-day
operational and scheduling decisions. This requires the complete disaggregation of the information generated
at higher levels into the details consistent with the managerial procedures followed in daily activities. Typical
decisions at this level are the assignment of customer orders to individual machines, the sequencing of these
∗ Robert N. Anthony, Planning and Control Systems: A Framework for Analysis, Harvard University Graduate School
of Business Administration, Boston, 1965.
orders in the work shop, inventory accounting and inventory control activities, dispatching, expediting and
processing of orders, vehicular scheduling, and credit granting to individual customers.
These three types of decisions differ markedly in various dimensions. The nature of these differences,
expressed in relative terms, can be characterized as in Table 5.1.
Table E5.1 Distinct Characteristics of Strategic, Tactical, and
Implications of Anthony’s Framework: A Hierarchical Integrative Approach
There are significant conclusions that can be drawn from Anthony’s classification, regarding the nature of the
model-based decision-support systems. First, strategic, tactical, and operational decisions cannot be madein
isolation because they interact strongly with one another. Therefore, an integrated approach is required in order
to avoid suboptimization. Second, this approach, although essential, cannot be made without decomposing
the elements of the problem in some way, within the context of a hierarchical system that links higher-level
decisions with lower-level ones in an effective manner. Decisions that are made at higher levels of the system
provide constraints for lower-level decision making, and decision-makers must recognize their impact upon
This hierarchical approach recognizes the distinct characteristics of the type of management participation,
the scope of the decision, the level of aggregation of the required information, and the time frame in which
the decision is to be made. In our opinion, it would be a serious mistake to attempt to deal with all these
decisions at once via a monolithic system (or model). Even if computer and methodological capabilities
would permit the solution of large, detailed integrated models—clearly not the case today—that approach is
inappropriate because it is not responsive to management needs at each level of the organization, and would
prevent interactions between models and managers at each organization echelon.
In designing a system to support management decision-making, it is imperative, therefore, to identify
ways in which the decision process can be partitioned, to select adequate models to deal with the individual
decisions at each hierarchical level, to design linking mechanisms for the transferring of the higher-level
results to the lower hierarchical levels, which include means to disaggregate information, and to provide
quantitative measures to evaluate the resulting deviations from optimal performance at each level.
Mathematical programming is suited particularly well for supporting tactical decisions. This category
of decisions, dealing with allocation of resources through a middle-range time horizon, lends itself quite
naturally to representation by means of mathematical-programming models. Typically, tactical decisions
generate models with a large number of variables and constraints due to the complex interactions among
the choices available to the decision-maker. Since these choices are hard to evaluate on merely intuitive
grounds, a decision-maker could benefit greatly from a model-based support effort. Historically, mathematical
programming has been the type of model used most widely in this capacity, and has contributed a great deal
to improving the quality of decision-making at the tactical level.
As we indicated before, tactical decisions are affected by only moderate uncertainties. This characteristic
is useful for the application of linear programming, since models of this kind do not handle uncertainties
directly. The impact of moderate uncertainties, however, can be assessed indirectly by performing sensitivity
analysis. Furthermore, sensitivity tests and shadow price information allow the decision-maker to evaluate
how well the resources of the firm are balanced.
For example, a tactical linear-programming model designed to support production-planning decisions
might reveal insufficient capacity in a given stage of the production process. The shadow price associated
with that capacity constraint provides a local indication of the payoff to be obtained from a unit increase in
The role of mathematical programming in supporting strategic and operational decisions has been more
limited. The importance of uncertainties and risk in strategic decisions, and the great amount of detailed
information necessary to resolve operational problems work against the direct use of mathematical programming at these levels. In the decision-making hierarchy, mathematical-programming models become the links
between strategic and operational decisions. By carefully designing a sequence of model runs, the decisionmaker can identify bottlenecks or idle facilities; and this information provides useful feedback for strategic
decisions dealing with acquisition or divestment of resources. On the other hand, by contributing to the
optimalallocation of the aggregate resources of the firm, mathematical-programming models generate the
broad guidelines for detailed implementation. Operational decisions are reduced, therefore, to producing the
appropriate disaggregation of the tactical plans suggested by the mathematical-programming model against
The design of a hierarchical system to support the overall managerial process is an art that demands a
great deal of pragmatism and experience. In Chapter 6 we describe anintegrated system to deal with strategic
and tactical decisions in the aluminum industry. The heart of the system is formed by two linear-programming
models that actively interact with one another. In Chapter 10 we analyze a hierarchical system to decideon
the design of a job-shop facility. In that case a mixed-integer programming model and a simulation model
represent tactical and operational decisions, respectively. Chapter 7 presentsanother practical application of
linear programming, stressing the role of sensitivity analysis in coping with future uncertainties. Chapter 14
discusses the use of decomposition for bond-portfolio decisions.
Simon’s Framework: Programmed and Nonprogrammed Decisions
A second decision framework that is useful in analyzing the role of models in managerial decision-making
was proposed by Herbert A. Simon.∗ Simon distinguishes two types of decisions: programmed and nonprogrammed, which also are referred to as structured and unstructured decisions, respectively. Although
decisions cover a continuous spectrum between these two extremes, it is useful first to analyze the characteristics of these two kinds.
Programmed decisions are those that occur routinely and repetitively. They can be structured into specific
procedural instructions, so they can be delegated without undue supervision to the lower echelons of the
organization. As Simon put it, programmed decisions are normally the domain of clerks. This does not
necessarily imply that high-level managers do not have their share of programmed decision-making; it simply
indicates that the incidence of programmed decisions increases the lower we go in the hierarchy of the
Herbert A. Simon, The Shape of Automation for Men and Management, Harper and Row, 1965.
Nonprogrammed decisions are complex, unique, and unstructured. They usually do not lend themselves to a
well defined treatment, but rather require a large amount of good judgment and creativity in order for them
to be handled effectively. Normally, top managers are responsible for the more significant nonprogrammed
Implications of Simon’s Framework: The Degree ofAutomation of the Decision-Making Process
Simon’s framework is also very helpful in identifying the role of models in the decision-making process. Its
implications are summarized in Table 5.2 which shows the contribution of both conventional and modern
methods to support programmed and nonprogrammed decisions.
Table E5.2 The Implications of Simon’s Taxonomy
A major issue regarding programmed decisions is how to develop a systematic approach to cope with
routine situations that an organization faces on a repetitive basis. A traditional approach is the preparation of
written procedures and regulations that establish what to do under normal operating conditions, and that signal
higher-management intervention whenever deviations from current practices occur. If properly designed and
implemented, these procedures tend to create desirable patterns of behavior and habits among the personnel
dealing with routine decisions. Control mechanisms normally are designed to motivate people, to measure
the effectiveness of the decisions, and to take corrective actions if necessary.
What allows the proper execution and management of programmed decisions is the organizational structure of the firm, which breaks the management functions into problems of smaller and smaller scope. At the
lower echelons of the organization, most of the work assumes highly structured characteristics and, therefore,
can be delegated easily to relatively unskilled personnel.
During the last twenty years, we have witnessed a tremendous change in the way programmed decisions
are made. First, the introduction of computers has created new capabilities to store, retrieve, and process
huge amounts of information. When these capabilities are used intelligently, significant improvements can
be made in the quality of decision-making at all levels. Second, the data bank that usually is developed
in the preliminary stages of computer utilization invites the introduction of models to support management
decisions. In many situations, these models have been responsible for adding to the structure of a given
decision. Inventory control, production planning, and capital budgeting are just a few examples of managerial
functions that were thought of as highly nonprogrammed, but now have become significantly structured.
Conventional methods for dealing with nonprogrammed decisions rely quite heavily on the use of judgment. Policies and rules of thumb sometimes can be formulated to guide the application of sound judgment
and lessen the chances that poor judgment is exercised. Since good judgment seems to be the most precious
element for securing high-quality decision-making in nonprogrammed decisions, part of the conventional
efforts are oriented toward the recognition of those individuals who possess this quality. Managementdevelopment programs attempt to stimulate the growth of qualified personnel, and promotions tend to raise
the level of responsibility of those who excel in their managerial duties.
One of the greatest disappointments for the advocates of management science is that, in its present
form, it has not had a strong impact in dealing with nonprogrammed decisions. Broad corporate models
have been constructed to help the coordination of the high-level managerial functions. Also, hierarchical
systems are beginning to offer meaningful ways to approach problems of the firm in which various echelons
of managers are involved. In addition, disciplines like decision theory and heuristic problem-solving have
made contributions to the effective handling of nonprogrammed decisions. However, it is fair to say that we
are quite short of achieving all the potentials of management science in this area of decision-making. This
situation is changing somewhat with all the interest in unstructured social problems such as energy systems,
population control, environmental issues, and so forth.
We can conclude, therefore, that the more structured the decision, the more it is likely that a meaningful
model can be developed to support that decision.
STAGES OF FORMULATION, SOLUTION, AND IMPLEMENTATION
Having seen where mathematical programming might be most useful and indicated its interplay with other
managerial tools, we will now describe an orderly sequence of steps that can be followed for a systematic
formulation, solution, and implementation of a mathematical-programming model. These steps could be
applied to the development of any management-science model. However, due to the nature of this book, we
will limit our discussions to the treatment of mathematical-programming models.
Although the practical applications of mathematical programming cover a broad range of problems, it
is possible to distinguish five general stages that the solution of any mathematical-programming problem
Obviously, these stages are not defined very clearly, and they normally overlap and interact with each
other. Nevertheless we can analyze, in general terms, the main characteristics of each stage.
The first step to be taken in a practical application is the development of the model. The following are
elements that define the model structure:
One of the first decisions the model designer has to make, when applying mathematical programming to a
planning situation, is the selection of the time horizon (also referred to as planning horizon, or cutoff date).
The time horizon indicates how long we have to look into the future to account for all the significant factors of
the decision under study. Its magnitude reflects the future impact of the decision under consideration. It might
cover ten to twenty years in a major capital-investment decision, one year in an aggregate production-planning
problem, or just a few weeks in a detailed scheduling issue.
Sometimes it is necessary to divide the time horizon into several time periods. This is done in order to
identify the dynamic changes that take place throughout the time horizon. For example, in a productionplanning problem it is customary to divide the one-year time horizon into time periods of one month’s duration
to reflect fluctuations in the demand pattern due to product seasonalities. However, if the model is going to
be updated and resolved at the beginning of each month with a rolling one-year time horizon, it could be
advantageous to consider unequal time periods; for example, to consider time periods of one month’s duration
during the first three months, and then extend the duration of the time periods to three months, up to the end
Stages of Formulation, Solution, and Implementation
of the time horizon. This generally will not adversely affect the quality of the decisions and will reduce the
computational burden on the model significantly.
b) Selection of Decision Variables and Parameters
The next step in formulating the mathematical-programming model is to identify the decision variables, which
are those factors under the control of the decision-maker, and the parameters, which are beyond the control
of the decision-maker and are imposed by the external environment.
The decision variables are the answers the decision-maker is seeking. If we are dealing with productionplanning models, some relevant decision variables might be the amount to be manufactured of each product at
each time period, the amount of inventory to accumulate at each time period, and the allotment of man-hours
of regular and overtime labor at each time period.
On some occasions, a great amount of ingenuity is required to select those decision variables that most
adequately describe the problem being examined. In some instances it is possible to decrease the number of
constraints drastically or to transform an apparent nonlinear problem into a linear one, by merely defining
the decision variables to be used in the model formulation in a different way.
The parameters represent those factors which affect the decision but are not controllable directly (such as
prices, costs, demand, and so forth). In deterministic mathematical-programming models, all the parameters
are assumed to take fixed, known values, where estimates are provided via point forecasts. The impact of this
assumption can be tested by means of sensitivity analysis. Examples of some of the parameters associated
with a production-planning problem are: product demands, finished product prices and costs, productivity of
the manufacturing process, and manpower availability.
The distinction made between parameters and decision variables is somewhat arbitrary and one could
argue that, for a certain price, most parameters can be controlled to some degree by the decision-maker.
For instance, the demand for products can be altered by advertising and promotional campaigns; costs and
prices can be increased or decreased within certain margins, and so on. We always can start, however, from
a reference point that defines the appropriate values for the parameters, and insert as additional decision
variables those actions the decision-maker can make (like promotions or advertising expenditures) to create
changes in the initial values of the parameters. Also, shadow-price information can be helpful in assessing
the consequences of changing the values of the initial parameters used in the model.
The constraint set reflects relationships among decision variables and parameters that are imposed by the
characteristics of the problem under study (e.g., the nature of the production process, the resources available to
the firm, and financial, marketing, economical, political, and institutional considerations). These relationships
should be expressed in a precise, quantitative way. The nature of the constraints will, to a great extent,
determine the computational difficulty of solving the model.
It is quite common, in the initial representation of the problem, to overlook some vital constraints or to
introduce some errors into the model description, which will lead to unacceptable solutions. However, the
mathematical programming solution of the ill-defined model provides enough information to assist in the
detection of these errors and their prompt correction. The problem has to be reformulated and a new cycle
Once the decision variables are established, it is possible to determine the objective function to be minimized
or maximized, provided that a measure of performance (or effectiveness) has been established and can be
associated with the values that the decision variables can assume. This measure of performance provides
a selection criterion for evaluating the various courses of action that are available in the situation being
investigated. The most common index of performance selected in business applications is dollar value; thus,
we define the objective function as the minimization of cost or the maximization of profit. However, other
objective functions could become more relevant in some instances. Examples of alternative objectives are:
Maximize share of market for all or some products.
Maximize total sales, in dollars or units.
Minimize the use of a particular scarce (or expensive) commodity.
The definition of an acceptable objective function might constitute a serious problem in some situations,
especially when social and political problems are involved. In addition, there could be conflicting objectives,
each important in its own right, that the decision-maker wants to fulfill. In these situations it is usually helpful
to define multiple objective functions and to solve the problem with respect to each one of them separately,
observing the values that all the objective functions assume in each solution. If no one of these solutions
appears to be acceptable, we could introduce as additional constraints the minimum desirable performance
level of each of the objective functions we are willing to accept, and solve the problem again, having as an
objective the most relevant of those objective functions being considered. Sequential tests and sensitivity
analysis could be quite valuable in obtaining satisfactory answers in this context.
Another approach available to deal with the problem of multiple objectives is to unify all the conflicting
criteria into a single objective function. This can be accomplished by attaching weights to the various measures
of performance established by the decision-maker, or by directly assessing a multiattribute preference (or
utility function) of the decision-maker. This approach, which is conceptually extremely attractive but requires
a great deal of work in implementation, is the concern of a discipline called decision theory (or decision
analysis) and is outside the scope of our present work.∗
Having defined the model, we must collect the data required to define the parameters of the problem. The data
involves the objective-function coefficients, the constraint coefficients (also called the matrix coefficients)
and the righthand side of the mathematical-programming model. This stage usually represents one of the
most time-consuming and costly efforts required by the mathematical-programming approach.
Because of the lengthy calculations required to obtain the optimal solution of a mathematical-programming
model, a digital computer is invariably used in this stage of model implementation. Today, all the computer
manufacturers offer highly efficient codes to solve linear-programming models. These codes presently can
handle general linear-programming problems of up to 4000 rows, with hundreds of thousands of decision
variables, and are equipped with sophisticated features that permit great flexibility in their operation and
make them extraordinarily accurate and effective. Instructions for use of these codes are provided by the
manufacturers; they vary slightly from one computer firm to another.
Recently, very efficient specialized codes also have become available for solving mixed-integer programming problems, separable programming problems, and large-scale problems with specific structures (using
generalized upper-bounding techniques, network models, and partitioning techniques). Models of this nature
and their solution techniques will be dealt with in subsequent chapters.
When dealing with large models, it is useful, in utilizing computer programs, to input the required data
automatically. These programs, often called matrix generators, are designed to cover specific applications.
Similarly, computer programs often are written to translate the linear-programming output, usually too technical in nature, into meaningful managerial reports ready to be used by middle and top managers. In the next
∗ For an introduction to decision theory, the reader is referred to Howard Raiffa, Decision Analysis—Introductory
Lectures on Choices under Uncertainty, Addison-Wesley, 1970.
Stages of Formulation, Solution, and Implementation
section, dealing with the role of the computer in solving mathematical-programming models, we will discuss
One of the most useful characteristics of linear-programming codes is their capability to perform sensitivity
analysis on the optimalsolutions obtained for the problem originally formulated. These postoptimum analyses
Much of the information that is used in formulating the linear program is uncertain. Future production
capacities and product demand, product specifications and requirements, cost and profit data, among other
information, usually are evaluated through projections and average patterns, which are far from being known
with complete accuracy. Therefore, it is often significant to determine how sensitive the optimal solutionis
to changes in those quantities, and how the optimal solutionvaries when actual experience deviates from the
Even if the data were known with complete certainty, we would still want to perform sensitivity analysis
on the optimal solution to find out how the recommended courses ofaction should be modified after some
time, when changes most probably will have taken place in the original specification of the problem. In other
words, instead of getting merely a static solution to the problem, it is usually desirable to obtain at least some
Finally, we want to inquire how errors we may have committed in the original formulation of the problem
In general, the type of changes that are important to investigate are changes in the objective-function
coefficients, in the righthand-side elements, and in the matrix coefficients. Further, it is sometimes necessary to
evaluate the impact on the objective function of introducing new variables or new constraints into the problem.
Although it is often impossible to assess all of these changes simultaneously, good linear-programming codes
provide several means of obtaining pertinent information about the impact of these changes with a minimum
Further discussions on this topic, including a description of the types of output generated by computer
codes, are presented in the next section of this chapter.
The solution should be tested fully to ensure that the model clearly represents the real situation. We already
have pointed out the importance of conducting sensitivity analysis as part of this testing effort. Should the
solution be unacceptable, new refinements have to be incorporated into the model and new solutions obtained
until the mathematical-programming model is adequate.
When testing is complete, the model can be implemented. Implementation usually means solving the
model with real data to arrive at a decision or set of decisions. We can distinguish two kinds of implementation:
a single or one-time use, such as a plant location problem; and continual or repeated use of the model, such
as production planning or blending problems. In the latter case, routine systems should be established to
provide input data to the linear-programming model, and to transform the output into operating instructions.
Care must be taken to ensure that the model is flexible enough to allow for incorporating changes that take
Solving even small mathematical-programming problems demands a prohibitive amount of computational
effort, if undertaken manually. Thus, all practical applications of mathematical programming require the use
In this section we examine the role of digital computers in solving mathematical-programming models.
The majority of our remarks will be directed to linear-programming models, since they have the most advanced
computer support and are the models used most widely in practice.
The task of solving linear programs is greatly facilitated by the very efficient linear-programming codes
that most computer manufacturers provide for their various computer models. In a matter of one or two days,
a potential user can become familiar with the program instructions (control language or control commands)
that have to be followed in order to solve a given linear-programming problem by means of a specific
commercial code. The ample availability of good codes is one of the basic reasons for the increasing impact
of mathematical programming on management decision-making.
Commercial mathematical-programming codes have experienced an interesting evolution during the last
decade. At the beginning, they were simple and rigid computer programs capable of solving limited-size
models. Today, they are sophisticated and highly flexible information-processing systems, with modules that
handle incoming information, provide powerful computational algorithms, and report the model results in
a way that is acceptable to a manager or an application-oriented user. Most of the advances experienced
in the design of mathematical-programming codes have been made possible by developments in software
and hardware technology, as well as break-throughs in mathematical-programming theory. The continual
improvement in mathematical-programming computational capabilities is part of the trend to reduce running
times and computational costs, to facilitate solutions of larger problems (by using network theory and largescale system theory), and to extend the capabilities beyond the solution of linear-programming models into
nonlinear and integer-programmingproblems.
The field mathematical-programming computer systems is changing rapidly and the number of computer
codes currently available is extremely large. For these reasons, we will not attempt to cover the specific
instructions of any linear-programming code in detail. Rather, we will concentrate on describing the basic
features common to most good commercial systems, emphasizing those important concepts the user has to
understand in order to make sound use of the currently existing codes.
The first task the user is confronted with, when solving a linear-programming model by means of a commercial
computer code, is the specification of the model structure and the input of the corresponding values of the
parameters. There are several options available to the user in the performance of this task. We will examine
some of the basic features common to most good codes in dealing with input descriptions.
In general, a linear-programming problem has the following structure:
This model formulation permits constraints to be specified either as ‘‘greater than or equal to’’ (≥)
inequalities, ‘‘less than or equal to’’ (≤) inequalities, or simple equalities (=). It also allows for some
variables to be nonnegative, some to be unconstrained in sign, and some to have lower and/or upper bounds.
The most important elements the user has to specify in order to input the problem data are:
Names of the decision variables, constraints, objective function(s), and righthand side(s). Names have
to be given to each of this model’s elements so that they can be identified easily by the user. The names
cannot exceed a given number of characters (normally 6 or 8), depending on the code being used. Moreover,
it is important to adopt proper mnemonics in assigning names to these elements for easy identification of the
actual meaning of the variables and constraints. For instance, instead of designating by X37 and X38 the
production of regular and white-wall tires during the month of January, it would be better to designate them
Numerical values of the parameters ai j , bi , and c j . Only nonzero coefficients have to be designated. This
leads to significant savings in the amount of information to be input, since a great percentage of coefficientsare
zero in most linear-programming applications. The specification of a nonzero coefficient requires three pieces
of information: the row name, the column name, and the numerical value corresponding to the coefficient.
Nature of the constraint relationship. The user should indicate whether a given constraint has a =, ≥, or ≤
relationship. Also, many systems permit the user to specify a range on a constraint consisting of both the ≥
Free and bounded variables. Almost all codes assume the variables to be nonnegative unless specified
otherwise. This reduces the amount of data to be input, since in most practical applications the variables are
indeed nonnegative. Thus the user need only specify those variables that are ‘‘free’’ (i.e., bounded neither
from above nor from below), and those variables that have lower and upper bounds. The lower and upper
bounds may be either positive or negative numbers.
Nature of the optimization command. Instructions have to establish whether the objective function is to be
minimized or maximized. Moreover, most linear-programming codes allow the user to specify, if so desired,
several objective functions and righthand sides. The code then proceeds to select one objective function and
one righthand side at a time, in a sequence prescribed by the user, and the optimal solution is found for eachof
the resulting linear programs. This is a practical and effective way to perform sensitivity analysis. Whenever
several objective functions and righthand sides are input, the user should indicate which one of these elements
Title of problem and individual runs. It is useful to assign a title to the overall problem and to each of the
sensitivity runs that might be performed. These titles have to be supplied externally by the user.
The information given to the computer is stored in the main memory core or, if the problem is extremely
large, in auxiliary memory devices. Needless to say, the computational time required to solve a problem
increases significantly whenever auxiliary memory is required, due to the added information-processing
time. Within the state of the current computer technology, large computers (e.g., IBM 370/195) can handle
problems with up to 4000 constraints without using special large-scale theoretical approaches.
b) Retrieving a Summary of the Input Data
Most codes permit the user to obtain summarized or complete information on the input data. This information
is useful in identifying possible errors due to careless data specification, or to inappropriate model formulation.
In addition, the input summary can be of assistance in detecting any special structure of the model that can
be exploited for more efficient computational purposes.
The following are examples of types of summary information on the data input that are available in many
Number of rows and columns in the coefficient matrix,
Number of righthand sides and objective functions,
Density of the coefficient matrix (i.e., the percentage of nonzero coefficients in the
Number of nonzero elements in each row and column,
Value of the largest and smallest element in the coefficient matrix, righthand side(s),
Printout of all equations in expanded form,
Picture of the full coefficient matrix or a condensed form of the coefficient matrix.
The simultaneous presence of both large and small numbers in the matrix of coefficients should be avoided
whenever possible, because it tends to create problems of numerical instability. This can be avoided by
changing the unit of measure of a given variable (say, from lbs to 100 lbs, or from $1000 to $)—this change
will reduce (or increase) the numerical values on a given column; or by dividing (or multiplying) a row by a
constant, thus reducing (or increasing) the numerical values of the coefficients belonging to that row.
When dealing with large linear-programming models, the task of producing the original matrix of coefficients usually requires an extraordinary amount of human effort and elapsed time. Moreover, the chance of
performing these tasks without errors is almost nil. For example, a problem consisting of 500 rows and 2000
variables, with a matrix density of 10 percent, has 500×2000×0.10 = 100,000 nonzero coefficients that need
to be input. As we indicated before, most linear-programming codes require three pieces of information to
be specified when reporting a nonzero coefficient; these are the corresponding row name, column name, and
coefficient value. Thus, in our example the user will need to input 300,000 elements. If the input operations
are to be performed manually, the chance of absolute freedom from error is extremely low.
Moreover, in most practical applications, there is a great need for restructuring the matrix of coefficients
due to dynamic changes in the problem under study, to model-formulation alternatives to be analyzed, and to
sensitivity runs to be performed. A matrix generator helps address these difficulties by providing an effective
mechanism to produce and revise the coefficient matrix.
A matrix generator is a computer program that allows the user to input the linear-programming data in a
convenient form by prescribing only a minimum amount of information. Normally, it takes advantage of the
repetitive structure that characterizes most large linear-programming models, where many of the coefficients
are +1, −1, or zero. The matrix generator fills in those coefficients automatically, leaving to the user the
task of providing only the input of those coefficients the program cannot anticipate or compute routinely.
Multistage or multiperiod models have the tendency to repeat a given submatrix of coefficients several times.
The matrix generator automatically duplicates this submatrix as many times as necessary to produce the final
model structure. Matrix generators also provide consistency checks on input data to help detect possible
Matrix generators also can be used to compute the values of some of the model coefficients directly from
raw data provided by the user (e.g., the program might calculate the variable unit cost of an item by first
evaluating the raw material costs, labor costs, and variable overhead). Moreover, the matrix generator can
provide validity checks to ensure that no blunt errors have been introduced in the data. Simple checks consist
of counting the number of nonzero coefficients in some or all of the rows andcolumns, in analyzing the signs
of some critical variable coefficients,and so forth.
Sophisticated mathematical-programming codes have general-purpose matrix generators as part of their
system. Instances are also quite common where the user can prepare his own special-purpose matrix generator
to be used as part of the linear-programming computations.
There has been considerable concern in the development of mathematical-programming systems to reduce
the computational time required to solve a linear-programming problem by improving the techniques used
in the optimization stage of the process. This has been accomplished primarily by means of refinements in
the matrix-inversion procedures (derived from matrix triangularization concepts), improvements in the pathselection criterion (by allowing multiple pricing of several columns to be considered as possible incoming
variables), and use of more efficient presolution techniques (by providing crashing options to be used in order
to obtain an initial feasible solution, or by permitting the user to specify starting columns in the initial basis).
Other important issues associated with the use computers in solving linear-programming problems are
the presence of numerical errors and the tolerances allowed in defining the degree of accuracy sought in
performing the computations. Most codes permit the user to exercise some options with regard to these
issues. We will comment briefly on some of the most important features of those options.
Since the simplex method is a numeric computational procedure, it is inevitable for roundoff errors to be
produced and accumulated throughout the sequence of iterations required to find the optimal solution. These
errors could create infeasibility ornonoptimal conditions; that is, when the final solution is obtained and the
corresponding values of the variables are substituted in the original set of constraints, either the solution might
not satisfy the original requirements, or the pricing-out computations might generate some nonzero reduced
To address these problems, most codes use the original values of the coefficient matrix to reinvert the
basis periodically, thus maintaining its accuracy. The frequency of reinversion can be specified externally by
the user; otherwise, it will be defined internally by the mathematical-programming system. Some computer
codes fix the automatic reinversion frequency at a constant number of iterations performed; e.g., the basis
is reinverted every 50 to 100 iterations. Other codes define the reinversion frequency as a multiple of the
number of rows in the problem to be optimized; e.g., the basis is reinverted every 1.25 to 1.40m iterations,
Most codes compute a basis reinversion when the final solution has been obtained to assure its feasibility
In order to control the degree of accuracy obtained in the numerical computations, most linear-programming
codes permit the user to specify the tolerances he is willing to accept. Feasibility tolerances are designed to
check whether or not the values of the nonbasic variables and the reduced cost of the basic variables are zero.
Unless otherwise specified by the user, these checks involve internally set-up tolerance limits. Typical limits
There are also pivot rejection tolerances that prevent a coefficient very close to zero from becoming a
pivot element in a simplex iteration. Again, 10−6 is a normal tolerance to use for this purpose, unless the
As we have indicated before, errors usually are detected when the optimal values of the variables are substituted
in theoriginal set of constraints. Row errors measure the difference between the computed values of the
lefthand sides of the constraints, and the original righthand-side value, i.e., for equality constraints:
where the x 0j ’s are the corresponding optimal values ofthe variable. Similarly, there are column errors, which
are calculated by performing similar computations with the dual problem, i.e., for a basic column:
where the yi0 ’s are the corresponding optimal values for thedual variables. Some codes have an internally
determined or externally specified error frequency, which dictates how often errors are calculated and checked
against the feasibility tolerances. If the computed errors exceed the prescribed tolerances, a basis reinversion
is called for automatically. Restoring feasibility might demand a Phase I computation, or a dual simplex
Many codes offer options to the user with regard to the output of the error calculations. The user might
opt for a detailed printout of all column and row errors, or might be satisfied with just the maximum column
Whenever extra accuracy is required, some codes allow double precision to be used. This means that the
space reserved in the computer for the number of significant figures to represent the value of each variable
is doubled. Computing with the additional significant digits provides additional precision in the calculations
Once the optimal solution has been obtained, most computer codesprovide the user with a great amount of
information that describes in detail the specific values of the optimal solution and itssensitivity to changes
in some of the parameters of the original linear-programming problem. We will review some of the most
important features associated with output specifications.
Typical information produced by standard commercial codes might include:
Optimal value of the objective function. This isobtained by substituting the optimal values of the decisionvariables in the original objective function. When the model has been constructed properly, the value of
the objective function is a finite number. If no feasible solution exists, the computerprogram will indicate
that the problem is infeasible, and no specific value of the objective function will be given. The remaining
alternative occurs when the objective function can be increased (if we are maximizing) or decreased (if we
are minimizing) indefinitely. In this situation, the program will report an unbounded solution, which is a
clear indication in any practical application that an error has been made in the model formulation.
Optimal values of the decision variables. For each ofthe decision variables the program specifies its optimal
value.Except for degenerate conditions, all the basic variables assume positive values. Invariably, all nonbasic
variables have zero values. There are as many basic variables as constraints in the original problem.
Slacks and surpluses in the constraints. ‘‘Less than or equal to’’ (≤) constraints might have positive slacks
associated with them. Correspondingly, ‘‘greater than or equal to’’ (≥) constraints might have positive
surpluses associated with them. The program reports the amount of these slacks and surpluses in the optimal
solution. Normally, a slackcorresponds to an unused amount of a given resource, and a surplus corresponds
to an excess above a minimum requirement.
Shadow prices for constraints. The shadow price associated with a given constraint corresponds to the
change in the objective function when the original righthand side of that constraint is increased by one unit.
Shadow prices usually can be interpreted as marginal costs (if we are minimizing) or marginal profits (if we
are maximizing). Constraints that have positive slacks or surpluses have zero shadow prices.
Reduced costs for decision variables. Reduced cost can be interpreted as the shadow prices corresponding to
the nonnegativity constraints. All basic variables have zero reduced costs. The reduced cost associated with
a nonbasic variable corresponds tothe change in the objective function whenever the corresponding value of
the nonbasic variable is increased from 0 to 1.
Ranges on coefficients of the objective function. Ranges are given for each decision variable, indicating the
lower and upper bound the cost coefficient of the variable can take without changing the current value of the
Ranges on coefficients of the righthand side. Ranges are given for the righthand-side element of each constraint, indicating the lower and upper value the righthand-side coefficient of a given constraint can take
without affecting the value of the shadow price associated with that constraint.
Variable transitions resulting from changes in the coefficients of the objective function. Whenever a coefficient of the objective function is changed beyond the range prescribed above, a change of the basis will take
place. This element of the output report shows, for each variable, what variable will leave the basis and what
new variable will enter the basis if the objective-function coefficient of the corresponding variable were to
assume a value beyond its current range. If there is no variable to drop, the problem becomes unbounded.
Variable transitions resulting from changes in thecoefficient of the righthand side. Similarly, whenever a
coefficient of the righthand side of a constraint is changed beyond the range prescribed above, a change in
the current basis will occur. This portion of the report shows, for each constraint, which variable will leave
the basis and which new variable will enter the basis if the righthand-side coefficient of the corresponding
constraint were to assume a value beyond its current range. If there is no variable to enter, the problem
In the next section we present a simple illustration of these output reports.
In addition to providing the information just described, most codes allow the user to perform a variety of
sensitivity and parametric runs, which permit an effective analysis of the changes resulting in the optimal
solution when theoriginal specifications of the problem are modified. Quite often the user is not interested in
obtaining a single solution to a problem, but wants to examine thoroughly a series of solutions to a number
of cases. Some of the system features to facilitate this process are:
Multiple objective functions and righthand sides. We noticed before that provisions are made in many codes
for the user to input several objective functions. The problem is solved with one objective function at a time,
the optimal solution of oneproblem serving as an initial solution for the new problem. Sometimes only a few
iterations are required to determine the new optimum, so that this process is quite effective. In this fashion,
changes of the optimal solution with changes in the cost or revenue structure of the model can be assessed
very rapidly. Similar options are available for processing the problem with one righthand side at a time,
through a sequence of righthand sides provided by the user. Some codes use the dual simplex method for this
Parametric Variation. Another way to assess sensitivity analysis with regard to objective functions and
righthand sides is to allow continuous changes to occur from a specified set of coefficients for the objective
function or the righthand side to another specified set. This continuous parametrization exhaustively explores
the pattern of the solution sensitivity in a very efficient manner. Some codes allow for a joint parametrization
of cost coefficients and righthand-side elements.
Revisions of the original model formulation. Finally, many codes allow revisions to be incorporated in the
model structure without requiring a complete reprocessing of the new problem. These revisions might effect
changes in specific parameters of the model, as well as introduce new variables andnew constraints.
Given the massive amount of highly technical information produced by a linear-programming code, it is
most desirable to translate the output into a report directed to an application-oriented user. This is almost
mandatory when using linear programming as an operational tool to support routine managerial decisionmaking. The most sophisticated mathematical-programming systems contain capabilities for the generation
of general-purpose reports. Special-purpose reports easily can be programmed externally in any one of the
high-level programming languages (like FORTRAN, APL, or BASIC).
The basic purpose of this section is to illustrate, via a very small and simple example, the elements contained in
a typical computer output of a linear-programming model. The example presented is a multistage productionplanning problem. In order tosimplify our discussion and to facilitate the interpretation of the computer output,
we have limited the size of the problem by reducing to a bare minimum the number of machines, products, and
time periods being considered. This tends to limit the degree of realism of the problem, but greatly simplifies
the model formulation. For some rich and realistic model-formulation examples, the reader is referred to the
exercises at the end of this chapter, and to Chapters 6, 7, 10,and 14.
An automobile tire company has the ability to produce both nylon and fiberglass tires. During the next three
months they have agreed to deliver tires as follows:
The company has two presses, a Wheeling machine and a Regal machine, and appropriate molds that can
be used to produce these tires, with the following production hours available in the upcoming months:
The production rates for each machine-and-tire combination, in terms of hours per tire, are as follows:
The variable costs of producing tires are $5.00 per operating hour, regardless of which machine is being
used or which tire is being produced. There is also an inventory-carrying charge of $0.10 per tire per month.
Material costs for the nylon and fiberglass tires are $3.10 and $3.90 per tire, respectively. Finishing, packaging
and shipping costs are $0.23 per tire. Prices have been set at $7.00 per nylon tire and $9.00 per fiberglass
The following questions have been raised by the production manager of the company:
a) How should the production be scheduled in order to meet the delivery requirements at minimum costs?
b) What would be the total contribution to be derived from this optimal schedule?
c) A new Wheeling machine is due to arrive at the beginning of September. For a $200 fee, it would be
possible to expedite the arrival of the machine to August 2, making available 172 additional hours of
Wheeling machine time in August. Should the machine be expedited?
d) When would it be appropriate to allocate time for the yearly maintenance check-up of the two machines?
We begin by applying the steps in model formulation recommended in Section 5.2.
In this particular situation the time horizon covers three months, divided into three time periods of a month’s
duration each. More realistic production-planning models normally have a full-year time horizon.
Selection of Decision Variables and Parameters
We can determine what decision variables are necessary by defining exactly what information the plant
foreman must have in order to schedule the production. Essentially, he must know the number of each type of
tire to be produced on each machine in each month and the number of each type of tire to place in inventory
at the end of each month. Hence, we have the following decision variables:
Wn,t = Number of nylon tires to be produced on the Wheeling machine during
Rn,t = Number of nylon tires to be produced on the Regal machine during
Wg,t = Number of fiberglass tires to be produced on the Wheeling machine in
Rg,t = Number of fiberglass tires to be produced on the Regal machine in
In,t = Number of nylon tires put into inventory at the end of month t;
Ig,t = Number of fiberglass tires put into inventory at the end of month t.
variables per time period and since there are three months under consideration, we have a total of eighteen
variables. However, it should be clear that it would never be optimal to put tires into inventory at the end of
August since all tires must be delivered by then. Hence, we can ignore the inventory variables for August.
The parameters of the problem are represented by the demand requirements, the machine availabilities,
the machine productivity rates, and the cost and revenue information. All these parameters are assumed to
There are two types of constraint in this problem representing production-capacity available and demand
Let us develop the constraints for the month of June. The production-capacity constraints can be written
in terms of production hours on each machine. For the Wheeling machine in June we have:
while, for the Regal machine in June, we have:
The production constraints for future months differ only in the available number of hours of capacity for the
Now consider the demand constraints for June. For each type of tire produced in June we must meet the
demand requirement and then put any excess production into inventory. The demand constraint for nylon
while for fiberglass tires in June it is:
In July, however, the tires put into inventory in June are available to meet demand. Hence, the demand
while for fiberglass tires in July it is:
In August it is clear that tires will not be put into inventory at the end of the month, so the demand constraint
while for fiberglass tires in August it is:
Finally, we have the nonnegativity constraints on all of the decision variables:
The total revenues to be obtained in this problem are fixed, because we are meeting all the demand requirements, and maximization of profit becomes equivalent to minimization of cost. Also, the material-cost
component is fixed, since we know the total amount of each product to be produced during the model time horizon. Thus, a proper objective function to select is the minimization of the variable relevant cost components:
variable production costs plus inventory-carrying costs.
Now, since each kind of tire on each machine has a different production rate, the cost of producing a tire
on a particular machine will vary, even though the variable cost per hour is constant for each tire-and-machine
combination. The variable production cost per tire for the fiberglass tires made on the Regal machine can
be determined by multiplying the production rate (in hours/tire) by the variable production cost (in $/hour)
resulting in (0.14)(5) = $0.70/tire. The remaining costs for producing each tire on each machine can be
Given the inventory-carrying cost of $0.10 per tire per month, we have the following objective function
(0.75Wn, t + 0.80Rn, t + 0.60Wg, t + 0.70Rg, t + 0.10In, t + 0.10Ig, t );
and we understand that In, 3 = 0 and Ig, 3 = 0.
The formulation of this problem is summarized in Table 5.3. This problem is what we call a multistage
model, because it contains more than one time period. Note that the constraints of one time period are linked
to the constraints of another only by the inventory variables. This type of problem structure is very common
in mathematical programming. Note that there are very few elements different from 0, 1, and −1 in the
tableau given in Table 5.3. This problem structure can be exploited easily in the design of a matrix generator,
to provide the input for the linear-programming computation.
We will now present the computer output obtained by solving the linear-programming model set forth in
Table 5.3 by means of an interactive system operated from a computer terminal.
The notation describing the decision variables has been changed slightly, in order to facilitate computer
Similar interpretations can be given to variables WG–T (number of fiberglass tires on the Wheeling
machine), RN–T, and RG–T (number of nylon and fiberglass tires, respectively, produced on the Regal
machine at month T). IN–T and IG–T denote the number of nylon and fiberglass tires, respectively, left over
The production constraints are represented by W–T and R–T, meaning the hours of Wheeling and Regal
machine availability at period T. N–T and G–T stand for the demand at period T of nylon and fiberglass tires,
Figure 5.1 is the computer output of the problem. The reader should reflect about the meaning of each
of the elements of the output. The output provides exactly the same information discussed under the title
Standard Output Reports in Section 5.3. The reader is referred to that section for a detailed explanation of
With the aid of the optimal solution of the linear-programmingmodel, we can answer the questions that were
formulated at the beginning of this problem.
Examination of the optimal values of the decision variables in thelinear-programming solution reveals that
the appropriate production schedule should be:
The unused hours of each machine are the slack variables of the computer output.
The resulting inventory at the end of each month for the two types of products is as follows:
Figure 5.1 Computer printout of solution of the problem. (Cont. on next page.)
Total costs. The total costs are the variable production costs, the inventory costs, the cost of raw materials,
and the finishing, packaging, and shipping costs.
The variable production and inventory costs are obtained directly from the optimal value of the objective
function of thelinear-programming model. These costs are equal to $19,173.30.
Raw-material costs are $3.10 per nylon tire and $3.90 per fiberglass tire. The total production of nylon
and fiberglass tires is given in the delivery schedule. The total material costs are therefore:
The finishing, packaging, and shipping costs are $0.23 per tire. Since we are producing 26,000 tires, this
Total revenues. Prices per tire are $7.00 for nylon and $9.00 for fiberglass. Therefore, the total revenue is:
From this contribution we should subtract the corresponding overhead cost to be absorbed by this contract,
in order to obtain the net contribution before taxes to the company.
The new machine is a Wheeling machine, which is preferred to the Regal equipment. The question is can it
be used, and how much? Even if the machine were fully utilized, the hourly marginal cost would be:
Examination of the shadow price for Wheeling machines in August reveals that it would be worth only
$0.33 to have an additional hour of time on Wheeling equipment. We should therefore recommend against
We are not told in the problem statement the amount of time required to service a given machine, or whether
maintenance can just as well be performed later, or how much it would cost to do it at night and on weekends.
We therefore cannot tell the maintenance department exactly what to do. We can, however, tell them that the
Wheeling machines are completely used, but 278 hours are available on the Regal machines in June and 246
in August. These hours would be ‘‘free.’’
The shadow prices show that, by adjusting the production schedule, Wheeling machine time could be
made available in June and August at a cost of $0.33/hr. During June we can have, at this cost, a total of
261.25 hours (the difference between the current availability, 700 hours, and the lower bound of the range
for the W–1 righthand-side coefficient, 438.75). During August we will have available at $0.33/hr a total of
231.25 hours (the difference betweenthe current availability, 1000 hours, and the lower bound of the range
for the W–3 righthand-side coefficient, 768.75).
1. The Pearce Container Corporation manufactures glass containers for a variety of products including soft drinks,
beer, milk, catsup and peanut butter. Pearce has two products that account for 34% of its sales: container Type 35
and container Type 42. Pearce is interested in using a linear program to allocate production of these two containers
to the five plants at which they are manufactured. The following is the estimated demand for the two types of
containers for each quarter of next year: (1 unit = 100,000 containers)
Pearce has ten machines at the five plants; eight of the machines can produce both Types 35 and 42, but two
of the machines can produce only Type 42. Because the ten machines were purchased singly over a long period of
time, no two machines have the same production rate or variable costs. After considerable research, the following
information was gathered regarding the production of 1 unit (100,000 containers) by each of the ten machines:
During production a residue from the glass containers is deposited on the glass machines; during the course of
a year machines are required to be shut down in order to clean off the residue. However, four of the machines are
relatively new and will not be required to be shut down at all during the year; these are machines: C4, D5, K4, and
V1. The following table shows the production days available for each machine by quarters:
In order to meet demands most efficiently, Pearce ships products from plant to plant. This transportation process
ensures that the most efficient machines will be used first. However, transportation costs must also be considered.
The following table shows transportation costs for shipping one unit between the five plants; the cost is the same
for Type 35 and Type 42; Type 35 is not shipped to or from Plant 5.
Inter-plant transport (100,000 containers)
It is possible to store Type 35 and Type 42 containers almost indefinitely without damage to the containers.
However, there is limited storage space at the five plants. Also, due to storage demands for other products, the
available space varies during each quarter. The space available for Types 35 and 42 is as follows:
Inventory capacity (100,000 bottles = 1 unit)
It was found that there was no direct cost for keeping the containers in inventory other than using up storage
space. However, there were direct costs for handling items, i.e., putting in and taking out of inventory. The costs
for handling containers was as follows by type and by plant for one unit:
a) Apply the stages of model formulation discussed in Section 5.2 to the Pearce Container Corp. problem. Precisely
interpret the decision variables, the constraints, and the objective function to be used in the linear-programming
b) Indicate how to formulate the linear program mathematically. It is not necessary to write out the entire initial
c) Determine the number of decision variables and constraints involved in the model formulation.
2. The Maynard Wire Company was founded in 1931 primarily to capitalize on the telephone company’s expanding
need for high-quality color-coded wire. As telephone services were rapidly expanding at that time, the need for
quality color-coded wire was also expanding. Since then, the Maynard Wire Company has produced a variety of
wire coatings, other wire products, and unrelated molded-plastic components. Today a sizable portion of its business
remains in specially coated wire. Maynard Wire has only one production facility for coated wire, located in eastern
Massachusetts, and has sales over much of the northeastern United States.
Maynard Wire is an intermediate processor, in that it purchases uncoated wire in standard gauges and then
applies the various coatings that its customers desire. Basically there are only two types of coatings requested—
standard inexpensive plastic and the higher-quality Teflon. The two coatings then come in a variety of colors,
achieved by putting special dyes in the basic coating liquid. Since changing the color of the coating during the
production process is a simple task, Maynard Wire has essentially two basic products.
Planning at Maynard Wire is done on a quarterly basis, and for the next quarter the demands for each type of
The production of each type of wire must then be scheduled to minimize the cost of meeting this demand.
The Production process at Maynard Wire is very modern and highly automated. The uncoated wire arrives in
large reels, which are put on spindles at one end of the plant. The uncoated wire is continuously drawn off each
successive reel over some traverse guides and through a coating bath containing either the standard plastic or the
more expensive Teflon. The wire then is pulled through an extruder, so that the coating liquid adheres evenly to the
wire, which then continues through a sequence of four electric drying ovens to harden the coating. Finally, the wire
is reeled up on reels similar to those it arrived on. Different dyes are added to the coating liquid during the process
to produce the various colors of wire ordered.
Maynard Wire has two, basically independent, wire trains within the plant, one engineered by the Kolbert
Engineering Corporation and the other purchased secondhand from the now defunct Loomis Wire Company. Both
the standard plastic and the quality Teflon types of wire can be produced on either process train. The production
Producing the quality Teflon wire is a slower process due to the longer drying time required. The associated
variable operating cost for the month of July in dollars per day are:
However, because each month the process trains must be shut down for scheduled maintenance, there are fewer
days available for production than days in the month. The process-train availabilities in days per month are:
Both types of wire may be stored for future delivery. Space is available in Maynard Wire’s own warehouse,
but only up to 100 tons. Additional space is available essentially without limit on a leased basis. The warehousing
costs in dollars per ton between July and August are:
A linear program has been formulated and solved that minimizes the total discounted manufacturing and
warehousing costs. Future manufacturing and warehousing costs have been discounted at approximately ten percent
per month. The MPS input format∗ , picture, and solution of the model are presented (see Figs. E5.1 and E5.2). Also,
there is a parametric righthand-side study that increases the demand for standard plastic-coated wire in September
from 1300 to 1600 tons. Finally, there is a parametric cost run that varies the warehousing cost for quality Tefloncoated wire from $8.00 to $12.00.
Typical rows and columns of the linear program are defined as follows:
∗ MPS stands for Mathematical Programming System. It is a software package that IBM has developed to solve general
Demand for plastic-coated wire in month 1
Production of plastic-coated wire on Kolbert train in month 1
Warehousing plastic-coated wire from the end of month 1 to the end of month 2
Leasing warehouse space for plastic-coated wire from the end of month 1 to the
a) Explain the optimal policy for Maynard Wire Company when the objective function is COST and the righthand
b) What is the resulting production cost for the 300-ton incremental production of plastic-coated wire in month 3?
c) How does the marginal production cost of plastic-coated wire vary when its demand in month 3 is shifted from
d) How does the operating strategy vary when the warehousing cost for quality Teflon-coated wire shifts from $8.00
to $12.00 with the demand for plastic-coated wire in month 3 held at 1600 tons?
3. Toys, Inc., is a small manufacturing company that produces a variety of children’s toys. In the past, water pistols
have been an exceptionally profitable item, especially the miniature type which can be hidden in the palm of one
hand. However, children recently have been buying water rifles, which permit the stream of water to be projected
much farther. Recognizing that this industry trend was not a short-lived fad, Toys, Inc., started to produce a line of
After several months of production, Toys’ General Manager, Mr. Whett, ran into a storage problem. The older
and smaller water pistols had not occupied much space, but the larger water rifles were quite bulky. Consequently,
Mr. Whett was forced to rent storage space in a public warehouse at 28c/ per case per month, plus 44c/ per case for
cost of handling. This made Mr. Whett wonder whether producing water rifles was profitable. In addition, Mr.
Whett wondered whether it might not be better to increase his production capacity so that fewer cases would be
The following information was obtained from Toys’ accounting department:
Desired return on investment: 10% after taxes
Variable manufacturing cost: $21.00/case, or $9.50/case after taxes
(Variable costs include all overhead and so-called ‘‘fixed" costs, except for the cost of production equipment. This
seems appropriate, since the company has expanded so rapidly that ‘‘fixed" costs have actually been variable.)
Warehousing: $0.28/case per month, or $0.126/case per month after taxes
Handling: $0.44/case, or $0.198/case after taxes
Opporturnity cost of tying up capital in inventory: ($21.00 × 10%) ÷ 12 months = $0.18/case per month
Selling price: $28.10/case, or $12.61 after taxes
Existing production capacity: 2750 cases per month
Cost of additional production capacity: $6400/year after taxes, for each additional 1000 cases/month. This figure
takes into account the investment tax credit and the discounted value of the tax shield arising out of future depreciation.
The anticipated demand, based on past sales data, for the next 12 months is given below. The first month is
The program variables are defined as follows:
PRD-1 to PRD12 identify the production constraints for the 12 periods.
DEM-1 to DEM12 identify the demand constraints for the 12 periods.
CAP-1 to CAP12 identify the capacity constraints for the 12 periods.
CNG-1 to CNG12 identify the constraints describing changes in inventory levels for the 12 periods.
X1 to X12 are the cases produced in each period. Associated with these variables are production costs of $9.50.
S1 to S12 are the cases sold in each period. Associated with these variables are revenues of $12.61 per case.
Y1 to Y12 are the cases in inventory at the beginning of the designated period. Associated with these variables are
storage and cost of capital charges, totaling $0.306/case per month.
U1 to U12 are the unfilled demand in each period. No attempt has been made to identify a penalty cost associated
Q1 to Q11 are the changes in inventory levels from one period to the next. Since a handling charge of $0.198/case
is associated only with increases in inventory, these variables have been further designated as Q1+, Q1−, etc. to
indicate increases (+) and decreases (−) in inventory levels.
+CAP-1 to +CAP12 are the slack variables supplied by the computer to represent unused production capacity in
A typical production constraint, PRD-2, is shown below:
This expression indicates that the beginning inventory, plus the production, minus the sales must equal the ending
In the beginning of period 1 and at the end of period 12, the inventory level is set equal to zero. Hence, these
A typical demand constraint, DEM-2, is shown below:
This expression indicates that the cases sold, plus the unfilled demand, must equal the total demand for that period.
A typical capacity constraint, CAP-2, is shown below:
This inequality indicates that the maximum number of cases that can be produced in any given month is 2750.
And lastly, a typical inventory level constraint, CNG-2, is shown below:
This expression indicates that Q2 must equal the change in inventory level that occurs during period 2.
Since there is no beginning inventory, the change in inventory level that occurs during period 1 must equal the
Q1– must be zero, since negative inventories are impossible.
The objective function is to maximize the contribution, which equals:
The following 9 pages provide the output to be used in discussing the Toys, Inc. problem.
Page 257 gives the optimum solution for the initial problem statement. Capacity is fixed at 2750 cases per
Pages 258 and 259 contain, respectively, the cost ranges and righthand-side ranges associated with the optimum
Pages 260 through 264 give details pertaining to a parametric analysis of the capacity availability. In each time
period, the capacity is increased from its original value of 2750 to 2750 + THETA × 1375. The computer reports
only solutions corresponding to a change of basis. Such changes have taken place at values of THETA equal to
0.235, 0.499, 1.153, 1.329, and 1.450, which are reported on pages 260 to 264, respectively.
Page 265 presents a parametric study for the cost associated with unfilled demand. The cost of unfilled demand
is increased from its initial value of 0 to PHI × 1, for every demand period. Page 257 gives the optimum solution
for PHI = 0; page 265 provides the optimum solution for PHI = 0.454. Beyond this value of PHI the solution does
Figure E5.1 Model of program for manufacturing and warehousing costs. (Continued on next page.)
Figure E5.3 Optimum solution for Toys, Inc., cost and righthand-side ranges; parametric RHS
Using the computer output supplied, answer the following questions.
a) Draw a graph depicting the following as a function of time, assuming a capacity of 2750 cases per month.
Explain thoroughly what this graph implies about the optimal operations of Toys, Inc.
Give a complete economic interpretation of the dual variables.
Give a concise explanation of the righthand-side and cost ranging output.
Use the parametric programming of the righthand side as a basis for discussion the optimal production capacity.
Use the parametric programming of the cost function as a basis for discussing the ‘‘value" of goodwill loss
associated with unfilled demand. (When demand is not met, we lose some goodwill of our customer. What is
4. Solving an LP by computer. Your doctor has found in you a very rare disease, ordinarily incurable, but, in your
case, he believes that perhaps something can be done by a series of very elaborate treatments coupled with a strict
diet. The treatments are so expensive that it becomes necessary to minimize the cost of the diet.
The diet must provide minimum amounts of the following items: calories, calcium, vitamin A, riboflavin, and
ascorbic acid. Your daily requirement for these items (in the above order) may be determined by reading off the
numerical values corresponding to the first five letters of your name on Table 5.4. The following are the units used:
102 calories, 10−2 grams, 102 international units, 10−1 milligrams, and milligrams.
Your choice of foods is somewhat limited because you find it financially advantageous to trade at a discount
store that has little imagination. You can buy: (1) wheat flour (enriched), (2) evaporated milk, (3) cheddar cheese,
(4) beef liver, (5) cabbage, (6) spinach, (7) sweet potatoes, (8) lima beans (dried).
The nutritional values per dollar spent have been tabulated by Dantzig (who regularly patronizes the store) in
Table 5.5. In addition, the store features a grayish powder, Product X, sold in bulk, whose nutritional values per unit
cost are also given in Table 5.4. The units (same order of items as before) are 103 calories/dollar, 10−1 grams/dollar,
103 international units/dollar, 10−1 milligrams/dollar, milligrams/dollar.
Your doctor has coded your diet requirements and the nutritional properties of Product X under the first five
a) Find your minimum-cost diet and its cost.
b) How much would you be willing to pay for pure vitamin A? pure riboflavin?
Table E5.5 Nutritive Values of Common Foods Per Dollar of Expenditure∗
Calories Protein Calcium Iron Vitamin A Thiamine Riboflavin Niacin Acid
(1000) (grams) (grams) (mg.) (1000 I.U.) (mg.)
∗ Source: G. B. Dantzig, Linear Programming and Extension, Princeton University Press, Princeton, N.J., 1963.
c) A new food has come out (called GLUNK) having nutritional values per dollar of 83, 17, 25, 93, 07 (values are
in the same order and same units as for Product X). Would you want to include the new food in your diet?
d) By how much would the cost of lima beans have to change before it would enter (or leave, as the case may be)
e) Over what range of values of cost of beef liver would your diet contain this wonderful food?
f) Suppose the cost of foods 1, 3, 5, 7, and 9 went up 10% but you continued on the diet found in (a). How much
would you be willing to pay for pure vitamin A? pure riboflavin?
g) If the wheat flour were enriched by 10 units of vitamin A without additional cost, would this change your diet?
Exercise 1 is based on Chapter 14 of Applied Linear Programming, by Norman J. Driebeck, Addison-Wesley
Exercises 2 and 3 are based on cases with the same names written by one of the authors.
Exercise 4 is a variation of the diet problem used by John D.C. Little of the Massachusetts Institute of
There are several kinds of linear-programming models that exhibit a special structure that can be exploited
in the construction of efficient algorithms for their solution. The motivation for taking advantage of their
structure usually has been the need to solve larger problems than otherwise would be possible to solve with
existing computer technology. Historically, the first of these special structures to be analyzed was the transportation problem, which is a particular type of network problem. The development of an efficient solution
procedure for this problem resulted in the first widespread application of linear programming to problems of
industrial logistics. More recently, the development of algorithms to efficiently solve particular large-scale
systems has become a major concern in applied mathematical programming.
Network models are possibly still the most important of the special structures in linear programming. In
this chapter, we examine the characteristics of network models, formulate some examples of these models,
and give one approach to their solution. The approach presented here is simply derived from specializing the
rules of the simplex method to take advantage of the structure of network models. The resulting algorithms are
extremely efficient and permit the solution of network models so large that they would be impossible to solve
by ordinary linear-programming procedures. Their efficiency stems from the fact that a pivot operation for
the simplex method can be carried out by simple addition and subtraction without the need for maintaining
and updating the usual tableau at each iteration. Further, an added benefit of these algorithms is that the
optimal solutions generated turn out to be integer if the relevant constraint data are integer.
A common scenario of a network-flow problem arising in industrial logistics concerns the distribution of a
single homogeneous product from plants (origins) to consumer markets (destinations). The total number of
units produced at each plant and the total number of units required at each market are assumed to be known.
The product need not be sent directly from source to destination, but may be routed through intermediary
points reflecting warehouses or distribution centers. Further, there may be capacity restrictions that limit
some of the shipping links. The objective is to minimize the variable cost of producing and shipping the
The sources, destinations, and intermediate points are collectively called nodes of the network, and the
transportation links connecting nodes are termed arcs. Although a production/distribution problem has been
given as the motivating scenario, there are many other applications of the general model. Table E8.1 indicates
A numerical example of a network-flow problem is given in Fig 8.1. The nodes are represented by
numbered circles and the arcs by arrows. The arcs are assumed to be directed so that, for instance, material
can be sent from node 1 to node 2, but not from node 2 to node 1. Generic arcs will be denoted by i– j, so
that 4–5 means the arc from node 4 to node 5. Note that some pairs of nodes, for example 1 and 5, are not
Table E8.1 Examples of Network Flow Problems
Figure 8.1 exhibits several additional characteristics of network flow problems. First, a flow capacity is
assigned to each arc, and second, a per-unit cost is specified for shipping along each arc. These characteristics
are shown next to each arc. Thus, the flow on arc 2–4 must be between 0 and 4 units, and each unit of flow
on this arc costs $2.00. The ∞’s in the figure have been used to denote unlimited flow capacity on arcs 2–3
and 4–5. Finally, the numbers in parentheses next to the nodes give the material supplied or demanded at that
node. In this case, node 1 is an origin or source node supplying 20 units, and nodes 4 and 5 are destinations
or sink nodes requiring 5 and 15 units, respectively, as indicated by the negative signs. The remaining nodes
have no net supply or demand; they are intermediate points, often referred to as transshipment nodes.
The objective is to find the minimum-cost flow pattern to fulfill demands from the source nodes. Such
problems usually are referred to as minimum-cost flow or capacitated transshipment problems. To transcribe
the problem into a formal linear program, let
xi j = Number of units shipped from node i to j using arc i– j.
Then the tabular form of the linear-programming formulation associated with the network of Fig. 8.1 is
The first five equations are flow-balance equations at the nodes. They state the conservation-of-flow law,
As examples, at nodes 1 and 2 the balance equations are:
It is important to recognize the special structure of these balance equations. Note that there is one balance
equation for each node in the network. The flow variables xi j have only 0, +1, and −1 coefficients in these
Table E8.2 Tableau for Minimum-Cost Flow Problem
equations. Further, each variable appears in exactly two balance equations, once with a +1 coefficient,
corresponding to the node from which the arc emanates; and once with a −1 coefficient, corresponding to
the node upon which the arc is incident. This type of tableau is referred to as a node–arc incidence matrix; it
completely describes the physical layout of the network. It is this particular structure that we shall exploit in
developing specialized, efficient algorithms.
The remaining two rows in the table give the upper bounds on the variables and the cost of sending one
unit of flow across an arc. For example, x12 is constrained by 0 ≤ x12 ≤ 15 and appears in the objective
function as 2x12 . In this example the lower bounds on the variables are taken implicitly to be zero, although
in general there may also be nonzero lower bounds.
This example is an illustration of the following general minimum-cost flow problem with n nodes:
The summations are taken only over the arcs in the network. That is, the first summation in the ith flowbalance equation is over all nodes j such that i– j is an arc of the network, and the second summation is over
all nodes k such that k–i is an arc of the network. The objective function summation is over arcs i– j that
are contained in the network and represents the total cost of sending flow over the network. The ith balance
equation is interpreted as above: it states that the flow out of node i minus the flow into i must equal the
net supply (demand if bi is negative) at the node. u i j is the upper bound on arc flow and may be +∞ if the
capacity on arc i– j is unlimited. `i j is the lower bound on arc flow and is often taken to be zero, as in the
previous example. In the following sections we shall study variations of this general problem in some detail.
There are a number of interesting special cases of the minimum-cost flow model that have received a great
deal of attention. This section introduces several of these models, since they have had a significant impact
on the development of a general network theory. In particular, algorithms designed for these specific models
have motivated solution procedures for the more general minimum-cost flow problem.
The transportation problem is a network-flow model without intermediate locations. To formulate the problem,
ai = Number of units available at source i (i = 1, 2, . . . , m);
b j = Number of units required at destination j ( j = 1, 2, . . . , n);
ci j = Unit transportation cost from source i to destination j
(i = 1, 2, . . . , m; j = 1, 2, . . . , n).
For the moment, we assume that the total product availability is equal to the total product requirements; that
Later we will return to this point, indicating what to do when this supply–demand balance is not satisfied. If
xi j = Number of units to be distributed from source i to destination j
(i = 1, 2, . . . , m; j = 1, 2, . . . , n),
we may then formulate the transportation problem as follows:
(i = 1, 2, . . . , m; j = 1, 2, . . . , n)
Expression (1) represents the minimization of the total distribution cost, assuming a linear cost structure
for shipping. Equation (2) states that the amount being shipped from source i to all possible destinations
should be equal to the total availability, ai , at that source. Equation (3) indicates that the amounts being
shipped to destination j from all possible sources should be equal to the requirements, b j , at that destination.
Usually Eq. (3) is written with positive coefficients and righthand sides by multiplying through by minus one.
Let us consider a simple example. A compressor company has plants in three locations: Cleveland,
Chicago, and Boston. During the past week the total production of a special compressor unit out of each
plant has been 35, 50, and 40 units respectively. The company wants to ship 45 units to a distribution center
in Dallas, 20 to Atlanta, 30 to San Francisco, and 30 to Philadelphia. The unit production and distribution
costs from each plant to each distribution center are given in Table E8.3. What is the best shipping strategy
The linear-programming formulation of the corresponding transportation problem is:
Minimize z = 8x11 + 6x12 + 10x13 + 9x14 + 9x21 + 12x22 + 13x23
Table E8.3 Unit Production and Shipping Costs
Because there is no ambiguity in this case, the same numbers normally are used to designate the origins and
destinations. For example, x11 denotes the flow from source 1 to destination 1, although these are two distinct
nodes. The network corresponding to this problem is given in Fig. 8.2.
Though the transportation model has been cast in terms of material flow from sources to destinations, the
model has a number of additional applications. Suppose, for example, than n people are to be assigned to n
jobs and that ci j measures the performance of person i in job j. If we let
we can find the optimal assignment by solving the optimization problem:
(i = 1, 2, . . . , n; j = 1, 2, . . . , n).
The first set of constraints shows that each person is to be assigned to exactly one job and the second set of
constraints indicates that each job is to be performed by one person. If the second set of constraints were
multiplied by minus one, the equations of the model would have the usual network interpretation.
As stated, this assignment problem is formally an integer program, since the decision variables xi j are
restricted to be zero or one. However, if these constraints are replaced by xi j ≥ 0, the model becomes a special
case of the transportation problem, with one unit available at each source (person) and one unit required by
each destination (job). As we shall see, network-flow problems have integer solutions, and therefore formal
specification of integrality constraints is unnecessary. Consequently, application of the simplex method, or
most network-flow algorithms, will solve such integer problems directly.
For the maximal flow problem, we wish to send as much material as possible from a specified node s in a
network, called the source, to another specified node t, called the sink. No costs are associated with flow. If
v denotes the amount of material sent from node s to node t and xi j denotes the flow from node i to node j
(i = 1, 2, . . . , n; j = 1, 2, . . . , n).
As usual, the summations are taken only over the arcs in the network. Also, the upper bound u i j for the flow
on arc i– j is taken to be +∞ if arc i– j has unlimited capacity. The interpretation is that v units are supplied
Let us introduce a fictitious arc t–s with unlimited capacity; that is, u ts = +∞. Now xts represents the
variable v, since xts simply returns the v units of flow from node t back to node s, and no formal external
supply of material occurs. With the introduction of the arc t–s, the problem assumes the following special
(i = 1, 2, . . . , n; j = 1, 2, . . . , n).
Let us again consider a simple example. A city has constructed a piping system to route water from a lake
to the city reservoir. The system is now underutilized and city planners are interested in its overall capacity.
The situation is modeled as finding the maximum flow from node 1, the lake, to node 6, the reservoir, in the
The numbers next to the arcs indicate the maximum flow capacity (in 100,000 gallons/day) in that section
of the pipeline. For example, at most 300,000 gallons/day can be sent from node 2 to node 4. The city now
sends 100,000 gallons/day along each of the paths 1–2–4–6 and 1–3–5–6. What is the maximum capacity of
the network for shipping water from node 1 to node 6?
The shortest-path problem is a particular network model that has received a great deal of attention for both
practical and theoretical reasons. The essence of the problem can be stated as follows: Given a network with
distance ci j (or travel time, or cost, etc.) associated with each arc, find a path through the network from a
particular origin (source) to a particular destination (sink) that has the shortest total distance. The simplicity
of the statement of the problem is somewhat misleading, because a number of important applications can be
formulated as shortest- (or longest-) path problems where this formulation is not obvious at the outset. These
include problems of equipment replacement, capital investment, project scheduling, and inventory planning.
The theoretical interest in the problem is due to the fact that it has a special structure, in addition to being
a network, that results in very efficient solution procedures. (In Chapter 11 on dynamic programming, we
illustrate some of these other procedures.) Further, the shortest-path problem often occurs as a subproblem in
more complex situations, such as the subproblems in applying decomposition to traffic-assignment problems
or the group-theory problems that arise in integer programming.
In general, the formulation of the shortest-path problem is as follows:
xi j ≥ 0 for all arcs i– j in the network.
We can interpret the shortest-path problem as a network-flow problem very easily. We simply want to send
one unit of flow from the source to the sink at minimum cost. At the source, there is a net supply of one unit;
at the sink, there is a net demand of one unit; and at all other nodes there is no net inflow or outflow.
As an elementary illustration, consider the example given in Fig. 8.4, where we wish to find the shortest
distance from node 1 to node 8. The numbers next to the arcs are the distance over, or cost of using, that arc.
For the network specified in Fig. 8.4, the linear-programming tableau is given in Tableau 1.
Node–Arc Incidence Tableau for a Shortest-PathProblem
Relax12 x13 x24 x25 x32 x34 x37 x45 x46 x47 x52 x56 x58 x65 x67 x68 x76 x78 tions
Distance 5.1 3.4 0.5 2.0 1.0 1.5 5.0 2.0 3.0 4.2 1.0 3.0 6.0 1.5 0.5 2.2 2.0 2.4
The Critical-Path Method (CPM) is a project-management technique that is used widely in both government
and industry to analyze, plan, and schedule the various tasks of complex projects. CPM is helpful in identifying
which tasks are critical for the execution of the overall project, and in scheduling all the tasks in accordance
with their prescribed precedence relationships so that the total project completion date is minimized, or a
Typically, CPM can be applied successfully in large construction projects, like building an airport or a
highway; in large maintenance projects, such as those encountered in nuclear plants or oil refineries; and
in complex research-and-development efforts, such as the development, testing, and introduction of a new
product. All these projects consist of a well specified collection of tasks that should be executed in a certain
prescribed sequence. CPM provides a methodology to define the interrelationships among the tasks, and to
determine the most effective way of scheduling their completion.
Although the mathematical formulation of the scheduling problem presents a network structure, this is
not obvious from the outset. Let us explore this issue by discussing a simple example.
Suppose we consider the scheduling of tasks involved in building a house on a foundation that already
exists. We would like to determine in what sequence the tasks should be performed in order to minimize
Figure 8.4 Network for a shortest-path problem.
the total time required to execute the project. All we really know is how long it takes to carry out each task
and which tasks must be completed before commencing any particular task. In fact, it will be clear that we
need only know the tasks that immediately precede a particular task, since completion of all earlier tasks will
be implied by this information. The tasks that need to be performed in building this particular house, their
immediate predecessors, and an estimate of their duration are give in Table E8.4.
It is clear that there is no need to indicate that the siding must be put up before the outside painting can
begin, since putting up the siding precedes installing the windows, which precedes the outside painting. It
is always convenient to identify a ‘‘start’’ task, that is, an immediate predecessor to all tasks, which in itself
does not have predecessors; and a ‘‘finish’’ task, which has, as immediate predecessors, all tasks that in
Table E8.4 Tasks and Precedence Relationships
Although it is by no means required in order to perform the necessary computations associated with the
scheduling problem, often it is useful to represent the interrelations among the tasks of a given project by
means of a network diagram. In this diagram, nodes represent the corresponding tasks of the project, and
arcs represent the precedence relationships among tasks. The network diagram for our example is shown in
As we can see, there are nine nodes in the network, each representing a given task. For this reason, this
network representation is called a task- (or activity-) oriented network.
If we assume that our objective is to minimize the elapsed time of the project, we can formulate a linearprogramming problem. First, we define the decision variables ti for i = 1, 2, . . . , 6, as the earliest starting
times for each of the tasks. Table 8.4. gives the earliest starting times where the same earliest starting time
is assigned to tasks with the same immediate predecessors. For instance, tasks 4 and 5 have task 3 as their
immediate predecessor. Obviously, they cannot start until task 3 is finished; therefore, they should have the
same earliest starting time. Letting t6 be the earliest completion time of the entire project, out objective is to
subject to the precedence constraints among tasks. Consider a particular task, say 6, installing the electricity.
The earliest starting time of task 6 is t4 , and its immediate predecessors are tasks 2 and 4. The earliest starting
times of tasks 2 and 4 are t2 and t3 , respectively, while their durations are 1 and 2.5 weeks, respectively.
Hence, the earliest starting time of task 6 must satisfy:
In general, if t j is the earliest starting time of a task, ti is the earliest starting time of an immediate predecessor,
and di j is the duration of the immediate predecessor, then we have:
For our example, these precedence relationships define the linear program given in Tableau E8.2.
We do not yet have a network flow problem; the constraints of (5) do not satisfy our restriction that each
column have only a plus-one and a minus-one coefficient in the constraints. However, this is true for the
rows, so let us look at the dual of (5). Recognizing that the variables of (5) have not been explicitly restricted
to the nonnegative, we will have equalityconstraints in the dual. If we let xi j be the dual variable associated
with the constraint of (5) that has a minus one as a coefficient for ti and a plus one as a coefficient of t j , the
Now we note that each column of (6) has only one plus-one coefficient and one minus-one coefficient, and
hence the tableau describes a network. If we multiply each equation through by minus one, we will have the
usual sign convention with respect to arcs emanating from or incident to a node. Further, since the righthand
side has only a plus one and a minus one, we have flow equations for sending one unit of flow from node 1 to
node 6. The network corresponding to these flow equations is given in Fig. 8.6; this network clearly maintains
the precedence relationships from Table 8.4. Observe that we have a longest-path problem, since we wish to
maximize z (in order to minimize the project completion date T ). Note that, in this network, the arcs represent
the tasks, while the nodes describe the precedence relationships among tasks. This is the opposite of the network representation given in Fig. 8.5. As we can see, the network of Fig. 8.6. contains 6 nodes, which is the
number of sequencing constraints prescribed in the task definition of Table 8.4. since only six earliest starting
times were required to characterize these constraints. Because the network representation of Fig. 8.6 emphasizes the event associated with the starting of each task, it is commonly referred to as an event-oriented network.
There are several other issues associated with critical-path scheduling that also give rise to network-model
formulations. In particular, we can consider allocating funds among the various tasks in order to reduce the
total time required to complete the project. The analysis of the cost-vs.-time tradeoff for such a change is an
important network problem. Broader issues of resource allocation and requirements smoothing can also be
interpreted as network models, under appropriate conditions.
Network-flow models are more prevalent than one might expect, since many models not cast naturally as
networks can be transformed into a network format. Let us illustrate this possibility by recalling the strategicplanning model for aluminum production developed in Chapter 6. In that model,bauxite ore is converted to
aluminum products in several smelters, to be shipped to a number of customers. Production and shipment
are governed by the following constraints:
(s = 1, 2, . . . , 11; p = 1, 2, . . . , 8),
(a = 1, 2, . . . , 40; p = 1, 2, . . . , 8),
Variable Q sap is the amount of product p to be produced at smelter s and shipped to customer a. The constraints
(7) and (8) merely define the amount Ms produced at smelter s and the amount E sp of product p (ingots) to be
‘‘cast’’ at smelter s. Equations (9) state that the total production from all smelters must satisfy the demand
dap for product p of each customer a. The upper bounds of Ms and E sp reflect smelting and casting capacity,
whereas the lower bounds indicate minimum economically attractive production levels.
As presented, the model is not in a network format, since it does not satisfy the property that every variable
appear in exactly two constraints, once with a +1 coefficient and once with a −1 coefficient. It can be stated
as a network, however, by making a number of changes. Suppose, first, that we rearrange all the constraints
and substitute, for the term in parenthesis, E sp defined by (8). Let us also multiply the constraints of (9) by
(s = 1, 2, . . . , 11; p = 1, 2, . . . , 8),
= −dap (a = 1, 2, . . . , 40; p = 1, 2, . . . , 8),
Each variable E sp appears once in the equations of (10) with a +1 coefficient and once in the equations of
(11) with a −1 coefficient; each variable Q sap appears once in the equations of (11) with a +1 coefficient and
once in the equations of (12) with a −1 coefficient. Consequently, except for the variables Ms , the problem
is in the form of a network. Now, suppose that we add all the equations to form one additional redundant
constraint. As we have just noted, the terms involving the variables Q sap and E sp will all vanish, so that the
resulting equation, when multiplied by minus one, is:
Each variable Ms now appears once in the equations of (10) with a +1 coefficient and once in the equations of
(13) with a −1 coefficient, so appending this constraint to the previous formulation gives the desired network
The network representation is shown Fig. 8.7. As usual, each equation in the model defines a node in the
network. The topmost node corresponds to the redundant equation just added to the model; it just collects
production from the smelters. The other nodes correspond to the smelters, the casting facilities forP
the smelters, and the customer–product demand combinations. The overall supply to the system, a p dap ,
as indicated at the topmost node, is the total production at the smelters, and must equal the demand for all
In practice, manipulations like these just performed for re-expressing problems can be used frequently
to exhibit network structure that might be hidden in a model formulation. They may not always lead to pure
network-flow problems, as in this example, but instead might show that the problem has a substantial network
component. The network features might then be useful computationally in conjunction with large-scale
systems techniques that exploit the network structure.
Figure 8.7 Network formulation of the aluminum production-planning model.
Finally, observe that the network in Fig. 8.7 contains only a small percentage of the arcs that could
potentially connect the nodes since, for example, the smelters do not connect directly with customer demands.
This low density of arcs is common in practice, and aids in both the information storage and the computations
Ultimately in this chapter we want to develop an efficient algorithm for the general minimum-cost flow problem
by specializing the rules of the simplex method to take advantage of the problem structure. However, before
taking a somewhat formal approach to the general problem, we will indicate the basic ideas by developing
a similar algorithm for the transportation problem. The properties of this algorithm for the transportation
problem will then carry over to the more general minimum-cost flow problem in a straightforward manner.
Historically, the transportation problem was one of the first special structures of linear programming for
which an efficient special-purpose algorithm was developed. In fact, special-purpose algorithms have been
developed for all of the network structures presented in Section 8.1, but they will not be developed here.
As we have indicated before, many computational algorithms are characterized by three stages:
2. checking an optimality criterion that indicates whether or not a termination condition has been met (i.e.,
in the simplex algorithm, whether the problem is infeasible, the objective is unbounded over the feasible
region, or an optimal solution has been found);
3. developing a procedure to improve the current solution if a termination condition has not been met.
After an initial solution is found, the algorithm repetitively applies steps 2 and 3 so that, in most cases, after
a finite number of steps, a termination condition arises. The effectiveness of an algorithm depends upon its
efficiency in attaining the termination condition.
Since the transportation problem is a linear program, each of the above steps can be performed by the
simplex method. Initial solutions can be found very easily in this case, however, so phase I of the simplex
method need not be performed. Also, when applying the simplex method in this setting, the last two steps
The transportation problem is a special network problem, and the steps of any algorithm for its solution
can be interpreted in terms of network concepts. However, it also is convenient to consider the transportation problem in purely algebraic terms. In this case, the equations are summarized very nicely by a tabular
representation like that in Tableau E8.4.
Each row in the tableau corresponds to a source node and each column to a destination node. The numbers
in the final column are the supplies available at the source nodes and those in the bottom row are the demands
required at the destination nodes. The entries in cell i– j in the tableau denote the flow allocation xi j from
source i to destination j and the corresponding cost per unit of flow is ci j . The sum of xi j across row i must
equal ai in any feasible solution, and the sum of xi j down column j must equal b j .
In order to apply the simplex method to the transportation problem, we must first determine a basic feasible
solution. Since there are (m + n) equations in the constraint set of the transportation problem, one might
conclude that, in a nondegenerate situation, a basic solution will have (m + n) strictly positive variables. We
one of the equations in the constraint set is redundant. In fact, any one of these equations can be eliminated
without changing the conditions represented by the original constraints. For instance, in the transportation
example in Section 8.2, the last equation can be formed by summing the first three equations and subtracting
the next three equations. Thus, the constraint set is composed of (m + n − 1) independent equations, and a
corresponding nondegenerate basic solution will have exactly (m + n − 1) basic variables.
There are several procedures used to generate an initial basic feasible solution, but we will consider only
a few of these. The simplest procedure imaginable would be one that ignores the costs altogether and rapidly
produces a basic feasible solution. In Fig. 8.8, we have illustrated such a procedure for the transportation
problem introduced in Section 8.2. We simply send as much as possible from origin 1 to destination 1, i.e.,
the minimum of the supply and demand, which is 35. Since the supply at origin 1 is then exhausted but the
demand at destination 1 is not, we next fulfill the remaining demand at destination 1 from that available at
origin 2. At this point destination 1 is completely supplied, so we send as much as possible (20 units) of the
Table E8.5 Finding an Initial Basis by the Northwest Corner Method
1. Dallas 2. Atlanta 3. San Fran. 4. Phila. Supply
remaining supply of 40 at origin 2 to destination 2, exhausting the demand there. Origin 2 still has a supply
of 20 and we send as much of this as possible to destination 3, exhausting the supply at origin 2 but leaving a
demand of 10 at destination 3. This demand is supplied from origin 3, leaving a supply there of 30, exactly
corresponding to the demand of 30 needed at destination 4. The available supply equals the required demand
for this final allocation because we have assumed that the total supply equals the total demand, that is,
This procedure is called the northwest-corner rule since, when interpreted in terms of the transportation
array, it starts with the upper leftmost corner (the northwest corner) and assigns the maximum possible flow
allocation to that cell. Then it moves to the right, if there is any remaining supply in the first row, or to the
next lower cell, if there is any remaining demand in the first column, and assigns the maximum possible flow
allocation to that cell. The procedure repeats itself until one reaches the lowest right corner, at which point
we have exhausted all the supply and satisfied all the demand.
Table E8.5 summarizes the steps of the northwest-corner rule, in terms of the transportation tableau, when
applied to the transportation example introduced in Section 8.2.
The availabilities and requirements at the margin of the table are updated after each allocation assignment.
Although the northwest-corner rule is easy to implement, since it does not take into consideration the cost of
using a particular arc, it will not, in general, lead to a cost-effective initial solution.
An alternative procedure, which is cognizant of the costs and straightforward to implement, is the minimum
matrix method. Using this method, we allocate as much as possible to the available arc with the lowest cost.
Figure 8.9 illustrates the procedure for the example that we have been considering. The least-cost arc joins
origin 3 and destination 4, at a cost of $5/unit, so we allocate the maximum possible, 30 units, to this arc,
Figure 8.8 Finding an initial basis by the northwest-corner method.
Figure 8.9 Finding an initial basis by the minimum-matrix method.
completely supplying destination 4. Ignoring the arcs entering destination 4, the least-cost remaining arc
joins origin 1 and destination 2, at a cost of $6/unit, so we allocate the maximum possible, 20 units, to this arc,
completely supplying destination 2. Then, ignoring the arcs entering either destination 2 or 4, the least-cost
remaining arc joins origin 1 and destination 1, at a cost of $8/unit, so we allocate the maximum possible,
15 units, to this arc, exhausting the supply at origin 1. Note that this arc is the least-cost remaining arc
but not the next-lowest-cost unused arc in the entire cost array. Then, ignoring the arcs leaving origin 1 or
entering destinations 2 or 4, the procedure continues. It should be pointed out that the last two arcs used by
this procedure are relatively expensive, costing $13/unit and $16/unit. It is often the case that the minimum
matrix method produces a basis that simultaneously employs some of the least expensive arcs and some of
There are many other methods that have been used to find an initial basis for starting the transportation
method. An obvious variation of the minimum matrix method is the minimum row method, which allocates
as much as possible to the available arc with least cost in each row until the supply at each successive origin
is exhausted. There is clearly the analogous minimum column method.
It should be pointed out that any comparison among procedures for finding an initial basis should be
made only by comparing solution times, including both finding the initial basis and determining an optimal
solution. For example, the northwest-corner method clearly requires fewer operations to determine an initial
basis than does the minimum matrix rule, but the latter generally requires fewer iterations of the simplex
The two procedures for finding an initial basic feasible solution resulted in different bases; however, both
have a number of similarities. Each basis consists of exactly (m + n − 1) arcs, one less than the number of
nodes in the network. Further, each basis is a subnetwork that satisfies the following two properties:
1. Every node in the network is connected to every other node by a sequence of arcs from the subnetwork,
where the direction of the arcs is ignored.
2. The subnetwork contains no loops, where a loop is a sequence of arcs connecting a node to itself, where
again the direction of the arcs is ignored.
A subnetwork that satisfies these two properties is called a spanning tree.
It is the fact that a basis corresponds to a spanning tree that makes the solution of these problems by the
simplex method very efficient. Suppose you were told that a feasible basis consists of arcs 1–1, 2–1, 2–2, 2–4,
3–2, and 3–3. Then the allocations to each arc can be determined in a straightforward way without algebraic
manipulations of tableaus. Start by selecting any end (a node with only 1 arc connecting it to the rest of the
network) in the subnetwork. The allocation to the arc joining that end must be the supply or demand available
at that end. For example, source 1 is an end node. The allocation on arc 1–1 must then be 35, decreasing
Figure 8.10 Determining the values of the basic variables.
the unfulfilled demand at destination 1 from 45 to 10 units. The end node and its connecting arc are then
dropped from the subnetwork and the procedure is repeated. In Fig. 8.10, we use these end-node evaluations
to determine the values of the basic variables for our example.
This example also illustrates that the solution of a transportation problem by the simplex method results
in integer values for the variables. Since any basis corresponds to a spanning tree, as long as the supplies and
demands are integers the amount sent across any arc must be an integer. This is true because, at each stage
of evaluating the variables of a basis, as long as the remaining supplies and demands are integer the amount
sent to any end must also be an integer. Therefore, if the initial supplies and demands are integers, any basic
feasible solution will be an integer solution.
Because it is so common to find the transportation problem written with +1 coefficients for the variables
xi j (i.e., with the demand equations of Section 8.2 multiplied by minus one), we will give the optimality
conditions for this form. They can be easily stated in terms of the reduced costs of the simplex method. If
xi j for i = 1, 2, . . . , m and j = 1, 2, . . . , n is a feasible solution to the transportation problem:
then it is optimal if there exist shadow prices (or simplex multipliers) u i associated with the origins and v j
associated with the destinations, satisfying:
Figure 8.11 Determining the simplex multipliers.
The simplex method selects multipliers so that condition (15) holds for all basic variables, even if some basic
These conditions not only allow us to test whether the optimalsolution has been found or not, but provide
us with the necessary foundation to reinterpret the characteristics of the simplex algorithm in order to solve
the transportation problem efficiently. The algorithm will proceed as follows: after a basic feasible solution
has been found (possibly by applying the northwest-corner method or the minimum matrix method), we
choose simplex multipliers u i and v j (i = 1, 2, . . . , m; j = 1, 2, . . . , n) that satisfy:
for basic variables. With these values for the simplex multipliers, we compute the corresponding values of
for all nonbasic variables. If every ci j is nonnegative, then the optimal solution has been found; otherwise,
we attempt to improve the current solution by increasing as much as possible the variable that corresponds
to the most negative (since this is a minimization problem) reduced cost.
First, let us indicate the mechanics of determining from (16) the simplex multipliers associated with a
particular basis. Conditions (16) consist of (m + n − 1) equations in (m + n) unknowns. However, any
one of the simplex multipliers can be given an arbitrary value since, as we have seen, any one of the (m + n)
equations of the transportation problem can be considered redundant. Since there are (m + n −1) equations in
(16), once one of the simplex multipliers has been specified, the remaining values of u i and v j are determined
uniquely. For example, Fig. 8.11 gives the initial basic feasible solution produced by the minimum matrix
method. The simplex multipliers associated with this basis are easily determined by first arbitrarily setting
u 1 = 0. Given u 1 = 0, v1 = 8 and v2 = 6 are immediate from (16); then u 2 = 1 is immediate from v1 , and
so on. It should be emphasized that the set of multipliers is not unique, since any multiplier could have been
chosen and set to any finite value, positive or negative, to initiate the determination.
Once we have determined the simplex multipliers, we can then easily find the reduced costs for all
nonbasic variables by applying (17). These reduced costs are given in Tableau 5. The —’s indicate the
basic variable, which therefore has areduced cost of zero. This symbol is used to distinguish between basic
variables and nonbasic variables at zero level.
Since, in Tableau 5, c13 = −2 and c32 = −1, the basis constructed by the minimum matrixmethod does
not yield an optimal solution. We, therefore, need to find an improved solution.
As we indicated, every basic variable has associated with it a value of ci j = 0. If the current basic solution is
not optimal, then there exists at least one nonbasic variable xi j at value zero with ci j negative. Let us select,
among all those variables, the one with the most negative ci j (ties are broken by choosing arbitrarily from
cst = Min ci j = ci j − u i − v j |ci j < 0 .
Thus, we would like to increase the corresponding value of xst as much as possible, and adjust the values of
the other basic variables to compensate for that increase. In our illustration, cst = c13 = −2, so we want
to introduce x13 into the basis. If we consider Fig. 8.5 we see that adding the arc 1–3 to the spanning tree
corresponding to the current basis creates a unique loop O1 –D3 –O2 –D1 –O1 where O and D refer to origin
It is easy to see that if we make xst = θ , maintaining all other nonbasic variables equal to zero, the flows
on this loop must be adjusted by plus or minus θ , to maintain the feasibility of the solution. The limit to which
θ can be increased corresponds to the smallest value of a flow on this loop from which θ must be subtracted.
In this example, θ may be increased to 15, corresponding to x11 being reduced to zero and therefore dropping
out of the basis. The basis has x13 replacing x11 , and the corresponding spanning tree has arc 1–3 replacing
arc 1–1 in Fig. 8.12. Given the new basis, the procedure of determining the shadow prices and then the
reduced costs, to check the optimality conditions of the simplex method, can be repeated.
It should be pointed out that the current solution usually is written out not in network form but in tableau
form, for case of computation. The current solution given in Fig. 8.12 would then be written as in Tableau 6.
Note that the row and column totals are correct for any value of θ satisfying 0 ≤ θ ≤ 15. The tableau
form for the current basic solution is convenient to use for computations, but the justification of its use is
most easily seen by considering the corresponding spanning tree. In what follows we will use the tableau
form to illustrate the computations. After increasing θ to 15, the resulting basic solution is given in Tableau
7 (ignoring θ ) and the new multipliers and reduced costs in Tableau 8.
Since the only negative reduced cost corresponds to c̄32 = −3, x32 is next introduced into the basis.
Adding the arc 3–2 to the spanning tree corresponds to increasing the allocation to cell 3–2 in the tableau and
creates a unique loop O3 –D2 –O1 –D3 –O3 . The flow θ on this arc may be increased until θ = 10, corresponding
to x33 dropping from the basis. The resulting basic solution is Tableau 9 and the new multipliers and reduced
Since all of the reduced costs are now nonnegative, we have the optimal solution.
In the previous section, we described how the simplex method has been specialized in order to solve transportation problems efficiently. There are three steps to the approach:
1. finding an initial basic feasible solution;
2. checking the optimality conditions; and
3. constructing an improved basic feasible solution, if necessary.
The problem we solved was quite structured in the sense that total supply equaled total demand, shipping
between all origins and destinations was permitted, degeneracy did not occur, and so forth. In this section,
we address some of the important variations of the approach given in the previous section that will handle
We have analyzed the situation where the total availability is equal to the total requirement. In practice, this is
usually not the case, since often either demand exceeds supply or supply exceeds demand. Let us see how to
transform a problem in which this assumption does not hold to the previously analyzed problem with equality
of availability and requirement. Two situations will exhaust all the possibilities:
First, assume that the total availability exceeds the total requirement; that is,
In this case, we create an artificial destination j = n + 1, with corresponding ‘‘requirement’’ bn+1 = d,
and make the corresponding cost coefficients to this destination equal to zero, that is, ci,n+1 = 0 for i =
1, 2, . . . , m. The variable xi,n+1 in the optimal solution will show how the excess availability is distributed
Second, assume that the total requirement exceeds the total availability, that is,
In this case, we create an artificial origin i = m + 1, with corresponding ‘‘availability’’ am+1 = d, and assign
zero cost coefficients to this destination, that is, cm+1, j = 0 for j = 1, 2, . . . , n. The optimal value for the
variable xm+1, j will show how the unsatisfied requirements are allocated among the destinations.
In each of the two situations, we have constructed an equivalent transportation problem such that the total
‘‘availability’’ is equal to the total ‘‘requirement.’’
If it is impossible to ship any goods from source i to destination j, we assign a very high cost to the
corresponding variable xi j , that is, ci j = M, where M is a very large number, and use the procedure
previously discussed. If these prohibited routes cannot be eliminated from the optimal solution then the
Alternatively, we can use the two-phase simplex method. We start with any initial basic feasible solution,
which may use prohibited routes. The first phase will ignore the given objective function and minimize the
sum of the flow along the prohibited routes. If the flow on the prohibited routes cannot be driven to zero, then
no feasible solution exists without permitting flow on at least one of the prohibited routes. If, on the other
hand, flow on the prohibited routes can be made zero, then an initial basic feasible solution without positive
flow on prohibited routes has been constructed. It is necessary then simply to prohibit flow on these routes
in the subsequent iterations of the algorithm.
Degeneracy can occur on two different occasions during the computational process described in the previous
section. First, during the computation of the initial solution of the transportation problem, we can simultaneously eliminate a row and a column at an intermediate step. This situation gives rise to a basic solution with
less than (m + n − 1) strictly positive variables. To rectify this, one simply assigns a zero value to a cell in
either the row or column to be simultaneously eliminated, and treats that variable as a basic variable in the
As an example, let us apply the northwest-corner rule to the case in Tableau 11.
In this instance, when making x12 = 5, we simultaneously satisfy the first row availability and the second
column requirement. We thus make x13 = 0, and treat it as a basicvariable in the rest of the computation.
A second situation where degeneracy arises is while improving a current basic solution. A tie might be
found when computing the new value to be given to the entering basic variable, xst = θ . In this case, more
than one of the old basic variables will take the value zero simultaneously, creating a new basic solution
with less than (m + n − 1) strictly positive values. Once again, the problem is overcome by choosing the
variable to leave the basis arbitrarily from among the basic variables reaching zero at xst = θ, and treating
the remaining variables reaching zero at xst = θ as basic variables at zero level.
Finally, we should point out that there have been a tremendous number of procedures suggested for finding
an initial basic feasible solution to the transportation problem. In the previous section, we mentioned four
methods: northwest corner, minimum matrix, minimum column, and minimum row.
The first of these ignores the costs altogether, while the remaining methods allocate costs in such a way
that the last fewassignments of flows often results in very high costs being incurred. The high costs are due
to the lack of choice as to how the final flows are to be assigned to routes, once the initial flows have been
established. The initial flows are not chosen with sufficient foresight as to how they might impair later flow
The Vogel approximation method was developed to overcome this difficulty and has proved to be so effective that it is sometimes used to obtain an approximation to the optimal solution of the problem. The method,
instead of sequentially using the least-cost remaining arc, bases its selection on the difference between the
two lowest-cost arcs leaving an origin or entering a destination. This difference indicates where departure
from the lowest-cost allocations will bring the highest increase in cost. Therefore, one assigns the maximum
possible amount to that arc that has the lowest cost in that row or column having the greatest cost difference.
If this assignment exhausts the demand at that destination, the corresponding column is eliminated from
further consideration; similarly, if the assignment exhausts the supply at that origin, the corresponding row
is eliminated. In either case, the origin and destination cost differences are recomputed, and the procedure
The Vogel approximation method is applied to our illustrative example in Tableau 12, and the resulting basic feasible solution is given in Fig. 8.13. It is interesting to note that the approximation finds the
optimal solution in this particular case, as can be seen by comparing the initial basis from the Vogel approximation in Fig. 8.13 with the optimal basis in Tableau 7. This, of course, does not mean that the Vogel
approximation is the best procedure for determining the initial basic feasible solution. Any such comparison among computational procedures must compare total time required, from preprocessing to final optimal
Figure 8.13 Initial basis for Vogel approximation method.
The application of the simplex method to the transportation problem presented in the previous section takes
advantage of the network structure of the problem and illustrates a number of properties that extend to the
general minimum-cost flow problem. All of the models formulated in Section 8.2 are examples of the general
a number, including the transportation problem, exhibit further special structure of their own. Historically,
many different algorithms have been developed for each of these models; but, rather than consider each model
separately, we will develop the essential step underlying the efficiency of all of the simplex-based algorithms
We already have seen that, for the transportation problem, a basis corresponds to a spanning tree, and
that introducing a new variable into the basis adds an arc to the spanning tree that forms a unique loop. The
variable to be dropped from the basis is then determined by finding which variable in the loop drops to zero
first when flow is increased on the new arc. It is this property, that bases correspond to spanning trees, that
extends to the general minimum-cost flow problem and makes solution by the simplex method very efficient.
In what follows, network interpretations of the steps of the simplex method will be emphasized; therefore, it is convenient todefine some of the network concepts that will be used. Though these concepts are
quite intuitive, the reader should be cautioned that the terminology of network flow models has not been
standardized, and that definitions vary from one author to another.
Formally, a network is defined to be any finite collection of points, called nodes, together with a collection
of directed arcs that connect particular pairs of these nodes. By convention, we do not allow an arc to connect
a node to itself, but we do allow more than one arc to connect the same two nodes. We will be concerned
only with connected networks in the sense that every node can be reached from every other node by following
a sequence of arcs, where the direction of the arcs is ignored. In linear programming, if a network is
disconnected, then the problem it describes can be treated as separate problems, one for each connected
A loop is a sequence of arcs, where the direction of the arcs is ignored, connecting a particular node to
itself. In Fig. 8.1, the node sequences 3–4–5–3 and 1–2–3–1 are both examples of loops.
A spanning tree is a connected subset of a network including all nodes and containing no loops. Figure
8.7 shows two examples of spanning trees for the minimum-cost flow problem of Fig. 8.1.
It is the concept of a spanning tree, which proved most useful in solving the transportation problem in the
previous section, that will be the foundation of the algorithm for the general minimum-cost flow problem.
Finally, an end is a node of a network with exactly one arc incident to it. In the first example of Fig. 8.7,
nodes 1,2, and 4 are ends, and in the second examples, nodes 1, 2, and 5 are ends. It is easy to see that every
tree must have at least two ends. If you start with any node i in a tree and follow any arc away from it, you
eventually come to an end, since the tree contains no loops. If node i is an end, then you have two ends. If
node i is not an end, there is another arc from node i that will lead to a second end, since again there are no
In the transportation problem we saw that there are (m + n − 1) basic variables, since any one of the
equations is redundant under the assumption that the sum of the supplies equals the sum of the demands. This
implies that the number of arcs in any spanning tree corresponding to a basis in the transportation problem is
always one less than the number of nodes in the network. Note that the number of arcs is one less than the
number of nodes in each of the trees shown in Fig. 8.14, since they each contain 5 nodes and 4 arcs. In fact,
this characterization of spanning trees holds for the general minimum-cost flow problem.
A subnetwork of anetwork with n nodes is a spanning tree if and
only if it is connected and contains (n − 1) arcs.
We can briefly sketch an inductive proof to show the spanning-tree characterization. The result is clearly
true for the two node networks containing one arc. First, we show that is a subnetwork of an n-node network
is a spanning tree, it contains (n − 1) arcs. Remove any end and incident arc from the n-node network. The
reduced network with (n − 1) nodes is still a tree, and by our inductive assumption it must have (n − 2) arcs.
Therefore, the original network with n nodes must have had (n − 1) arcs. Next, we show that if an n-node
connected subnetwork has (n − 1) arcs and no loops, it is a spanning tree. Again, remove any end and its
incident arc from the n-node network. The reduced network is connected, has (n − 1) nodes, (n − 2) arcs,
and no loops; and by our inductive assumption, it must be a spanning tree. Therefore, the original network
with n nodes and (n − 1) arcs must be a spanning tree.
The importance of the spanning-tree characterization stems from the relationship between a spanning
tree and a basis in the simplex method. We have already seen that a basis for the transportation problem
corresponds to a spanning tree, and it is this property that carries over to the general network-flow model.
In a general minimum-cost flow model, a spanning
tree for the network corresponds to a basis for the simplex method.
This is an important property since, together with the spanning-tree characterization, it implies that the
number of basic variables is always one less than the number of nodes in a general network-flow problem. Now
let us intuitively argue that the spanning-tree property holds, first by showing that the variables corresponding
to a spanning tree constitute a basis, and second by showing that a set of basic variables constitutes a spanning
First, assume that we have a network with n nodes, which is a spanning tree. In order to show that the
variables corresponding to the arcs in the tree constitute a basis, it is sufficient to show that the (n − 1) tree
variables are uniquely determined. In the simplex method, this corresponds to setting the nonbasic variables
to specific values and uniquely determining the basic variables. First, set the flows on all arcs not in the tree
to either their upper or lower bounds, and update the righthand-side values by their flows. Then choose any
node corresponding to an end in the subnetwork, say node k. (There must be at least two ends in the spanning
tree since it contains no loops.) Node k corresponds to a row in the linear-programming tableau for the tree
with exactly one nonzero coefficient in it. To illustrate this the tree variables of the first example in Fig. 8.14
Since there is only one nonzero coefficient in row k, the corresponding arc incident to node k must have
flow across it equal to the righthand-side value for that row. In the example above, x13 = 20. Now, drop node
k from further consideration and bring the determined variable over to the righthand side, so that the righthand
side of the third constraint becomes +20. Now we have an (n − 1)-node subnetwork with (n − 2) arcs and
no loops. Hence, we have a tree for the reduced network, and the process may be repeated. At each iteration
exactly one flow variable is determined. On the last iteration, there are two equations corresponding to two
nodes, and one arc joining them. Since we have assumed that the total net flow into or out of the network is
zero, the last tree variable will satisfy the last two equations. Hence we have shown that a spanning tree in a
network corresponds to a basis in the simplex method. Further, since we have already shown that a tree for a
connected network with n nodes contains (n − 1) arcs, we have shown that the number of basic variables for
a connected network-flow problem is (n − 1).
Now assume that we have a network with n nodes and that we know the (n − 1) basic variables. To
show that these variables correspond to a tree, we need only show that the subnetwork corresponding to the
basic variables does not contain any loops. We establish this property by assuming that there is a loop and
showing that this leads to a contradiction. In Fig. 8.15, we have a four-arc network containing a loop and its
If there exists a loop, then choose weights for the column corresponding to arcs in the loop such that the
weight is +1 for a forward arc in the loop and −1 for a backward arc in the loop. If we then add the columns
corresponding to the loop weighted in this manner, we produce a column containing all zeros. In Fig. 8.15,
the loop is 2–5–3–2, and adding the columns for the variables x25 , x53 , and x32 with weights 1, −1, and
−1, respectively, produces a zero column. This implies that the columns corresponding to the loop are not
independent. Since a basis consists of a set of (n − 1) independent columns, any set of variables containing
a loop cannot be a basis. Therefore, (n − 1) variables corresponding to a basis in the simplex method must
If a basis in the simplex method corresponds to a tree, what, then, is the interpretation of introducing a
new variable into the basis? Introducing a new variable into the basis adds an arc to the tree, and since every
node of the tree is connected to every other node by a sequence of arcs, the addition will form a loop in the
subnetwork corresponding to the tree. In Fig. 8.16, arc 4–5 is being introduced into the tree, forming the loop
4–5–3–4. It is easy to argue that adding an arc to a tree creates a unique loop in the augmented network. At
least one loop must be created, since adding the arc connects two nodes that were already connected. Further,
no more than one loop is created, since, if adding the one arc created more than one loop, the entering arc
would have to be common to two distinct loops, which, upon removal of their common arcs, would yield a
single loop that was part of the original network.
Figure 8.16 Introducing a new arc in a tree.
To complete a basis change in the simplex method, one of the variables currently in the basis must be
dropped. It is clear that the variable to be dropped must correspond to one of the arcs in the loop, since dropping
any arc not in the loop would leave the loop in the network and hence would not restore the spanning-tree
property. We must then be able to determine the arcs that form the loop.
This is accomplished easily by starting with the subnetwork including the loop and eliminating all ends
in this network. If the reduced network has no ends, it must be the loop. Otherwise, repeat the process of
eliminating all the ends in the reduced network, and continue. Since there is a unique loop created by adding
an arc to a spanning tree, dropping any arc in that loop will create a new spanning tree, since each node will be
connected to every other node by a sequence of arcs, and the resulting network will contain no loops. Figure
8.16 illustrates this process by dropping arc 3–5. Clearly, any arc in the loop could have been dropped, to
In the transportation problem, the unique loop was determined easily, although we did not explicitly show
how this could be guaranteed. Once the loop is determined, we increased the flow on the incoming arc and
adjusted the flows on the other arcs in the loop, until the flow in one of the arcs in the loop was reduced to zero.
The variable corresponding to the arc whose flow was reduced to zero was then dropped out of the basis. This
is essentially the same procedure that will be employed by the general minimum-cost flow problem, except
that the special rules of the simplex method with upper and lower bounds on the variables will be employed.
In the next section an example is carried out that applies the simplex method to the general minimum-cost
Finally, we should comment on the integrality property of the general minimum-cost flow problem. We
saw that, for the transportation problem, since the basis corresponds to a spanning tree, as long as the supplies
and demands are integers, the flows on the arcs for a basic solution are integers. This is also true for the
general minimum-cost flow problem, so long as the net flows at any node are integers and the upper and lower
Integrality Property. In the general minimum-cost flow problem, assuming that the upper and lower
bounds on the variables are integers and the righthand-side values for the flow-balance equations are
integers, the values of the basic variables are also integers when the nonbasic variables are set to their
In the simplex method with upper and lower bounds on the variables, the nonbasic variables are at either
their upper orlower bound. If these bounds are integers, then the net flows at all nodes, when the flows
on the nonbasic arcs are included, are also integers. Hence, the flows on the arcs corresponding to the
basic variables also will be integers, since these flows are determined by first considering all ends in the
corresponding spanning tree and assigning a flow to the incident arc equal to the net flow at the node. These
assigned flows must clearly be integers. The ends and the arcs incident to them are then eliminated, and the
process is repeated, yielding an integer assignment of flows to the arcs in the reduced tree at each stage.
The integrality property of the general minimum-cost flow problem was established easily by using the
fact that a basis corresponds to a spanning tree. Essentially, all ends could be immediately evaluated, then
eliminated, and the procedure repeated. We were able to solve a system of equations by recognizing that at
least one variable in the system could be evaluated by inspection at each stage, since at each stage at least
one equation would have only one basic variable in it. A system of equations with this property is called
In Tableau E8.14 we have rewritten the system of equations corresponding to the tree variables given
in Tableau E8.13. Then we have arbitrarily dropped the first equation, since a connected network with n
nodes has (n − 1) basic variables. We have rearranged the remaining variables and constraints to exhibit
The variables on the diagonal of the triangular system then may be evaluated sequentially, starting with
the first equation. Clearly x25 = 0. Then, moving the evaluated variable to the righthand side, we have a new
triangular system with one less equation. Then the next diagonal variable may be evaluated in the same way
and the procedure repeated. It is easy to see that, for our example, the values of the variables are x25 = 0,
x34 = 5, x35 = 15, x13 = 20. Note that the value of x13 satisfies the first equation that was dropped. It
should be pointed out that many other systems of equations besides network-flow problems can be put in the
form of a triangular system and therefore can be easily solved.
In this section we apply the simplex method to the general minimum-cost flow problem, using the network
concepts developed in the previous section. Consider the minimum-cost flow problem given in Section 8.1
and repeated here in Fig. 8.17 for reference.
This problem is more complicated than the transportation problem since it contains intermediate nodes
(points of transshipment) and capacities limiting the flow on some of the arcs.
In order to apply the simplex method to this example, we must first determine a basic feasible solution.
Whereas, in the case of the transportation problem, an initial basic feasible solution is easy to determine
(by the northwest-corner method, the minimum matrix method, or the Vogel approximation method), in the
general case an initital basic feasible solution may be difficult to find. The difficulty arises from the fact that
the upper and lower bounds on the variables are treated implicitly and, hence, nonbasic variables may be at
either bound. We will come back to this question later. For the moment, assume that we have been given the
initial basic feasible solution shown in Fig. 8.18.
The dash–dot arcs 1–3 and 3–5 indicate nonbasic variables at their upper bounds of 8 and 5, respectively.
Figure 8.18 Initial basic feasible solution.
The arcs not shown are nonbasic at their lower bounds of zero. The solid arcs form a spanning tree for the
network and constitute a basis for the problem.
To detemine whether this initial basic feasible solution is optimal, we must compute the reduced costs
of all nonbasic arcs. To do this, we first determine multipliers yi (i = 1, 2, . . . , n) and, if these multipliers
then we have an optimal solution. Since the network-flow problem contains a redundant constraint, any one
multiplier may be chosen arbitrarily, as was indicated in previous sections. Suppose y2 = 0 is set arbitrarily;
the remaining multipliers are determined from the equations:
for basic variables. The resulting multipliers for the initial basis are given as node labels in Fig. 8.19. These
were determined from the cost data given in Fig. 8.17.
Given these multipliers, we can compute the reduced costs of the nonbasis variables by ci j = ci j − yi + y j .
The reduced costs are determined by using the given cost data in Fig. 8.17 as:
In the simplex method with bounded variables, the nonbasic variables are at either their upper or lower
bounds. An improved solution can be found by either:
1. increasing a variable that has a negative reduced cost and is currently at its lower bound; or
2. decreasing a variable that has a positive reduced cost and is currently at its upper bound.
In this case, the only promising candidate is x45 , since the other two negative reduced costs correspond to
nonbasic variables at their upper bounds. In Fig. 8.19 we have added the arc 4–5 to the network, forming the
unique loop 4–5–2–4 with the basic variables. If the flow on arc 4–5 is increased by θ , the remaining arcs in
the loop must be appropriately adjusted. The limit on how far we can increase θ is given by arc 2–4, which
has an upper bound of 4. Hence, θ = 2 and x24 becomes nonbasic at its upper bound. The corresponding
basic feasible solution is given in Fig. 8.20, ignoring the dashed arc 2–3.
The new multipliers are computed as before and are indicated as node labels in Fig. 8.20. Note that not
all of the multipliers have to be recalculated. Those multipliers corresponding to nodes that are connected to
node 2 by the same sequence of arcs as before will not change labels. The reduced costs for the new basis
Again there is only one promising candidate, x23 , since the other two negative reduced costs correspond
to nonbasic variables at their upper bounds. In Fig. 8.20 we have added the arc 2–3 to the network, forming
the unique loop 2–3–4–5–2 with the basic variables. If we increase the flow on arc 2–3 by θ and adjust the
flows on the remaining arcs in the loop to maintain feasibility, the increase in θ is limited by arc 2–5. When
θ = 8, the flow on arc 2–5 is reduced to zero and x25 becomes nonbasic at its lower bound. Figure 8.21
shows the corresponding basic feasible solution.
The new multipliers are computed as before and are indicated as node labels in Fig. 8.8. The reduced
This is an optimal solution, since all negative reduced costs correspond to nonbasic variables at their upper
bounds and all positive reduced costs correspond to nonbasic variables at their lower bounds.
The reduced cost c35 = 0 indicates that alternative optimal solutions may exist. In fact, it is easily verified
that the solution given in Fig. 8.22 is an alternative optimal solution.
Figure 8.22 Alternative optimal solution.
Hence, given an initial basic feasible solution, it is straightforward to use the concepts developed in
the previous section to apply the simplex method to the general minimum-cost flow problem. There are
two essential points to recognize: (1) a basis for the simplex method corresponds to a spanning tree for the
network, and (2) introducing a new variable into the basis forms a unique loop in the spanning tree, and the
variable that drops from the basis is the limiting variable in this loop.
Finally, we must briefly discuss how to find an initial basic feasible solution if one is not readily available.
There are a number of good heuristics for doing this, depending on the particular problem, but almost all of
these procedures involve adding some artificial arcs at some point. It is always possible to add uncapacitated
arcs from the points of supply to the points of demand in such a fashion that a basis is formed. In our
illustrative example, we could have simply added the artificial arcs 1–4 and 1–5 and had the initial basis given
Then either a phase I procedure is performed, minimizing the sum of the flows on the artificial arcs, or
a very high cost is attached to the artificial arcs to drive them out of the basis. Any heuristic procedure for
finding an initial basis usually attempts to keep the number of artificial arcs that have to be added as small as
1. A gas company owns a pipeline network, sections of which are used to pump natural gas from its main field to its
distribution center. The network is shown below, where the direction of the arrows indicates the only direction in
which the gas can be pumped. The pipeline links of the system are numbered one through six, and the intermediate
nodes are large pumping stations. At the present time, the company nets 1200 mcf (million cubic feet) of gas per
month from its main field and must transport that entire amount to the distribution center. The following are the
maximum usage rates and costs associated with each link:
Maximum usage: mcf/month 500 900 700 400 600 1000
The gas company wants to find those usage rates that minimize total cost of transportation.
b) Formulate the problem as a linear program.
c) For the optimal solution, do you expect the dual variable associated with the maximum usage of link 1 to be
d) Suppose there were maximum usage rates on the pumping stations; how would your formulation change?
2. On a particular day during the tourist season a rent-a-car company must supply cars to four destinations according
The company has three branches from which the cars may be supplied. On the day in question, the inventory status
The distances between branches and destinations are given by the following table:
Plan the day’s activity such that supply requirements are met at a minimum cost (assumed proportional to car-miles
3. The National Association of Securities Dealers Automated Quotation Systems (NASDAQ) is a network system in which quotation information in over-the-counter operations is collected. Users of the system can receive, in a matter of seconds, buy and sell prices and the exact bid and ask price of each market maker that
deals in a particular security. There are 1700 terminals in 1000 locations in almost 400 cities. The central
processing center is in Trumbull, Conn., with concentration facilities in New York, Atlanta, Chicago, and San
Francisco. On this particular day, the market is quiet, so there are only a few terminals being used. The information they have has to be sent to one of the main processing facilities. The following table gives terminals (supply centers), processing facilities (demand centers), and the time that it takes to transfer a message.
a) Solve, using the minimum matrix method to find an initial feasible solution.
b) Are there alternative optimal solutions?
4. A large retail sporting-goods chain desires to purchase 300, 200, 150, 500, and 400 tennis racquets of five different
types. Inquiries are received from four manufacturers who will supply not more than the following quantities (all
The store estimates that its profit per racquet will vary with the manufacturer as shown below:
5. A construction project involves 13 tasks; the tasks, their estimated duration, and their immediate predecessors are
Our objective is to find the schedule of tasks that minimizes the total elapsed time of the project.
a) Draw the event- and task-oriented networks for this problem and formulate the corresponding linear program.
6. The Egserk Catering Company manages a moderate-sized luncheon cafeteria featuring prompt service, delectable
cuisine, and luxurious surroundings. The desired atmosphere requires fresh linen napkins, which must be available
at the start of each day. Normal laundry takes one full day at 1.5 cents per napkin; rapid laundry can be performed
overnight but costs 2.5 cents a napkin. Under usual usage rates, the current napkin supply of 350 is adequate to
permit complete dependence upon the normal laundry; however, the additional usage resulting from a three-day
seminar to begin tomorrow poses a problem. It is known that the napkin requirements for the next three days will
be 300, 325, and 275, in that order. It is now midafternoon and there are 175 fresh napkins, and 175 soiled napkins
ready to be sent to the laundry. It is against the health code to have dirty napkins linger overnight. The cafeteria
will be closed the day after the seminar and, as a result, all soiled napkins on the third day can be sent to normal
laundry and be ready for the next business day.
The caterer wants to plan for the napkin laundering so as to minimize total cost, subject to meeting all his fresh
napkin requirements and complying with the health code.
Formulate the problem as a linear program.
Interpret the resulting model as a network-flow problem. Draw the corresponding network diagram.
For the optimal solution, do you expect the dual variable associated with tomorrow’s requirement of 300 to be
e) Suppose you could hold over dirty napkins at no charge; how would your formulation change?
7. An automobile association is organizing a series of car races that will last for four days. The organizers know that
r j ≥ 0 special tires in good condition will be required on each of the four successive days, j = 1, 2, 3, 4. They can
meet these needs either by buying new tires at P dollars apiece or by reshaping used tires (reshaping is a technique by
which the grooves on the tire are deepened, using a special profile-shaped tool). Two kinds of service are available
for reshaping: normal service, which takes one full day at N dollars a tire, and quick service, which takes overnight
at Q dollars a tire. How should the association, which starts out with no special tires, meet the daily requirements
a) Formulate a mathematical model for the above problem. Does it exhibit the characteristics of a network problem? Why? (Hint. Take into account the fact that, at the end of day j, some used tires may not be sent to
b) If the answer to (a) is no, how can the formulation be manipulated to become a network problem? Draw the
associated network. (Hint. Add a redundant constraint introducing a fictitious node.)
c) Assume that a tire may be reshaped only once. How does the above model change? Will it still be network
8. Conway Tractor Company has three plants located in Chicago, Austin (Texas), and Salem (Oregon). Three customers located respectively in Tucson (Arizona), Sacramento (California), and Charlestown (West Virginia) have
placed additional orders with Conway Tractor Company for 10, 8, and 10 tractors, respectively. It is customary for
Conway Tractor Company to quote to customers a price on a delivered basis, and hence the company absorbs the
delivery costs of the tractors. The manufacturing cost does not differ significantly from one plant to another, and
the following tableau shows the delivery costs incurred by the firm.
The firm is now facing the problem of assigning the extra orders to its plants to minimize delivery costs and
to meet all orders (The Company, over the years, has established a policy of first-class service, and this includes
quick and reliable delivery of all goods ordered). In making the assignment, the company has to take into account
the limited additional manufacturing capacity at its plants in Austin and Salem, of 8 and 10 tractors, respectively.
There are no limits on the additional production capacity at Chicago (as far as these extra orders are concerned).
a) Formulate as a transportation problem.
9. A manufacturer of electronic calculators produces its goods in Dallas, Chicago, and Boston, and maintains regional
warehousing distribution centers in Philadelphia, Atlanta, Cleveland, and Washington, D.C. The company’s staff
has determined that shipping costs are directly proportional to the distances from factory to storage center, as listed
The cost per calculator-mile is $0.0002 and supplies and demands are:
a) Use the Vogel approximation method to arrive at an initial feasible solution.
b) Show that the feasible solution determined in (a) is optimal.
c) Why does the Vogel approximation method perform so well, compared to other methods of finding an initial
10. Colonel Cutlass, having just taken command of the brigade, has decided to assign men to his staff based on previous
experience. His list of major staff positions to be filled is adjutant (personnel officer), intelligence officer, operations
officer, supply officer, and training officer. He has five men he feels could occupy these five positions. Below are
their years of experience in the several fields.
Adjutant Intelligence Operations Supply Training
Who, based on experience, should be placed in which positions to give the greatest total years of experience for all
jobs? (Hint. A basis, even if degenerate, is a spanning tree.)
11. Consider the following linear program:
Minimize z = 3x12 + 2x13 + 5x14 + 2x41 + x23 + 2x24 + 6x42 + 4x34 + 4x43 ,
a) Show that this is a network problem, stating it in general minimum-cost flow form. Draw the associated network
and give an interpretation to the flow in this network.
b) Find an initial feasible solution. (Hint. Exploit the triangular property of the basis.)
c) Show that your initial solution is a spanning tree.
12. A lot of three identical items is to be sequenced through three machines. Each item must be processed first on
machine 1, then on machine 2, and finally on machine 3. It takes 20 minutes to process one item on machine 1, 12
minutes on machine 2, and 25 minutes on machine 3. The objective is to minimize the total work span to complete
a) Write a linear program to achieve our objective. (Hint. Let xi j be the starting time of processing item i on
machine j. Two items may not occupy the same machine at the same time; also, an item may be processed on
machine ( j + 1) only after it has been completed on machine j.)
b) Cast the model above as a network problem. Draw the associated network and give an interpretation in terms of
flow in networks. (Hint. Formulate and interpret the dual problem of the linear program obtained in (a).)
c) Find an initial feasible solution; solve completely.
13. A manufacturer of small electronic calculators is working on setting up his production plans for the next six months.
One product is particularly puzzling to him. The orders on hand for the coming season are:
The product will be discontinued after satisfying the June demand. Therefore, there is no need to keep any inventory
after June. The production cost, using regular manpower, is $10 per unit. Producing the calculator on overtime costs
an additional $2 per unit. The inventory-carrying cost is $0.50 per unit per month. If the regular shift production
is limited to 100 units per month and overtime production is limited to an additional 75 units per month, what
is the optimal production schedule? (Hint. Treat regular and overtime capacities as sources of supply for each
14. Ships are available at three ports of origin and need to be sent to four ports of destination. The number of ships
available at each origin, the number required at each destination, and the sailing times are given in the tableau below.
Our objective is to minimize the total number of sailing days.
a) Find an initial basic feasible solution.
b) Show that your initial basis is a spanning tree.
c) Find an initial basic feasible solution using the other two methods presented in the text. Solve completely, starting
from the three initial solutions found in parts (a) and (c). Compare how close these solutions were to the optimal
d) Which of the dual variables may be chosen arbitrarily, and why?
e) Give an economic interpretation of the optimal simplex multipliers associated with the origins and destinations.
15. A distributing company has two major customers and three supply sources. The corresponding unit from each
supply center to each customer is given in the following table, together with the total customer requirements and
Note that Customer 1 has strong preferences for Supplier 1 AND will be willing not only to absorb all the transportation costs but also to pay a premium price of $1 per unit of product coming from Supplier 1.
a) The top management of the distributing company feels it is obvious that Supply Center 1 should send all its
available products to Customer 1. Is this necessarily so? (Hint. Obtain the least-cost solution to the problem.
Explore whether alternative optimal solutions exist where not all the 300 units available in Supply Center 1 are
b) Assume Customer 2 is located in an area where all shipments will be subject to taxes defined as a percentage of
the unit cost of a product. Will this tax affect the optimal solution of part (a)?
c) Ignore part (b). What will be the optimal solution to the original problem if Supply Center 1 increases its product
availability from 300 units to 400 units?
16. After solving a transportation problem with positive shipping costs ci j along all arcs, we increase the supply at
one source and the requirement at one destination in a manner that will maintain equality of total supply and total
a) Would you expect the shipping cost in the modified problem with a larger total shipment of goods to be higher
than the optimal shipping plan from the original problem?
b) Solve the following transportation problem:
c) Increase the supply at source S1 by 1 unit and the demand at demand center D3 by 1 unit, and re-solve the
problem. Has the cost of the optimal shipping plan decreased? Explain this behavior.
17. Consider a very elementary transportation problem with only two origins and two destinations. The supplies,
demands, and shipping costs per unit are given in the following tableau.
Since the total number of units supplied equals the total number of units demanded, the problem may be formulated
with equality constraints. An optimal solution to the problem is:
and a corresponding set of shadow prices on the nodes is:
Why is the least expensive route not used?
Are the optimal values of the decision variables unique?
Are the optimal values of the shadow prices unique?
Determine the ranges on the righthand-side values, changed one at a time, for which the basis remains unchanged.
e) What happens when the ranges determined in (d) are exceeded by some small amount?
18. Consider a transportation problem identical to the one given in Exercise 17. One way the model may be formulated
is as a linear program with inequality constraints. The formulation and solution are given below.
a) Are the optimal values of the shadow prices unique?
b) Determine the ranges on the righthand-side values, changed one at a time, for which the basis remains unchanged.
c) Reconcile the results of (b) with those obtained in Exercise 17.
19. Suppose that there are three suppliers S1 , S2 , and S3 in a distribution system that can supply 5, 5, and 6 units,
respectively, of the company’s good. The distribution system contains five demand centers, that require 2, 2, 4, 4,
and 3 units each of the good. The transportation costs, in dollars per unit, are as follows:
a) Compute an optimum shipping schedule. Is the optimal solution unique?
b) Find the range over which the cost of transportation from S1 to D3 can vary while maintaining the optimal basis
c) To investigate the sensitivity of the solution to this problem, we might consider what happens if the amount
supplied from any one supplier and the amount demanded by any one demand center were both increased. Is
it possible for the total shipping costs to decrease by increasing the supply and the demand for any particular
choice of supply and demand centers? Establish a limit on these increases as specific pairs of supply and demand
d) A landslide has occurred on the route from S2 to D5 . If you bribe the state highway crew with $10, they will
clear the slide. If not, the route will remain closed. Should you pay the bribe?
20. An oil company has three oil fields and five refineries. The production and transportation costs from each oil field
each refinery, in dollars per barrel, are given in the table below:
The corresponding production capacity of each field and requirements of each refinery, in millions of barrels per
a) What is the optimum weekly production program? Parts (b), (c), and (d) are independent, each giving modifications to part (a).
b) Suppose that field OF1 has worked under capacity so far, and that its production increases by one unit (i.e.,
1 million barrels). What is the new optimal production plan? Has the optimal basis changed? How does the
objective function change? What is the range within which the production of field OF1 may vary?
c) Because of pipeline restrictions, it is impossible to send more than 1 million barrels from OF2 to R5. How would
you have formulated the problem if it has been stated in this form from the very beginning? (Hint. Decompose
R5 into two destinations: one with a requirement of one unit (i.e., 1 million barrels), the other with a requirement
of three. Prohibit the route from OF2 to the second destination of R5.) Change the optimum solution in (a) to
d) Suppose that fields OF1, OF2, and OF3 have additional overtime capacities of 1, 1, and 1.5 units, respectively
(that is, 1, 1, and 1.5 million barrels, respectively). This causes an increase in the corresponding production costs
of 0.5, 1.5, and 2 dollars per barrel, respectively. Also assume that the refinery requirements are increased by
one million barrels at each refinery and that there is no convenient route to ship oil from field OF2 to refinery
21. Consider the following transshipment problem where goods are shipped from two plants to either a warehouse or
two distribution centers and then on to the two end markets.
The production rates in units per month are 250 and 450 for plants 1 and 2, respectively. The demands of the two
markets occur at rates 200 and 500 units per month. The costs of shipping one unit over a particular route is shown
adjacent to the appropriate arc in the network.
a) Redraw the above transshipment network as a network consisting of only origins and destinations, by replacing
all intermediate nodes by two nodes, an origin and destination, connected by an arc, from the destination back
b) The network in (a) is a transportation problem except that a backwards arc, with flow xii , from newly created
destination i to its corresponding newly created source, is required. Convert this to a transportation network by
substituting xii0 = B − xii . How do you choose a value for the constant B?
c) Certain arcs are inadmissible in the original transshipment formulation; how can these be handled in the reformulated transportation problem?
d) Interpret the linear-programming tableau of the original transshipment network and that of the reformulated
e) Can any transshipment problem be transformed into an equivalent transportation problem?
22. Consider the following minimum-cost flow model:
We wish to send eight units from node 1 to node 5 at minimum cost. The numbers next to the arcs indicate
upper bounds for the flow on an arc and the cost per unit of flow. The following solution has been proposed, where
The total cost of the proposed solution is $66.8.
a) Is the proposed solution a feasible solution? Is it a basic feasible solution? Why?
b) How can the proposed solution be modified to constitute a basic feasible solution?
c) Determine multipliers on the nodes associated with the basic feasible solution given in (b). Are these multipliers
d) Show that the basic feasible solution determine in (b) is not optimal.
e) What is the next basis suggested by the reduced costs? What are the values of the new basic variables? Nonbasic
23. For the minimum-cost flow model given in Exercise 22, suppose that the spanning tree indicated by the solid lines
in the following network, along with the dash–dot arcs at their upper bounds, has been proposed as a solution:
What are the flows on the arcs corresponding to this solution?
Determine a set of shadow prices for the nodes.
24. For the minimum-cost flow model given in Exercise 22, with the optimal solution determined in Exercise 23, answer
a) For each nonbasic variable, determine the range on its objective-function coefficient so that the current basis
b) For each basic variable, determine the range on its objective-function coefficient so that the current basis remains
c) Determine the range on each righthand-side value so that the basis remains unchanged.
d) In question (c), the righthand-side ranges are all tight, in the sense that any change in one righthand-side value
by itself will apparently change the basis. What is happening?
25. The following model represents a simple situation of buying and selling of a seasonal product for profit:
In this formulation, the decision variables xt and yt denote, respectively, the amount of the product purchased and
sold, in time period t. The given data is:
capacity for storing the product in any period.
The constraints state (i) that the amount of the product on hand at the end of any period cannot exceed the storage
capacity C, and (ii) that the amount of the product sold at the beginning of period t cannot exceed its availability
denote slack variables for the constraints (with z 1 = I − y1 ). Show that the given model is equivalent to the
b) State the dual to the problem formulation in part (a), letting u i denote the dual variable for the constraint +xi ,
and v j denote the dual variable for the constraint containing +y.
c) Into what class of problems does this model fall? Determine the nature of the solution for T = 3.
26. A set of words (for example, ace, bc, dab, dfg, fe) is to be transmitted as messages. We want to investigate the possibility of representing each word by one of the letters in the word such that the words will be represented uniquely. If such
a representation is possible, we can transmit a single letter instead of a complete word for a message we want to send.
a) Using as few constraints and variables as possible, formulate the possibility of transmitting letters to represent
words as the solution to a mathematical program. Is there anything special about the structure of this program
that facilitates discovery of a solution?
b) Suppose that you have a computer code that computes the solution to the following transportation problem:
(i = 1, 2, . . . , m; j = 1, 2, . . . , n).
ai , b j , ci j ≥ 0 and integer (i = 1, 2, . . . , m; j = 1, 2, . . . , n),
xt ≥ 0, yt ≥ 0, wt ≥ 0, z t ≥ 0 for t = 1, . . . , T.
How would you use this code to solve the problem posed in (a)? Answer the question in general, and use the
specific problem defined above as an illustration.
27. The Defense Communications Agency is responsible for operating and maintaining a world-wide communications
system. It thinks of costs as being proportional to the ‘‘message units’’ transmitted in one direction over a particular
link in the system. Hence, under normal operating conditions it faces the following minimum-cost flow problem:
ci j = cost per message unit over link (i − j).
bi = message units generated (or received) at station i,
u i j = upper bound on number of message units that can be
Suppose that the agency has been given a budget of B dollars to spend on increasing the capacity of any link in
the system. The price for increasing capacity on link (i − j) is pi j .
a) Formulate a linear program (not necessarily a network) with only (n + 1) constraints, that will minimize operating
costs subject to this budget constraint. (Hint. You must allow for investing in additional capacity for each link.)
b) How can the ‘‘near’’ network model formulated in (a) be analyzed by network-programming techniques? (Hint.
How could parametric programming be used?)
28. The general minimum-cost flow problem is given as follows:
a) Assuming that the lower bounds on the variables are all finite, this is, `i j > −∞, show that any problem of this
form can be converted to a transportation problem with lower bounds on the variables of zero and nonnegative,
or infinite, upper bounds. (Hint. Refer to Exercise 22.)
b) Comment on the efficiency of solving minimum-cost flow problems by a bounded-variables transportation
method, versus the simplex method for general networks.
29. One difficulty with solving the general minimum-cost flow problem with upper and lower bounds on the variables
lies in determining an initial basic feasible solution. Show that an initial basic feasible solution to this problem
can be determined by solving an appropriate maximum-flow problem. (Hints. (1) Make a variable substitution to
eliminate the nonzero lower bounds on the variables. (2) Form a ‘‘super source,’’ connected to all the source nodes,
and a ‘‘super sink,’’ connected to all the sink nodes, and maximize the flow from super sink to super source.)
Exercises 1 and 6 are due to Sherwood C. Frey, Jr., of the Harvard Business School.
Exercise 6, in turn, is based on ‘‘The Caterer Problem,’’ in Flows in Networks by L. R. Ford and D. R. Fulkerson, Princeton University Press, 1962. In their 1955 article ‘‘Generalizations of the Warehousing Model,’’
from the Operational Research Quarterly, A. Charnes and W. W. Cooper introduced the transformation used
The linear-programming models that have been discussed thus far all have been continuous, in the sense that
decision variables are allowed to be fractional. Often this is a realistic assumption. For instance, we might
easily produce 102 43 gallons of a divisible good such as wine. It also might be reasonable to accept a solution
giving an hourly production of automobiles at 58 21 if the model were based upon average hourly production,
and the production had the interpretation of production rates.
At other times, however, fractional solutions are not realistic, and we must consider the optimization
This problem is called the (linear) integer-programming problem. It is said to be a mixed integer program
when some, but not all, variables are restricted to be integer, and is called a pure integer program when all
decision variables must be integers. As we saw in the preceding chapter, if the constraints are of a network
nature, then an integer solution can be obtained by ignoring the integrality restrictions and solving the resulting
linear program. In general, though, variables will be fractional in the linear-programming solution, and further
measures must be taken to determine the integer-programming solution.
The purpose of this chapter is twofold. First, we will discuss integer-programming formulations. This
should provide insight into the scope of integer-programming applications and give some indication of
why many practitioners feel that the integer-programming model is one of the most important models in
management science. Second, we consider basic approaches that have been developed for solving integer
Integer-programming models arise in practically every area of application of mathematical programming. To
develop a preliminary appreciation for the importance of these models, we introduce, in this section, three
areas where integer programming has played an important role in supporting managerial decisions. We do
not provide the most intricate available formulations in each case, but rather give basic models and suggest
Capital Budgeting In a typical capital-budgeting problem, decisions involve the selection of a number of
potential investments. The investment decisions might be to choose among possible plant locations, to select
a configuration of capital equipment, or to settle upon a set of research-and-development projects. Often it
makes no sense to consider partial investments in these activities, and so the problem becomes a go–no-go
integer program, where the decision variables are taken to be x j = 0 or 1, indicating that the jth investment
is rejected or accepted. Assuming that c j is the contribution resulting from the jth investment and that ai j is
the amount of resource i, such as cash or manpower, used on the jth investment, we can state the problem
The objective is to maximize total contribution from all investments without exceeding the limited availability
One important special scenario for the capital-budgeting problem involves cash-flow constraints. In this
reflect incremental cash balance in each period. The coefficients ai j represent the net cash flow from investment j in period i. If the investment requires additional cash in period i, then ai j > 0, while if the
investment generates cash in period i, then ai j < 0. The righthand-side coefficients bi represent the incremental exogenous cash flows. If additional funds are made available in period i, then bi > 0, while if funds
are withdrawn in period i, then bi < 0. These constraints state that the funds required for investment must
be less than or equal to the funds generated from prior investments plus exogenous funds made available (or
The capital-budgeting model can be made much richer by including logical considerations. Suppose, for
example, that investment in a new product line is contingent upon previous investment in a new plant. This
contingency is modeled simply by the constraint
which states that if xi = 1 and project i (new product development) is accepted, then necessarily x j = 1 and
project j (construction of a new plant) must be accepted. Another example of this nature concerns conflicting
for example, states that only one of the first four investments can be accepted. Constraints like this commonly
are called multiple-choice constraints. By combining these logical constraints, the model can incorporate
many complex interactions between projects, in addition to issues of resource allocation.
The simplest of all capital-budgeting models has just one resource constraint, but has attracted much
attention in the management-science literature. It is stated as:
Usually, this problem is called the 0–1 knapsack problem, since it is analogous to a situation in which a
hiker must decide which goods to include on his trip. Here c j is the ‘‘value’’ or utility of including good j,
which weighs a j > 0 pounds; the objective is to maximize the ‘‘pleasure of the trip,’’ subject to the weight
limitation that the hiker can carry no more than b pounds. The model is altered somewhat by allowing more
than one unit of any good to be taken, by writing x j ≥ 0 and x j -integer in place of the 0–1 restrictions on
the variables. The knapsack model is important because a number of integer programs can be shown to be
equivalent to it, and further, because solution procedures for knapsack models have motivated procedures for
Warehouse Location In modeling distribution systems, decisions must be made about tradeoffs between
transportation costs and costs for operating distribution centers. As an example, suppose that a manager must
decide which of n warehouses to use for meeting the demands of m customers for a good. The decisions to
be made are which warehouses to operate and how much to ship from any warehouse to any customer. Let
xi j = Amount to be sent from warehouse i to customer j.
f i = Fixed operating cost for warehouse i, ifopened (for example, a cost to
ci j = Per-unit operating cost at warehouse i plus the transportation cost for
There are two types of constraints for the model:
i) the demand d j of each customer must be filled from the warehouses; and
ii) goods can be shipped from a warehouse only if it is opened.
(i = 1, 2, . . . , m; j = 1, 2, . . . , n),
The objective function incorporates transportation and variable warehousing costs, in addition to fixed
costs for operating warehouses. The constraints (2) indicate that each customer’s demand must be met. The
summation over the shipment variables xi j in the ith constraint of (3) is the amount of the good shipped from
warehouse i. When the warehouse is not opened, yi = 0 and the constraint specifies that nothing can be
shipped from the warehouse. On the other hand, when the warehouse is opened and yi = 1, the constraint
simply states that the amount to be shipped from warehouse i can be no larger than the total demand, which
is always true. Consequently, constraints (3) imply restriction (ii) as proposed above.
Although oversimplified, this model forms the core for sophisticated and realistic distribution models
1. multi-echelon distribution systems from plant to warehouse to customer;
2. capacity constraints on both plant production and warehouse throughput;
3. economies of scale in transportation and operating costs;
4. service considerations such as maximum distribution time from warehouses to customers;
6. conditions preventing splitting of orders (in the model above, the demand for any customer can be supplied
These features can be included in the model by changing it in several ways. For example, warehouse
capacities are incorporated by replacing the term involving yi in constraint (3) with yi K i , where K i is the
throughput capacity of warehouse i; multi-echelon distribution may require triple-subscripted variables xi jk
denoting the amount to be shipped, from plant i to customer k through warehouse j. Further examples of
how the simple warehousing model described here can be modified to incorporate the remaining features
mentioned in this list are given in the exercises at the end of the chapter.
Scheduling The entire class of problems referred to as sequencing, scheduling, and routing are inherently
integer programs. Consider, for example, the scheduling of students, faculty, and classrooms in such a way
that the number of students who cannot take their first choice of classes is minimized. There are constraints on
the number and size of classrooms available at any one time, the availability of faculty members at particular
times, and the preferences of the students for particular schedules. Clearly, then, the ith student is scheduled
for the jth class during the nth time period or not; hence, such a variable is either zero or one. Other
examples of this class of problems include line-balancing, critical-path scheduling with resource constraints,
As a specific example, consider the scheduling of airline flight personnel. The airline has a number of
routing ‘‘legs’’ to be flown, such as 10 A.M. New York to Chicago, or 6 P.M.Chicago to Los Angeles. The
airline must schedule its personnel crews on routes to cover these flights. One crew, for example, might be
scheduled to fly a route containing the two legs just mentioned. The decision variables, then, specify the
c j = Cost for assigning a crew to route j.
The coefficients ai j define the acceptable combinations of legs and routes, taking into account such characteristics as sequencing of legs for making connections between flights and for including in the routes ground
The ith constraint requires that one crew must be assigned on a route to fly leg i. An alternative formulation
permits a crew to ride as passengers on a leg. Then the constraints (4) become:
then two crews fly as passengers on leg 1, possibly to make connections to other legs to which they have been
These airline-crew scheduling models arise in many other settings, such as vehicle delivery problems,
political districting, and computer data processing. Often model (4) is called a set-partitioning problem, since
the set of legs will be divided, or partitioned, among the various crews. With constraints (5), it is called a
set-covering problem, since the crews then will cover the set of legs.
Another scheduling example is the so-called traveling salesman problem. Starting from his home, a
salesman wishes to visit each of (n − 1) other cities and return home at minimal cost. He must visit each city
exactly once and it costs ci j to travel from city i to city j. What route should he select? If we let
we may be tempted to formulate his problem as the assignment problem:
(i = 1, 2, . . . , n; j = 1, 2, . . . , n).
The constraints require that the salesman must enter and leave each city exactly once. Unfortunately, the
assignment model can lead to infeasible solutions. It is possible in a six-city problem, for example, for the
assignment solution to route the salesman through two disjoint subtours of the cities instead of on a single
Consequently, additional constraints must be included in order to eliminate subtour solutions. There are
a number of ways to accomplish this. In this example, we can avoid the subtour solution of Fig. 9.1 by
x14 + x15 + x16 + x24 + x25 + x26 + x34 + x35 + x36 ≥ 1.
This inequality ensures that at least one leg of the tour connects cities 1, 2, and 3 with cities 4, 5, and 6. In
general, if a constraint of this form is included for each way in which the cities can be divided into two groups,
then subtours will be eliminated. The problem with this and related approaches is that, with n cities, (2n − 1)
constraints of this nature must be added, so that the formulation becomes a very large integer-programming
problem. For this reason the traveling salesman problem generally is regarded as difficult when there are
The traveling salesman model is used as a central component of many vehicular routing and scheduling
models. It also arises in production scheduling. For example, suppose that we wish to sequence (n − 1)
jobs on a single machine, and that ci j is the cost for setting up the machine for job j, given that job i has
just been completed. What scheduling sequence for the jobs gives the lowest total setup costs? The problem
can be interpreted as a traveling salesman problem, in which the ‘‘salesman’’ corresponds to the machine
which must ‘‘visit’’ or perform each of the jobs. ‘‘Home’’ is the initial setup of the machine, and, in some
applications, the machine will have to be returned to this initial setup after completing all of the jobs. That
is, the ‘‘salesman’’ must return to ‘‘home’’ after visiting the ‘‘cities.’’
The illustrations in the previous section not only have indicated specific integer-programming applications,
but also have suggested how integer variables can be used to provide broad modeling capabilities beyond those
available in linear programming. In many applications, integrality restrictions reflect natural indivisibilities
of the problem under study. For example, when deciding how many nuclear aircraft carriers to have in the
U.S. Navy, fractional solutions clearly are meaningless, since the optimal number is on the order of one or
two. In these situations, the decision variables are inherently integral by the nature of the decision-making
This is not necessarily the case in every integer-programming application, as illustrated by the capitalbudgeting and the warehouse-location models from the last section. In these models, integer variables arise
from (i) logical conditions, such as if a new product is developed, then a new plant must be constructed,
and from (ii) non-linearities such as fixed costs for opening a warehouse. Considerations of this nature
are so important for modeling that we devote this section to analyzing and consolidating specific integerprogramming formulation techniques, which can be used as tools for a broad range of applications.
Suppose that we are to determine whether or not to engage in the following activities: (i) to build a new plant,
(ii) to undertake an advertising campaign, or (iii) to develop a new product. In each case, we must make a
yes–no or so-called go–no–go decision. These choices are modeled easily by letting x j = 1 if we engage in
the jth activity and x j = 0 otherwise. Variables that are restricted to 0 or 1 in this way are termed binary,
bivalent, logical, or 0–1 variables. Binary variables are of great importance because they occur regularly in
many model formulations, particularly in problems addressing long-range and high-cost strategic decisions
associated with capital-investment planning.
If, further, management had decided that at most one of the above three activities can be pursued, the
As we have indicated in the capital-budgeting example in the previous section, this restriction usually is
referred to as a multiple-choice constraint, since it limits our choice of investments to be at most one of the
Binary variables are useful whenever variables can assume one of two values, as in batch processing. For
example, suppose that a drug manufacturer must decide whether or not to use a fermentation tank. If he uses
the tank, the processing technology requires that he make B units. Thus, his production y must be 0 or B,
and the problem can be modeled with the binary variable x j = 0 or 1 by substituting Bx j for y everywhere
Frequently, problem settings impose logical constraints on the decision variables (like timing restrictions,
contingencies, or conflicting alternatives), which lend themselves to integer-programming formulations. The
following discussion reviews the most important instances of these logical relationships.
Possibly the simplest logical question that can be asked in mathematical programming is whether a given
choice of the decision variables satisfies a constraint. More precisely, when is the general constraint
We introduce a binary variable y with the interpretation:
if the constraint is known to be satisfied,
where the constant B is chosen to be large enough so that the constraint always is satisfied if y = 1; that is,
for every possible choice of the decision variables x1 , x2 , . . . , xn at our disposal. Whenever y = 0 gives a
feasible solution to constraint (7), we know that constraint (6) must be satisfied. In practice, it is usually very
easy to determine a large number to serve as B, although generally it is best to use the smallest possible value
of B in order to avoid numerical difficulties during computations.
Consider a situation with the alternative constraints:
At least one, but not necessarily both, of these constraints must be satisfied. This restriction can be modeled
by combining the technique just introduced with a multiple-choice constraint as follows:
f 1 (x1 , x2 , . . . , xn ) − B1 y1 ≤ b1 ,
f 2 (x1 , x2 , . . . , xn ) − B2 y2 ≤ b2 ,
The variables y1 and y2 and constants B1 and B2 are chosen as above to indicate when the constraints are
satisfied. The multiple-choice constraint y1 + y2 ≤ 1 implies that at least one variable y j equals 0, so that,
as required, at least one constraint must be satisfied.
We can save one integer variable in this formulation by noting that the multiple-choice constraint can be
replaced by y1 + y2 = 1, or y2 = 1 − y1 , since this constraint also implies that either y1 or y2 equals 0. The
f 2 (x1 , x2 , . . . , xn ) − B2 (1 − y1 ) ≤ b2 ,
As an illustration of this technique, consider again the custom-molder example from Chapter 1. That
which represented the production capacity for producing x1 hundred cases of six-ounce glasses and x2 hundred
cases of ten-ounce glasses. Suppose that there were an alternative production process that could be used,
Then the decision variables x1 and x2 must satisfy either (8) or (9), depending upon which production process
is selected. The integer-programming formulation replaces (8) and (9) with the constraints:
In this case, both B1 and B2 are set to 100, which is large enough so that the constraint is not limiting for the
implies that f 2 (x1 , x2 , . . . , xn ) ≤ b2 .
Since this implication is not satisfied only when both f 1 (x1 , x2 , . . . , xn )
f 2 (x1 , x2 , . . . , xn ) > b2 , the conditional constraint is logically equivalent to the alternative constraints
where at least one must be satisfied. Hence, this situation can be modeled by alternative constraints as
Suppose that we must satisfy at least k of the constraints:
For example, these restrictions may correspond to manpower constraints for p potential inspection systems
for quality control in a production process. If management has decided to adopt at least k inspection systems,
then the k constraints specifying the manpower restrictions for these systems must be satisfied, and the
remaining constraints can be ignored. Assuming that B j for j = 1, 2, . . . , p, are chosen so that the ignored
constraints will not be binding, the general problem can be formulated as follows:
f j (x1 , x2 , . . . , xn ) − B j (1 − y j ) ≤ b j
That is, y j = 1 if the jth constraint is to be satisfied, and at least k of the constraints must be satisfied. If
we define y 0j ≡ 1 − y j , and substitute for y j in these constraints, the form of the resulting constraints is
analogous to that given previously for modeling alternative constraints.
The feasible region shown in Fig. 9.2 consists of three disjoint regions, each specified by a system of
inequalities. The feasible region is defined by alternative sets of constraints, and can be modeled by the
Note that we use the same binary variable y j for eachconstraint defining one of the regions, and that the
Figure 9.2 An example of compound alternatives.
Figure 9.3 Geometry of alternative constraints.
constraint y1 + y2 + y3 ≤ 2 implies that the decision variables x1 and x2 lie in at least one of the required
regions. Thus, for example, if y3 = 0, then each of the constraints
The regions do not have to be disjoint before we can apply this technique. Even the simple alternative
f 1 (x1 , x2 ) ≤ b1 or f 2 (x1 , x2 ) ≤ b2
shown in Fig. 9.3 contains overlapping regions.
Nonlinear functions can be represented by integer-programming formulations. Let us analyze the most useful
Frequently, the objective function for a minimization problem contains fixed costs (preliminary design costs,
fixed investment costs, fixed contracts, and so forth). For example, the cost of producing x units of a specific
product might consist of a fixed cost of setting up the equipment and a variable cost per unit produced on the
equipment. An example of this type of cost is given in Fig. 9.4.
Assume that the equipment has a capacity of B units. Define y to be a binary variable that indicates when
the fixed cost is incurred, so that y = 1 when x > 0 and y = 0 when x = 0. Then the contribution to cost
As required, these constraints imply that x = 0 when the fixed cost is not incurred, i.e., when y = 0. The
constraints themselves do not imply that y = 0 if x = 0. But when x = 0, the minimization will clearly
Figure 9.5 Modeling a piecewise linear curve.
select y = 0, so that the fixed cost is not incurred. Finally, observe that if y = 1, then the added constraint
becomes x ≤ B, which reflects the capacity limit on the production equipment.
Another type of nonlinear function that can be represented by integer variables is a piecewise linear curve.
Figure 9.5 illustrates a cost curve for plant expansion that contains three linear segments with variable costs
of 5, 1, and 3 million dollars per 1000 items of expansion.
To model the cost curve, we express any value of x as the sum of three variables δ1 , δ2 , δ3 , so that the
cost for each of these variables is linear. Hence,
Note that we have defined the variables so that:
δ1 corresponds to the amount by which x exceeds 0, but is less than or equal to 4;
δ2 is the amount by which x exceeds 4, but is less than or equal to 10; and
δ3 is the amount by which x exceeds 10, but is less than or equal to 15.
If this interpretation is to be valid, we must also require that δ1 = 4 whenever δ2 > 0 and that δ2 = 6
whenever δ3 > 0. Otherwise, when x = 2, say, the cost would be minimized by selecting δ1 = δ3 = 0 and
δ2 = 2, since the variable δ2 has the smallest variable cost. However, these restrictions on the variables are
simply conditional constraints and can be modeled by introducing binary variables, as before.
to ensure that the proper conditional constraints hold. Note that if w1 = 0, then w2 = 0, to maintain feasibility
for the constraint imposed upon δ2 , and (11) reduces to
If w1 = 1 and w2 = 0, then (11) reduces to
Finally, if w1 = 1 and w2 = 1, then (11) reduces to
Hence, we observe that there are three feasible combinations for the values of w1 and w2 :
The same general technique can be applied to piecewise linear curves with any number of segments. The
general constraint imposed upon the variable δ j for the jth segment will read:
An important special case for representing nonlinear functions arises when only diseconomies of scale apply—
that is, when marginal costs are increasing for a minimization problem or marginal returns are decreasing
for a maximization problem. Suppose that the expansion cost in the previous example now is specified by
subject only to the linear constraints without integer variables,
The conditional constraints involving binary variables in the previous formulation can be ignored if the
cost curve appears in a minimization objective function, since the coefficients of δ1 , δ2 , and δ3 imply that it
is always best to set δ1 = 4 before taking δ2 > 0, and to set δ2 = 6 before taking δ3 > 0. As a consequence,
the integer variables have been avoided completely.
This representation without integer variables is not valid, however, if economies of scale are present; for
example, if the function given in Fig. 9.6 appears in a maximization problem. In such cases, it would be best
to select the third segment with variable δ3 before taking the first two segments, since the returns are higher
on this segment. In this instance, the model requires the binary-variable formulation of the previous section.
One of the most useful applications of the piecewise linear representation is for approximating nonlinear
functions. Suppose, for example, that the expansion cost in our illustration is given by the heavy curve in
If we draw linear segments joining selected points on the curve, we obtain a piecewise linear approximation, which can be used instead of the curve in the model. The piecewise approximation, of course, is
represented by introducing integer variables as indicated above. By using more points on the curve, we can
make the approximation as close as we desire.
Figure 9.7 Approximation of a nonlinear curve.
Proper placement of service facilities such as schools, hospitals, and recreational areas is essential to efficient
urban design. Here we will present a simplified model for firehouse location. Our purpose is to show
formulation devices of the previous section arising together in a meaningful context, rather than to give a
comprehensive model for the location problem per se. As a consequence, we shall ignore many relevant
Assume that population is concentrated in I districts within the city and that district i contains pi people.
Preliminary analysis (land surveys, politics, and so forth) has limited the potential location of firehouses to
J sites. Let di j ≥ 0 be the distance from the center of district i to site j. We are to determine the ‘‘best’’ site
selection and assignment of districts to firehouses. Let
The basic constraints are that every district should be assigned to exactly one firehouse, that is,
and that no district should be assigned to an unused site, that is, y j = 0 implies xi j = 0 (i = 1, 2, . . . , I ).
The latter restriction can be modeled as alternative constraints, or more simply as:
Since xi j are binary variables, their sum never exceeds I , so that if y j = 1, then constraint j is nonbinding.
This section may be omitted without loss of continuity.
Next note that di , the distance from district i to its assigned firehouse, is given by:
since one xi j will be 1 and all others 0.
Also, the total population serviced by site j is:
Assume that a central district is particularly susceptible to fire and that either sites 1 and 2 or sites 3 and
4 can be used to protect this district. Then one of a number of similar restrictions might be:
We let y be a binary variable; then these alternative constraints become:
Next assume that it costs f j (s j ) to build a firehouse at site j to service s j people and that a total budget
of B dollars has been allocated for firehouse construction. Then
Finally, one possible social-welfare function might be to minimize the distance traveled to the district
farthest from its assigned firehouse, that is, to:
Collecting constraints and substituting above for di in terms of its defining relationship
‡ The inequalities D ≥ d imply that D ≥ max d . The minimization of D then ensures that it will actually be the
Some Characteristics Of Integer Programs—A Sample Problem
(i = 1, 2, . . . , I ; j = 1, 2, . . . , J ).
At this point we might replace each function f j (s j ) by an integer-programming approximation to complete
the model. Details are left to the reader. Note that if f j (s j ) contains a fixed cost, then new fixed-cost variables
need not be introduced—the variable y j serves this purpose.
The last comment, and the way in which the conditional constraint ‘‘y j = 0 implies xi j = 0 (i =
1, 2, . . . , I )’’ has been modeled above, indicate that the formulation techniques of Section 9.2 should not
be applied without thought. Rather, they provide a common framework for modeling and should be used in
conjunction with good modeling ‘‘common sense.’’ In general, it is best to introduce as few integer variables
SOME CHARACTERISTICS OF INTEGER PROGRAMS—A SAMPLE PROBLEM
Whereas the simplex method is effective for solving linear programs, there is no single technique for solving
integer programs. Instead, a number of procedures have been developed, and the performance of any particular
technique appears to be highly problem-dependent. Methods to date can be classified broadly as following
i) enumeration techniques, including the branch-and-bound procedure;
In addition, several composite procedures have been proposed, which combine techniques using several of
these approaches. In fact, there is a trend in computer systems for integer programming to include a number
of approaches and possibly utilize them all when analyzing a given problem. In the sections to follow, we
shall consider the first two approaches in some detail. At this point, we shall introduce a specific problem
and indicate some features of integer programs. Later we will use this example to illustrate and motivate the
solution procedures. Many characteristics of this example are shared by the integer version of the custommolder problem presented in Chapter 1.
The feasible region is sketched in Fig. 9.8. Dots in the shaded region are feasible integer points.
Figure 9.8 An integer programming example.
If the integrality restrictions on variables are dropped, the resulting problem is a linear program. We will
call it the associated linear program. We may easily determine its optimal solution graphically. Table 9.1
depicts some of the features of the problem.
Observe that the optimal integer-programming solution is not obtained by rounding the linear-programming
solution. The closest point to the optimal linear-program solution is not even feasible. Also, note that the
nearest feasible integer point to the linear-program solution is far removed from the optimal integer point.
Thus, it is not sufficient simply to round linear-programming solutions. In fact, by scaling the righthand-side
and cost coefficients of this example properly, we can construct a problem for which the optimal integerprogramming solution lies as far as we like from the rounded linear-programming solution, in either z value
In an example as simple as this, almost any solution procedure will be effective. For instance, we could
easily enumerate all the integer points with x1 ≤ 9, x2 ≤ 6, and select the best feasible point. In practice, the
number of points to be considered is likely to prohibit such an exhaustive enumeration of potentially feasible
points, and a more sophisticated procedure will have to be adopted.
Figure 9.9 Subdividing the feasible region.
Branch-and-bound is essentially a strategy of ‘‘divide and conquer.’’ The idea is to partition the feasible
region into more manageable subdivisions and then, if required, to further partition the subdivisions. In
general, there are a number of ways to divide the feasible region, and as a consequence there are a number of
branch-and-bound algorithms. We shall consider one such technique, for problems with only binary variables,
in Section 9.7. For historical reasons, the technique that will be described next usually is referred to as the
An integer linear program is a linear program further constrained by the integrality restrictions. Thus, in a
maximization problem, the value of the objective function, at the linear-program optimum, will always be an
upper bound on the optimal integer-programming objective. In addition, any integer feasible point is always
a lower bound on the optimal linear-program objective value.
The idea of branch-and-bound is to utilize these observations to systematically subdivide the linearprogramming feasible region and make assessments of the integer-programming problem based upon these
subdivisions. The method can be described easily by considering the example from the previous section.
At first, the linear-programming region is not subdivided: The integrality restrictions are dropped and the
associated linear program is solved, giving an optimal value z 0 . From our remark above, this gives the upper
bound on z ∗ , z ∗ ≤ z 0 = 41 41 . Since the coefficients in the objective function are integral, z ∗ must be integral
Next note that the linear-programming solution has x1 = 2 41 and x2 = 3 43 . Both of these variables must
be integer in the optimal solution, and we can divide the feasible region in an attempt to make either integral.
We know that, in any integer programming solution, x2 must be either an integer ≤ 3 or an integer ≥ 4. Thus,
our first subdivision is into the regions where x2 ≤ 3 and x2 ≥ 4 as displayed by the shaded regions L 1 and
L 2 in Fig. 9.9. Observe that, by making the subdivisions, we have excluded the old linear-program solution.
(If we selected x1 instead, the region would be subdivided with x1 ≤ 2 and x1 ≥ 3.)
The results up to this point are pictured conveniently in an enumeration tree (Fig. 9.10). Here L 0
represents the associated linear program, whose optimal solution has been included within the L 0 box, and
the upper bound on z ∗ appears to the right of the box. The boxes below correspond to the new subdivisions;
the constraints that subdivide L 0 are included next to the lines joining the boxes. Thus, the constraints of L 1
are those of L 0 together with the constraint x2 ≥ 4, while the constraints of L 2 are those of L 0 together with
The strategy to be pursued now may be apparent: Simply treat each subdivision as we did the original
problem. Consider L 1 first. Graphically, from Fig. 9.9 we see that the optimal linear-programming solution
lies on the second constraint with x2 = 4, giving x1 = 15 (45 − 9(4)) = 95 and an objective value z =
5 59 +8(4) = 41. Since x1 is not integer, we subdivide L 1 further, into the regions L 3 with x1 ≥ 2 and L 4 with
x1 ≤ 1. L 3 is an infeasible problem and so this branch of the enumeration tree no longer needs to be considered.
The enumeration tree now becomes that shown in Fig. 9.12. Note that the constraints of any subdivision
are obtained by tracing back to L 0 . For example, L 4 contains the original constraints together with x2 ≥ 4
and x1 ≤ 2. The asterisk (∗) below box L 3 indicates that the region need not be subdivided or, equivalently,
that the tree will not be extended from this box.
At this point, subdivisions L 2 and L 4 must be considered. We may select one arbitrarily; however,
in practice, a number of useful heuristics are applied to make this choice. For simplicity, let us select the
subdivision most recently generated, here L 4 . Analyzing the region, we find that its optimal solution has
Since x2 is not integer, L 4 must be further subdivided into L 5 with x2 ≤ 4, and L 6 with x2 ≥ 5, leaving L 2 ,
Treating L 5 first (see Fig. 9.13), we see that its optimum has x1 = 1, x2 = 4, and z = 37. Since this is
the best linear-programming solution for L 5 and the linear program contains every integer solution in L 5 , no
integer point in that subdivision can give a larger objective value than this point. Consequently, other points
Figure 9.13 Final subdivisions for the example.
in L 5 need never be considered and L 5 need not be subdivided further. In fact, since x1 = 1, x2 = 4, z = 37,
is a feasible solution to the original problem, z ∗ ≥ 37 and we now have the bounds 37 ≤ z ∗ ≤ 41. Without
further analysis, we could terminate with the integer solution x1 = 1, x2 = 4, knowing that the objective
value of this point is within 10 percent of the true optimum. For convenience, the lower bound z ∗ ≥ 37 just
determined has been appended to the right of the L 5 box in the enumeration tree (Fig. 9.14).
Although x1 = 1, x2 = 4 is the best integer point in L 5 , the regions L 2 and L 6 might contain better
feasible solutions, and we must continue the procedure by analyzing these regions. In L 6 , the only feasible
point is x1 = 0, x2 = 5, giving an objective value z = +40. This is better than the previous integer point and
thus the lower bound on z ∗ improves, so that 40 ≤ z ∗ ≤ 41. We could terminate with this integer solution
knowing that it is within 2.5 percent of the true optimum. However, L 2 could contain an even better integer
The linear-programming solution in L 2 has x1 = x2 = 3 and z = 39. This is the best integer point in
L 2 but is not as good as x1 = 0, x2 = 5, so the later point (in L 6 ) must indeed be optimal. It is interesting
to note that, even if the solution to L 2 did not give x1 and x2 integer, but had z < 40, then no feasible
(and, in particular, no integer point) in L 2 could be as good as x1 = 0, x2 = 5, with z = 40. Thus, again
x1 = 0, x2 = 5 would be known to be optimal. This observation has important computational implications,
since it is not necessary to drive every branch in the enumeration tree to an integer or infeasible solution, but
only to an objective value below the best integer solution.
The problem now is solved and the entire solution procedure can be summarized by the enumeration tree
There are three points that have yet to be considered with respect to the branch-and-bound procedure:
i) Can the linear programs corresponding to the subdivisions be solved efficiently?
ii) What is the best way to subdivide a given region, and which unanalyzed subdivision should be considered
iii) Can the upper bound (z = 41, in the example) on the optimal value z ∗ of the integer program be improved
The answer to the first question is an unqualified yes. When moving from a region to one of its subdivisions,
we add one constraint that is not satisfied by the optimal linear-programming solution over the parent region.
Moreover, this was one motivation for the dual simplex algorithm, and it is natural to adopt that algorithm
Referring to the sample problem will illustrate the method. The first two subdivisions L 1 and L 2 in that
example were generated by adding the following constraints to the original problem:
In either case we add the new constraint to the optimal linear-programming tableau. For subdivision 1, this
where s1 and s2 are slack variables for the two constraints in the original problem formulation. Note that
the new constraint has been multiplied by −1, so that the slack variable s3 can be used as a basic variable.
Since the basic variable x2 appears with a nonzero coefficient in the new constraint, though, we must pivot
to isolate this variable in the second constraint to re-express the system as:
These constraints are expressed in the proper form for applying the dual simplex algorithm, which will pivot
next to make s1 the basic variable in the third constraint. The resulting system is given by:
This tableau is optimal and gives the optimal linear-programming solution over the region L 1 as x1 = 95 , x2 =
4, and z = 41. The same procedure can be used to determine the optimal solution in L 2 .
When the linear-programming problem contains many constraints, this approach for recovering an optimal
solution is very effective. After adding a new constraint and making the slack variable for that constraint
basic, we always have a starting solution for the dual-simplex algorithm with only one basic variable negative.
Usually, only a few dual-simplex pivoting operations are required to obtain the optimal solution. Using the
primal-simplex algorithm generally would require many more computations.
Issue (ii) raised above is very important since, if we can make our choice of subdivisions in such a way
as to rapidly obtain a good (with luck, near-optimal) integer solution ẑ, then we can eliminate many potential
subdivisions immediately. Indeed, if any region has its linear programming value z ≤ ẑ, then the objective
value of no integer point in that region can exceed ẑ and the region need not be subdivided. There is no
universal method for making the required choice, although several heuristic procedures have been suggested,
such as selecting the subdivision with the largest optimal linear-programming value.†
Rules for determining which fractional variables to use in constructing subdivisions are more subtle.
Recall that any fractional variable can be used to generate a subdivision. One procedure utilized is to look
ahead one step in the dual-simplex method for every possible subdivision to see which is most promising. The
details are somewhat involved and are omitted here. For expository purposes, we have selected the fractional
Finally, the upper bound z on the value z ∗ of the integer program can be improved as we solve the problem.
Suppose for example, that subdivision L 2 was analyzed before subdivisions L 5 or L 6 in our sample problem.
The enumeration tree would be as shown in Fig. 9.16.
At this point, the optimal solution must lie in either L 2 or L 4 . Since, however, the largest value for
any feasible point in either of these regions is 40 95 , the optimal value for the problem z ∗ cannot exceed 40 59 .
Because z ∗ must be integral, this implies that z ∗ ≤ 40 and the upper bound has been improved from the value
41 provided by the solution to the linear program on L 0 . In general, the upper bound is given in this way as
the largest value of any ‘‘hanging’’ box (one that has not been divided) in the enumeration tree.
The essential idea of branch-and-bound is to subdivide the feasible region to develop bounds z < z ∗ < z on z ∗ .
For a maximization problem, the lower bound z is the highest value of any feasible integer point encountered.
The upper bound is given by the optimal value of the associated linear program or by the largest value for
the objective function at any ‘‘hanging’’ box. After considering a subdivision, we must branch to (move to)
another subdivision and analyze it. Also, if either
One common method used in practice is to consider subdivisions on a last-generated–first-analyzed basis. We used
this rule in our previous example. Note that data to initiate the dual-simplex method mentioned above must be stored for
each subdivision that has yet to be analyzed. This data usually is stored in a list, with new information being added to the
top of the list. When required, data then is extracted from the top of this list, leading to the last-generated–first-analyzed
rule. Observe that when we subdivide a region into two subdivisions, one of these subdivisions will be analyzed next.
The data required for this analysis already will be in the computer core and need not be extracted from the list.
i) the linear program over L j is infeasible;
ii) the optimal linear-programming solution over L j is integer; or
iii) the value of the linear-programming solution z j over L j satisfies z j ≤ z (if maximizing),
then L j need not be subdivided. In these cases, integer-programming terminology says that L j has been
fathomed.† Case (i) is termed fathoming by infeasibility, (ii) fathoming by integrality, and (iii) fathoming by
The flow chart in Fig. 9.17 summarizes the general procedure.
Figure 9.17 Branch-and-bound for integer-programming maximization.
† To fathom is defined as ‘‘to get to the bottom of; to understand thoroughly.’’ In this chapter, fathomed might be more
appropriately defined as ‘‘understood enough or already considered.’’
BRANCH-AND-BOUND FOR MIXED-INTEGER PROGRAMS
The branch-and-bound approach just described is easily extended to solve problems in which some, but not
all, variables are constrained to be integral. Subdivisions then are generated solely by the integral variables.
In every other way, the procedure is the same as that specified above. A brief example will illustrate the
The problem, as stated, is in canonical form, with x3 and x4 optimal basic variables for the associated linear
The continuous variable x4 cannot be used to generate subdivisions since any value of x4 ≥ 0 potentially
can be optimal. Consequently, the subdivisions must be defined by x3 ≤ 2 and x3 ≥ 3. The complete
procedure is summarized by the enumeration tree in Fig. 9.18.
The solution in L 1 satisfies the integrality restrictions, so z ∗ ≥ z = 8 21 . The only integral variable with a
fractional value in the optimal solution of L 2 is x2 , so subdivisions L 3 and L 4 are generated from this variable.
Finally, the optimal linear-programming value of L 4 is 8, so no feasible mixed-integer solution in that region
can be better than the value 8 21 already generated. Consequently, that region need not be subdivided and the
The dual-simplex iterations that solve the linear programs in L 1 , L 2 , L 3 , and L 4 are given below in
Tableau 1. The variables s j in the tableaus are the slack variables for the
constraints added to generate the subdivisions. The coefficients in the appended constraints are determined
as we mentioned in the last section, by eliminating the basic variables x j from the new constraint that is
introduced. To follow the iterations, recall that in the dual-simplex method, pivots are made on negative
elements in the generating row; if all elements in this row are positive, as in region L 3 , then the problem is
A special branch-and-bound procedure can be given for integer programs with only binary variables. The
algorithm has the advantage that it requires no linear-programming solutions. It is illustrated by the following
z ∗ = max z = −8x1 − 2x2 − 4x3 − 7x4 − 5x5 + 10,
One way to solve such problems is complete enumeration. List all possible binary combinations of the
variables and select the best such point that is feasible. The approach works very well on a small problem
such as this, where there are only a few potential 0–1 combinations for the variables, here 32. In general,
though, an n-variable problem contains 2n 0–1 combinations; for large values of n, the exhaustive approach
is prohibitive. Instead, one might implicitly consider every binary combination, just as every integer point
was implicitly considered, but not necessarily evaluated, for the general problem via branch-and-bound.
Recall that in the ordinary branch-and-bound procedure, subdivisions were analyzed by maintaining the
linear constraints and dropping the integrality restrictions. Here, we adopt the opposite tactic of always
maintaining the 0–1 restrictions, but ignoring the linear inequalities.
The idea is to utilize a branch-and-bound (or subdivision) process to fix some of the variables at 0 or
1. The variables remaining to be specified are called free variables. Note that, if the inequality constraints
are ignored, the objective function is maximized by setting the free variables to zero, since their objectivefunction coefficients are negative. For example, if x1 and x4 are fixed at 1 and x5 at 0, then the free variables
are x2 and x3 . Ignoring the inequality constraints, the resulting problem is:
max [−8(1) − 2x2 − 4x3 − 7(1) − 5(0) + 10] = max [−2x2 − 4x3 − 5],
Since the free variables have negative objective-function coefficients, the maximization sets x2 = x3 = 0.
The simplicity of this trivial optimization, as compared to a more formidable linear program, is what we
Returning to the example, we start with no fixed variables, and consequently every variable is free and set
to zero. The solution does not satisfy the inequality constraints, and we must subdivide to search for feasible
solutions. One subdivision choice might be:
Now variable x1 is fixed in each subdivision. By our observations above, if the inequalities are ignored, the
optimal solution over each subdivision has x2 = x3 = x4 = x5 = 0. The resulting solution in subdivision 1
z = −8(1) − 2(0) − 4(0) − 7(0) − 5(0) + 10 = 2,
and happens to satisfy the inequalities, so that the optimal solution to the original problem is at least 2, z ∗ ≥ 2.
Also, subdivision 1 has been fathomed: The above solution is best among all 0–1 combinations with x1 = 1;
thus it must be best among those satisfying the inequalities. No other feasible 0–1 combination in subdivision
1 needs to be evaluated explicitly. These combinations have been considered implicitly.
The solution with x2 = x3 = x4 = x5 = 0 in subdivision 2 is the same as the original solution with
every variable at zero, and is infeasible. Consequently, the region must be subdivided further, say with
The enumeration tree to this point is as given in Fig. 9.19.
Observe that this tree differs from the enumeration trees of the previous sections. For the earlier procedures, the linear-programming solution used to analyze each subdivision was specified explicitly in a box.
Here the 0–1 solution (ignoring the inequalities) used to analyze subdivisions is not stated explicitly, since
it is known simply by setting free variables to zero. In subdivision 3i, for example, x1 = 0 and x2 = 1 are
fixed, and the free variables x3 , x4 andx5 are set to zero.
Continuing to fix variables and subdivide in this fashion produces the complete tree shown in Fig. 9.20.
The tree is not extended after analyzing subdivisions 4, 5, 7, 9, and 10, for the following reasons.
i) At 5i, the solution x1 = 0, x2 = x3 = 1 , with free variables x4 = x5 = 0, is feasible, with z = 4 ,
thus providing an improved lower bound on z ∗ .
ii) At 7i, the solution x1 = x3 = 0, x2 = x4 = 1, and free variable x5 = 0, has z = 1 < 4, so that no
solution in that subdivision can be as good as that generated at 5i.
iii) At 9iand 10i, every free variable is fixed. In each case, the subdivisions contain only a single point,
which is infeasible, and further subdivision is not possible.
iv) At 4i, the second inequality (with fixed variables x1 = x2 = 0) reads:
No 0–1 values of x3 , x4 , or x5 ‘‘completing’’ the fixed variables x1 = x2 = 0 satisfy this constraint,
since the lowest value for the lefthand side of this equation is −3 when x3 = x4 = 1 and x5 = 0. The
subdivision then has no feasible solution and need not be analyzed further.
The last observation is completely general. If, at any point after substituting for the fixed variables,
the sum of the remaining negative coefficients in any constraint exceeds the righthand side, then the region
defined by these fixed variables has no feasible solution. Due to the special nature of the 0–1 problem, there
are a number of other such tests that can be utilized to reduce the number of subdivisions generated. The
efficiency of these tests is measured by weighing the time needed to perform them against the time saved by
The techniques used here apply to any integer-programming problem involving only binary variables,
so that implicit enumeration is an alternative branch-and-bound procedure for this class of problems. In this
case, subdivisions are fathomed if any of three conditions hold:
i) the integer program is known to be infeasible over the subdivision, for example, by the above infeasibility
ii) the 0–1 solution obtained by setting free variables to zero satisfies the linear inequalities; or
iii) the objective value obtained by setting free variables to zero is no larger than the best feasible 0–1
These conditions correspond to the three stated earlier for fathoming in the usual branch-and-bound procedure.
If a region is not fathomed by one of these tests, implicit enumeration subdivides that region by selecting any
free variable and fixing its values to 0 or 1.
Our arguments leading to the algorithm were based upon stating the original 0–1 problem in the following
1. the objective is a maximization with all coefficients negative; and
2. constraints are specified as ‘‘less than or equal to’’ inequalities.
As usual, minimization problems are transformed to maximization by multiplying cost coefficients by −1.
If x j appears in the maximization form with a positive coefficient, then the variable substitution x j = 1 − x 0j
everywhere in the model leaves the binary variable x 0j with a negative objective-function coefficient. Finally,
‘‘greater than or equal to’’ constraints can be multiplied by −1 to become ‘‘less than or equal to’’ constraints;
and general equality constraints are converted to inequalities by the special technique discussed in Exercise
Like the branch-and-bound procedure for general integer programs, the way we choose to subdivide
regions can have a profound effect upon computations. In implicit enumeration, we begin with the zero
solution x1 = x2 = · · · = xn = 0 and generate other solutions by setting variables to 1. One natural approach
is to subdivide based upon the variable with highest objective contribution. For the sample problem, this
would imply subdividing initially with x2 = 1 or x2 = 0.
Another approach often used in practice is to try to drive toward feasibility as soon as possible. For
instance, when x1 = 0, x2 = 1, and x3 = 0 are fixed in the example problem, we could subdivide based
upon either x4 or x5 . Setting x4 or x5 to 1 and substituting for the fixed variables, we find that the constraints
For x4 = 1, the first constraint is infeasible by 1 unit and the second constraint is feasible, giving 1 total unit
of infeasibility. For x5 = 1, the first constraint is infeasible by 2 units and the second by 2 units, giving 4
total units of infeasibility. Thus x4 = 1 appears more favorable, and we would subdivide based upon that
variable. In general, the variable giving the least total infeasibilities by this approach would be chosen next.
Reviewing the example problem the reader will see that this approach has been used in our solution.
The cutting-plane algorithm solves integer programs by modifying linear-programming solutions until the
integer solution is obtained. It does not partition the feasible region into subdivisions, as in branch-and-bound
approaches, but instead works with a single linear program, which it refines by adding new constraints. The
new constraints successively reduce the feasible region until an integer optimal solution is found.
In practice, the branch-and-bound procedures almost always outperform the cutting-plane algorithm.
Nevertheless, the algorithm has been important to the evolution of integer programming. Historically, it was
the first algorithm developed for integer programming that could be proved to converge in a finite number of
steps. In addition, even though the algorithm generally is considered to be very inefficient, it has provided
insights into integer programming that have led to other, more efficient, algorithms.
Again, we shall discuss the method by considering the sample problem of the previous sections:
s1 and s2 are, respectively, slack variables for the first and second constraints.
Solving the problem by the simplex method produces the following optimal tableau:
Let us rewrite these equations in an equivalent but somewhat altered form:
These algebraic manipulations have isolated integer coefficients to one side of the equalities and fractions to
the other, in such a way that the constant terms on the righthand side are all nonnegative and the slack variable
coefficients on the righthand side are all nonpositive.
In any integer solution, the lefthand side of each equation in the last tableau must be integer. Since s1 and
s2 are nonnegative and appear to the right with negative coefficients, each righthand side necessarily must
be less than or equal to the fractional constant term. Taken together, these two observations show that both
sides of every equation must be an integer less than or equal to zero (if an integer is less than or equal to a
fraction, it necessarily must be 0 or negative). Thus, from the first equation, we may write:
Similarly, other conditions can be generated from the remaining constraints:
Note that, in this case, (C1 ) and (C3 ) are identical.
The new equations (C1 ), (C2 ), and (C3 ) that have been derived are called cuts for the following reason:
Their derivation did not exclude any integer solutions to the problem, so that any integer feasible point to the
original problem must satisfy the cut constraints. The linear-programming solution had s1 = s2 = 0; clearly,
these do not satisfy the cut constraints. In each case, substituting s1 = s2 = 0 gives either s3 , s4 , or s5 < 0.
Thus the net effect of a cut is to cut away the optimal linear-programming solution from the feasible region
without excluding any feasible integer points.
The geometry underlying the cuts can be established quite easily. Recall from (11) that slack variables
Substituting these values in the cut constraints and rearranging, we may rewrite the cuts as:
In this form, the cuts are displayed in Fig. 9.21. Notethat they exhibit the features suggested above. In each
case, the added cut removes the linear-programming solution x1 = 49 , x2 = 15
the same time including every feasible integer solution.
The basic strategy of the cutting-plane technique is to add cuts (usually only one) to the constraints
defining the feasible region and then to solve the resulting linear program. If the optimal values for the
decision variables in the linear program are all integer, they are optimal; otherwise, a new cut is derived from
the new optimal linear-programming tableau and appended to the constraints.
Note from Fig. 9.21 that the cut C1 = C3 leads directly to the optimal solution. Cut C2 does not, and
further iterations will be required if this cut is appended to the problem (without the cut C1 = C3 ). Also
note that C1 cuts deeper into the feasible region than does C2 . For problems with many variables, it is
generally quite difficult to determine which cuts will be deep in this sense. Consequently, in applications, the
algorithm frequently generates cuts that shave very little from the feasible region, and hence the algorithm’s
A final point to be considered here is the way in which cuts are generated. The linear-programming
tableau for the above problem contained the constraint:
Figure 9.21 Cutting away the linear-programming solution.
Suppose that we round down the fractional coefficients to integers, that is, 49 to 2, − 41 to −1, and 49 to 2.
Writing these integers to the left of the equality and the remaining fractions to the right, we obtain as before,
Another example may help to clarify matters. Suppose that the final linear-programming tableau to a
Observe the way that fractions are determined for negative coefficients. The fraction in the cut constraint
determined by the x7 coefficient − 67 = −1 16 is not 16 , but rather it is the fraction generated by rounding down
to −2; i.e., the fraction is −1 16 − (−2) = 56 .
Tableau 2 shows the complete solution of the sample problem by the cutting-plane technique. Since cut
C1 = C3 leads directly to the optimal solution, we have chosen to start with cut C2 . Note that, if the slack
variable for any newly generated cut is taken as the basic variable in that constraint, then the problem is in
the proper form for the dual-simplex algorithm. For instance, the cut in Tableau 2(b) generated from the x1
x1 + 73 s1 − 13 s2 = 73 or x1 + 2s1 − s2 − 2 = 31 − 13 s1 − 23 s2
Letting s4 be the slack variable in the constraint, we obtain:
Since s1 and s2 are nonbasic variables, we may take s4 to be the basic variable isolated in this constraint (see
By making slight modifications to the cutting-plane algorithm that has been described, we can show that
an optimal solution to the integer-programming problem will be obtained, as in this example, after adding
only a finite number of cuts. The proof of this fact by R. Gomory in 1958 was a very important theoretical
break-through, since it showed that integer programs can be solved by some linear program (the associated
linear program plus the added constraints). Unfortunately, the number of cuts to be added, though finite, is
usually quite large, so that this result does not have important practical ramifications.
1. As the leader of an oil-exploration drilling venture, you must determine the least-cost selection of 5 out of 10 possible
sites. Label the sites S1 , S2 , . . . , S10 , and the exploration costs associated with each as C1 , C2 , . . . , C10 .
Regional development restrictions are such that:
i) Evaluating sites S1 and S7 will prevent you from exploring site S8 .
ii) Evaluating site S3 or S4 prevents you from assessing site S5 .
iii) Of the group S5 , S6 , S7 , S8 , only two sites may be assessed.
Formulate an integer program to determine the minimum-cost exploration scheme that satisfies these restrictions.
2. A company wishes to put together an academic ‘‘package’’ for an executive training program. There are five area
colleges, each offering courses in the six fields that the program is designed to touch upon.
The package consists of 10 courses; each of the six fields must be covered.
The tuition (basic charge), assessed when at least one course is taken, at college i is Ti (independent of
the number of courses taken). Moreover, each college imposes an additional charge (covering course materials,
instructional aids, and so forth) for each course, the charge depending on the college and the field of instructions.
Formulate an integer program that will provide the company with the minimum amount it must spend to meet
3. The marketing group of A. J. Pitt Company is considering the options available for its next advertising campaign
program. After a great deal of work, the group has identified a selected number of options with the characteristics
magazine Newspaper Radio magazine campaign
The objective of the advertising program is to maximize the number of customers reached, subject to the
limitation of resources (money, designers, and salesman) given in the table above. In addition, the following
i) If the promotional campaign is undertaken, it needs either a radio or a popular magazine campaign effort to
ii) The firm cannot advertise in both the trade and popular magazines.
Formulate an integer-programming model that will assist the company to select an appropriate advertising campaign
4. Three different items are to be routed through three machines. Each item must be processed first on machine 1, then
on machine 2, and finally on machine 3. The sequence of items may differ for each machine. Assume that the times
ti j required to perform the work on item i by machine j are known and are integers. Our objective is to minimize
the total time necessary to process all the items.
a) Formulate the problem as an integer programming problem. [Hint. Let xi j be the starting time of processing
item i on machine j. Your model must prevent two items from occupying the same machine at the same time;
also, an item may not start processing on machine (j + 1) unless it has completed processing on machine j.]
b) Suppose we want the items to be processed in the same sequence on each machine. Change the formulation in
a) Reformulate the problem as an equivalent integer linear program.
b) How would your answer to part (a) change if the objective function were changed to:
6. Formulate, but do not solve, the following mathematical-programming problems. Also, indicate the type of algorithm
a) A courier traveling to Europe can carry up to 50 kilograms of a commodity, all of which can be sold for $40 per
kilogram. The round-trip air fare is $450 plus $5 per kilogram of baggage in excess of 20 kilograms (one way).
Ignoring any possible profits on the return trip, should the courier travel to Europe and, if so, how much of the
commodity should be taken along in order to maximize his profits?
b) A copying service incurs machine operating costs of:
and has a capacity of 1000 copies per hour. One hour has been reserved for copying a 10-page article to be sold
to MBA students. Assuming that all copies can be sold for $0.50 per article, how many copies of the article
c) A petrochemical company wants to maximize profit on an item that sells for $0.30 per gallon. Suppose that
increased temperature increases output according to the graph in Fig. E9.1. Assuming that production costs are
directly proportional to temperature as $7.50 per degree centigrade, how many gallons of the item should be
7. Suppose that you are a ski buff and an entrepreneur. You own a set of hills, any or all of which can be developed.
Figure E9.2 illustrates the nature of the cost for putting ski runs on any hill.
The cost includes fixed charges for putting new trails on a hill. For each hill j, there is a limit d j on the number
of trails that can be constructed and a lower limit t j on the number of feet of trail that must be developed if the hill
Use a piecewise linear approximation to formulate a strategy based on cost minimization for locating the ski
runs, given that you desire to have M total feet of developed ski trail in the area.
8. Consider the following word game. You are assigned a number of tiles, each containing a letter a, b, . . . , or z from
the alphabet. For any letter α from the alphabet, your assignment includes Nα (a nonnegative integer) tiles with
the letter α. From the letters you are to construct any of the words w1 , w2 , . . . , wn . This list might, for example,
contain all words from a given dictionary.
You may construct any word at most once, and use any tile at most once. You receive v j ≥ 0 points for making
word w j and an additional bonus of bi j ≥ 0 points for making both words wi and w j (i = 1, 2, …, n; j = 1, 2, …,
a) Formulate a linear integer program to determine your optimal choice of words.
b) How does the formulation change if you are allowed to select 100 tiles with no restriction on your choice of
9. In Section 9.1 of the text, we presented the following simplified version of the warehouse-location problem:
(i = 1, 2, . . . , m; j = 1, 2, . . . , n)
a) The above model assumes only one product and two distribution stages (from warehouse to customer). Indicate
how the model would be modified if there were three distribution stages (from plant to warehouse to customer)
and L different products. [Hint. Define a new decision variable xi jkl equal to the amount to be sent from plant
i, through warehouse j, to customer k, of product `.]
b) Suppose there are maximum capacities for plants and size limits (both upper and lower bounds) for warehouses.
c) Assume that each customer has to be served from a single warehouse; i.e., no splitting of orders is allowed. How
should the warehousing model be modified? [Hint. Define a new variable z jk = fraction of demand of customer
d) Assume that each warehouse i experiences economies of scale when shipping above a certain threshold quantity
to an individual customer; i.e., the unit distribution cost is ci j whenever the amount shipped is between 0 and
di j , and ci0 j (lower than ci j ) whenever the amount shipped exceeds di j . Formulate the warehouse location model
Apply the branch-and-bound procedure, graphically solving each linear-programming problem encountered. Interpret the branch-and-bound procedure graphically as well.
11. Solve the following integer program using the branch-and-bound technique:
The optimal tableau to the linear program associated with this problem is:
The variables x4 and x5 are slack variables for the two constraints.
12. Use branch-and-bound to solve the mixed-integer program:
13. Solve the mixed-integer programming knapsack problem:
14. Solve the following integer program using implicit enumeration:
15. A college intramural four-man basketball team is trying to choose its starting line-up from a six-man roster so as to
maximize average height. The roster follows:
The starting line-up must satisfy the following constraints:
ii) Either John or Ken must be held in reserve.
iv) If John or Rich starts, then Jim cannot start.
a) Formulate this problem as an integer program.
b) Solve for the optimal starting line-up, using the implicit enumeration algorithm.
16. Suppose that one of the following constraints arises when applying the implicit enumeration algorithm to a 0−1
In each case, the variables on the lefthand side of the inequalities are free variables and the righthand-side coefficients
include the contributions of the fixed variables.
a) Use the feasibility test to show that constraint (1) contains no feasible completion.
b) Show that x2 = 1 and x4 = 0 in any feasible completion to constraint (2). State a general rule that shows when a
variable x j , like x2 or x4 in constraint (2), must be either 0 or 1 in any feasible solution. [Hint. Apply the usual
feasibility test after setting x j to 1 or 0.]
c) Suppose that the objective function to minimize is:
and that z = 17 is the value of an integer solution obtained previously. Show that x3 = 0 in a feasible completion
to constraint (3) that is a potential improvement upon z with z < z. (Note that either x1 = 1 or x2 = 1 in any
feasible solution to constraint (3) having x3 = 1.)
d) How could the tests described in parts (b) and (c) be used to reduce the size of the enumeration tree encountered
to a zero–one integer program both have feasible solutions, the system composed of both constraints is infeasible.
One way to exhibit the inconsistency in the system is to add the two constraints, producing the constraint
which has no feasible solution with x2 = 0 or 1.
More generally, suppose that we multiply the ith constraint of a system
by nonnegative constraints u i and add to give the composite, or surrogate, constraint:
a) Show that any feasible solution x j = 0 or 1 ( j = 1, 2, . . . , n) for the system of constraints must also be feasible
b) How might the fathoming tests discussed in the previous exercise be used in conjunction with surrogate constraints
c) A ‘‘best’’ surrogate constraint might be defined as one that eliminates as many nonoptimal solutions x j = 0 or 1
as possible. Consider the objective value of the integer program when the system constraints are replaced by the
surrogate constraint; that is the problem:
Let us say that a surrogate constraint with multipliers u 1 , u 2 . . . , u m is stronger than another surrogate constraint
with multipliers u 1 , u 2 , . . . , u m , if the value v(u) of the surrogate constraint problem with multipliers u 1 , u 2 , . . . , u m
is larger than the value of v(u) with multipliers u 1 , u 2 , . . . , u m . (The larger we make v(u), the more nonoptimal
Suppose that we estimate the value of v(u) defined above by replacing x j = 0 or 1 by 0 ≤ x j ≤ 1 for
j = 1, 2, . . . , n. Then, to estimate the strongest surrogate constraint, we would need to find those values of the
multipliers u 1 , u 2 , . . . , u m to maximize v(u), where
v(u) = Min c1 x1 + c2 x2 + · · · + cn xn ,
Show that the optimal shadow prices to the linear program
solve the problem of maximizing v(u) in (1).
18. The following tableau specifies the solution to the linear program associated with the integer program presented
a) Derive cuts from each of the rows in the optimal linear-programming tableau, including the objective function.
b) Express the cuts in terms of the variables x1 and x2 . Graph the feasible region for x1 and x2 and illustrate the
c) Append the cut derived from the objective function to the linear program, and re-solve. Does the solution to this
new linear program solve the integer program? If not, how would you proceed to find the optimal solution to the
19. Given the following integer linear program:
solve, using the cutting-plane algorithm. Illustrate the cuts on a graph of the feasible region.
which has the same ‘‘contribution’’ for each item under consideration, has proved to be rather difficult to solve for
most general-purpose integer-programming codes when n is an odd number.
a) What is the optimal solution when n is even? when n is odd?
b) Comment specifically on why this problem might be difficult to solve on general integer-programming codes
21. Suppose that a firm has N large rolls of paper, each W inches wide. It is necessary to cut Ni rolls of width Wi from
these rolls of paper. We can formulate this problem by defining variables
xi j = Number of smaller rolls of width Wi cut from large roll j.
We assume there are m different widths Wi . In order to cut all the required rolls of width Wi , we need constraints
Further, the number of smaller rolls cut from a large roll is limited by the width W of the large roll. Assuming no
loss due to cutting, we have constraints of the form:
a) Formulate an objective function to minimize the number of large rolls of width W used to produce the smaller
b) Reformulate the model to minimize the total trim loss resulting from cutting. Trim loss is defined to be that part
of a large roll that is unusable due to being smaller than any size needed.
c) Comment on the difficulty of solving each formulation by a branch-and-bound method.
d) Reformulate the problem in terms of the collection of possible patterns that can be cut from a given large roll.
e) Comment on the difficulty of solving the formulation in (d), as opposed to the formulations in (a) or (b), by a
22. The Bradford Wire Company produces wire screening woven on looms in a process essentially identical to that of
weaving cloth. Recently, Bradford has been operating at full capacity and is giving serious consideration to a major
capital investment in additional looms. They currently have a total of 43 looms, which are in production all of their
available hours. In order to justify the investment in additional looms, they must analyze the utilization of their
Of Bradford’s 43 looms, 28 are 50 inches wide, and 15 are 80 inches wide. Normally, one or two widths totaling
less than the width of the loom are made on a particular loom. With the use of a ‘‘center-tucker,’’ up to three widths
can be simultaneously produced on one loom; however, in this instance the effective capacities of the 50-inch and
80-inch looms are reduced to 49 inches and 79 inches, respectively. Under no circumstance is it possible to make
more than three widths simultaneously on any one loom.
Figure E9.3 gives a typical loom-loading configuration at one point in time. Loom #1, which is 50 inches wide,
has two 24-inch widths being produced on it, leaving 2 inches of unused or ‘‘wasted’’ capacity. Loom #12 has
only a 31-inch width on it, leaving 19 inches of the loom unused. If there were an order for a width of 19 inches or
less, then it could be produced at zero marginal machine cost along with the 31-inch width already being produced
on this loom. Note that loom #40 has widths of 24, 26, and 28 inches, totaling 78 inches. The ‘‘waste’’ here is
considered to be only 1 inch, due to the reduced effective capacity from the use of the center-tucker. Note also that
the combination of widths 24, 26, and 30 is not allowed, for similar reasons.
The total of 383 43 inches of ‘‘wasted’’ loom capacity represents roughly seven and one-half 50-inch looms;
and members of Bradford’s management are sure that there must be a more efficient loom-loading configuration
that would save some of this ‘‘wasted’’ capacity. As there are always numerous additional orders to be produced,
any additional capacity can immediately be put to good use.
The two types of looms are run at different speeds and have different efficiencies. The 50-inch looms are
operated at 240 pics per second, while the 80-inch looms are operated at 214 pics per second. (There are 16 pics
to the inch). Further, the 50-inch looms are more efficient, since their ‘‘up time’’ is about 85% of the total time, as
The problem of scheduling the various orders on the looms sequentially over time is difficult. However, as
a first cut at analyzing how efficiently the looms are currently operating, the company has decided to examine the
loom-loading configuration at one point in time as given in Fig. E9-3. If these same orders can be rearranged in
such a way as to free up one or two looms, then it would be clear that a closer look at the utilization of existing
equipment would be warranted before additional equipment is purchased.
a) Since saving an 80-inch loom is not equivalent to saving a 50-inch loom, what is an appropriate objective function
b) Formulate an integer program to minimize the objective function suggested in part (a).
23. In the export division of Lowell Textile Mills, cloth is woven in lengths that are multiples of the piece-length required
by the customer. The major demand is for 18-meter piece-lengths, and the cloth is generally woven in 54-meter
Cloth cannot be sold in lengths greater than the stipulated piece-length. Lengths falling short are classified into
four groups. For 18-meter piece-lengths, the categories and the contribution per meter are as follows:
∗ Joined parts consist of lengths obtained by joining two pieces
such that the shorter piece is at least 6 meters long.
The current cutting practice is as follows. Each woven length is inspected and defects are flagged prominently.
The cloth is cut at these defects and, since the cloth is folded in exact meter lengths, the lengths of each cut piece is
known. The cut pieces are then cut again, if necessary, to obtain as many pieces of first sort as possible. The short
lengths are joined wherever possible to make joined parts.
Since the process is continuous, it is impossible to pool all the woven lengths and then decide on a cutting
pattern. Each woven length has to be classified for cutting before it enters the cutting room.
As an example of the current practice, consider a woven length of 54 meters with two defects, one at 19 meters
and one at 44 meters. The woven length is first cut at the defects, giving three pieces of lengths 19, 25, and 10
meters each. Then further cuts are made as follows: The resulting contribution is
2 × 18 × 1.00 + (7 + 10) × 0.75 + 1 × 0.60 = 49.35.
It is clear that this cutting procedure can be improved upon by the following alternative cutting plan: By joining 7
+ 11 and 8 + 10 to make two joined parts, the resulting contribution is:
Thus with one woven length, contribution can be increased by $1.05 by merely changing the cutting pattern. With a
daily output of 1000 such woven lengths (two defects on average), substantial savings could be realized by improved
a) Formulate an integer program to maximize the contribution from cutting the woven length described above.
b) Formulate an integer program to maximize the contribution from cutting a general woven length with no more
than four defects. Assume that the defects occur at integral numbers of meters.
c) How does the formulation in (b) change when the defects are not at integral numbers of meters?
24. Custom Pilot Chemical Company is a chemical manufacturer that produces batches of specialty chemicals to order.
Principal equipment consists of eight interchangeable reactor vessels, five interchangeable distillation columns, four
large interchangeable centrifuges, and a network of switchable piping and storage tanks. Customer demand comes
in the form of orders for batches of one or more (usually not more than three) specialty chemicals, normally to be
delivered simultaneously for further use by the customer. Customer Pilot Chemical fills these orders by means of a
sort of pilot plant for each specialty chemical formed by inter-connecting the appropriate quantities of equipment.
Sometimes a specialty chemical requires processing by more than one of these ‘‘pilot’’ plants, in which case one or
more batches of intermediate products may be produced for further processing. There is no shortage of piping and
holding tanks, but the expensive equipment (reactors, distillation columns, and centrifuges) is frequently inadequate
The company’s schedules are worked out in calendar weeks, with actual production always taking an integer
multiple of weeks. Whenever a new order comes in, the scheduler immediately makes up a precedence tree-chart for
it. The precedence tree-chart breaks down the order into ‘‘jobs.’’ For example, an order for two specialty chemicals,
of which one needs an intermediate stage, would be broken down into three jobs (Fig. E9.4). Each job requires
certain equipment, and each is assigned a preliminary time-in-process, or ‘‘duration.’’ The durations can always be
predicted with a high degree of accuracy.
Currently, Custom Pilot Chemical has three orders that need to be scheduled (see the accompanying table).
Orders can be started at the beginning of their arrival week and should be completed by the end of their week due.
Distillation Centrinumber number relations week in weeks due Reactors columns fuges
For example, AK14 consists of three jobs, where Job 2 cannot be started until Job 1 has been completed.
Figure E9-4 is an appropriate precedence tree for this order. Generally, the resources required are tied up for the
entire duration of a job. Assume that Custom Pilot Chemical is just finishing week 14.
a) Formulate an integer program that minimizes the total completion time for all orders.
b) With a more complicated list of orders, what other objective functions might be appropriate? How would these
25. A large electronics manufacturing firm that produces a single product is faced with rapid sales growth. Its planning
group is developing an overall capacity-expansion strategy, that would balance the cost of building new capacity,
the cost of operating the new and existing facilities, and the cost associated with unmet demand (that has to be
The following model has been proposed to assist in defining an appropriate strategy for the firm.
A binary integer variable that will be 1 if a facility exists at site
A binary integer variable that will be 1 if facility is constructed
The increase in capacity at site i in period t.
The decrease in capacity at site i in period t.
Total units produced at site i in period t.
Total unmet demand (subcontracted) units in period t.
Cost of operating a facility at site i in period t.
Cost of building a facility at site i in period t.
Cost of occupying 1 sq ft of fully equipped capacity at site i
Cost of increasing capacity by 1 sq ft at site i in period t.
Cost of decreasing capacity by 1 sq ft at site i in period t.
Cost of unmet demand (subcontracting + opportunity cost)
Tax-adjusted variable cost (material + labor + taxes) of
producing one unit at site i in period t.
Capacity needed (sq ft years) at site i in period t to produce
Maximum, minimum facility size at site i in period t (if the
Maximum growth (sq ft) of site i in period t.
The model’s objective function is to minimize total cost:
Explain the choice of decision variables, objective function, and constraints. Make a detailed discussion of the
model assumptions. Estimate the number of constraints, continuous variables, and integer variables in the model.
Is it feasible to solve the model by standard branch-and-bound procedures?
26. An investor is considering a total of I possible investment opportunities (i = 1, 2, . . . , I ), during a planning horizon
covering T time periods (t = 1, 2, . . . , T ). A total of bit dollars is required to initiate investment i in period t.
Investment in project i at time period t provides an income stream ai, t + 1 , ai, t + 2 , . . . , ai, T in succeeding time
periods. This money is available for reinvestment in other projects. The total amount of money available to the
investor at the beginning of the planning period is B dollars.
a) Assume that the investor wants to maximize the net present value of the net stream of cash flows (ct is the
corresponding discount factor for period t). Formulate an integer-programming model to assist in the investor’s
b) How should the model be modified to incorporate timing restrictions of the form:
i) Project j cannot be initiated until after project k has been initiated; or
ii) Projects j and k cannot both be initiated in the same period?
c) If the returns to be derived from these projects are uncertain, how would you consider the risk attitudes of the
decision-maker? [Hint. See Exercises 22 and 23 in Chapter 3.]
27. The advertising manager of a magazine faces the following problem: For week t, t = 1, 2 . . . , 13, she has been
allocated a maximum of n t pages to use for advertising. She has received requests r1 , r2 , . . . , r B for advertising,
ii) the duration dk of the ad (in weeks),
iii) the page allocation ak of the ad (half-, quarter-, or full-page),
The manager must determine which bids to accept to maximize revenue, subject to the following restrictions:
i) Any ad that is accepted must be run in consecutive weeks throughout its duration.
ii) The manager cannot accept conflicting ads. Formally, subsets T j and T̄ j for j = 1, 2, . . . , n of the bids are
given, and she may not select an ad from both T j and T̄ j ( j = 1, 2, . . . , n). For example, if T1 = {r1 , r2 }, T̄1 =
{r3 , r4 , r5 }, and bid r1 or r2 is accepted, then bids r3 , r4 , or r5 must all be rejected; if bid r3 , r4 , or r5 is accepted,
then bids r1 and r2 must both be rejected.
iii) The manager must meet the Federal Communication Commission’s balanced advertising requirements. Formally,
subsets S j and S̄ j for j = 1, 2, . . . , m of the bids are given; if she selects a bid from S j , she must also select a
bid from S̄ j ( j = 1, 2, . . . , m). For example, if S1 = {r1 , r3 , r8 } and S2 = {r4 , r6 }, then either request r4 or r6
must be accepted if any of the bids r1 , r3 , or r8 are accepted.
28. The m-traveling-salesman problem is a variant of the traveling-salesman problem in which m salesmen stationed
at a home base, city 1, are to make tours to visit other cities, 2, 3, . . . , n. Each salesman must be routed through
some, but not all, of the cities and return to his (or her) home base; each city must be visited by one salesman. To
avoid redundancy, the sales coordinator requires that no city (other than the home base) be visited by more than one
salesman or that any salesman visit any city more than once.
Suppose that it cost ci j dollars for any salesman to travel from city i to city j.
a) Formulate an integer program to determine the minimum-cost routing plan. Be sure that your formulation does
not permit subtour solutions for any salesman.
b) The m-traveling-salesman problem can be reformulated as a single-salesman problem as follows: We replace
the home base (city 1) by m fictitious cities
10 , 20 , . . . , m 0 . We link each of these fictitious cities to each
other with an arc with high cost M > i=1 j=1 |ci j |, and we connect each fictitious city i 0 to every city j at
cost ci 0 j = ci j . Figure E9.5 illustrates this construction for m = 3.
Suppose that we solve this reformulation as a single-traveling-salesman problem, but identify each portion of
the tour that travels from one of the fictitious cities i 0 through the original network and back to another fictitious city
j 0 as a tour for one of the m salesmen. Show that these tours solve the m-traveling-salesman problem. [Hint. Can
the solution to the single-salesman problem ever use any of the arcs with a high cost M? How many times must the
single salesman leave from and return to one of the fictitious cities?]
29. Many practical problems, such as fuel-oil delivery, newspaper delivery, or school-bus routing, are special cases of
the generic vehicle-routing problem. In this problem, a fleet of vehicles must be routed to deliver (or pick up) goods
from a depot, node 0, to n drop-points, i = 1, 2, . . . , n.
Q k = Loading capacity of the k th vehicle in the fleet (k = 1, 2, . . . , m);
di = Number of items to be left at drop-point i (i = 1, 2, . . . , n);
tik = Time to unload vehicle k at drop-point i (i = 1, 2, . . . n; k = 1, 2, . . . , m);
tikj = Time for vehicle k to travel from drop-point i to drop-point
j (i = 0, 1, . . . , n; j = 0, 1, . . . , n; k = 1, 2, . . . , m)
cikj = Cost for vehicle k to travel from node i to node j (i = 0, 1, . . . , n;
j = 0, 1, . . . , n; k = 1, 2, . . . , m).
If a vehicle visits drop-point i, then it fulfills the entire demand di at that drop-point. As in the traveling or
m-traveling salesman problem, only one vehicle can visit any drop-point, and no vehicle can visit the same droppoint more than once. The routing pattern must satisfy the service restriction that vehicle k’s route take longer than
Define the decision variables for this problem as:
if vehicle k travels from drop-point i to drop-point j,
Formulate an integer program that determines the minimum-cost routing pattern to fulfill demand at the drop-points
that simultaneously meets the maximum routing-time constraints and loads no vehicle beyond its capacity. How
many constraints and variables does the model contain when there are 400 drop-points and 20 vehicles?
Exercise 22 is based on the Bradford Wire Company case written by one of the authors. Exercise 23 is
extracted from the Muda Cotton Textiles case written by Munakshi Malya and one of the authors.
Exercise 24 is based on the Custom Pilot Chemical Co. case, written by Richard F. Meyer and Burton Rothberg,
which in turn is based on ‘‘Multiproject Scheduling with Limited Resources: A Zero–One Programming
Approach,’’ Management Science 1969, by A. A. B. Pritsken, L. J. Watters, and P. M. Wolfe.
In his master’s thesis (Sloan School of Management, MIT, 1976), entitled ‘‘A Capacity Expansion Planning
Model with Bender’s Decomposition,’’ M. Lipton presents a more intricate version of the model described
The transformation used in Exercise 28 has been proposed by several researchers; it appears in the 1971
book Distribution Management by S. Eilson, C. Watson-Gandy, and N. Christofides, Hafner Publishing Co.,
Dynamic programming is an optimization approach that transforms a complex problem into a sequence of
simpler problems; its essential characteristic is the multistage nature of the optimization procedure. More so
than the optimization techniques described previously, dynamic programming provides a general framework
for analyzing many problem types. Within this framework a variety of optimization techniques can be
employed to solve particular aspects of a more general formulation. Usually creativity is required before
we can recognize that a particular problem can be cast effectively as a dynamic program; and often subtle
insights are necessary to restructure the formulation so that it can be solved effectively.
We begin by providing a general insight into the dynamic programming approach by treating a simple
example in some detail. We then give a formal characterization of dynamic programming under certainty,
followed by an in-depth example dealing with optimal capacity expansion. Other topics covered in the
chapter include the discounting of future returns, the relationship between dynamic-programming problems
and shortest paths in networks, an example of a continuous-state-space problem, and an introduction to
In order to introduce the dynamic-programming approach to solving multistage problems, in this section we
analyze a simple example. Figure 11.1 represents a street map connecting homes and downtown parking
lots for a group of commuters in a model city. The arcs correspond to streets and the nodes correspond to
intersections. The network has been designed in a diamond pattern so that every commuter must traverse five
streets in driving from home to downtown. The design characteristics and traffic pattern are such that the total
time spent by any commuter between intersections is independent of the route taken. However, substantial
delays, are experienced by the commuters in the intersections. The lengths of these delays in minutes, are
indicated by the numbers within the nodes. We would like to minimize the total delay any commuter can
incur in the intersections while driving from his home to downtown. Figure 11.2 provides a compact tabular
representation for the problem that is convenient for discussing its solution by dynamic programming. In this
figure, boxes correspond to intersections in the network. In going from home to downtown, any commuter
must move from left to right through this diagram, moving at each stage only to an adjacent box in the next
column to the right. We will refer to the ‘‘stages to go," meaning the number of intersections left to traverse,
not counting the intersection that the commuter is currently in.
The most naive approach to solving the problem would be to enumerate all 150 paths through the diagram,
selecting the path that gives the smallest delay. Dynamic programming reduces the number of computations
by moving systematically from one side to the other, building the best solution as it goes.
Suppose that we move backward through the diagram from right to left. If we are in any intersection (box)
with no further intersections to go, we have no decision to make and simply incur the delay corresponding to
that intersection. The last column in Fig. 11.2 summarizes the delays with no (zero) intersections to go.
Figure 11.1 Street map with intersection delays.
Figure 11.2 Compact representation of the network.
Our first decision (from right to left) occurs with one stage, or intersection, left to go. If for example, we
are in the intersection corresponding to the highlighted box in Fig. 11.2, we incur a delay of three minutes in
this intersection and a delay of either eight or two minutes in the last intersection, depending upon whether
we move up or down. Therefore, the smallest possible delay, or optimal solution, in this intersection is
3 + 2 = 5 minutes. Similarly, we can consider each intersection (box) in this column in turn and compute the
smallest total delay as a result of being in each intersection. The solution is given by the bold-faced numbers
in Fig. 11.3. The arrows indicate the optimal decision, up or down, in any intersection with one stage, or one
Note that the numbers in bold-faced type in Fig. 11.3 completely summarize, for decision-making purposes, the total delays over the last two columns. Although the original numbers in the last two columns
have been used to determine the bold-faced numbers, whenever we are making decisions to the left of these
columns we need only know the bold-faced numbers. In an intersection, say the topmost with one stage to
go, we know that our (optimal) remaining delay, including the delay in this intersection, is five minutes. The
bold-faced numbers summarize all delays from this point on. For decision-making to the left of the bold-faced
With this in mind, let us back up one more column, or stage, and compute the optimal solution in each
intersection with two intersections to go. For example, in the bottom-most intersection, which is highlighted
in Fig. 11.3, we incur a delay of two minutes in the intersection, plus four or six additional minutes, depending
upon whether we move up or down. To minimize delay, we move up and incur a total delay in this intersection
and all remaining intersections of 2 + 4 = 6 minutes. The remaining computations in this column are
summarized in Fig. 11.4, where the bold-faced numbers reflect the optimal total delays in each intersection
with two stages, or two intersections, to go.
Once we have computed the optimal delays in each intersection with two stages to go, we can again move
back one column and determine the optimal delays and the optimal decisions with three intersections to go.
In the same way, we can continue to move back one stage at a time, and compute the optimal delays and
decisions with four and five intersections to go, respectively. Figure 11.5 summarizes these calculations.
Figure 11.5(c) shows the optimal solution to the problem. The least possible delay through the network
is 18 minutes. To follow the least-cost route, a commuter has to start at the second intersection from the
bottom. According to the optimal decisions, or arrows, in the diagram, we see that he should next move down
to the bottom-most intersection in column 4. His following decisions should be up, down, up, down, arriving
finally at the bottom-most intersection in the last column.
Figure 11.3 Decisions and delays with one intersection to go.
Figure 11.4 Decisions and delays with two intersections to go.
However, the commuters are probably not free to arbitrarily choose the intersection they wish to start
from. We can assume that their homes are adjacent to only one of the leftmost intersections, and therefore
each commuter’s starting point is fixed. This assumption does not cause any difficulty since we have, in
fact, determined the routes of minimum delay from the downtown parking lots to all the commuter’s homes.
Note that this assumes that commuters do not care in which downtown lot they park. Instead of solving the
minimum-delay problem for only a particular commuter, we have embedded the problem of the particular
commuter in the more general problem of finding the minimum-delay paths from all homes to the group
of downtown parking lots. For example, Fig. 11.5 also indicates that the commuter starting at the topmost
intersection incurs a delay of 22 minutes if he follows his optimal policy of down, up, up, down, and then
down. He presumably parks in a lot close to the second intersection from the top in the last column. Finally,
note that three of the intersections in the last column are not entered by any commuter. The analysis has
determined the minimum-delay paths from each of the commuter’s homes to the group of downtown parking
lots, not to each particular parking lot.
Using dynamic programming, we have solved this minimum-delay problem sequentially by keeping track
of how many intersections, or stages, there were to go. In dynamic-programming terminology, each point
where decisions are made is usually called a stage of the decision-making process. At any stage, we need
only know which intersection we are in to be able to make subsequent decisions. Our subsequent decisions do
not depend upon how we arrived at the particular intersection. Information that summarizes the knowledge
required about the problem in order to make the current decisions, such as the intersection we are in at a
particular stage, is called a state of the decision-making process.
In terms of these notions, our solution to the minimum-delay problem involved the following intuitive
idea, usually referred to as the principle of optimality.
Any optimal policy has the property that, whatever the current state and decision, the remaining decisions
must constitute an optimal policy with regard to the state resulting from the current decision.
To make this principle more concrete, we can define the optimal-value function in the context of the
vn (sn ) = Optimal value (minimum delay) over the current and subsequent stages (intersections), given that we are in state sn
(in a particular intersection) with n stages (intersections) to go.
The optimal-value function at each stage in the decision-making process is given by the appropriate column
Figure 11.5 Charts of optimal delays and decisions.
of Fig. 11.5(c). We can write down a recursive relationship for computing the optimal-value function by
recognizing that, at each stage, the decision in a particular state is determined simply by choosing the
minimum total delay. If we number the states at each stage as sn = 1 (bottom intersection) up to sn = 6 (top
vn (sn ) = Min {tn (sn ) + vn−1 (sn−1 )} ,
where tn (sn ) is the delay time in intersection sn at stage n.
The columns of Fig. 11.5(c) are then determined by starting at the right with
and successively applying Eq. (1). Corresponding to this optimal-value function is an optimal-decision
function, which is simply a list giving the optimal decision for each state at every stage. For this example,
the optimal decisions are given by the arrows leaving each box in every column of Fig. 11.5(c).
The method of computation illustrated above is called backward induction, since it starts at the right and
moves back one stage at a time. Its analog, forward induction, which is also possible, starts at the left and
moves forward one stage at a time. The spirit of the calculations is identical but the interpretation is somewhat
different. The optimal-value function for forward induction is defined by:
u n (sn ) = Optimal value (minimum delay) over the current andcompleted
stages (intersections), given that we are in state sn
(in a particular intersection) with n stages (intersections) to go.
The recursive relationship for forward induction on the minimum-delay problem is
u n−1 (sn−1 ) = Min {u n (sn ) + tn−1 (sn−1 )} ,
sn−1 = sn − 1 if we choose down and n odd,
where the stages are numbered in terms of intersections to go. The computations are carried out by setting
and successively applying (3). The calculations for forward induction are given in Fig. 11.6. When performing
forward induction, the stages are usually numbered in terms of the number of stages completed (rather than
the number of stages to go). However, in order to make a comparison between the two approaches easier, we
have avoided using the ‘‘stages completed" numbering.
The columns of Fig. 11.6(f) give the optimal-value function at each stage for the minimum-delay problem,
computed by forward induction. This figure gives the minimum delays from each particular downtown parking
lot to the group of homes of the commuters. Therefore, this approach will only guarantee finding the minimum
delay path from the downtown parking lots to one of the commuters’ homes. The method, in fact, finds the
minimum-delay path to a particular origin only if that origin may be reached from a downtown parking lot
by a backward sequence of arrows in Fig. 11.6(f).
If we select the minimum-delay path in Fig. 11.6(f), lasting 18 minutes, and follow the arrows backward,
we discover that this path leads to the intersection second from the bottom in the first column. This is the
same minimum-delay path determined by backward induction in Fig. 11.5(c).
Figure 11.6 Solution by forward induction.
Formalizing the Dynamic-Programming Approach
Forward induction determined the minimum-delay paths from each individual parking lot to the group
of homes, while backward induction determined the minimum-delay paths from each individual home to the
group of downtown parking lots. The minimum-delay path between the two groups is guaranteed to be the
same in each case but, in general, the remaining paths determined may be different. Therefore, when using
dynamic programming, it is necessary to think about whether forward or backward induction is best suited
FORMALIZING THE DYNAMIC-PROGRAMMING APPROACH
The elementary example presented in the previous section illustrates the three most important characteristics
The essential feature of the dynamic-programming approach is the structuring of optimization problems
into multiple stages, which are solved sequentially one stage at a time. Although each one-stage problem
is solved as an ordinary optimization problem, its solution helps to define the characteristics of the next
Often, the stages represent different time periods in the problem’s planning horizon. For example, the
problem of determining the level of inventory of a single commodity can be stated as a dynamic program.
The decision variable is the amount to order at the beginning of each month; the objective is to minimize the
total ordering and inventory-carrying costs; the basic constraint requires that the demand for the product be
satisfied. If we can order only at the beginning of each month and we want an optimal ordering policy for
the coming year, we coulddecompose the problem into 12 stages, each representing the ordering decision at
the beginning of the corresponding month.
Sometimes the stages do not have time implications. For example, in the simple situation presented
in the preceding section, the problem of determining the routes of minimum delay from the homes of the
commuters to the downtown parking lots was formulated as a dynamic program. The decision variable was
whether to choose up or down in any intersection, and the stages of the process were defined to be the number
of intersections to go. Problems that can be formulated as dynamic programs with stages that do not have
time implications are often difficult to recognize.
Associated with each stage of the optimization problem are the states of the process. The states reflect
the information required to fully assess the consequences that the current decision has upon future actions.
In the inventory problem given in this section, each stage has only one variable describing the state: the
inventory level on hand of the single commodity. The minimum-delay problem also has one state variable:
the intersection a commuter is in at a particular stage.
The specification of the states of the system is perhaps the most critical design parameter of the dynamicprogramming model. There are no set rules for doing this. In fact, for the most part, this is an art often
requiring creativity and subtle insight about the problem being studied. The essential properties that should
i) The states should convey enough information to make future decisions without regard to how the process
ii) The number of state variables should be small, since the computational effort associated with the dynamicprogramming approach is prohibitively expensive when there are more than two, or possibly three, state
variables involved in the model formulation.
This last feature considerably limits the applicability of dynamic programming in practice.
The final general characteristic of the dynamic-programming approach is the development of a recursive
optimization procedure, which builds to a solution of the overall N -stage problem by first solving a one-stage
problem and sequentially including one stage at a time and solving one-stage problems until the overall
optimum has been found. This procedure can be based on a backward induction process, where the first stage
to be analyzed is the final stage of the problem and problems are solved moving back one stage at a time until
all stages are included. Alternatively, the recursive procedure can be based on a forward induction process,
where the first stage to be solved is the initial stage of the problem and problems are solved moving forward
one stage at a time, until all stages are included. In certain problem settings, only one of these induction
processes can be applied (e.g., only backward induction is allowed in most problems involving uncertainties).
The basis of the recursive optimization procedure is the so-called principle of optimality, which has
already been stated: an optimal policy has the property that, whatever the current state and decision, the
remaining decisions must constitute an optimal policy with regard to the state resulting from the current
In what follows, we will formalize the ideas presented thus far. Suppose we have a multistage decision
process where the return (or cost) for a particular stage is:
where dn is a permissible decision that may be chosen from the set Dn , and sn is the state of the process with
n stages to go. Normally, the set of feasible decisions, Dn , available at a given stage depends upon the state
of the process at that stage, sn , and could be written formally as Dn (sn ). To simplify our presentation, we
will denote the set of feasible decisions simply as Dn . Now, suppose that there are a total of N stages in the
process and we continue to think of n as the number of stages remaining in the process. Necessarily, this
view implies a finite number of stages in the decision process and therefore a specific horizon for a problem
involving time. Further, we assume that the state sn of the system with n stages to go is a full description of
the system for decision-making purposes and that knowledge of prior states is unnecessary. The next state
of the process depends entirely on the current state of the process and the current decision taken. That is, we
can define a transition function such that, given sn , the state of the process with n stages to go, the subsequent
state of the process with (n − 1) stages to go is given by
where dn is the decision chosen for the current stage and state. Note that there is no uncertainty as to what
the next state will be, once the current state and current decision are known. In Section 11.7, we will extend
these concepts to include uncertainty in the formulation.
Our multistage decision process can be described by the diagram given in Fig. 11.7. Given the current
state sn which is a complete description of the system for decision-making purposes with n stages to go, we
want to choose the decision dn that will maximize the total return over the remaining stages. The decision
dn , which must be chosen from a set Dn of permissible decisions, produces a return at this stage of f n (dn , sn )
and results in a new state sn−1 with (n − 1) stages to go. The new state at the beginning of the next stage
is determined by the transition function sn−1 = tn (dn , sn ), and the new state is a complete description of the
system for decision-making purposes with (n − 1) stages to go. Note that the stage returns are independent
In order to illustrate these rather abstract notions, consider a simple inventory example. In this case, the
state sn of the system is the inventory level In with n months to go in the planning horizon. The decision dn
is the amount On to order this month. The resulting inventory level In−1 with (n − 1) months to go is given
by the usual inventory-balance relationship:
Formalizing the Dynamic-Programming Approach
where Rn is the demand requirement this month. Thus, formally, the transition function with n stages to go
The objective to be minimized is the total ordering and inventory-carrying costs, which is the sum of the
For the general problem, our objective is to maximize the sum of the return functions (or minimize the
sum of cost functions) over all stages of the decision process; and our only constraints on this optimization are
that the decision chosen for each stage belong to some set Dn of permissible decisions and that the transitions
from state to state be governed by Eq. (6). Hence, given that we are in state sn with n stages to go, our
optimization problem is to choose the decision variables dn , dn−1 , . . . , d0 to solve the following problems:
vn (sn ) = Max f n (dn , sn ) + f n−1 (dn−1 , sn−1 ) + · · · + f 0 (d0 , s0 ) ,
We call vn (sn ) the optimal-value function, since it represents the maximum return possible over the n stages
vn (sn ) = Optimal value of all subsequent decisions, given that we are in state
Now since f n (dn , sn ) involves only the decision variable dn and not the decision variables dn−1 , . . . , d0 ,
we could first maximize over this latter group for every possible dn and then choose dn so as to maximize the
entire expression. Therefore, we can rewrite Eq. (7) as follows:
vn (sn ) = Max f n (dn , sn ) + Max f n−1 (dn−1 , sn−1 ) + · · · + f 0 (d0 , s0 ) ,
Note that the second part of Eq. (8) is simply the optimal-value function for the (n − 1)-stage dynamicprogramming problem defined by replacing n with (n − 1) in (7). We can therefore rewrite Eq. (8) as the
vn (sn ) = Max f n (dn , sn ) + vn−1 (sn−1 ) ,
To emphasize that this is an optimization over dn , we can rewrite Eq. (9) equivalently as:
vn (sn ) = Max { f n (dn , sn ) + vn−1 [tn (dn , sn )]} ,
The relationship in either Eq. (9) or (10) is a formal statement of the principle of optimality. As we have
indicated, this principle says that an optimal sequence of decisions for a multistage problem has the property
that, regardless of the current decision dn and current state sn , all subsequent decisions must be optimal, given
the state sn−1 resulting from the current decision.
Since vn (sn ) is defined recursively in terms of vn−1 (sn−1 ), in order to solve Eqs. (9) or (10) it is
necessary to initiate the computation by solving the ‘‘stage-zero" problem. The stage-zero problem is not
defined recursively, since there are no more stages after the final stage of the decision process. The stage-zero
Often there is no stage-zero problem, as v0 (s0 ) is identically zero for all final stages. In the simple example of
the previous section, where we were choosing the path of minimum delay through a sequence of intersections,
the stage-zero problem consisted of accepting the delay for the intersection corresponding to each final state.
In this discussion, we have derived the optimal-value function for backward induction. We could easily
have derived the optimal-value function for forward induction, as illustrated in the previous section. However,
rather than develop the analogous result, we will only state it here. Assuming that we continue to number the
states ‘‘backwards," we can define the optimal-value function for forward induction as follows:
u n (sn ) = Optimal value of all prior decisions, given that we are in state sn
The optimal-value function is then given by:
u n−1 (sn−1 ) = Max [u n (sn ) + f n (dn , sn )] ,
where the computations are usually initialized by setting
or by solving some problem, external to the recursive relationship, that gives a value to being in a particular
initial state. Note that, for forward induction, you need to think of the problem as one of examining all the
combinations of current states and actions that produce a specific state at the next stage, and then choose
It should be pointed out that nothing has been said about the specific form of the stage-return functions
or the set of permissible decisions at each stage. Hence, what we have said so far holds regardless of whether
the decisions are discrete, continuous, or mixtures of the two. All that is necessary is that the recursive
relationship be solvable for the optimal solution at each stage, and then a global optimal solution to the
overall problem is determined. The optimization problem that is defined at each stage could lead to the
application of a wide variety of techniques, i.e., linear programming, network theory, integer programming,
and so forth, depending on the nature of the transition function, the constraint set Dn , and the form of the
It should also be pointed out that nowhere in developing the fundamental recursive relationship of dynamic
programming was any use made of the fact that there were a finite number of states at each stage. In fact,
Eqs. (9), (10), and (12) hold independent of the number of states. The recursive relationship merely needs to
be solved for all possible states of the system at each stage. If the state space, i.e., the set of possible states, is
continuous, and therefore an infinite number of states are possible at each stage, then the number of states is
usually made finite by making a discrete approximation of the set of possible states, and the same procedures
are used. An example of a dynamic-programming problem with a continuous state space is given in Section
Finally, we have assumed certainty throughout out discussion so far; this assumption will be relaxed in
Section 11.7, and a very similar formal structure will be shown to hold.
In this section, we further illustrate the dynamic-programming approach by solving a problem of optimal
capacity expansion in the electric power industry.
A regional electric power company is planning a large investment in nuclear power plants over the next
few years. A total of eight nuclear power plants must be built over the next six years because of both increasing
demand in the region and the energy crisis, which has forced the closing of certain of their antiquated fossilfuel plants. Suppose that, for a first approximation, we assume that demand for electric power in the region is
known with certainty and that we must satisfy the minimum levels of cumulative demand indicated in Table
11.1. The demand here has been converted into equivalent numbers of nuclear power plants required by the
end of each year. Due to the extremely adverse public reaction and subsequent difficulties with the public
utilities commission, the power company has decided at least to meet this minimum-demand schedule.
The building of nuclear power plants takes approximately one year. In addition to a cost directly associated
with the construction of a plant, there is a common cost of $1.5 million incurred when any plants are
constructed in any year, independent of the number of plants constructed. This common cost results from
contract preparation and certification of the impact statement for the Environmental Protection Agency. In
any given year, at most three plants can be constructed. The cost of construction per plant is given in Table
11.1 for each year in the planning horizon. These costs are currently increasing due to the elimination of an
investment tax credit designed to speed investment in nuclear power. However, new technology should be
available by 1984, which will tend to bring the costs down, even given the elimination of the investment tax
We can structure this problem as a dynamic program by defining the state of the system in terms of
the cumulative capacity attained by the end of a particular year. Currently, we have no plants under construction, and by the end of each year in the planning horizon we must have completed a number of plants
equal to or greater than the cumulative demand. Further, it is assumed that there is no need ever to construct more than eight plants. Figure 11.8 provides a graph depicting the allowable capacity (states) over
time. Any node of this graph is completely described by the corresponding year number and level of
cumulative capacity, say the node (n, p). Note that we have chosen to measure time in terms of years to go
in the planning horizon. The cost of traversing any upward-sloping arc is the common cost of $1.5 million
Table E11.1 Demand and cost per plant ($ ×1000)
Figure 11.8 Allowable capacity (states) for each tage
plus the plant costs, which depend upon the year of construction and whether 1, 2, or 3 plants are completed.
Measured in thousands of dollars, these costs are
where cn is the cost per plant in the year n and xn is the number of plants constructed. The cost for traversing
any horizontal arc is zero, since these arcs correspond to a situation in which no plant is constructed in the
Rather than simply developing the optimal-value function in equation form, as we have done previously,
we will perform the identical calculations in tableau form to highlight the dynamic-programming methodology. To begin, we label the final state zero or, equivalently define the ‘‘stage-zero" optimal-value function to
be zero for all possible states at stage zero. We will define a state as the cumulative total number of plants
completed. Since the only permissible final state is to construct the entire cumulative demand of eight plants,
Now we can proceed recursively to determine the optimal-value function with one stage remaining. Since the
demand data requires 7 plants by 1985, with one year to go the only permissible states are to have completed
7 or 8 plants. We can describe the situation by Tableau 1.
The dashes indicate that the particular combination of current state and decision results in a state that is
not permissible. In this table there are no choices, since, if we have not already completed eight plants, we
will construct one more to meet the demand. The cost of constructing the one additional plant is the $1500
common cost plus the $5200 cost per plant, for a total of $6700. (All costs are measured in thousands of
dollars.) The column headed d1∗ (s1 ) gives the optimal decision function, which specifies the optimal number
of plants to construct, given the current state of the system.
Now let us consider what action we should take with two years (stages) to go. Tableau 2 indicates the
If we have already completed eight plants with two years to go, then clearly we will not construct any
more. If we have already completed seven plants with two years to go, then we can either construct the one
plant we need this year or postpone its construction. Constructing the plant now costs $1500 in common
costs plus $5500 in variable costs, and results in state 8 with one year to go. Since the cost of state 8 with one
year to go is zero, the total cost over the last two years is $7000. On the other hand, delaying construction
costs zero this year and results in state 7 with one year to go. Since the cost of state 7 with one year to go is
$6700, the total cost over the last two years is $6700. If we arrive at the point where we have two years to go
and have completed seven plants, it pays to delay the production of the last plant needed. In a similar way,
we can determine that the optimal decision when in state 6 with two years to go is to construct two plants
To make sure that these ideas are firmly understood, we will determine the optimal-value function and
optimal decision with three years to go. Consider Tableau 3 for three years to go:
Now suppose that, with three years to go, we have completed five plants. We need to construct at least
one plant this year in order to meet demand. In fact, we can construct either 1, 2, or 3 plants. If we construct
one plant, it costs $1500 in common costs plus $5700 in plant costs, and results in state 6 with two years to
go. Since the minimum cost following the optimal policy for the remaining two years is then $12,500, our
total cost for three years would be $19,700. If we construct two plants, it costs the $1500 in common costs
plus $11,400 in plant costs and results in state 7 with two years to go. Since the minimum cost following the
optimal policy for the remaining two years is then $6700, our total cost for three years would be $19,600.
Finally, if we construct three plants, it costs the $1500 in common costs plus $17,100 in plant costs and
results in state 8 with two years to go. Since the minimum cost following the optimal policy for the remaining
Figure 11.9 Tableaus to complete power-plant example.
two years is then zero, our total cost for three years would be $18,600. Hence, the optimal decision, having
completed five plants (being in state 5) with three years (stages) to go, is to construct three plants this year.
The remaining tableaus for the entire dynamic-programming solution are determined in a similar manner (see
Since we start the construction process with no plants (i.e., in state 0) with six years (stages) to go, we
can proceed to determine the optimal sequence of decisions by considering the tableaus in the reverse order.
With six years to go it is optimal to construct three plants, resulting in state 3 with five years to go. It is then
optimal to construct three plants, resulting in state 6 with four years to go, and so forth. The optimal policy
Hence, from Tableau 6, the total cost of the policy is $48.8 million.
In the example on optimal capacity expansion presented in the previous section, a very legitimate objection
might be raised that the present value of money should have been taken into account in finding the optimal
construction schedule. The issue here is simply that a dollar received today is clearly worth more than a
dollar received one year from now, since the dollar received today could be invested to yield some additional
return over the intervening year. It turns out that dynamic programmingis extremely well suited to take this
We will define, in the usual way, the one-period discount factor β as the present value of one dollar
received one period from now. In terms of interest rates, if the interest rate for the period were i, then one
dollar invested now would accumulate to (1 + i) at the end of one period. To see the relationship between
the discount factor β and the interest rate i, we ask the question ‘‘How much must be invested now to yield
one dollar one period from now?" This amount is clearly the present value of a dollar received one period
from now, so that β(1 + i) = 1 determines the relationship between β and i, namely, β = 1/(1 + i). If we
invest one dollar now for n periods at an interest rate per period of i, then theaccumulated value at the end
of n periods, assuming the interest is compounded, is (1 + i)n . Therefore, the present value of one dollar
received n periods from now is 1/(1 + i)n or, equivalently, β n .
The concept of discounting can be incorporated into the dynamic-programming framework very easily
since we often have a return per period (stage) that we may wish to discount by the per-period discount factor.
If we have an n-stage dynamic-programming problem, the optimal-value function, including the appropriate
discounting of future returns, is given by
vn (sn ) = Max [ f n (dn , sn ) +β f n−1 (dn−1 , sn−1 ) + β 2 f n−2 (dn−2 , sn−2 )
sm−1 = tm (dm , sm )(m = 1, 2, . . . , n),
where the stages (periods) are numbered in terms of stages to go. Making the same argument as in Section
11.3 and factoring out the β, we can rewrite Eq. (13) as:
vn (sn ) = Max { f n (dn , sn ) + β Max [ f n−1 (dn−1 , sn−1 ) + β f n−2 (dn−2 , sn−2 )
Since the second part of Eq. (14) is simply the optimal-value function for the (n −1)-stage problem multiplied
vn (sn ) = Max[ f n (dn , sn ) + βvn−1 (sn−1 )],
which is simply the recursive statement of the optimal-value function for backward induction with discounting.
If β = 1, we have the case of no discounting and Eq. (15) is identical to Eq. (9). Finally, if the discount rate
depends on the period, β can be replaced by βn and (15) still holds.
We can look at the impact of discounting future-stage returns by considering again the optimal capacity
expansion problem presented in the previous section. Suppose that the alternative uses of funds by the electric
power company result in a 15 percent return on investment. This corresponds to a yearly discount factor of
approximately 0.87. If we merely apply backward induction to the capacity expansion problem according to
Eq. (15), using β = 0.87, we obtain the optimal-value function for each stage as given in Fig. 11.10.
Figure 11.10 Optimal-value and decision functions with discounting.
Given that the system is in state zero with six stages to go, we determine the optimal construction strategy
by considering the optimal decision function dn∗ (sn ) from stage 6 to stage 0. The optimal construction
sequence is then shown in the following tabulation:
and the optimal value of the criterion function, present value of total future costs, is $37.8 million for this
strategy. Note that this optimal strategy is significantly different from that computed in the previous section
without discounting. The effect of the discounting of future costs is to delay construction in general, which
Although we have not emphasized this fact, dynamic-programming and shortest-path problems are very
similar. In fact, as illustrated by Figs. 11.1 and 11.8, our previous examples of dynamic programming can
both be interpreted as shortest-path problems.
In Fig. 11.8, we wish to move through the network from the starting node (initial state) at stage 6, with
no plants yet constructed, to the end node (final state) at stage 0 with eight plants constructed. Every path in
the network specifies a strategy indicating how many new plants to construct each year.
Since the cost of a strategy sums the cost at each stage, the total cost corresponds to the ‘‘length" of a
path from the starting to ending nodes. The minimum-cost strategy then is just the shortest path.
Figure 11.11 illustrates a shortest-path network for the minimum-delay problem presented in Section
11.1. The numbers next to the arcs are delay times. An end node representing the group of downtown
parking lots has been added. This emphasizes the fact that we have assumed that the commuters do not care
in which lot they park. A start node has also been added to illustrate that the dynamic-programming solution
by backward induction finds the shortest path from the end node to the start node. In fact, it finds the shortest
paths from the end node to all nodes in the network, thereby solving the minimum-delay problem for each
commuter. On the other hand, the dynamic-programming solution by forward induction finds the shortest
path from the start node to the end node. Although the shortest path will be the same for both methods,
forward induction will not solve the minimum-delay problem for all commuters, since the commuters are not
To complete the equivalence that we have suggested between dynamic programming and shortest paths,
we next show how shortest-path problems can be solved by dynamic programming. Actually, several different
dynamic-programming solutions can be given, depending upon the structure of the network under study. As
a general rule, the more structured the network, the more efficient the algorithm that can be developed. To
illustrate this point we give two separate algorithms applicable to the following types of networks:
i) Acyclic networks. These networks contain no directed cycles. That is, we cannot start from any node and
follow the arcs in their given directions to return to the same node.
ii) Networks without negative cycles. These networks may contain cycles, but the distance around any cycle
(i.e., the sum of the lengths of its arcs) must be nonnegative.
In the first case, to take advantage of the acyclic structure of the network, we order the nodes so that, if the
network contains the arc i– j, then i > j. To obtain such an ordering, begin with the terminal node, which can
be thought of as having only entering arcs, and number it ‘‘one." Then ignore that node and the incident arcs,
and number any node that has only incoming arcs as the next node. Since the network is acyclic, there must be
Figure 11.11 Shortest-path network for minimum-delay problem.
such a node. (Otherwise, from any node, we can move along an arc to another node. Starting from any node
and continuing to move away from any node encountered, we eventually would revisit a node, determining
a cycle, contradicting the acyclic assumption.) By ignoring the numbered nodes and their incident arcs, the
procedure is continued until all nodes are numbered.
This procedure is applied, in Fig. 11.12, to the longest-path problem introduced as a critical-path scheduling example in Section 8.1.
Figure 11.12 Finding the longest path in an acyclic network.
We can apply the dynamic-programming approach by viewing each node as a stage, using either backward
induction to consider the nodes in ascending order, or forward induction to consider the nodes in reverse order.
For backward induction, vn will be interpreted as the longest distance from node n to the end node. Setting
v1 = 0, dynamic programming determines v2 , v3 , . . . , v N in order, by the recursion
where dn j is the given distance on arc n– j. The results of this procedure are given as node labels in Fig. 11.12
For a shortest-path problem, we use minimization instead of maximization in this recursion. Note that
the algorithm finds the longest (shortest) paths from every node to the end node. If we want only the longest
path to the start node, we can terminate the procedure once the start node has been labeled. Finally, we could
have found the longest distances from the start node to all other nodes by labeling the nodes in the reverse
Figure 11.13 Shortest paths in a network without negative cycles.
A more complicated algorithm must be given for the more general problem of finding the shortest path
between two nodes, say nodes 1 and N , in a network without negative cycles. In this case, we can devise a
dynamic-programming algorithm based upon a value function defined as follows:
vn ( j) = Shortest distance from node 1 to node j along paths using at
the length d1 j of arc 1– j since no intermediate nodes are used. The dynamic-programming recursion is
which uses the principle of optimality: that any path from node 1 to node j, using at most n intermediate
nodes, arrives at node j from node i along arc i– j after using the shortest path with at most (n − 1) intermediate nodes from node j to node i. We allow i = j in the recursion and take d j j = 0, since the optimal path
using at most n intermediate nodes may coincide with the optimal path with length vn−1 ( j) using at most
The algorithm computes the shortest path from node 1 to every other node in the network. It terminates
when vn ( j) = vn−1 ( j) for every node j, since computations in Eq. (16) will be repeated at every stage from
n on. Because no path (without cycles) uses any more than (N − 1) intermediate nodes, where N is the total
number of nodes, the algorithm terminates after at most (N − 1) steps.
As an application of the method, we solve the shortest-path problem introduced in Chapter 8 and given
Initially the values v0 ( j) are given by
since these nodes are not connected to node 1 by an arc. The remaining steps are specified in Tableaus 7,
8, and 9. The computations are performed conveniently by maintaining a table of distances di j . If the list
v0 (i) is placed to the left of this table, then recursion Eq. (14) states that v1 ( j) is given by the smallest of the
That is, place the column v0 (i) next to the jth column of the di j table, add the corresponding elements, and
take v1 ( j) as the smallest of the values. If v1 ( j) is recorded below the jth column, the next iteration to find
v2 ( j) is initiated by replacing the column v0 (i) with the elements v1 ( j) from below the distance table.
As the reader can verify, the next iteration gives v4 ( j) = v3 ( j) for all j. Consequently, the values v3 ( j)
recorded in Tableau 9 are the shortest distances from node 1 to each of the nodes j = 2, 3, . . . , 8.
Until now we have dealt only with problems that have had a finite number of states associated with each
stage. Since we also have assumed a finite number of stages, these problems have been identical to finding
the shortest path through a network with special structure. Since the development, in Section 11.3, of the
fundamental recursive relationship of dynamic programming did not depend on having a finite number of
states at each stage, here we introduce an example that has a continuous state space and show that the same
Suppose that some governmental agency is attempting to perform cost/benefit analysis on its programs in
order to determine which programs should receive funding for the next fiscal year. The agency has managed to
put together the information in Table 11.2. The benefits of each program have been converted into equivalent
tax savings to the public, and the programs have been listed by decreasing benefit-to-cost ratio. The agency
has taken the position that there will be no partial funding of programs. Either a program will be funded at
the indicated level or it will not be considered for this budget cycle. Suppose that the agency is fairly sure of
receiving a budget of $34 million from the state legislature if it makes a good case that the money is being
used effectively. Further, suppose that there is some possibility that the budget will be as high as $42 million.
How can the agency make the most effective use of its funds at either possible budget level?
Table 11.2 Cost/benefit information by program.
We should point out that mathematically this problem is an integer program. If b j is the benefit of the
jth program and c j is the cost of that program, then an integer-programming formulation of the agency’s
where B is the total budget allocated. This cost/benefit example is merely a variation of the well-known
knapsack problem that was introduced in Chapter 9.We will ignore, for the moment, this integer-programming
formulation and proceed to develop a highly efficient solution procedure using dynamic programming.
In order to approach this problem via dynamic programming, we need to define the stages of the system,
the state space for each stage, and the optimal-value function.
vk (B) = Maximum total benefit obtainable, choosing from the first
With this definition of the optimal-value function, we are letting the first k programs included be the number
of ‘‘stages to go" and the available budget at each stage be the state space. Since the possible budget might
take on any value, we are allowing for a continuous state space for each stage. In what follows the order of
the projects is immaterial although the order given in Table 11.2 may have some computational advantages.
Let us apply the dynamic-programming reasoning as before. It is clear that with k = 0 programs, the
total benefit must be zero regardless of the budget limitation. Therefore
If we now let k = 1, it is again clear that the optimal-value function can be determined easily since the budget
is either large enough to fund the first project, or not. (See Tableau 10.)
Now consider which programs to fund when the first two programs are available. The optimal-value
function v2 (B2 ) and optimal decision function d2∗ (B2 ) are developed in Tableau 11.
Here again the dash means that the current state and decision combination will result in a state that is not
permissible. Since this tableau is fairly simple, we will go on and develop the optimal-value function v3 (B3 )
and optimal decision function d3∗ (B3 ) when the first three programs are available (see Tableau 12).
For any budget level, for example, $4.0 M, we merely consider the two possible decisions: either funding
program C (x3 = 1) or not (x3 = 0). If we fund program C, then we obtain a benefit of $15.7 M while
consuming $1.0 M of our own budget. The remaining $3.0 M of our budget is then optimally allocated to the
remaining programs, producing a benefit of $59.2 M, which we obtain from the optimal-value function with
the first two programs included (Tableau 11). If we do not fund program C, then the entire amount of $4.0 M
is optimally allocated to the remaining two programs (Tableau 11), producing a benefit of $59.2. Hence, we
should clearly fund program C if our budget allocation is $4.0 M. Optimal decisions taken for other budget
levels are determined in a similar manner.
Although it is straightforward to continue the recursive calculation of the optimal-value function for
succeeding stages, we will not do so since the number of ranges that need to be reported rapidly becomes
rather large. The general recursive relationship that determines the optimal-value function at each stage is
vn (Bn ) = Max [cn xn + vn−1 (Bn − cn xn )],
The calculation is initialized by observing that
for all possible values of B0 . Note that the state transition function is simply
We can again illustrate the usual principle of optimality: Given budget Bn at stage n, whatever decision is
made with regard to funding the nth program, the remaining budget must be allocated optimally among the
first (n − 1) programs. If these calculations were carried to completion, resulting in v10 (B10 ) and d10
then the problem would be solved for all possible budget levels, not just $3.4 M and $4.2 M.
Although this example has a continuous state space, a finite number of ranges can be constructed because
of the zero–one nature of the decision variables. In fact, all breaks in the range of the state space either are
the breaks from the previous stage, or they result from adding the cost of the new program to the breaks in
the previous range. This is not a general property of continuous state space problems, and in most cases
such ranges cannot be determined. Usually, what is done for continuous state space problems is that they
are converted into discrete state problems by defining an appropriate grid on the continuous state space. The
optimal-value function is then computed only for the points on the grid. For our cost/benefit example, the
total budget must be between zero and $62.5 M, which provides a range on the state space, although at any
stage a tighter upper limit on this range is determined by the sum of the budgets of the first n programs. An
appropriate grid would consist of increments of $0.1 M over the limits of the range at each stage, since this
is the accuracy with which the program costs have been estimated. The difference between problems with
continuous state spaces and those with discrete state spaces essentially then disappears for computational
Up to this point we have considered exclusively problems with deterministic behavior. In a deterministic
dynamic-programming process, if the system is in state sn with n stages to go and decision dn is selected
from the set of permissible decisions for this stage and state, then the stage return f n (dn , sn ) and the state of
Figure 11.14 Decision tree for deterministic dynamic programming.
the system at the next stage, given by sn−1 = tn (dn , sn ), are both known with certainty. This deterministic
process can be represented by means of the decision tree in Fig. 11.14. As one can observe, given the current
state, a specific decision leads with complete certainty to a particular state at the next stage. The stage returns
are also known with certainty and are associated with the branches of the tree.
When uncertainty is present in a dynamic-programming problem, a specific decision for a given state and
stage of the process does not, by itself, determine the state of the system at the next stage; this decision may
not even determine the return for the current stage. Rather, in dynamic programming under uncertainty, given
the state of the system sn with n stages to go and the current decision dn , an uncertain event occurs which is
determined by a random variable ẽn whose outcome en is not under the control of the decision maker. The
stage return function may depend on this random variable, that is,
while the state of the system sn−1 with (n − 1) stages to go invariably will depend on the random variable by
The outcomes of the random variable are governed by a probability distribution, pn (en |dn , sn ), which
may be the same for every stage or may be conditional on the stage, the state at the current stage, and even
Figure 11.15 depicts dynamic programming under uncertainty as a decision tree, where squares represent
states where decisions have to be made and circles represent uncertain events whose outcomes are not under
the control of the decision maker. These diagrams can be quite useful in analyzing decisions under uncertainty
if the number of possible states is not too large. The decision tree provides a pictorial representation of the
sequence of decisions, outcomes, and resulting states, in the order in which the decisions must be made and
the outcomes become known to the decision maker. Unlike deterministic dynamic programming wherein the
optimal decisions at each stage can be specified at the outset, in dynamic programming under uncertainty,
the optimal decision at each stage can be selected only after we know the outcome of the uncertain event at
the previous stage. At the outset, all that can be specified is a set of decisions that would be made contingent
on the outcome of a sequence of uncertain events.
Figure 11.15 Decision tree for dynamic programming under uncertainty.
In dynamic programming under uncertainty, since the stage returns and resulting stage may both be
uncertain at each stage, we cannot simply optimize the sum of the stage-return functions. Rather, we must
optimize the expected return over the stages of the problem, taking into account the sequence in which
decisions can be made and the outcomes of uncertain events become known to the decision maker. In this
situation, backward induction can be applied to determine the optimal strategy, but forward induction cannot.
The difficulty with forward induction is that it is impossible to assign values to states at the next stage that
are independent of the uncertain evolution of the process from that future state on. With backward induction,
on the other hand, no such difficulties arise since the states with zero stages to go are evaluated first, and then
the states with one stage to go are evaluated by computing the expected value of any decision and choosing
We start the backward induction process by computing the optimal-value function at stage 0. This
amounts to determining the value of ending in each possible stage with 0 stages to go. This determination
may involve an optimization problem or the value of the assets held at the horizon. Next, we compute the
optimal-value function at the previous stage. To do this, we first compute the expected value of each uncertain
event, weighting the stage return plus the value of the resulting state for each outcome by the probability of
each outcome. Then, for each state at the previous stage, we select the decision that has the maximum (or
minimum) expected value. Once the optimal-value function for stage 1 has been determined, we continue in
a similar manner to determine the optimal-value functions at prior stages by backward induction.
The optimal-value function for dynamic programming under uncertainty is then defined in the following
vn (sn ) = Max E f n (dn , sn , ẽn ) + vn−1 (s̃n−1 ) ,
where E[·] denotes the expected value of the quantity in brackets. To initiate the recursive calculations we
need to determine the optimal-value function with zero stages to go, which is given by:
The optimization problems that determine the optimal-value function with zero stages to go are not determined
recursively, and therefore may be solved in a straight-forward manner. If the objective function is to maximize
the expected discounted costs, then Eq. (17) is modified as in Section 11.4 by multiplying the term vn−1 (s̃n−1 )
by βn , the discount factor for period n.
We can make these ideas more concrete by considering a simple example. A manager is in charge of
the replenishment decisions during the next two months for the inventory of a fairly expensive item. The
production cost of the item is $1000/unit, and its selling price is $2000/unit. There is an inventory-carrying
cost of $100/unit per month on each unit left over at the end of the month. We assume there is no setup cost
associated with running a production order, and further that the production process has a short lead time;
therefore any amount produced during a given month is available to satisfy the demand during that month.
At the present time, there is no inventory on hand. Any inventory left at the end of the next two months has
to be disposed of at a salvage value of $500/unit.
The demand for the item is uncertain, but its probability distribution is identical for each of the coming
two months. The probability distribution of the demand is as follows:
The issue to be resolved is how many units to produce during the first month and, depending on the actual
demand in the first month, how many units to produce during the second month. Since demand is uncertain,
the inventory at the end of each month is also uncertain. In fact, demand could exceed the available units
on hand in any month, in which case all excess demand results in lost sales. Consequently, our production
decision must find the proper balance between production costs, lost sales, and final inventory salvage value.
The states for this type of problem are usually represented by the inventory level In at the beginning of
each month. Moreover, the problem is characterized as a two-stage problem, since there are two months
involved in the inventory-replenishment decision. To determine the optimal-value function, let
vn (In ) = Maximum contribution, given that we have In units of inventory
We initiate the backward induction procedure by determining the optimal-value function with 0 stages to
go. Since the salvagevalue is $500/unit, we have:
To compute the optimal-value function with one stage to go, we need to determine, for each inventory
level (state), the corresponding contribution associated with each possible production amount (decision) and
level of sales (outcome). For each inventory level, we select the production amount that maximizes the
Table 11.3 provides all the necessary detailed computations to determine the optimal-value function with
one stage to go. Column 1 gives the state (inventory level) of the process with one stage to go. Column 2 gives
the possible decisions (amount to produce) for each state, and, since demand cannot be greater than three, the
amount produced is at most three. Column 3 gives the possible outcomes for the uncertain level of sales for
each decision and current state, and column 4 gives the probability of each of these possible outcomes. Note
that, in any period, it is impossible to sell more than the supply, which is the sum of the inventory currently
on hand plus the amount produced. Hence, the probability distribution of sales differs from that of demand
since, whenever demand exceeds supply, the entire supply is sold and the excess demand is lost. Column 5 is
the resulting state, given that we currently have I1 on hand, produce d1 , and sell s1 . The transition function
where the tildes (∼) indicate that the level of sales is uncertain and, hence, the resulting state is also uncertain.
Columns 6, 7, and 8 reflect the revenue and costs for each state, decision, and sales level, and column 9 reflects
the value of being in the resulting state at the next stage. Column 10 merely weights the sum of columns
6 through 9 by the probability of their occurring, which is an intermediate calculation in determining the
expected value of making a particular decision, given the current state. Column 11 is then just this expected
value; and the asterisk indicates the optimal decision for each possible state.
Table 11.3 Computation of optimal-value function with one stage to go.
The resulting optimal-value function and the corresponding optimal-decision function are determined
directly from Table 11.3 and are the following:
Next we need to compute the optimal-value function with two stagesto go. However, since we have
assumed that there is no initial inventory on hand, it is not necessary to describe the optimal-value function
for every possible state, but only for I2 = 0. Table 11.4 is similar to Table 11.3 and gives the detailed
computations required to evaluate the optimal-value function for this case.
Table 11.4 Computation of optimal-value function with two stages to go, I2 = 0 only.
ProProbaResult- ProducState duce Sell bility
The optimal-value function and the corresponding decision function for I2 = 0 are taken directly from
The optimal strategy can be summarized by the decision tree given in Fig. 11.16. The expected contribution determined by the dynamic-programming solution corresponds to weighting the contribution of every
path in this tree by the probability that this path occurs. The decision tree in Fig. 11.16 emphasizes the
contingent nature of the optimal strategy determined by dynamic programming under uncertainty.
Solutions to exercises marked with an asterisk (∗ ) involve extensive computations. Formulate these problems as dynamic
programs and provide representative computations to indicate the nature of the dynamic programming recursions; solve
to completion only if a computer system is available.
1. In solving the minimum-delay routing problem in Section 11.1, we assumed the same delay along each street (arc)
in the network. Suppose, instead, that the delay when moving along any arc upward in the network is 2 units greater
than the delay when moving along any arc downward. The delay at the intersections is still given by the data in
Fig. 11.1. Solve for the minimum-delay route by both forward and backward induction.
2. Decatron Mills has contracted to deliver 20 tons of a special coarsely ground wheat flour at the end of the current
month, and 140 tons at the end of the next month. The production cost, based on which the Sales Department has
bargained with prospective customers, is c1 (x1 ) = 7500 + (x1 − 50)2 per ton for the first month, and c2 (x2 ) =
7500 + (x2 − 40)2 per ton for the second month; x1 and x2 are the number of tons of the flour produced in the
first and second months, respectively. If the company chooses to produce more than 20 tons in the first month, any
excess production can be carried to the second month at a storage cost of $3 per ton.
Assuming that there is no initial inventory and that the contracted demands must be satisfied in each month
(that is, no back-ordering is allowed), derive the production plan that minimizes total cost. Solve by both backward
and forward induction. Consider x1 and x2 as continuous variables, since any fraction of a ton may be produced in
3. A construction company has four projects in progress. According to the current allocation of manpower, equipment,
and materials, the four projects can be completed in 15, 20, 18, and 25 weeks. Management wants to reduce the
completion times and has decided to allocate an additional $35,000 to all four projects. The new completion times
as functions of the additional funds allocated to each projects are given in Table E11.1.
How should the $35,000 be allocated among the projects to achieve the largest total reduction in completion
times? Assume that the additional funds can be allocated only in blocks of $5000.
4. The following table specifies the unit weights and values of five products held in storage. The quantity of each item
A plane with a capacity of 13 weight units is to be used to transport the products. How should the plane be
loaded to maximize the value of goods shipped? (Formulate the problem as an integer program and solve by dynamic
5. Any linear-programming problem with n decision variables and m constraints can be converted into an n-stage
dynamic-programming problem with m state parameters.
Set up a dynamic-programming formulation for the following linear program:
Why is it generally true that the simplex method rather than dynamic programming is recommended for solving
6. Rambling Roger, a veteran of the hitchhiking corps, has decided to leave the cold of a Boston winter and head for
the sunshine of Miami. His vast experience has given him an indication of the expected time in hours it takes to
hitchhike over certain segments of the highways. Knowing he will be breaking the law in several states and wishing
to reach the warm weather quickly, Roger wants to know the least-time route to take. He summarized his expected
travel times on the map in Fig. E11.1. Find his shortest time route.
7. J. J. Jefferson has decided to move from the West Coast, where he lives, to a mid-western town, where he intends
to buy a small farm and lead a quiet life. Since J. J. is single and has accumulated little furniture, he decides to
rent a small truck for $200 a week or fraction of a week (one-way, no mileage charge) and move his belongings
by himself. Studying the map, he figures that his trip will require four stages, regardless of the particular routing.
Each node shown in Fig. E11.2 corresponds to a town where J. J. has either friends or relatives and where he plans
to spend one day resting and visiting if he travels through the town. The numbers in brackets in Fig. E11.2 specify
the travel time in days between nodes. (The position of each node in the network is not necessarily related to its
geographical position on the map.) As he will travel through different states, motel rates, tolls, and gas prices vary
significantly; Fig. E11.2 also shows the cost in dollars for traveling (excluding truck rental charges) between every
two nodes. Find J. J.’s cheapest route between towns 1 and 10, including the truck rental charges.
8. At THE CASINO in Las Vegas, a customer can bet only in dollar increments. Betting a certain amount is called
‘‘playing a round.’’ Associated with each dollar bet on a round, the customer has a 40% chance to win another dollar
and a 60% chance to lose his, or her, dollar. If the customer starts with $4 and wants to maximize the chances of
finishing with at least $7 after two rounds, how much should be bet on each round? [Hint. Consider the number
of dollars available at the beginning of each round as the state variable.]
In a youth contest, Joe will shoot a total of ten shots at four different targets. The contest has been designed so that
Joe will not know whether or not he hits any target until after he has made all ten shots. He obtains 6 points if any
shot hits target 1, 4 points for hitting target 2, 10 points for hitting target 3, and 7 points for hitting target 4. At each
shot there is an 80% chance that he will miss target 1, a 60% chance of missing target 2, a 90% chance of missing
target 3, and a 50% chance of missing target 4, given that he aims at the appropriate target.
If Joe wants to maximize his expected number of points, how many shots should he aim at each target?
10. A monitoring device is assembled from five different components. Proper functioning of the device depends upon
its total weight q so that, among other tests, the device is weighted; it is accepted only if r1 ≤ q ≤ r2 , where the
two limits r1 and r2 have been prespecified.
The weight q j ( j = 1, 2, . . . , 5) of each component varies somewhat from unit to unit in accordance with a
normal distribution with mean µ j and variance σ j2 . As q1 , q2 , . . . , q5 are independent, the total weight q will also
be a normal variable with mean µ = 5j=1 µ j and variance σ 2 = 5j=1 σ j2 .
Clearly, even if µ can be adjusted to fall within the interval [r1 , r2 ], the rejection rate will depend upon σ 2 ; in
this case, the rejection rate can be made as small as desired by making the variance σ 2 sufficiently small. The design
department has decided that σ 2 = 5 is the largest variance that would make the rejection rate of the monitoring
device acceptable. The cost of manufacturing component j is c j = 1/σ j2 .
Determine values for the design parameters σ j2 for j = 1, 2, . . . , 5 that would minimize the manufacturing cost
of the components while ensuring an acceptable rejection rate. [Hint. Each component is a stage; the state variable
is that portion of the total variance σ 2 not yet distributed. Consider σ j2 ’s as continuous variables.]
A scientific expedition to Death Valley is being organized. In addition to the scientific equipment, the expedition
also has to carry a stock of spare parts, which are likely to fail under the extreme heat conditions prevailing in that
area. The estimated number of times that the six critical parts, those sensitive to the heat conditions, will fail during
the expedition are shown below in the form of probability distributions.
The spare-park kit should not weight more than 30 pounds. If one part is needed and it is not available in the
spare-park kit, it may be ordered by radio and shipped by helicopter at unit costs as specified in Table E11.2, which
Determine the composition of the spare-park kit to minimize total expected ordering costs.
After a hard day at work I frequently wish to return home as quickly as possible. I must choose from several alternate
routes (see Fig. E11.3); the travel time on any road is uncertain and depends upon the congestion at the nearest major
intersection preceding that route. Using the data in Table E11.3, determine my best route, given that the congestion
Assume that if I am at intersection i with heavy congestion and I take road i–j, then
If the congestion is light at intersection i and I take road i–j, then
13. Find the shortest path from node 1 to every other node in the network given in Fig. E11.4, using the shortest-route
algorithm for acyclic networks. The number next to each arc is the ‘‘length’’ of that arc.
14. Find the shortest path from node 1 to every other node in the network given in Fig. E11.5.
15. a) Give a dynamic-programming recursion for finding the shortest path from every node to a particular node, node
b) Apply the recursion from part (a) to find the shortest path from every node to node 6 in the network specified in
16. A state’s legislature has R representatives. The state is sectioned into s districts, where District
p j and s < R. Under strictly proportional representation. District j would receive Rp j /( sj=1 p j ) = r j representatives; this allocation is not feasible, however, because r j may not be integer-valued. The objective is to allocate y j
representatives to District j for j = 1, 2, . . . , s, so as to minimize, over all the districts, the maximum difference
between y j and r j ; that is, minimize [maximum (|y1 − r1 |, |y2 − r2 |, . . . , |ys − rs |)].
a) Formulate the model in terms of a dynamic-programming recursion.
b) Apply your method to the data R = 4, s = 3, and r1 = 0.4, r2 = 2.4, and r3 = 1.2.
c) Discuss whether the solution seems reasonable, given the context of the problem.
17. In a textile plant, cloth is manufactured in rolls of length L. Defects sometimes occur along the length of the cloth.
Consider a specific roll with (N − 1) defects appearing at distances y1 , y2 , . . . , y N −1 from the start of the roll
(yi+1 > yi for all i). Denote the start of the roll by y0 , the end by y N .
The roll is cut into pieces for sale. The value of a piece depends on its length and the number of defects. Let
v(x, m) = Value of a piece of length x having m defects.
Assume that all cuts are made through defects and that such cutting removes the defect.
Specify how to determine where to cut the cloth to maximize total value.
18. A manufacturing company, receiving an order for a special product, has worked out a production plan for the next 5
months. All components will be manufactured internally except for one electronic part that must be purchased. The
purchasing manager in charge of buying the electronic part must meet the requirements schedule established by the
production department. After negotiating with several suppliers, the purchasing manager has determined the best
possible price for the electronic part for each of the five months in the planning horizon. Table E11.4 summarizes
the requirement schedule and purchase price information.
The storage capacity for this item is limited to 12,000 units; there is no initial stock, and after the five-month
period the item will no longer be needed. Assume that the orders for the electronic part are placed once every
month (at the beginning of each month) and that the delivery lead time is very short (delivery is made practically
instantaneously). No back-ordering is permitted.
a) Derive the monthly purchasing schedule if total purchasing cost is to be minimized.
b) Assume that a storage charge of $250 is incurred for each 1000 units found in inventory at the end of a month.
What purchasing schedule would minimize the purchasing and storage costs?
Table E11.5 Profits in response to advertising
19. Rebron, Inc., a cosmetics manufacturer, markets five different skin lotions and creams: A, B, C, D, E. The company
has decided to increase the advertising budget allocated to this group of products by 1 million dollars for next year.
The marketing department has conducted a research program to establish how advertising affects the sales levels
of these products. Table E11.5 shows the increase in each product’s contribution to net profits as a function of the
Given that maximization of net profits is sought, what is the optimal allocation of the additional advertising
budget among the five products? Assume, for simplicity, that advertising funds must be allocated in blocks of
A machine tool manufacturer is planning an expansion program. Up to 10 workers can be hired and assigned to
the five divisions of the company. Since the manufacturer is currently operating with idle machine capacity, no new
Hiring new workers adds $250/day to the indirect costs of the company. On the other hand, new workers add
value to the company’s output (i.e., sales revenues in excess of direct costs) as indicated in Table E11.6. Note that
the value added depends upon both the number of workers hired and the division to which they are assigned.
Increase in contribution to overhead ($/day)
The company wishes to hire workers so that the value that they add exceeds the $250/day in indirect costs.
What is the minimum number of workers the company should hire and how should they be allocated among the five
21. A retailer wishes to plan the purchase of a certain item for the next five months. Suppose that the demand in these
The retailer orders at the beginning of each month. Initially he has no units of the item. Any units left at the end of
a month will be transferred to the next month, but at a cost of 10 /c per unit. It costs $20 to place an order. Assume
that the retailer can order only in lots of 10, 20, . . . units and that the maximum amount he can order each month is
60 units. Further assume that he receives the order immediately (no lead time) and that the demand occurs just after
he receives the order. He attempts to stock whatever remains but cannot stock more than 40 units—units in excess
of 40 are discarded at no additional cost and with no salvage value. How many units should the retailer order each
Suppose that the retailer of the previous exercise does not know demand with certainty. All assumptions are as in
Exercise 21 except as noted below. The demand for the item is the same for each month and is given by the following
Each unit costs $1. Each unit demanded in excess of the units on hand is lost, with a penalty of $2 per unit. How
many units should be ordered each month to minimize total expected costs over the planning horizon? Outline a
dynamic-programming formulation and complete the calculations for the last two stages only.
The owner of a hardware store is surprised to find that he is completely out of stock of ‘‘Safe-t-lock,’’ an extremely
popular hardened-steel safety lock for bicycles. Fortunately, he became aware of this situation before anybody asked
for one of the locks; otherwise he would have lost $2 in profits for each unit demanded but not available. He decides
to use his pickup truck and immediately obtain some of the locks from a nearby warehouse.
Although the demand for locks is uncertain, the probability distribution for demand is known; it is the same in
The storage capacity is 400 units, and the carrying cost is $1 per unit per month, charged to the month’s average
inventory [i.e., (initial + ending)/2]. Assume that the withdrawal rate is uniform over the month. The lock is
replenished monthly, at the beginning of the month, in lots of one hundred.
What is the replenishment strategy that minimizes the expected costs (storage and shortage costs) over a planning
horizon of four months? No specific inventory level is required for the end of the planning horizon.
In anticipation of the Olympic games, Julius, a famous Danish pastry cook, has opened a coffee-and-pastry shop not
far from the Olympic Village. He has signed a contract to sell the shop for $50,000 after operating it for 5 months.
Julius has several secret recipes that have proved very popular with consumers during the last Olympic season,
but now that the games are to be held on another continent, variations in tastes and habits cast a note of uncertainty
The pastry cook plans to sell all types of common pastries and to use his specialties to attract large crowds
to his shop. He realizes that the popularity of his shop will depend upon how well his specialties are received;
consequently, he may alter the offerings of these pastries from month to month when he feels that he can improve
business. When his shop is not popular, he may determine what type of specialties to offer by running two-day
market surveys. Additionally, Julius can advertise in the Olympic Herald Daily and other local newspapers to attract
The shop’s popularity may change from month to month. These transitions are uncertain and depend upon
advertising and market-survey strategies. Table E11.7 summarizes the various possibilities. The profit figures in
this table include advertising expenditures and market-survey costs.
Note that Julius has decided either to advertise or to run the market survey whenever the shop is not popular.
Assume that, during his first month of operation, Julius passively waits to see how popular his shop will be.
What is the optimal strategy for him to follow in succeeding months to maximize his expected profits?
25. A particular city contains six significant points of interest. Figure E11.6 depicts the network of major two-way
avenues connecting the points; the figure also shows travel time (in both directions) along each avenue. Other
streets, having travel times exceeding those along the major avenues, link the points but have been dropped from
In an attempt to reduce congestion of traffic in the city, the city council is considering converting some two-way
The city council is considering two alternative planning objectives:
Table E11.7 Profit possibilities (p = probability; E = expected profit)
a) Given that point (1) is the tourist information center for the city, from which most visitors depart, which avenues
should be made one-way so as to minimize the travel times from point (1) to every other point?
b) If the travel times from each point to every other point were to be minimized, which avenues would be converted
In both cases, assume that the travel times shown in Fig E11.6 would not be affected by the conversion. If the
total conversion cost is proportional to the number of avenues converted to one-way, which of the above solutions
Consider the following one-period problem: a certain item is produced centrally in a factory and distributed to four
warehouses. The factory can produce up to 12 thousand pieces of the item. The transportation cost from the factory
to warehouse n is tn dollars per thousand pieces.
From historical data, it is known that the demand per period from warehouse n for the item is governed by a
Poisson distribution† with mean λn (in thousands of pieces). If demand exceeds available stock a penalty of πn
dollars per thousand units out of stock is charged at warehouse n.
The current inventory on hand at warehouse n is qn thousand units.
a) Formulate a dynamic program for determining the amount to be produced and the optimal allocation to each
warehouse, in order to minimize transportation and expected stockout costs.
b) Solve the problem for a four-warehouse system with the data given in Table E11.8.
The Poisson distribution is given by Prob. (k̃ = k) =
Precision Equipment, Inc., has won a government contract to supply 4 pieces of a high precision part that is used
in the fuel throttle-valve of an orbital module. The factory has three different machines capable of producing the
item. They differ in terms of setup cost, variable production cost, and the chance that every single item will meet
the high-quality standards (see Table E11.9).
After the parts are produced, they are sent to the engine assembly plant where they are tested. There is no way
to recondition a rejected item. Any parts in excess of four, even if good, must be scrapped. If less than 4 parts are
good, the manufacturer has to pay a penalty of $200 for each undelivered item.
How many items should be produced on each machine in order to minimize total expected cost? [Hint. Consider
each machine as a stage and define the state variable as the number of acceptable parts still to be produced.]
One of the systems of a communications satellite consists of five electronic devices connected in series; the system as
a whole would fail if any one of these devices were to fail. A common engineering design to increase the reliability
of the system is to connect several devices of the same type in parallel, as shown in Fig E11.7. The parallel devices
in each group are controlled by a monitoring system, so that, if one device fails, another one immediately becomes
The total weight of the system may not exceed 20 pounds. Table E11.10 shows the weight in pounds and the
probability of failure for each device in group j of the system design. How many devices should be connected in
parallel in each group so as to maximize the reliability of the overall system?
The production manager of a manufacturing company has to devise a production plan for item AK102 for the
next four months. The item is to be produced at most once monthly; because of capacity limitations the monthly
production may not exceed 10 units. The cost of one setup for any positive level of production in any month is $10.
The demand for this item is uncertain and varies from month to month; from past experience, however, the
manager concludes that the demand in each month can be approximated by a Poisson distribution with parameter
λn (n shows the month to which the distribution refers).
Inventory is counted at the end of each month and a holding cost of $10 is charged for each unit; if there are
stockouts, a penalty of $20 is charged for every unit out of stock. There is no initial inventory and no outstanding
back-orders; no inventory is required at the end of the planning period. Assume that the production lead time is
short so that the amount released for production in one month can be used to satisfy demand within the same month.
What is the optimal production plan, assuming that the optimality criterion is the minimum expected cost?
Assume that λ1 = 3, λ2 = 5, λ3 = 2, λ4 = 4 units.
Just before the Christmas season, Bribham of New England, Inc., has signed a large contract to buy four varieties
of Swiss chocolate from a local importer. As it was already late, the distributor could arrange for only a limited
transportation of 20 tons of Swiss chocolate to be delivered in time for Christmas.
Chocolate is transported in containers; the weight and the transportation cost per container are given in Table
A marketing consulting firm has conducted a study and has estimated the demand for the upcoming holiday
season as a Poisson distribution with parameter λn (n = 1, 2, 3, 4 indicates the variety of the chocolate). Bribham
loses contribution (i.e., shortage cost) for each container that can be sold (i.e., is demanded) but is not available.
How many containers of each variety should the company make available for Christmas in order to minimize
total expected cost (transportation and shortage costs)?
The example in Section 11.6 is taken from the State Department of Public Health case by Richard F. Meyer.
Exercise 10 is based on Section 10.6 of Nonlinear and Dynamic Programming, Addison-Wesley, 1962, by
Exercise 24 is inspired by Dynamic Programming and Markov Processes, John Wiley & Sons, 1960, by
As mathematical-programming techniques and computer capabilities evolve, the spectrum of potential applications also broadens. Problems that previously were considered intractable, from a computational point of
view, now become amenable to practical mathematical-programming solutions. Today, commercial linearprogramming codes can solve general linear programs of about 4000 to 6000 constraints. Although this is
an impressive accomplishment, many applied problems lead to formulations that greatly exceed this existing
computational limit. Two approaches are available to deal with these types of problems.
One alternative, that we have discussed in Chapter 5, leads to the partitioning of the overall problem into
manageable subproblems, which are linked by means of a hierarchical integrative system. An application of
this approach was presented in Chapter 6, where two interactivelinear-programming models were designed
to support strategic and tactical decisions in the aluminum industry, including resource acquisition, swapping
contracts, inventory plans, transportation routes, production schedules and market-penetration strategies.
This hierarchical method of attacking large problems is particularly effective when the underlying managerial
process involves various decision makers, whose areas of concern can be represented by a specific part of
the overall problem and whose decisions have to be coordinated within the framework of a hierarchical
Some large-scale problems are not easily partitioned in this way. They present a monolithic structure
that makes the interaction among the decision variables very hard to separate, and lead to situations wherein
there is a single decision maker responsible for the actions to be taken, and where the optimal solution isvery
sensitive to the overall variable interactions. Fortunately, these large-scale problems invariably contain special
structure. The large-scale system approach is to treat the problem as a unit, devising specialized algorithms
to exploit the structure of the problem. This alternative will be explored in this chapter, where two of the most
important large-scale programming procedures—decomposition and column generation—will be examined.
The idea of taking computational advantage of the special structure of a specific problem to develop an
efficient algorithm is not new. The upper-bounding technique introduced in
Chapter 2, the revised simplex method presented in Appendix B, and the network-solution procedures discussed in Chapter 8 all illustrate this point. This chapter further extends these ideas.
Certain structural forms of large-scale problems reappear frequently in applications, and large-scale systems
theory concentrates on the analysis of these problems. In this context, structure means the pattern of zero and
nonzero coefficients in the constraints; the most important such patterns are depicted in Fig. 12.8. The first
illustration represents a problem composed of independent subsystems. It can be written as:
Observe that the variables x1 , x2 , . . . , xr , the variables xr +1 , xr +2 , . . . , xs , and the variables xs+1 , xs+2 , . . . , xn
do not appear in common constraints. Consequently, these variables are independent, and the problem can be
approached by solving one problem in the variables x1 , x2 , . . . , xr , another in the variables xr +1 , xr +2 , . . . , xs
and a third in the variables xs+1 , xs+2 , . . . , xn . This separation into smaller and independent subproblems
First, it provides significant computational savings, since the computations for linear programs are quite
sensitive to m, the number of constraints, in practice growing proportionally to m 3 . If each subproblem above
contains 31 of the constraints, then the solution to each subproblem requires on the order of (m/3)3 = m 3 /27
computations. All three subproblems then require about 3(m 3 /27) = m 3 /9 computations, or approximately
9 the amount for an m-constraint problem without structure. If the number of subsystems were k, the
calculations would be only 1/k 2 times those required for an unstructured problem of comparable size.
Second, each of the independent subproblems can be treated separately. Data can be gathered, analyzed,
and stored separately. The problem also can be solved separately and, in fact, simultaneously. Each of
these features suggests problems composed solely with independent subsystems as the most appealing of the
The most natural extensions of this model are to problems with nearly independent subsystems, as
illustrated by the next three structures in Fig. 12.8. In the primal block angular structure, the subsystem
variables appear together, sharing common resources in the uppermost ‘‘coupling’’ constraints. For example,
the subsystems might interact via a corporate budgetary constraint specifying that total capital expenditures
of all subsystems cannot exceed available corporate resources.
The dual block angular structure introduces complicating ‘‘coupling’’ variables. In this case, the subsystems interact only by engaging in some common activities. For example, a number of otherwise independent
subsidiaries of a company might join together in pollution-abatement activities that utilize some resources
The bordered angular system generalizes these models by including complications from both coupling
variables and coupling constraints. To solve any of these problems, we would like to decompose the system,
removing the complicating variables or constraints, to reduce the problem to one with independent subsystems.
Several of the techniques in large-scale system theory can be given this interpretation.
Dynamic models, in the sense of multistage optimization, provide another major source of large-scale
problems. In dynamic settings, decisions must be made at several points in time, e.g., weekly ormonthly.
Usually decisions made in any time period have an impact upon other time periods, so that, even when
every instantaneous problem is small, timing effects compound the decision process and produce large,
frequently extremely large, optimization problems. The staircase and block triangular structures of Fig. 12.8
are common forms for these problems. In the staircase system, some activities, such as holding of inventory,
couple succeeding time periods. In the block triangular case, decisions in each time period can directly affect
resource allocation in any future time period.
The last structure in Fig. 12.8 concerns problems with large network subsystems. In these situations, we
would like to exploit the special characteristics of network problems.
It should be emphasized that the special structures introduced here do not exhaust all possibilities. Other
special structures, like Leontief systems arising in economic planning, could be added. Rather, the examples
given are simply types of problems that arise frequently in applications. To develop a feeling for potential
applications, let us consider a few examples.
Many industries must schedule production and inventory for a large number of products over several periods
of time, subject to constraints imposed by limited resources. These problems can be cast as large-scale
1 if the kth production schedule is used for item j,
K j = Number of possible schedules for item j.
Each production schedule specifies how item j is to be produced in each time period t = 1, 2, . . . , T ;
for example, ten items in period 1 on machine 2, fifteen items in period 2 on machine 4, and so forth.
The schedules must be designed so that production plus available inventory in each period is sufficient to
satisfy the (known) demand for the items in that period. Usually it is not mandatory to consider every
potential production schedule; under common hypotheses, it is known that at most 2T −1 schedules must be
considered for each item in a T -period problem. Of course, this number can lead to enormous problems; for
example, with J = 100 items and T = 12 time periods, the total number of schedules (θ jk variables) will be
c jk = Cost of the kth schedule for item j (inventory plus production cost,
including machine setup costs for production),
bi = Availability of resource i (i = 1, 2, . . . , m),
a ijk = Consumption of resource i in the kth production plan for item j.
The resources might include available machine hours or labor skills, as well as cash-flow availability. We
also can distinguish among resource availabilities in each time period; e.g., b1 and b2 might be the supply of
a certain labor skill in the first and second time periods, respectively.
The J equality restrictions, which usually comprise most of the constraints, state that exactly one schedule
must be selected for each item. Note that any basis for this problem contains (m + J ) variables, and at least
one basic variable must appear in each of the last J constraints. The remaining m basic variables can appear
in no more than m of these constraints. When m is much smaller than J , this implies that most (at least
J − m) of the last constraints contain one basic variable whose value must be 1. Therefore, most variables
will be integral in any linear-programming basis. In practice, then, the integrality restrictions on the variables
will be dropped to obtain an approximate solution by linear programming. Observe that the problem has a
block angular structure. It is approached conveniently by either the decomposition procedure discussed in
this chapter or a technique referred to as generalized upper bounding (GUB), which is available on many
commercial mathematical-programming systems.
Exercises 11–13 at the end of this chapter discuss this multi-item production scheduling model in more
Communication systems such as telephone systems or national computer networks must schedule message
transmission over communication links with limited capacity. Let us assume that there are K types of messages
to be transmitted and that each type is to be transmitted from its source to a certain destination. For example, a
particular computer program might have to be sent to a computer with certain running or storage capabilities.
The communication network includes sending stations, receiving stations, and relay stations. For notation,
xikj = Number of messages of type k transmitted along the
communication link from station i to station j,
cikj = Per-unit cost for sending a type-k message along link i, j,
bik = Net messages of type k generated at station i.
In this context, bik < 0 indicates that i is a receiving station for type-k messages; (−bik ) > 0 then is the
number of type-k messages that this station will process; bik = 0 for relay stations. The formulation is:
The summations in each term are made only over indices that correspond to arcs in the underlying network.
The first constraints specify the transmission capacities u i j for the links. The remaining constraints give flow
balances at the communication stations i. For each fixed k, they state that the total messages of type k sent
from station i must equal the number received at that station plus the number generated there. Since these
are network-flow constraints, the model combines both the block angular and the near-network structures.
There are a number of other applications for this multicommodity-flow model. For example, the messages
can be replaced by goods in an import–export model. Stations then correspond to cities and, in particular,
include airport facilities and ship ports. In a traffic-assignment model, as another example, vehicles replace
messages and roadways replace communication links. A numerical example of the multicommodity-flow
Economic systems convert resources in the form of goods and services into output resources, which are other
goods and services. Assume that we wish to plan the economy to consume bit units of resource i at time
t (i = 1, 2, . . . , m; t = 1, 2, . . . , T ). The bit ’s specify a desired consumptionschedule. We also assume
that there are n production (service) activities for resource conversion, which are to be produced to meet the
ait j = Number of units of resource i that activity j ‘‘produces’’ at time t
By convention, ait j < 0 means that activity j consumes resource i at time t in its production of another
resource; this consumption is internal to the production process and does not count toward the bit desired by
the ultimate consumers. For example, if a11 j = −2, a21 j = −3, and a31 j = 1, it takes 2 and 3 units of goods
one and two, respectively, to produce 1 unit of good three in the first time period.
It is common to assume that activities are defined so that each produces exactly one output; that is, for
each j, ait j > 0 forone combination of i and t. An activity that produces output in period t is assumed to
utilize input resources only from the current or previous periods (for example, to produce at time t we may
have to train workers at time t − 1, ‘‘consuming’’ a particular skill from the labor market during the previous
period). If Jt are the activities that produce an output in period t and j is an activity from Jt , then the last
assumption states that aiτj = 0 whenever τ > t. The feasible region is specified by the following linear
One problem in this context is to see if a feasible plan exists and to find it by linear programming. Another
possibility is to specify one important resource, such as labor, and to
where c j is the per-unit consumption of labor for activity j.
In either case, the problem is a large-scale linear program with triangular structure. The additional feature
that each variable x j has a po sitive coefficient in exactly one constraint (i.e., it produces exactly one output) can
be used to devise a special algorithm that solves the problem as several small linear programs, one at each point
Several large-scale problems including any with block angular or near-network structure become much easier
to solve when some of their constraints are removed. The decomposition method is one way to approach these
problems. It essentially considers the problem in two parts, one with the ‘‘easy’’ constraints and one with
the ‘‘complicating’’ constraints. It uses the shadow prices of the second problem to specify resource prices
to be used in the first problem. This leads to interesting economic interpretations, and the method has had an
important influence upon mathematical economics. It also has provided a theoretical basis for discussing the
coordination of decentralized organization units, and for addressing the issue of transfer prices among such
This section will introduce the algorithm and motivate its use by solving a small problem. Following
sections will discuss the algorithm formally, introduce both geometric and economic interpretations, and
Consider a problem with bounded variables and a single resource constraint:
We will use the problem in this section to illustrate the decomposition procedure, though in practice it would
be solved by bounded-variable techniques.
First, note that the resource constraint complicates the problem. Without it, the problem is solved trivially
as the objective function is maximized by choosing x1 , x2 , and x3 as large as possible, so that the solution
In general, given any objective function, the problem
is also trivial to solve: One solution is to set x1 , x2 , or x3 to 2 if its objective coefficient is positive, or to 1 if
its objective coefficient is nonpositive.
Problem (1) contains some but not all of the original constraints and is referred to as a subproblem of
the original problem. Any feasible solution to the subproblem potentially can be a solution to the original
problem, and accordingly may be called a subproblem proposal. Suppose that we are given two subproblem
proposals and that we combine them with weights as in Table 12.1.
Observe that if the weights are nonnegative and sum to 1, then the weighted proposal also satisfies the
subproblem constraints and is also a proposal. We can ask for those weights that make this composite proposal
best for the overall problem, by solving the optimization problem:
The first constraint states that the composite proposal should satisfy the resource limitation. The remaining
constraints define λ1 and λ2 as weights. The linear-programming solution to this problem has λ1 = 45 , λ2 = 15 ,
We next consider the effect of introducing any new proposal to be weighted with the two above. Assuming
that each unit of this proposal contributes p1 to the objective function and uses r1 units of the resource, we
To discover whether any new proposal would aid the maximization, we price out the general new activity to
determine its reduced cost coefficient p̄1 . In this case, applying the shadow prices gives:
Note that we must specify the new proposal by giving numerical values to p1 and r1 before p̄1 can be
By the simplex optimality criterion, the weighting problem cannot be improved if p̄1 ≤ 0 for every new
proposal that the subproblem can submit. Moreover, if p̄1 > 0, then the proposal that gives p̄1 improves the
objective value. We can check both conditions by solving max p̄1 over all potential proposals.
Recall, from the original problem statement, that, for any proposal x1 , x2 , x3 ,
p̄1 = (4x1 + x2 + 6x3 ) − 1(3x1 + 2x2 + 4x3 ) − 4(1),
Checking potential proposals by using this objective in the subproblem, we find that the solution is x1 =
2, x2 = 1, x3 = 2, and p̄1 = (2) − (1) + 2(2) − 4 = 1 > 0. Equation (3) gives p1 = 21 and r1 = 16.
Table E12.1 Weighting subproblem proposals.
Geometrical Interpretation of Decomposition
Consequently, the new proposal is useful, and the weighting problem becomes:
The solution is λ1 = λ3 = 21 , and z has increased from 21 to 21 21 . Introducing a new proposal with
contribution p2 , resource usage r2 , and weight λ4 , we now may repeat the same procedure. Using the new
shadow prices and pricing out this proposal to determine its reduced cost, we find that:
= (4x1 + x2 + 6x3 ) − 21 (3x1 + 2x2 + 4x3 ) − 13,
Solving the subproblem again, but now with expression (5) as an objective function, gives x1 = 2, x2 =
Consequently, no new proposal improves the current solution to the weighting problem (4). The optimal
solution to the overall problem is given by weighting the first and third proposals each by 21 ; see Table 12.2.
Table E12.2 Optimal weighting of proposals.
The algorithm determines an optimal solution by successively generating a new proposal from the subproblem at each iteration, and then finding weights that maximize the objective function among all combinations of the proposals generated thus far. Each proposal is an extreme point of the subproblem feasible
region; because this region contains a finite number of extreme points, at most a finite number of subproblem
The following sections discuss the algorithm more fully in terms of its geometry, formal theory, and
GEOMETRICAL INTERPRETATION OF DECOMPOSITION
The geometry of the decomposition procedure can be illustrated by the problem solved in the previous section:
Figure 12.2 Geometry of the decomposition method. (a) First approximation to feasible region; (b) final
The feasible region is plotted in Fig. 12.2.
The feasible region to the subproblem is the cube 1 ≤ x j ≤ 2, and the resource constraint
The decomposition solution in Section 12.2 started with proposals (1) and (2) indicated in Fig. 12.2(a).
Note that proposal (1) is not feasible since it violates the resource constraint. The initial weighting problem
considers all combinations of proposals (1) and (2); these combinations correspond to the line segment joining
points (1) and (2). The solution lies at (∗) on the intersection of this line segment and the resource constraint.
Using the shadow prices from the weighting problem, the subproblem next generates the proposal (3).
The new weighting problem considers all weighted combinations of (1), (2) and (3). These combinations
correspond to the triangle determined by these points, as depicted in Fig. 12.2(b). The optimal solution lies
on the midpoint of the line segment joining (1) and (3), or at the point x1 = 2, x2 = 23 , and x3 = 2. Solving
the subproblem indicates that no proposal can improve upon this point and so it is optimal.
Note that the first solution to the weighting problem at (∗) is not an extreme point of the feasible region.
This is a general characteristic of the decomposition algorithm that distinguishes it from the simplex method.
In most applications, the method will consider many nonextreme points while progressing toward the optimal
Also observe that the weighting problem approximates the feasible region of the overall problem. As
more subproblem proposals are added, the approximation improves by including more of the feasible region.
The efficiency of the method is predicated on solving the problem before the approximation becomes too fine
and many proposals are generated. In practice, the algorithm usually develops a fairly good approximation
quickly, but then expends considerable effort refining it. Consequently, when decomposition is applied, the
objective value usually increases rapidly and then ‘‘tails off’’ by approaching the optimal objective value
very slowly. This phenomenon is illustrated in Fig. 12.3 which plots the progress of the objective function
for a typical application of the decomposition method.
Fortunately, as discussed in Section 12.7, one feature of the decomposition algorithm is that it provides
an upper bound on the value of the objective function at each iteration (see Fig. 12.3). As a result, the
procedure can be terminated, prior to finding an optimal solution, with a conservative estimate of how far the
current value of the objective function can be from its optimal value. In practice, since the convergence of
the algorithm has proved to be slow in the final stages, such a termination procedure is employed fairly often.
Figure 12.3 Objective progress for a typical application of decomposition.
This section formalizes the decomposition algorithm, discusses implementation issues, and introduces a
variation of the method applicable to primal block angular problems.
Decomposition is applied to problems with the following structure.
Maximize z = c1 x1 + c2 x2 + · · · + cn xn ,
The constraints are divided into two groups. Usually the problem is much easier to solve if the complicating
ai j constraints are omitted, leaving only the ‘‘easy’’ ei j constraints.
Given any subproblem proposal x1 , x2 , . . . , xn (i.e., a feasible solution to the subproblem constraints),
ri = ai1 x1 + ai2 x2 + · · · + ain xn (i = 1, 2, . . . , m),
which are, respectively, the amount of resource ri used in the ith complicating constraint and the profit p
When k proposals to the subproblem are known, the procedure acts to weight these proposals optimally.
Let superscripts distinguish between proposals so that ri is the use of resource i by the jth proposal and p j
is the profit for the jth proposal. Then the weighting problem is written as:
The weights λ1 , λ2 , . . . , λk are variables and ri and p j are known data in this problem.
Having solved the weighting problem and determined optimal shadow prices, we next consider adding
new proposals. As we saw in Chapters 3 and 4, the reduced cost for a new proposal in the weighting linear
Substituting from the expressions in (6) for p and the ri , we have
Observe that the coefficient for x j is the same reduced cost that was used in normal linear programming when
applied to the complicating constraints. The additional term σ , introduced for the weighting constraint in
problem (7), is added because of the subproblem constraints.
To determine whether any new proposal will improve the weighting linear program, we seek max p by
subject to the subproblem constraints. There are two possible outcomes:
i) If v k ≤ σ , then max p ≤ 0. No new proposal improves the weighting linear program, and the procedure
terminates. The solution is specified by weighting the subproblem proposals by the optimal weights
ii) If v k > σ , then the optimal solution x1∗ , x2∗ , . . . , xn∗ to the subproblem is used in the weighting problem,
by calculating the resource usages r1k+1 , r2k+1 , . . . , rmk+1 and profit p k+1 for this proposal from the
expressions in (6), and adding these coefficients with weight λk+1 . The weighting problem is solved
with this additional proposal and the procedure is repeated.
Section 12.7 develops the theory of this method and shows that it solves the original problem after a finite
number of steps. This property uses the fact that the subproblem is a linear program, so that the simplex
method for its solution determines each new proposal as an extreme point of the subproblem feasible region.
Finite convergence then results, since there are only a finite number of potential proposals (i.e., extreme
When solving linear programs, initial feasible solutions are determined by Phase I of the simplex method.
Since the weighting problem is a linear program, the same technique can be used to find an initial solution for
the decomposition method. Assuming that each righthand-side coefficient bi is nonnegative, we introduce
artificial variables a1 , a2 , . . . , am and solve the Phase I problem:
This problem weights subproblem proposals as in the original problem and decomposition can be used in its
solution. To initiate the procedure, we might include only the artificial variables a1 , a2 , . . . , am and any known
subproblem proposals. If no subproblem proposals are known, one can be found by ignoring the complicating
constraints and solving a linear program with only the subproblem constraints. New subproblem proposals
are generated by the usual decomposition procedure. In this case, though, the profit contribution of every
proposal is zero for the Phase I objective; i.e., the pricing calculation is:
Otherwise, the details are the same as described previously.
If the optimal objective value w ∗ < 0, then the originalconstraints are infeasible and the procedure
terminates. If w ∗ = 0, the final solution to the phase I problem identifiesproposals and weights that are
feasible in the weighting problem. We continue by applying decomposition with the phase II objective
The next section illustrates this phase I procedure in a numerical example.
Solving the weighting problem determines an optimal basis. After a new column (proposal) is added from
the subproblem, this basis can be used as a starting point to solve the new weighting problem by the revised
simplex method (see Appendix B). Usually, the old basis is near-optimal and few iterations are required for
the new problem. Similarly, the optimal basis for the last subproblem can be used to initiate the solution to
After many iterations the number of columns in the weighting problem may become large. Any nonbasic
proposal to that problem can be dropped to save storage. If it is required, it is generated again by the
The decomposition approach can be modified slightly for treating primal block-angular structures. For
notational convenience, let us consider the problem with only two subsystems:
Maximize z = c1 x1 + c2 x2 + · · · + ct xt + ct+1 xt+1 + · · · + cn xn ,
ai1 x1 + ai2 x2 · · · + ait xt + ai,t+1 xt+1 + · · · + ain xn
The easy ei j constraints in this case are composed of two independent subsystems, one containing the variables
x1 , x2 , . . . , xt and the other containing the variables xt+1 , xt+2 , . . . , xn .
Decomposition may be applied by viewing the ei j constraints as a single subproblem. Alternately, each
subsystem may be viewed as a separate subproblem. Each will submit its own proposals and the weighting
problem will act to coordinate these proposals in the following way. For any proposal x1 , x2 , . . . , xt from
ri1 = ai1 x1 + ai2 x2 + · · · + ait xt (i = 1, 2, . . . , m),
denote the resource usage ri1 in the ith ai j constraint and profit contribution p1 for this proposal. Similarly,
for any proposal xt+1 , xt+2 , . . . , xn from subproblem 2, let
ri2 = ai,t+1 xt+1 + ai,t+2 xt+2 + · · · + ain xn
p2 = ct+1 xt+1 + ct+2 xt+2 + · · · + cn xn
denote its corresponding resource usage and profit contribution.
Suppose that, at any stage in the algorithm, k proposals are available from subproblem 1, and ` proposals
are available from subproblem 2. Again, letting superscripts distinguish between proposals, we have the
Max p11 λ1 + p12 λ2 + · · · + p1k λk + p21 µ1 + p22 µ2 + · · · + p2` µ` ,
1 λ + r2 λ + · · · + rk λ + r1 µ + r2 µ + · · · + r` µ = b
( j = 1, 2, . . . , k; s = 1, 2, . . . , `).
The variables λ1 , λ2 , . . . , λk weight subproblem 1 proposals and the variables µ1 , µ2 , . . . , µ` weight
subproblem 2 proposals. The objective function adds the contribution from both subproblems and the ith
constraint states that the total resource usage from both subsystems should equal the resource availability bi
An Example of the Decomposition Procedure
After solving this linear program and determining the optimal shadow prices π1 , π2 , . . . , πm and σ1 , σ2 ,
optimality is assessed by pricing out potential proposals from each subproblem:
Substituting for p1 , p2 , ri1 , and ri2 in terms of the variable x j , we make these assessments, as in the usual
decomposition procedure, by solving the subproblems:
es,t+1 xt+1 + es,t+2 xt+2 + · · · + esn xn = ds
If vi ≤ σi for i = 1 and 2, then p 1 ≤ 0 for every proposal from subproblem 1 and p 2 ≤ 0 for every proposal
from subproblem 2; the optimal solution has been obtained. If v1 > σ1 , the optimal proposal to the first
subproblem is added to the weighting problem; if v2 > σ2 , the optimal proposal to the second subproblem is
added to the weighting problem. The procedure then is repeated.
This modified algorithm easily generalizes when the primal block-angular system contains more than
two subsystems. There then will be one weighting constraint for each subsystem. We should point out that
it is not necessary to determine a new proposal from each subproblem at every iteration. Consequently, it is
not necessary to solve each subproblem at every iteration, but rather subproblems must be solved until the
condition vi > σi (that, is, pi > 0) is achieved for one solution, so that at least one new proposal is added to
AN EXAMPLE OF THE DECOMPOSITION PROCEDURE
To illustrate the decomposition procedure with an example that indicates some of its computational advantages,
we consider a special case of the multicommodity-flow problem introduced as an example in Section 12.1.
An automobile company produces luxury and compact cars at two of its regional plants, for distribution
to three local markets. Tables 12.3 and 12.4 specify the transportation characteristics of the problem on a permonth basis, including the transportation solution. The problem is formulated in terms of profit maximization.
One complicating factor is introduced by the company’s delivery system. The company has contracted
to ship from plants to destinations with a trucking company.
The routes from plant 1 to both markets 1 and 3 are hazardous, however; for this reason, the trucking contract
specifies that no more than 30 cars in total should be sent along either of these routes in any single month.
The above solutions sending 35 cars (15 luxury and 20 compact) from plant 1 to market 1 does not satisfy
Let superscript 1 denote luxury cars, superscript 2 denote compact cars, and let xikj be the number of cars
of type k sent from plant i to market to j. The model is formulated as a primal block-angular problem with
The five supply and demand constraints of each transportation table and the following two trucking restrictions
This linear program is easy to solve without the last two constraints, since it then reduces to two separate
transportation problems. Consequently, it is attractive to use decomposition, with the transportation problems
The initial weighting problem considers the transportation solutions as one proposal from each subproblem. Since these proposals are infeasible, a Phase I version of the weighting problem with artificial variable
In this problem, s1 and s2 are slack variables for the complicating resource constraints. Since the two initial
proposals ship 15 + 20 = 35 cars on route 1 − 1, the first constraint is infeasible, and we must introduce
an artificial variable in this constraint. Only 20 cars are shipped on route 1 − 3, so the second constraint is
feasible, and the slack variable s2 can serve as an initial basic variable in this constraint. No artificial variable
An Example of the Decomposition Procedure
The solution to this problem is a1 = 5, λ1 = 1, µ1 = 1, s1 = 0, s2 = 10, with the optimal shadow prices
indicated above. Potential new luxury-car proposals are assessed by using the Phase I objective function and
Since the two resources for the problem are the shipping capacities from plant 1 to markets 1 and 3, r11 = x11
and r21 = x13 , and this expression reduces to:
The subproblem becomes the transportation problem for luxury cars with objective coefficients as shown in
Table 12.5. Note that this problem imposes a penalty of $1 for sending a car along route 1 − 1.
The solution indicated in the transportation tableau has an optimal objective value v1 = −5. Since p 1 =
v1 + 15 > 0, this proposal, using 5 units of resource 1 and 10 units of resource 2, is added to the weighting
problem. The inclusion of this proposal causes a1 to leave the basis, so that Phase I is completed.
Using the proposals now available, we may formulate the Phase II weighting problem as:
The optimal solution is given by λ1 = λ2 = 21 , µ1 = 1, s1 = 0, and s2 = 5, with an objective value of $6950.
Using the shadow prices to price out potential proposals gives:
In each case, the per-unit profit for producing in plant 1 for market 1 has decreased by $70. The decomposition
algorithm has imposed a penalty of $70 on route 1 − 1 shipments, in order to divert shipments to an alternative
route. The solution for luxury cars is given in Table 12.6. Since v1 − σ1 = 3450 = 0, no new luxury-car
proposal is profitable, and we must consider compact cars, as in Table 12.7.
Here v2 − σ2 = 2000 − 1400 > 0, so that the given proposal improves the weighting problem. It uses
no units of resource 1, 20 units of resource 2, and its profit contribution is 2000, which in this case happens
to equal v2 . Inserting this proposal in the weighting problem, we have:
Maximize 4500λ1 + 3800λ2 + 2800µ1 + 2000µ2 ,
λ1 ≥ 0, λ2 ≥ 0, µ1 ≥ 0, µ2 ≥ 0, s1 ≥ 0, s2 ≥ 0.
The optimal basic variables are λ1 = 1, µ1 = 43 , µ2 = 41 ,and s2 = 10, with objective value $7100, and the
The profit contribution for producing in plant 1 for market 1 now is penalized by $40 per unit for both types
of cars. The transportation solutions are given by Tables 12.8 and 12.9.
Since v1 − σ1 = 0 and v2 − σ2 = 0, neither subproblem can submit proposals to improve the last weighting
problem and the optimal solution uses the first luxury car proposal, since λ1 = 1, and weights the two compact
car proposals with µ1 = 43 , µ2 = 41 , giving the composite proposal shown in Table 12.10.
Observe that, although both of the transportation proposals shown on the righthand side of this expression
solve the final transportation subproblem for compact cars with value v2 = 2000, neither is an optimal solution
to the overall problem. The unique solution to the overall problem is the composite compact-car proposal
shown on the left together with the first luxury-car proposal.
The connection between prices and resource allocation has been a dominant theme in economics for some
time. The analytic basis for pricing systems is rather new, however, and owes much to the development of
mathematical programming. Chapter 4 established a first connection between pricing theory and mathematical
programming by introducing an economic interpretation of linear-programming duality theory. Decomposition extends this interpretation to decentralized decision making. It provides a mechanism by which prices
can be used to coordinate the activities of several decision makers.
For convenience, let us adopt the notation of the previous section and discuss primal block-angular systems
with two subsystems. We interpret the problem as a profit maximization for a firm with two divisions. There
are two levels of decision making—corporate and subdivision. Subsystem constraints reflect the divisions’
allocation of their own resources, assuming that these resources are not shared. The complicating constraints
limit corporate resources, which are shared and used in any proposal from either division.
Frequently, it is very expensive to gather detailed information about the divisions in a form usable by
either corporate headquarters or other divisions, or to gather detailed corporate information for the divisions.
Furthermore, each level of decision making usually requires its own managerial skills with separate responsibilities. For these reasons, it is often best for each division and corporate headquarters to operate somewhat
in isolation, passing on only that information required to coordinate the firm’s activities properly.
As indicated in Fig. 12.4, in a decomposition approach the information passed on are prices, from
corporate headquarters to the divisions, and proposals, from the divisions to the corporate coordinator. Only
the coordinator knows the full corporate constraints and each division knows its own operating constraints.
The corporate coordinator acts to weight subproblem proposals by linear programming, to maximize profits.
From the interpretation of duality given in Chapter 4, the optimal shadow prices from its solution establish a
Figure 12.4 Information transfer in decomposition.
per-unit value for each resource. These prices are an internal evaluation of resources by the firm, indicating
how profit will be affected by changes in the resource levels.
To ensure that the divisions are cognizant of the firm’s evaluation of resources, the coordinator ‘‘charges’’
the divisions for their use of corporate resources. That is, whatever decisions x1 , x2 , . . . , xt the first division
Consequently, its net profit is computed by:
(Net profit) = (Gross revenue) − (Resource cost)
or, substituting in terms of the x j ’s and rearranging,
In this objective, c j is the per-unit gross profit for activity x j . The
corporate resource, πi ai j is the cost of resource i for activity j, and i=1
Pm cost, to produce each unit of this activity.
πi ai j imposes a penalty upon activity j that reflects impacts resulting from this activity
that are external to the division. That is, by engaging in this activity, the firm uses additional units ai j of the
corporate resources. Because the firm has limited resources, the activities of other divisions must be modified
to compensate for this resource usage. The term i=1
πi ai j is the revenue lost by the firm as a result of the
modifications that the other divisions must make in their use of resources.
Once each division has determined its optimal policy with respect to its net profit objective, it conveys
this information in the form of a proposal to the coordinator. If the coordinator finds that no new proposals
are better than those currently in use in the weighting problem, then prices πi have stabilized (since the
former linear-programming solution remains optimal), and the procedure terminates. Otherwise, new prices
are determined, they are transmitted to the divisions, and the process continues.
Finally, the coordinator assesses optimality by pricing out the newly generated proposal in the weighting
problem. For example, for a new proposal from division 1, the calculation is:
p 1 = ( p1 − π1r11 − π2r21 − · · · − πm rm1 ) − σ1 ,
where σ1 is the shadow price of the weighting constraint for division 1 proposals. The first term is the net
profit of the new proposal as just calculated by the division. The term σ1 is interpreted as the value (gross
profit − resource cost) of the optimal composite or weighted proposal from the previous weighting problem.
If p 1 > 0, the new proposal’s profit exceeds that of the composite proposal, and the coordinator alters the
plan. The termination condition is that p 1 ≤ 0 and p 2 ≤ 0, when no new proposal is better than the current
composite proposals of the weighting problem.
Example: The final weighting problem to the automobile example of the previous section was:
Maximize 4500λ1+ 3800λ2 + 2800µ1 ,+2000µ2 ,
with optimal basic variables λ1 = 1, µ1 = 43 , µ2 = 41 , and s2 = 10. The first truck route from plant 1 to
market 1 (constraint 1) is used to capacity, and the firm evaluates sending another car along this route at $40.
The second truck route from plant 1 to market 3 is not used to capacity, and accordingly its internal evaluation
The composite proposal for subproblem 1 is simply its first proposal with λ1 = 1. Since this proposal
sends 15 cars on the first route at $40 each, its net profit is given by:
Similarly, the composite proposal for compact cars sends
cars along the first route. Its net profit is given by weighting its gross profit coefficients with µ1 =
µ2 = 41 and subtracting resource costs, that is, as
σ2 = [$2800( 43 ) + $2000( 41 )] − $40(15) = $2000.
By evaluating its resources, the corporate weighting problem places a cost of $40 on each car sent along
route 1–1. Consequently, when solving the subproblems, the gross revenue in the transportation array must
be decreased by $40 along the route 1–1; the profit of luxury cars along route 1–1 changes from $100 to
$60(= $100 − $40), and the profit of compact cars changes from $40 to $0(= $40 − $40).
To exhibit the effect of externalities between the luxury and compact divisions, suppose that the firm
ships 1 additional luxury car along route 1–1. Then the capacity along this route decreases from 30 to 29 cars.
Since λ1 = 1 is fixed in the optimal basic solution, µ1 must decrease by 20
resource constraint of the basic solution. Since µ1 + µ2 = 1, this means that µ2 must increase by 20
from the compact-car proposals then changes by $2800(− 20 ) + $2000(+ 20 ) = −$40 , as required. Note
that the 1-unit change in luxury-car operations induces a change in the composite proposal of compact cars
for subproblem 2. The decomposition algorithm allows the luxury-car managers to be aware of this external
impact through the price information passed on from the coordinator.
Finally, note that, although the price concept introduced in this economic interpretation provides an
internal evaluation of resources that permits the firm to coordinate subdivision activities, the prices by themselves do not determine the optimal production plan at each subdivision. As we observed in the last section,
the compact-car subdivision for this example has several optimal solutions to its subproblem transportation
problem with respect to the optimal resource prices of π1 = $40 and π2 = $0. Only one of these solutions
however, is optimal for the overall corporate plan problem. Consequently, the coordinator must negotiate the
final solution used by the subdivision; merely passing on the optimal resources will not suffice.
In this section, we assume that decomposition is applied to a problem with only one subproblem:
Maximize z = c1 x1 + c2 x2 + · · · + cn xn ,
(i = 1, 2, . . . , m), (Complicating constants)
The discussion extends to primal block-angular problems in a straightforward manner.
The theoretical justification for decomposition depends upon a fundamental result from convex analysis.
This result is illustrated in Fig. 12.5 for a feasible region determined by linear inequalities. The region is
bounded and has five extreme points denoted x 1 , x 2 , . . . , x 5 . Note that any point y in the feasible region can
be expressed as a weighted (convex) combination of extreme points. For example, the weighted combination
of the extreme points x 1 , x 2 , and x 5 given by
determines the shaded triangle in Fig. 12.5. Note that the representation of y as an extreme point is not
unique; y can also be expressed as a weighted combination of x 1 , x 4 , and x 5 , or x 1 , x 3 , and x 5 .
The general result that we wish to apply is stated as the Representation Property, defined as:
Figure 12.5 Extreme point representation.
Representation Property. Let x 1 , x 2 , . . . , x K be the extreme points [each x k specifies values for each
variable x j as (x1k , x2k , . . . , xnk )] of a feasible region determined by the constraints
and assume that the points in this feasible region are bounded. Then any feasible point x = (x1 , x2 , . . . , xn )
can be expressed as a convex (weighted) combination of the points x 1 , x 2 , . . . , x K , as
x j = λ1 x 1j + λ2 x 2j + · · · + λ K x Kj
By applying this result, we can express the overall problem in terms of the extreme points x 1 , x 2 , . . . , x K
of the subproblem. Since every feasible point to the subproblem is generated as the coefficients λk vary, the
original problem can be re-expressed as a linear program in the variables λk :
Max z = c1 (λ1 x11 + λ2 x12 + · · · + λ K x1K ) + · · · + cn ( λ1 xn1 + λ2 xn2 + · · · + λ K xnK ),
ai1 (λ1 x11 + λ2 x12 + · · · + λ K x1K ) + · · · + ain ( λ1 xn1 + λ2 xn2 + · · · + λ K xnK )
or, equivalently, by collecting coefficients for the λk :
Max z = p1 λ1 + p2 λ2 + · · · + p K λ K ,
rik = ai1 x1k + ai2 x2k + · · · + ain xnk
indicate, respectively, the profit and resource usage for the kth extreme point x k
(x1k , x2k , . . . , xnk ).Observe that this notation corresponds to that used in Section 12.4. Extreme points here
play the role of proposals in that discussion.
It is important to recognize that the new problem is equivalent to the original problem. The weights ensure
that the solution x j = λ1 x 1j + λ2 x 2j + · · · + λ K x Kj satisfies the subproblem constraints, and the resource
constraints for bi are equivalent to the original complicating constraints. The new form of the problem
includes all the characteristics of the original formulation and is often referred to as the master problem.
Note that the reformulation has reduced the number of constraints by replacing the subproblem constraints
with the single weighting constraint. At the same time, the new version of the problem usually has many more
variables, since the number of extreme points in the subproblem may be enormous (hundreds of thousands).
For this reason, it seldom would be tractable to generate all the subproblem extreme points in order to solve
the master problem directly by linear programming.
Decomposition avoids solving the full master problem. Instead, it starts with a subset of the subproblem
extreme points and generates the remaining extreme points only as needed. That is, it starts with the restricted
z = Max z = p1 λ1 + p2 λ2 + · · · + p J λ J ,
ri1 λ1 + ri2 λ2 + · · · + riJ λ J = bi (i = 1, 2, . . . , m),
where J is usually so much less than K that the simplex method can be employed for its solution.
Any feasible solution to the restricted master problem is feasible for the master problem by taking
λ J +1 = λ J +2 = · · · = λ K = 0. The theory of the simplex method shows that the solution to the restricted
master problem is optimal for the overall problem if every column in the master problem prices out to be
pk − π1r1k − π2r2k − · · · − πm rmk − σ ≤ 0
or, equivalently, in terms of the variables x kj generating pk and the rik, s,
This condition can be checked easily without enumerating every extreme point. We must solve only the
If v J − σ ≤ 0, then the optimality condition (9) is satisfied, and the problem has been solved. The optimal
solution x1∗ , x2∗ , . . . , xn∗ is given by weighting the extreme points x 1j , x 2j , . . . , x jJ used in the restricted master
problem by the optimal weights λ∗1 , λ∗2 , . . . , λ∗J to that problem, that is,
x ∗j = λ∗1 x 1j + λ∗2 x 2j + · · · + λ∗j x jJ
0, then the optimal extreme point solution to the subproblem x1J +1 ,
(J + 1)st extreme point to improve the restricted master. A new weight
p J +1 = c1 x1J +1 + c2 x2J +1 + · · · + cn xnJ +1 ,
riJ +1 = ai1 x1J +1 + ai2 x2J +1 + · · · + ain xnJ +1
The representation property has shown that decomposition is solving the
master problem by generating coefficient data as needed. Since the master problem is a linear program,
the decomposition algorithm inherits finite convergence from the simplex method. Recall that the simplex
method solves linear programs in a finite number of steps. For decomposition, the subproblem calculation
ensures that the variable introduced into the basis has a positive reduced cost, just as in applying the simplex
method to the master problem. Consequently, from the linear-programming theory, the master problem
is solved in a finite number of steps; the procedure thus determines an optimal solution by solving the
restricted master problem and subproblem alternately a finite number of times.
We previously observed that the value z J to the restricted master problem tends to tail off and approach z ∗ ,
the optimal value to the overall problem, very slowly. As a result, we may wish to terminate the algorithm
before an optimal solution has been obtained, rather than paying the added computational expense to improve
the current solution only slightly. An important feature of the decomposition approach is that it permits us to
assess the effect of terminating with a suboptimal solution by indicating how far z J is removed from z ∗ .
For notation let π1J , π2J , . . . , πmJ , and σ J denote the optimal shadow prices for the m resource constraints
and the weighting constraint in the current restricted master problem. The current subproblem is:
with optimal shadow prices α1 , α2 , . . . , αq . By linear programming duality theory these shadow prices solve
But these inequalities are precisely the dual feasibility conditions of the original problem, and so the solution
to every subproblem provides a dual feasible solution to that problem. The weak duality property of linear
programming, though, shows that every feasible solution to the dual gives an upper bound to the primal
Since the solution to every restricted master problem determines a feasible solution to the original problem
(via the master problem), we also know that
As the algorithm proceeds, the lower bounds z increase and approach z ∗ . There is, however, no guarantee
that the dual feasible solutions are improving. Consequently, theupper bound generated at any step may be
worse than those generated at previous steps, and we always record the best upper bound generated thus far.
The upper bound can be expressed in an alternative form. Since the variables πiJ and σ J are optimal
shadow prices to the restricted master problem, they solve its dual problem, so that:
Substituting this value together with the equality (10), in expression (11), gives the alternative form for the
This form is convenient since it specifies the bounds in terms of the objective values of the subproblem
and restricted master problem. The only dual variable used corresponds to the weighting constraint in the
To illustrate these bounds, reconsider the preview problem introduced in Section 12.2. The first restricted
master problem used two subproblem extreme points and was given by:
At this point, computations could have been terminated, with the assurance that the solution of the current
restricted master problem is within 5 percent of the optimal objective value, which in this case is z ∗ = 21 21 .
For expositional purposes, we have assumed that every subproblem encountered has an optimal solution, even
though its objective value might be unbounded. First, we should note that an unbounded objective value to a
subproblem does not necessarily imply that the overall problem is unbounded, since the constraints that the
subproblem ignores may prohibit the activity levels leading to an unbounded subproblem solution from being
feasible to the full problem. Therefore, we cannot simply terminate computations when the subproblem is
unbounded; a more extensive procedure is required; reconsidering the representation property underlying the
theory will suggest the appropriate procedure.
When the subproblem is unbounded, the representation property becomes more delicate. For example,
the feasible region in Fig. 12.6 contains three extreme points. Taking the weighted combination of these
points generates only the shaded portion of the feasible region. Observe, though, that by moving from the
shaded region in a direction parallel to either of the unbounded edges, every feasible point can be generated.
This suggests that the general representation property should include directions as well as extreme points.
Actually, we do not require all possible movement directions, but only those that are analogous to extreme
Before exploring this idea, let us introduce a definition.
i) A direction d = (d1 , d2 , . . . , dn ) is called a ray for the subproblem if, whenever x1 , x2 , . . . , xn is a
also is feasible for any choice of θ ≥ 0.
ii) A ray d = (d1 , d2 , . . . , dn ) is called an extreme ray if it cannot be expressed as a weighted combination
of two other rays; that is, if there are no two rays d 0 = (d10 , d20 , . . . , dn0 ) and d 00 = (d100 , d200 , . . . , dn00 ) and
Figure 12.6 Representing an unbounded region.
A ray is a direction that points from any feasible point only toward other feasible points. An extreme ray is
an unbounded edge of the feasible region. In Fig. 12.6, d 1 and d 2 are the only two extreme rays. Any other
ray such as d can be expressed as a weighted combination of these two rays; for example,
d = (1, 4) = 2d 1 + d 2 = 2(0, 1) + (1, 2).
The extended representation result states that there are only a finite number of extreme rays d 1 , d 2 , . . . , d L
to the subproblem and that any feasible solution x = (x1 , x2 , . . . , xn ) to the subproblem can be expressed
as a weighted combination of extreme points plus a nonnegative combination of extreme rays, as:
x j = λ1 x 1j + λ2 x 2j + · · · + λk x kj + θ1 d 1j + θ2 d 2j + · · · + θ L d Lj
(k = 1, 2, . . . , K ; ` = 1, 2, . . . , L).
Observe that the θ j need not sum to one.
Let p̂k and r̂ik denote, respectively, the per-unit profit and the ith resource usage of the kth extreme ray;
r̂ik = ai1 d1k + ai2 d2k + · · · + ain dnk
Substituting as before for x j in the complicating constraints in terms of extreme points and extreme rays gives
Max z = p1 λ1 + p2 λ2 + · · · + p K λ K + p̂1 θ1 + p̂2 θ2 + · · · + p̂ L θ L ,
ri1 λ1 +ri2 λ2 + · · · +riK λ K +r̂i1 θ1 +r̂i2 θ2 + · · · +r̂iL θ L = bi
(k = 1, 2, . . . , K ; ` = 1, 2, . . . , L).
The solution strategy parallels that given previously. At each step, we solve a restricted master problem
containing only a subset of the extreme points and extreme rays, and use the optimal shadow prices to define a
subproblem. If the subproblem has an optimal solution, a new extreme point is added to the restricted master
problem and it is solved again. When the subproblem is unbounded, though, an extreme ray is added to the
restricted master problem. To be precise, we must specify how an extreme ray is identified. It turns out that
an extreme ray is determined easily as a byproduct of the simplex method, as illustrated by the following
The subproblem has been identified as above solely for purposes of illustration. The feasible region to the
subproblem was given in terms of x1 and x2 in Fig. 12.6 by viewing x3 and x4 as slack variables.
As an initial restricted master problem, let us use the extreme points (x1 , x2 , x3 , x4 ) = (4, 0, 0, 2), (x1 , x2 , x3 , x4 ) =
(6, 2, 0, 0), and no extreme rays. These extreme points, respectively, use 4 and 6 units of the complicating
resource and contribute 20 and 28 units to the objective function. The restricted master problem is given by:
The solution is λ1 = 0, λ2 = 1, z 2 = 28, with a price of 0 on the complicating constraint.
Solving by the simplex method leads to the canonical form:
Since the objective coefficient for x3 is positive and x3 does not appear in any constraint with a positive
coefficient, the solution is unbounded. In fact, as we observed when developing the simplex method, by
taking x3 = θ , the solution approaches + ∞ by increasing θ and setting
This serves to alter x1 , x2 , x3 , x4 , from x1 = 6, x2 = 2, x3 = 0, x4 = 0, to x1 = 6 + θ, x2 = 2 + 2θ, x3 =
θ, x4 = 0, so that we move in the direction d = (1, 2, 1, 0) by a multiple of θ . This direction has a per-unit
profit of 3 and uses 1 unit of the complicating resource. It is the extreme ray added to the restricted master
and has optimal solution λ1 = 0, λ2 = 1, θ1 = 2, and z 3 = 34.
Since the price of the complicating resource is 3, the new subproblem objective function becomes:
v 3 = Max 5x1 − x2 − 3x1 = Max 2x1 − x2 .
Graphically we see from Fig. 12.6, that an optimal solution is x1 = 6, x2 = 2, x3 = x4 = 0, v 3 = 10.
Since v 3 ≤ σ 3 = 10, the last solution solves the full master problem and the procedure terminates. The
optimal solution uses the extreme point (x1 , x2 , x3 , x4 ) = (6, 2, 0, 0), plus two times the extreme ray
In general, whenever the subproblem is unbounded, the simplex method determines a canonical form
with c j > 0 and a i j ≤ 0 for each coefficient of some non-basic variable x j . As above, the extreme
ray d = (d1 , d2 , . . . , dn ) to be submitted to the restricted master problem has a profit coefficient c j and
−a i j if xk is the ith basic variable (changing the basis to compensate
0 if xk is nonbasic and k 6 = s (hold other nonbasics at 0).
The coefficients of this extreme ray simply specify how the values of the basic variables change per unit
change in the nonbasic variable xs being increased.
Large-scale systems frequently result in linear programs with enormous numbers of variables, that is, linear
z ∗ = Max z = c1 x1 + c2 x2 + · · · + cn xn ,
where n is very large. These problems arise directly from applications such as the multi-item production
scheduling example from Section 12.1, or the cutting-stock problem to be introduced below. They may arise
in other situations as well. For example, the master problem in decomposition has this form; in this case,
problem variables are the weights associated with extreme points and extreme rays.
Because of the large number of variables, direct solution by the simplex method may be inappropriate.
Simply generating all the coefficient data ai j usually will prohibit this approach. Column generation extends
the technique introduced in the decomposition algorithm, of using the simplex method, but generating the
coefficient data only as needed. The method is applicable when the data has inherent structural properties that
allow numerical values to be specified easily. In decomposition, for example, we exploited the fact that the
data for any variable corresponds to an extreme point or extreme ray of another linear program. Consequently,
new data could be generated by solving this linear program with an appropriate objective function.
The column-generation procedure very closely parallels the mechanics of the decomposition algorithm.
The added wrinkle concerns the subproblem, which now need not be a linear program, but can be any type of
optimization problem, including nonlinear, dynamic, or integer programming problems. As in decomposition,
we assume a priori that certain variables, say x J +1 , x J +2 , . . . , xn are nonbasic and restrict their values to
z J = Max c1 x1 +c2 x2 + · · · + c J x J ,
this is now small enough so that the simplex method can be employed for its solution. The original problem
(12) includes all of the problem characteristics and again is called a master problem, whereas problem (13)
Suppose that the restricted master problem has been solved by the simplex method and that π1J , π2J , . . . , πmJ
are the optimal shadow prices. The optimal solution together with x J +1 = x J +2 = · · · = xn = 0 is feasible
for the master problem (12). It is optimal if the simplex optimality condition
πiJ ai j ≤ 0 for every variable x j . Stated in another way, the solution to the
restricted master problem is optimal if v J ≤ 0 where:
If this condition is satisfied, the original problem has been solved without specifying all of the ai j data or
πiJ ais > 0, then the simplex method, when applied to the master problem, would
introduce variable xs into the basis. Column generation accounts for this possibility by adding variable xs
as a new variable to the restricted master problem. The new restricted master can be solved by the simplex
method and the entire procedure can be repeated.
This procedure avoids solving the full master problem; instead it alternately solves a restricted master
problem and makes the computations (14) to generate data a1s , a2s , . . . , ams for a new variable xs . Observe
that (14) is itself an optimization problem, with variables j = 1, 2, . . . , n. It is usually referred to as a
The method is specified in flow-chart form in Fig. 12.7. Its efficiency is predicated upon:
i) Obtaining an optimal solution before many columns have been added to the restricted master problem.
Otherwise the problems inherent in the original formulation are encountered.
ii) Being able to solve the subproblem effectively.
Details concerning the subproblem depend upon the structural characteristics of the problem being studied.
By considering a specific example, we can illustrate how the subproblem can be an optimization problem
(Cutting-stock problem) A paper (textile) company must produce various sizes of its paper products to meet
demand. For most grades of paper, the production technology makes it much easier to first produce the paper
on large rolls, which are then cut into smaller rolls of the required sizes. Invariably, the cutting process
involves some waste. The company would like to minimize waste or, equivalently, to meet demand using the
For notational purposes, assume that we are interested in one grade of paper and that this paper is
produced only in rolls of length ` for cutting. Assume, further, that the demand requires di rolls of size
`i (i = 1, 2, . . . , m) to be cut. In order for a feasible solution to be possible, we of course need `i ≤ `.
One approach to the problem is to use the possible cutting patterns for the rolls as decision variables.
Consider, for example, ` = 200 inches and rolls required for 40 different lengths `i ranging from 20 to 80
inches. One possible cutting pattern produces lengths of
with a waste of 5 inches. In general, let
x j = Number of times cutting pattern j is used,
ai j = Number of rolls of size `i used on the jth cutting pattern.
Then ai j x j is the number of rolls of size `i cut using pattern j, and the problem of minimizing total rolls
For the above illustration, the number of possible cutting patterns, n, exceeds 10 million, and this problem
is alarge-scale integer-programming problem. Fortunately, the demands di are usually high, so that rounding
optimal linear-programming solutions to integers leads to good solutions.
If we drop the integer restrictions, the problem becomes a linear program suited for the column-generation
since each objective coefficient is equal to one. Note that the subproblem is a minimization, since the restricted
master problem is a minimization problem seeking variables x j with c j < 0 (as opposed to seeking c j > 0
The subproblem considers all potential cutting plans. Since a cutting plan j is feasible whenever
the subproblem must determine the coefficients ai j of a new plan to minimize (15). For example, if the roll
length is given by ` = 10000 and the various lengths `i to be cut are 25, 30, 35, 40, 45, and 5000 , then the
25a1 j + 30a2 j + 35a3 j + 40a4 j + 45a5 j + 50a6 j ≤ 100,
The optimal values for ai j indicate how many of each length `i should be included in the new cutting pattern
j. Because subproblem (15) and (16) is a one-constraint integer-programming problem (called a knapsack
problem), efficient special-purpose dynamic-programming algorithms can be used for its solution.
As this example illustrates, column generation is a flexible approach for solving linear programs with
many columns. To be effective, the algorithm requires that the subproblem can be solved efficiently, as in
decomposition or the cutting-stock problem, to generate a new column or to show that the current restricted
master problem is optimal. In the next chapter, we discuss another important application by using column
1. Consider the following linear program:
Assuming no bounded-variable algorithm is available, solve by the decomposition procedure, using 0 ≤ x j ≤
1 ( j = 1, 2, 3, 4) as the subproblem constraints.
Initiate the algorithm with two proposals: the optimum solution to the subproblem and the proposal x1 = 1, x2 =
Consider the following linear-programming problem with special structure:
Maximize z = 15x1 + 7x2 + 15x3 + 20y1 + 12y2 ,
Tableau 1 represents the solution of this problem by the decomposition algorithm in the midst of the calculations.
The variables s1 and s2 are slack variables for the first two constraints of the master problem; the variables a1 and
a2 are artificial variables for the weighting constraints of the master problem.
The extreme points generated thus far are:
What are the shadow prices associated with each constraint of the restricted master?
Formulate the two subproblems that need to be solved at this stage using the shadow prices determined in part (a).
Solve each of the subproblems graphically.
Add any newly generated extreme points of the subproblems to the restricted master.
Solve the new restricted master by the simplex method continuing from the previous solution. (See Exercise 29
f) How do we know whether the current solution is optimal?
3. Consider a transportation problem for profit maximization:
Maximize z = c11 x11 + c12 x12 + c13 x13 + c21 x21 + c22 x22 + c23 x23 ,
a) Suppose that we solve this problem by decomposition, letting the requirement bi constraints and nonnegativity
xi j ≥ 0 constraints compose the subproblem. Is it easy to solve the subproblem at each iteration? Does the
restricted master problem inherit the network structure of the problem, or is the network structure ‘‘lost’’ at the
b) Use the decomposition procedure to solve for the data specified in the following table:
Distribution profits (ci j ) Availabilities ai
Initiate the algorithm with two proposals:
To simplify calculations, you may wish to use the fact that a transportation problem contains a redundant equation
and remove the second supply equation from the problem.
4. A small city in the northeast must racially balance its 10 elementary schools or sacrifice all federal aid being issued
to the school system. Since the recent census indicated that approximately 28% of the city’s population is composed
of minorities, it has been determined that each school in the city must have a minority student population of 25%
to 30% to satisfy the federal definition of ‘‘racial balance.’’ The decision has been made to bus children in order
to meet this goal. The parents of the children in the 10 schools are very concerned about the additional travel time
for the children who will be transferred to new schools. The School Committee has promised these parents that the
busing plan will minimize the total time that the children of the city have to travel. Each school district is divided
into 2 zones, one which is close to the local school and one which is far from the school, as shown in Fig. E12.1.
The School Committee has also promised the parents of children who live in a ‘‘close zone’’ that they will attempt
to discourage the busing of this group of children (minority and nonminority) away from their present neighborhood
school. The School Committee members are intent on keeping their promises to this group of parents.
An additional problem plaguing the Committee is that any school whose enrollment drops below 200 students must
be closed; this situation would be unacceptable to the Mayor and to the taxpayers who would still be supporting a
The available data include the following:
For each district i = 1, 2, . . . , 10, we have
Number of nonminority children in the close zone of school district i.
Number of minority children in the close zone of school district i.
Number of nonminority children in the far zone of school district i.
Number of minority children in the far zone of school district i.
For each pair (i, j), of school districts, we have the travel time ti j .
For each school i, the capacity Di is known (all Di > 200 and there is enough school capacity to accommodate
a) Formulate the problem as a linear program. [Hint. To discourage the busing of students who live close to their
neighborhood school, you may add a penalty, p, to the travel time to any student who lives in the close zone of
school district i and is assigned to school district j (i 6 = j). Assume that a student who lives in the close zone
of school i and is assigned to school i does not have to be bused.]
b) There is only a small-capacity minicomputer in the city, which cannot solve the linear program in its entirety.
Hence, the decomposition procedure could be applied to solve the problem. If you were a mathematical programming specialist hired by the School Committee, how would you decompose the program formulated in part
(a)? Identify the subproblem, the weighting program, and the proposal-generating program. Do not attempt to
5. A food company blames seasonality in production for difficulties that it has encountered in scheduling its activities
efficiently. The company has to cope with three major difficulties:
I) Its food products are perishable. On the average, one unit spoils for every seven units kept in inventory from one
II) It is costly to change the level of the work force to coincide with requirements imposed by seasonal demands. It
costs $750 to hire and train a new worker, and $500 to fire a worker.
III) On the average, one out of eight workers left idle in any month decides to leave the firm.
Because of the ever-increasing price of raw materials, the company feels that it should design a better scheduling
plan to reduce production costs, rather than lose customers by increasing prices of its products.
The task of the team hired to study this problem is made easier by the following operating characteristics of
i) Practically, the firm has no problems procuring any raw materials that it requires;
ii) Storage capacity is practically unlimited at the current demand level; and
iii) The products are rather homogeneous, so that all output can be expressed in standard units (by using certain
The pertinent information for decision-making purposes is:
iv) The planning horizon has T = 12 months (one period = one month);
v) Demand Di is known for each period (i = 1, 2, . . . , 12);
vi) Average productivity is 1100 units per worker per month;
vii) The level of the work force at the start of period 1 is L 1 ; S0 units of the product are available in stock at the start
viii) An employed worker is paid Wt as wages per month in period t;
ix) An idle worker is paid a minimum wage of Mt in month t, to be motivated not to leave;
x) It costs I dollars to keep one unit of the product in inventory for one month.
With the above information, the company has decided to construct a pilot linear program to determine work-force
level, hirings, firings, inventory levels, and idle workers.
a) Formulate the linear program based on the data above. Show that the model has a staircase structure.
b) Restate the constraints in terms of cumulative demand and work force; show that the model now has block
6. A firm wishing to operate with as decentralized an organizational structure as possible has two separate operating
divisions. The divisions can operate independently except that they compete for the firm’s two scarce resources—
working capital and a particular raw material. Corporate headquarters would like to set prices for the scarce resources
that would be paid by the divisions, in order to ration the scarce resources. The goal of the program is to let each
division operate independently with as little interference from corporate headquarters as possible.
Division #1 produces 3 products and faces capacity constraints as follows:
The contribution to the firm per unit from this division’s products are 2.50, 1.75, and 0.75, respectively. Division
#2 produces 2 different products and faces its own capacity constraints as follows:
The contribution to the firm per unit from this division’s products are 3 and 2, respectively. The joint constraints that
require coordination among the divisions involve working capital and one raw material. The constraint on working
and the constraint on the raw material is
Corporate headquarters has decided to use decomposition to set the prices for the scarce resources. The optimal
solution using the decomposition algorithm indicated that division #1 should produce x1 = 1, x2 = 2, and x3 = 0,
while division #2 should produce y1 = 21 and y2 = 3 21 . The shadow prices turned out to be 23 and 13 for working
capital and raw material, respectively. Corporate headquarters congratulated itself for a fine price of analysis. They
then announced these prices to the divisions and told the divisions to optimize their own operations independently.
Division #1 solved its subproblem and reported an operating schedule of x1 = 0, x2 = 4, x3 = 0. Similarly, division
#2 solved its subproblem and reported an operating schedule of y1 = 2, y2 = 2.
Corporate headquarters was aghast—together the divisions requested more of both working capital and the raw
Did the divisions cheat on the instructions given them by corporate headquarters?
Were the shadow prices calculated correctly?
What can the corporate headquarters do with the output of the decomposition algorithm to produce overall optimal
7. For the firm described in Exercise 6, analyze the decomposition approach in detail.
Graph the constraints of each subproblem, division #1 in three dimensions and division #2 in two dimensions.
List all the extreme points for each set of constraints.
Write out the full master problem, including all the extreme points.
The optimal shadow prices are 23 and 13 on the working capital and raw material, respectively. The shadow prices
on the weighting constraints are 58 and 83 for divisions #1 and #2, respectively. Calculate the reduced costs of all
e) Identify the basic variables and determine the weights on each extreme point that form the optimal solution.
f) Solve the subproblems using the above shadow prices. How do you know that the solution is optimal after solving
g) Show graphically that the optimal solution to the overall problem is not an extreme solution to either subproblem.
8. To plan for long-range energy needs, a federal agency is modeling electrical-power investments as a linear program.
The agency has divided its time horizon of 30 years into six periods t = 1, 2, . . . , 6, of five years each. By the end
of each of these intervals, the government can construct a number of plants (hydro, fossil, gas turbine, nuclear, and
so forth). Let xi j denote the capacity of plant j when initiated at the end of interval i, with per-unit construction
cost of ci j . Quantities x0 j denote capacities of plants currently in use.
Given the decisions xi j on plant capacity, the agency must decide how to operate the plants to meet energy needs.
Since these decisions require more detailed information to account for seasonal variations in energy demand, the
agency has further divided each of the time intervals t = 1, 2, . . . , 6 into 20 subintervals s = 1, 2, . . . , 20. The
agency has estimated the electrical demand in each (interval t, subinterval s) combination as dts . Let oi jts denote
the operating level during the time period ts of plant j that has been constructed in interval i. The plants must be
used to meet demand requirements and incur per-unit operating costs of vi jts . Because of operating limitations and
aging, the plants cannot always operate at full construction capacity. Let ai jt denote the availability during time
period t of plant j that was constructed in time interval i. Typically, the coefficient ai jt will be about 0.9. Note that
ai jt = 0 for t ≤ i, since the plant is not available until after the end of its construction interval i.
To model uncertainties in its demand forecasts, the agency will further constrain its construction decisions by
introducing a margin m of reserve capacity; in each period the total operating capacity from all plants must be at
Finally, the total output of hydroelectric power in any time interval t cannot exceed the capacity Hit imposed by
availability of water sources. (In a more elaborate model, we might incorporate Hit as a decision variable.)
The linear-programming model developed by the agency is:
(t = 1, 2, . . . , 6; s = 1, 2, . . . , 20),
(i = 0, 1, . . . , 6; t = 1, 2, . . . , 6;
j = 1, 2, . . . , 20; s = 1, 2, . . . , 20),
(t = 1, 2, . . . , 6; i = 0, 1, . . . , 6),
(t = 1, 2, . . . , 6; s = 1, 2, . . . , 20),
(i = 0, 1, . . . , 6; t = 1, 2, . . . , 6;
j = 1, 2, . . . , 20; s = 1, 2, . . . , 20).
In this formulation, θs denotes the length of time period s; the values of xi j are given. The subscript h denotes
a) Interpret the objective function and each of the constraints in this model. How large is the model?
b) What is the structure of the constraint coefficients for this problem?
c) Suppose that we apply the decomposition algorithm to solve this problem; for each plant j and time period t, let
(i = 0, 1, . . . , 6; s = 1, 2, . . . , 20),
(i = 0, 1, . . . , 6; s = 1, 2, . . . , 20),
form a subproblem. What is the objective function to the subproblem at each step? Show that each subproblem
either solves at oi jts = 0 and xi j = 0 for all i and s, or is unbounded. Specify the steps for applying the
decomposition algorithm with this choice of subproblems.
d) How would the application of decomposition discussed in part (c) change if the constraints
are added to each subproblem in which j = h denotes a hydroelectric plant?
9. The decomposition method can be interpreted as a ‘‘cutting-plane’’ algorithm. To illustrate this viewpoint, consider
Applying decomposition with the constraints 0 ≤ x1 ≤ 1 and 0 ≤ x2 ≤ 1 as the subproblem, we have four extreme
Evaluating the objective function 3x1 + 8x2 and resource usage 2x1 + 4x2 at these extreme-point solutions gives
Maximize z = 0λ1 + 8λ2 + 3λ3 + 11λ4 , Dual
a) Let the variable w be defined in terms of the dual variables π and σ as w = σ + 3π. Show that the dual to the
b) Figure E12.2 depicts the feasible region for the dual problem. Identify the optimal solution to the dual problem
in this figure. What is the value of z ∗ , the optimal objective value of the original problem?
c) Suppose that we initiate the decomposition with a restricted master problem containing only the third extreme
point x1 = 1 and x2 = 0. Illustrate the feasible region to the dual of this restricted master in terms of w and π,
and identify its optimal solution w∗ and π ∗ . Does this dual feasible region contain the feasible region to the full
d) Show that the next step of the decomposition algorithm adds a new constraint to the dual of the restricted master
problem. Indicate which constraint in Fig. E12.2 is added next. Interpret the added constraint as ‘‘cutting away’’
the optimal solution w∗ and π ∗ found in part (c) from the feasible region. What are the optimal values of the dual
variables after the new constraint has been added?
e) Note that the added constraint is found by determining which constraint is most violated at π = π ∗ ; that is, by
moving vertically in Fig. E12.2 at π = π ∗ , crossing all violated constraints until we reach the dual feasible region
at w = ŵ. Note that the optimal objective value z ∗ to the original problem satisfies the inequalities:
Relate this bound to the bounds discussed in this chapter.
f) Solve this problem to completion, using the decomposition algorithm. Interpret the solution in Fig. E12.2,
indicating at each step the cut and the bounds on z ∗ .
g) How do extreme rays in the master problem alter the formulation of the dual problem? How would the cutting-plane
interpretation discussed in this problem be modified when the subproblem is unbounded?
10. In this exercise we consider a two-dimensional version of the cutting stock problem.
a) Suppose that we have a W -by-L piece of cloth. The material can be cut into a number of smaller pieces and sold.
Let πi j denote the revenue for a smaller piece with dimensions wi by ` j (i = 1, 2, . . . , m; j = 1, 2, . . . , n).
Operating policies dictate that we first cut the piece along its width into strips of size wi . The strips are then cut
into lengths of size ` j . Any waste is scrapped, with no additional revenue.
For example, a possible cutting pattern for a 9-by-10 piece might be that shown in Fig. E12.3. The shaded
regions correspond to trim losses. Formulate a (nonlinear) integer program for finding the maximum-revenue
cutting pattern. Can we solve this integer program by solving several knapsack problems? [Hint. Can we use
the same-length cuts in any strips with the same width? What is the optimal revenue vi obtained from a strip of
width wi ? What is the best way to choose the widths wi to maximize the total value of the vi ’s?]
b) A firm has unlimited availabilities of W -by-L pieces to cut in the manner described in part (a). It must cut
these pieces into smaller pieces in order to meet its demand of di j units for a piece with width wi and length
` j (i = 1, 2, . . . , m; j = 1, 2, . . . , n). The firm wishes to use as few W -by-L pieces as possible to meet its sales
Formulate the firm’s decision-making problem in terms of cutting patterns. How can column generation be used
to solve the linear-programming approximation to the cutting-pattern formulation?
11. In Section 12.1 we provided a formulation for a large-scale multi-item production-scheduling problem. The purpose
of this exercise (and of Exercises 12 and 13) is to explore the implications of the suggested formulation, as well as
techniques that can be developed to solve the problem.
The more classical formulation of the multi-item scheduling problem can be stated as follows:
[s jt δ(x jt ) + v jt x jt + h jt I jt ],
(t = 1, 2, . . . , T ; j = 1, 2, . . . , J ),
(t = 1, 2, . . . , T ; j = 1, 2, . . . , J ),
= Units of item j to be produced in period t,
= Units of inventory of item j left over at the end of period t,
= Unit production cost of item j in period t,
= Inventory holding cost for item j in period t,
= Down time consumed in performing a setup for item j,
= Man-hours required to produce one unit of item j,
= Total man-hours available for period t.
a) Interpret the model formulation. What are the basic assumptions of the model? Is there any special structure to
b) Formulate an equivalent (linear) mixed-integer program for the prescribed model. If T = 12 (that is, we are
planning for twelve time periods) and J = 10,000 (that is, there are 10,000 items to schedule), how many integer
variables, continuous variables, and constraints does the model have? Is it feasible to solve a mixed-integer
12. Given the computational difficulties associated with solving the model presented in Exercise 11, A. S. Manne
conceived of a way to approximate the mixed-integer programming model as a linear program. This transformation
is based on defining for each item j a series of production sequences over the planning horizon T . Each sequence
is a set of T nonnegative integers that identify the amount to be produced of item j at each time period t during the
planning horizon, in such a way that demand requirements for the item are met. It is enough to consider production
sequences such that, at a given time period, the production is either zero or the sum of consecutive demands for
some number of periods into the future. This limits the number of production sequences to a total of 2T −1 for each
x jkt = amount to be produced of item j in period t by means of
To illustrate how the production sequences are constructed, assume that T = 3. Then the total number of production
sequences for item j is 23−1 = 4. The corresponding sequences are given in Table E12.1.
The total cost associated with sequence k for the production of item j is given by
[s jt δ(x jkt ) + v jt x jkt + h jt I jt ],
and the corresponding man-hours required for this sequence in period t is
a) Verify that, if the model presented in Exercise 11 is restricted to producing each item in production sequences,
( j = 1, 2, . . . , J ; k = 1, 2, . . . , K ).
b) Study the structure of the resulting model. How could you define the structure? For T = 12 and J = 10,000,
how many rows and columns does the model have?
c) Under what conditions can we eliminate the integrality constraints imposed on variables θ jk without significantly
affecting the validity of the model? [Hint. Read the comment made on the multi-term scheduling problem in
d) Propose a decomposition approach to solve the resulting large-scale linear-programming model. What advantages
and disadvantages are offered by this approach? (Assume that at this point the resulting subproblems are easy to
13. Reconsider the large-scale linear program proposed in the previous exercise:
( j = 1, 2, . . . , J ; k = 1, 2, . . . , K ),
a) Let us apply the column-generation algorithm to solve this problem. At some stage of the process, let πt for
t = 1, 2, . . . , T be the shadow prices associated with constraints (1), and let πT +k for k = 1, 2, . . . , K be the
shadow prices associated with constraints (2), in the restricted master problem. The reduced cost c jk for variable
θ jk is given by the following expression:
Show, in terms of the original model formulation described in Exercise 11, that c jk is defined as:
(s jt − πt ` j )δ(x jkt ) + (v jt − πt k j )x jkt + h jt I jt − πT +k .
The inner minimization can be interpreted as finding the minimum-cost production sequence for a specific item
j. This problem can be interpreted as an uncapacitated single-item production problem under fluctuating demand
requirements d jt throughout the planning horizon t = 1, 2, . . . , T . Suggest an effective dynamic-programming
approach to determine the optimum production sequence under this condition.
c) How does the above approach eliminate the need to generate all the possible production sequences for a given
item j? Explain the interactions between the master problem and the subproblem.
14. The ‘‘traffic-assignment’’ model concerns minimizing travel time over a large network, where traffic enters the
network at a number of origins and must flow to a number of different destinations. We can consider this model as
a multicommodity-flow problem by defining a commodity as the traffic that must flow between a particular origin–
destination pair. As an alternative to the usual node–arc formulation, consider chain flows. A chain is merely a
directed path through a network from an origin to a destination. In particular, let
1 if arc i is in chain j, which connects origin–destination pair k,
z kj = Flow over chain j between origin–destination pair k.
For example, the network in Fig. E12.4, shows the arc flows of one of the commodities, those vehicles entering
node 1 and flowing to node 5. The chains connecting the origin–destination pair 1–5 can be used to express the flow
Frequently an upper bound u i is imposed upon the total flow on each arc i. These restrictions are modeled as:
The summation indices jk correspond to chains joining the kth origin–destination pair. The total number of arcs
is I and the total number of origin–destination pairs is K . The requirement that certain levels of traffic must flow
between origin–destination pairs can be formulated as follows:
vk = Required flow between origin–destination pair (commodity) k.
Finally, suppose that the travel time over any arc is ti , so that, if xi units travel over arc i, the total travel time on arc
a) Complete the ‘‘arc–chain’’ formulation of the traffic-assignment problem by specifying an objective function that
minimizes total travel time on the network. [Hint. Define the travel time over a chain, using the ai j data.]
b) In reality, generating all the chains of a network is very difficult computationally. Suppose enough chains have
been generated to determine a basic feasible solution to the linear program formulated in part (a). Show how to
compute the reduced cost of the next chain to enter the basis from those generated thus far.
c) Now consider the chains not yet generated. In order for the current solution to be optimal, the minimum reduced
costs of these chains must be nonnegative. How would you find the chain with the minimum reduced cost for
each ‘‘commodity’’? [Hint. The reduced costs are, in general,
where πi and u k are the shadow prices associated with the capacity restriction on the ith constraint and flow
requirement between the kth origin–destination pair. What is the sign of πi ?]
d) Give an economic interpretation of πi . In the reduced cost of part (c), do the values of πi depend on which
15. Consider the node–arc formulation of the ‘‘traffic-assignment’’ model. Define a ‘‘commodity’’ as the flow from an
xikj = Flow over arc i − j of commodity k.
The conservation-of-flow equations for each commodity are:
xnk j = −vk if n = destination for commodity k,
The capacity restrictions on the arcs can be formulated as follows:
assuming that ti j the travel time on arc i − j. To minimize total travel time on the network, we have the following
a) Let the conservation-of-flow constraints for a commodity correspond to a subproblem, and the capacity restrictions
on the arcs correspond to the master constraints in a decomposition approach. Formulate the restricted master,
and the subproblem for the kth commodity. What is the objective function of this subproblem?
b) What is the relationship between solving the subproblems of the node–arc formulation and finding the minimum
reduced cost for each commodity in the arc–chain formulation discussed in the previous exercise?
c) Show that the solution of the node–arc formulation by decomposition is identical to solving the arc–chain formulation discussed in the previous exercise. [Hint. In the arc–chain formulation, define new variables
16. In the node–arc formulation of the ‘‘traffic-assignment’’ problem given in Exercise 15, the subproblems correspond
to finding the shortest path between the kth origin–destination pair. In general, there may be a large number of origin–
destination pairs and hence a large number of such subproblems. However, in Chapter 11 on dynamic programming,
we saw that we can solve simultaneously for the shortest paths from a particular origin to all destinations. We can then
consolidate the subproblems by defining one subproblem for each node where traffic originates. The conservationof-flow constraints become:
yns j = −vk if n = a destination node in the origin–destination pair k = (s, n)
the summation vk is the total flow emanating from origin s for all destination nodes. In this formulation,
xikj denotes the total flow on arc i − j that emanates from origin s; that is, the summation is carried over
all origin–destination pairs k = (s, t) whose origin is node s.
a) How does the decomposition formulation developed in Exercise 15 change with this change in definition of a
subproblem? Specify the new formulation precisely.
b) Which formulation has more constraints in its restricted master?
c) Which restricted master is more restricted? [Hint. Which set of constraints implies the other?]
d) How does the choice of which subproblems to employ affect the decomposition algorithm? which choice would
17. Consider a ‘‘nested decomposition’’ as applied to the problem
Let (1) be the constraints of the (first) restricted master problem. If πi (i = 1, 2, . . . , k) are shadow prices for the
constraints (1) in the weighting problem, then
constitutes subproblem 1 (the proposal-generating problem).
Suppose, though, that the constraints (30 ) complicate this problem and make it difficult to solve. Therefore, to
solve the subproblem we further apply decomposition on subproblem 1. Constraints (20 ) will be the constraints of
the ‘‘second’’ restricted master. Given any shadow prices αi (i = k + 1, k + 2, . . . , `) for constraints (20 ) in the
weighting problem, the subproblem 2 will be:
a) Consider the following decomposition approach: Given shadow prices πi , solve subproblem (1) to completion
by applying decomposition with subproblem (2). Use the solution to this problem to generate a new weighting
variable to the first restricted master problem, or show that the original problem (P) [containing all constraints
(1), (2), (3)] has been solved. Specify details of this approach.
b) Show finite convergence and bounds on the objective function to (P).
c) Now consider another approach: Subproblem 1 need not be solved to completion, but merely until a solution
x j ( j = 1, 2, . . . , n) is found, so that
where γ is the shadow price for the weighting constraint to the first restricted master. Indicate how to identify
such a solution x j ( j = 1, 2, . . . , n) while solving the second restricted master problem; justify this approach.
d) Discuss convergence and objective bounds for the algorithm proposed in part (c).
A number of the exercises in this chapter are based on or inspired by articles in the literature. Exercise 8:
D. Anderson, ‘‘Models for Determining Least-Cost Investments in Electricity Supply,’’ The Bell Journal of
Economics and Management Science, 3, No. 1, Spring 1972.
Exercise 10: P. E. Gilmore and R. E. Gomory, ‘‘A Linear Programming Approach to the Cutting Stock
Problem-II,’’ Operations Research, 11, No. 6, November–December 1963.
Exercise 12: A. S. Manne, ‘‘Programming of Economic Lot Sizes,’’ Management Science, 4, No. 2, January
Exercise 13: B. P. Dzielinski and R. E. Gomory, ‘‘Optimal Programming of Lot Sizes, Inventory, and Labor
Allocations,’’ Management Science, 11, No. 9, July 1965; and L. S. Lasdon and R. C. Terjung, ‘‘An Efficient
Algorithm for Multi-Item Scheduling,’’ Operation Research, 19, No. 4, July–August 1971.
Exercises 14 through 16: S. P. Bradley, ‘‘Solution Techniques for the Traffic Assignment Problem,’’ Operations Research Center Report ORC 65–35, University of California, Berkeley. Exercise 17: R. Glassey,
‘‘Nested Decomposition and Multi-Stage Linear Programs,’’ Management Science, 20, No. 3, 1973.
Numerous mathematical-programming applications, including many introduced in previous chapters, are
cast naturally as linear programs. Linear programming assumptions or approximations may also lead to
appropriate problem representations over the range of decision variables being considered. At other times,
though, nonlinearities in the form of either nonlinear objectivefunctions or nonlinear constraints are crucial
for representing an application properly as a mathematical program. This chapter provides an initial step
toward coping with such nonlinearities, first by introducing several characteristics of nonlinear programs and
then by treating problems that can be solved using simplex-like pivoting procedures. As a consequence, the
techniques to be discussed are primarily algebra-based. The final two sections comment on some techniques
As our discussion of nonlinear programming unfolds, the reader is urged to reflect upon the linearprogramming theory that we have developed previously, contrasting the two theories to understand why the
nonlinear problems are intrinsically more difficult to solve. At the same time, we should try to understand
the similarities between the two theories, particularly since the nonlinear results often are motivated by, and
are direct extensions of, their linear analogs. The similarities will be particularly visible for the material of
this chapter where simplex-like techniques predominate.
A general optimization problem is to select n decision variables x1 , x2 , . . . , xn from a given feasible region
in such a way as to optimize (minimize or maximize) a given objective function
of the decision variables. The problem is called a nonlinear programming problem (NLP) if the objective
function is nonlinear and/or thefeasible region is determined by nonlinear constraints. Thus, in maximization
form, the general nonlinear program is stated as:
where each of the constraint functions g1 through gm is given. A special case is the linear program that has
been treated previously. The obvious association for this case is
Note that nonnegativity restrictions on variables can be included simply by appending the additional constraints:
Sometimes these constraints will be treated explicitly, just like any other problem constraints. At other times,
it will be convenient to consider them implicitly in the same way that nonnegativity constraints are handled
For notational convenience, we usually let x denote the vector of n decision variables x1 , x2 , . . . , xn —
that is, x = (x1 , x2 , . . . , xn ) — and write the problem more concisely as
As in linear programming, we are not restricted to this formulation. To minimize f (x), we can of course
maximize − f (x). Equality constraints h(x) = b can be written as two inequality constraints h(x) ≤ b and
−h(x) ≤ −b. In addition, if we introduce a slack variable, each inequality constraint is transformed to an
equality constraint. Thus sometimes we will consider an alternative equality form:
Usually the problem context suggests either an equality or inequality formulation (or a formulation with both
types of constraints), and we will not wish to force the problem into either form.
The following three simplified examples illustrate how nonlinear programs can arise in practice.
Portfolio Selection An investor has $5000 and two potential investments. Let x j for j = 1 and j = 2
denote his allocation to investment j in thousands of dollars. From historical data, investments 1 and 2 have
an expected annual return of 20 and 16 percent, respectively. Also, the total risk involved with investments 1
and 2, as measured by the variance of total return, is given by 2x12 + x22 + (x1 + x2 )2 , so that risk increases with
total investment and with the amount of each individual investment. The investor would like to maximize his
expected return and at the same time minimize his risk. Clearly, both of these objectives cannot, in general, be
satisfied simultaneously. There are several possible approaches. For example, he can minimize risk subject
to a constraint imposing a lower bound on expected return. Alternatively, expected return and risk can be
combined in an objective function, to give the model:
Maximize f (x) = 20x1 + 16x2 − θ [2x12 + x22 + (x1 + x2 )2 ],
The nonnegative constant θ reflects his tradeoff between risk and return. If θ = 0, the model is a linear
program, and he will invest completely in the investment with greatest expected return. For very large θ , the
objective contribution due to expected return becomes negligible and he is essentially minimizing his risk.
Water Resources Planning In regional water planning, sources emitting pollutants might be required to
remove waste from the water system. Let x j be the pounds of Biological Oxygen Demand (an often-used
measure of pollution) to be removed at source j.
One model might be to minimize total costs to the region to meet specified pollution standards:
f j (x j ) = Cost of removing x j pounds of Biological Oxygen Demand at
bi = Minimum desired improvement in water quality at point i in the
ai j = Quality response, at point i in the water system, caused by removing
one pound of Biological Oxygen Demand at source j,
u j = Maximum pounds of Biological Oxygen Demand that can be
Constrained Regression A university wishes to assess the job placements of its graduates. For simplicity,
it assumes that each graduate accepts either a government, industrial, or academic position. Let
and let G j , I j , and A j denote the number entering government, industry, and academia, respectively, in year
One model being considered assumes that a given fraction of the student population joins each job
category each year. If these fractions are denoted as λ1 , λ2 , and λ3 , then the predicted number entering the
job categories in year j is given by the expressions
A reasonable performance measure of the model’s validity might be the difference between the actual number
of graduates G j , I j , and A j entering the three job categories and the predicted numbers Ĝ j , Iˆj , and Â j , as
[(G j − Ĝ j )2 + (I j − Iˆj )2 + (A j − Â j )2 ],
subject to the constraint that all graduates are employed in one of the professions. In terms of the fractions
entering each profession, the model can be written as:
[(G j − λ1 N j )2 + (I j − λ2 N j )2 + (A j − λ3 N j )2 ],
This is a nonlinear program in three variables λ1 , λ2 , and λ3 .
There are alternative ways to approach this problem. For example, the objective function can be changed
G j − Ĝ j | + |I j − Iˆj | + |A j − Â j .†
This formulation is appealing since the problem now can be transformed into a linear program. Exercise 28
(see also Exercise 20) from Chapter 1 illustrates this transformation.
The range of nonlinear-programming applications is practically unlimited. For example, it is usually simple
to give a nonlinear extension to any linear program. Moreover, the constraint x = 0 or 1 can be modeled
as x(1 − x) = 0 and the constraint x integer as sin (π x) = 0. Consequently, in theory any application of
integer programming can be modeled as a nonlinear program. We should not be overly optimistic about these
formulations, however; later we shall explain why nonlinear programming is not attractive for solving these
Geometrically, nonlinear programs can behave much differently from linear programs, even for problems
with linear constraints. In Fig. 13.1, the portfolio-selection example from the last section has been plotted for
several values of the tradeoff parameter θ . For each fixed value of θ , contours of constant objective values
are concentric ellipses. As Fig. 13.1 shows, the optimal solution can occur:
a) at an interior point of the feasible region;
b) on the boundary of the feasible region, which is not an extreme point; or
c) at an extreme point of the feasible region.
As a consequence, procedures, such as the simplex method, that search only extreme points may not determine
Figure 13.2 illustrates another feature of nonlinear-programming problems. Suppose that we are to
minimize f (x) in this example, with 0 ≤ x ≤ 10. The point x = 7 is optimal. Note, however, that in the
indicated dashed interval, the point x = 0 is the best feasible point; i.e., it is an optimal feasible point in the
local vicinity of x = 0 specified by the dashed interval.
The latter example illustrates that a solution optimal in a local sense need not be optimal for the overall
problem. Two types of solution must be distinguished. A global optimum is a solution to the overall
optimization problem. Its objective value is as good as any other point in the feasible region. A local
optimum, on the other hand, is optimal only with respect to feasible solutionsclose to that point. Points
far removed from a local optimum play no role in its definition and may actually be preferred to the local
Definition. Let x = (x1 , x2 , . . . , xn ) be a feasiblesolution to a maximization problem with objective
1. A global maximum if f (x) ≥ f (y) for every feasible point y = (y1 , y2 , . . . , yn );
| denotes absolute value; that is, |x| = x if x ≥ 0 and |x| = −x if x < 0.
Figure 13.1 Portfolio-selection example for various values of θ. (Lines are contours of constant objective values.)
2. A local maximum if f (x) ≥ f (y) for every feasible point y = (y1 , y2 , . . . , yn ) sufficiently close to x.
That is, if there is a number  > 0 (possibly quite small) so that, whenever each variable y j is within
 of x j — that is, x j −  ≤ y j ≤ x j +  —and y is feasible, then f (x) ≥ f (y).
Global and local minima are defined analogously. The definition of local maximum simply says that if we
place an n-dimensional box (e.g., a cube in three dimensions) about x, whose side has length 2, then f (x)
is as small as f (y) for every feasible point y lying within the box. (Equivalently, we can use n-dimensional
spheres in this definition.) For instance, if  = 1 in the above example, the one-dimensional box, or interval,
is pictured about the local minimum x = 0 in Fig. 13.2.
The concept of a local maximum is extremely important. As we shall see, most general-purpose nonlinearprogramming procedures are near-sighted and can do no better than determine local maxima. We should
point out that, since every global maximum is also a local maximum, the overall optimization problem can
be viewed as seeking the best local maxima.
Under certain circumstances, local maxima and minima are known to be global. Whenever a function
‘‘curves upward’’ as in Fig. 13.3(a), a local minimum will be global. These functionsare called convex.
Whenever a function ‘‘curves downward’’ as in Fig. 13.3(b) a local maximum will be a global maximum.
These functions are called concave.† For this reason we usually wish to minimize convex functions and
maximize concave functions. These observations are formalized below.
Because of both their pivotal role in model formulation and their convenient mathematical properties, certain
functional forms predominate in mathematical programming. Linear functions are by far the most important.
Next in importance are functions which are convex or concave. These functions are so central to the theory
that we take some time here to introduce a few of their basic properties.
An essential assumption in a linear-programming model for profit maximization is constant returns to scale
for each activity. This assumption implies that if the level of one activity doubles, then that activity’s profit
contribution also doubles; if the first activity level changes from x1 to 2x1 , then profit increases proportionally
from say $20 to $40 [i.e., from c1 x1 to c1 (2x1 )]. In many instances, it is realistic to assume constant returns
to scale over the range of the data. At other times, though, due to economies of scale, profit might increase
disproportionately, to say $45; or, due to diseconomies of scale (saturation effects), profit may be only $35.
In the former case, marginal returns are increasing with the activity level, and we say that the profit function
As a mnemonic, the ‘‘A’’ in concAve reflects the shape of these functions.
Figure 13.3 a) Convex function b) concave function (c) nonconvex, nonconcave function.
is convex (Fig. 13.3(a)). In the second case, marginal returns are decreasing with the activity level and we
say that the profit function is concave (Fig.13.3(b)). Of course, marginal returns may increase over parts of
the data range and decrease elsewhere, giving functions that are neither convex nor concave (Fig. 13.3(c)).
An alternative way to view a convex function is to note that linear interpolation overestimates its values.
That is, for any points y and z, the line segment joining f (y) and f (z) lies above the function (see Fig. 13.3).
More intuitively, convex functions are ‘‘bathtub like’’ and hold water. Algebraically,
A function f (x) is called convex if,for every y and z and every 0 ≤ λ ≤ 1,
f [λy + (1 − λ)z] ≤ λ f (y) + (1 − λ) f (z).
It is called strictly convex if, for every two distinct points y and z and every 0 < λ < 1,
f [λy + (1 − λ)z] < λ f (y) + (1 − λ) f (z).
The lefthand side in this definition is the function evaluation on the line joining x and y; the righthand side is
the linear interpolation. Strict convexity corresponds to profit functions whose marginal returns are strictly
Note that although we have pictured f above to be a function of one decision variable, this is not a restriction. If y = (y1 , y2 , . . . , yn ) and z = (z 1 , z 2 , . . . , z n ), we must interpret λy + (1 − λ)z only as weighting
the decision variables one at a time, i.e., as the decision vector (λy1 + (1 − λ)z 1 , . . . , λyn + (1 − λ)z n ).
Concave functions are simply the negative of convex functions. In this case, linear interpolation underestimates the function. The definition above is altered by reversing the direction of the inequality. Strict
concavity is defined analogously. Formally,
A function f (x) is called concave if,for every y and z and every 0 ≤ λ ≤ 1,
f [λy + (1 − λ)z] ≥ λ f (y) + (1 − λ) f (z).
It is called strictly concave if, for every y and z and every 0 < λ < 1,
f [λy + (1 − λ)z] > λ f (y) + (1 − λ) f (z).
We can easily show that a linear function is both convex and concave. Consider the linear function:
These manipulations state, quite naturally, that linear interpolation gives exact values for f and consequently,
from the definitions, that a linear function is both convex and concave. This property is essential, permitting
us to either maximize or minimize linear functions by computationally attractive methods such as the simplex
Other examples of convex functions are x 2 , x 4 , e x , e−x or –log x. Multiplying each example by minus
one gives aconcave function. The definition of convexity implies that the sum of convex functions is convex
and that any nonnegative multiple of a convex function also is convex. Utilizing this fact, we can obtain a
large number of convex functions met frequently in practice by combining these simple examples, giving, for
Similarly, we can easily write several concave functions by multiplying these examples by minus one.
A notion intimately related to convex and concave functions is that of a convex set. These sets are ‘‘fat,’’
in the sense that, whenever y and z are contained in the set, every point on the line segment joining these
points is also in the set (see Fig. 13.4). Formally,
Definition. A set of points C is called convex if, for all λ in the interval 0 ≤ λ ≤ 1, λy + (1 − λ)z is
contained in C whenever x and y are contained in C.
Again we emphasize that y and z in this definition are decision vectors; in the example, each of these vectors
We have encountered convex sets frequently before, since the feasible region for a linear program is
convex. In fact, the feasible region for a nonlinear program is convex if it is specified by less-than-or-equal-to
equalities with convex functions. That is, if f i (x) for i = 1, 2, . . . , m, are convex functions and if the points
then, for any 0 ≤ λ ≤ 1, λy + (1 − λ)z is feasible also, since the inequalities
f i (λy + (1 − λ)z) ≤ λ f i (y) + (1 − λ) f i (z) ≤ λbi + (1 − λ)bi = bi
hold for every constraint. Similarly, if the constraints are specified by greater-than-or-equal-to inequalities and the functions are concave, then the feasible region is convex. In sum, for convex feasible regions
we want convex functions for less-than-or-equal-to constraints and concave functions for greater-than-orequal-to constraints. Since linear functions are both convex and concave, they may be treated as equalities.
An elegant mathematical theory, which is beyond the scope of this chapter, has been developed for convex
and concave functions and convex sets. Possibly the most important property for the purposes of nonlinear
programming was previewed in the previous section. Under appropriate assumptions, a local optimumcan
function on a convex feasible region is also a
We can establish this property easily by reference to Fig. 13.5. The argument is for convex functions;
the concave case is handled similarly. Suppose that y is a local minimum. If y is not a global minimum,
then, by definition, there is a feasible point z with f (z) < f (y). But then if f is convex, the function must
lie on or below the dashed linear interpolation line. Thus, in any box about y, there must be an x on the line
segment joining y and z, with f (x) < f (y). Since the feasible region is convex, this x is feasible and we
have contradicted the hypothesis that y is a local minimum. Consequently, no such point z can exist and any
local minimum such as y must be a global minimum.
To see the second assertion, suppose that y is a local minimum. By Property 1 it is also a global minimum.
If there is another global minimum z (so that f (z) = f (y)), then 21 x + 21 z is feasible and, by the definition
f 21 x + 21 z < 21 f (y) + 21 f (z) = f (y).
But this states that 21 x + 21 z is preferred to y, contradicting our premise that y is a global minimum.
Consequently, no other global minimum such as z can possibly exist; that is, y must be the unique global
Figure 13.5 Local minima are global minima for convex function
Many of the nonlinear-programming solution procedures that have been developed do not solve the general
but rather some special case. For reference, let us list some of these special cases:
(Possibly x j ≥ 0 will be included as well).
i.e., the problem ‘‘separates’’ into functions of single variables. The functions f j and gi j are given.
Note that cases 2, 3, and 4 are successive generalizations. In fact linear programming is a special case of
every other problem type except for case 1.
Our first solution procedure is for separable programs, which are optimization problems of the form:
where each of the functions f j and gi j is known. These problems are called separable because the decision
variables appear separately, one in each function gi j in the constraints and one in each function f j in the
Separable problems arise frequently in practice, particularly for time-dependent optimization. In this case,
the variable x j usually corresponds to an activity level for time period j and the separable model assumes
that the decisions affecting resource utilization and profit (or cost) are additive over time. The model also
arises when optimizing over distinct geographical regions, an example being the water-resources planning
Actually, instead of solving the problem directly, we make an appropriate approximation so that linear
programming can be utilized. In practice, two types of approximations, called the δ-method and the λ-method,
are often used. Since we have introduced the δ-method when discussing integer programming, we consider
The general technique is motivated easily by solving a specific example. Consider the portfolio-selection
problem introduced in Section 13.1. Taking θ = 1, that problem becomes:
Maximize f (x) = 20x1 + 16x2 − 2x12 − x22 − (x1 + x2 )2 ,
As stated, the problem is not separable, because of the term (x1 + x2 )2 in the objective function. Letting
x3 = x1 + x2 , though, we can re-express it in separable form as:
Maximize f (x) = 20x1 + 16x2 − 2x12 − x22 − x32 ,
The objective function is now written as f (x) = f 1 (x1 ) + f 2 (x2 ) + f 3 (x3 ), where
Thus it is separable. Clearly, the linear constraints are also separable.
To form the approximation problem, we approximate each nonlinear term by a piecewise-linear curve,
as pictured in Fig. 13.6. We have used three segments to approximate the function f 1 and two segments to
approximate the functions f 2 and f 3 . Note that the constraints imply that
so that we need not extend the approximation beyond these bounds on the variables.
The dashed approximation curves for f 1 (x1 ), f 2 (x2 ), and f 3 (x3 ) are determined by linear approximation
between breakpoints. For example, if 1 ≤ x1 ≤ 3, then the approximation f 1a for f 1 is given by weighting
the function’s values at x1 = 1 and x1 = 3; that is, as
where the nonnegative variables λ1 and λ2 express x1 as a weighted combination of 1 and 3; thus,
For instance, evaluating the approximation at x1 = 1.5 gives
The overall approximation curve f 1a (x1 ) for f 1 (x1 ) is expressed as:
Figure 13.6 Approximating separable functions.
with the provision that the λ j variables satisfy the following restriction:
Adjacency Condition. At most two λ j weights arepositive. If two weights are positive, then they are
adjacent, i.e., of the form λ j and λ j+1 . A similar restriction applies to each approximation.
Figure 13.7 illustrates the need for the adjacency condition. If the weights λ0 =
as shown in Fig. 13.7(a) by the light curve joining λ0 and λ2 . In contrast, at x1 = 2 the approximation curve
An essential point to note here is that, for concave objective functions, the adjacency condition will
always be enforced by the maximization and can be ignored. This property is easy to see geometrically by
considering Fig 13.7(a). Suppose that the weights λ0 and λ2 are positive. By concavity, the function value
of 18 at x1 = 1 associated with the intermediate weight λ1 lies above the line segment joining λ0 and λ2 in
the figure. Consequently, the approximation curve must also lie above this line segment. The maximization,
therefore, will select the dashed approximation curve with only the adjacent weights λ0 and λ1 , or λ1 and
λ2 , positive, rather than any solution with both λ0 and λ2 positive. A similar argument applies if three or
more weights are positive. For example, if λ0 , λ2 , and λ3 are all positive, then the additional weight λ3 can
be viewed as weighting a point on the line segment joining λ0 and λ2 with the point at λ3 . Again, concavity
implies that this point lies below the approximation curve and will not be accepted by the maximization.
Note, however, that for the nonconcave function of Fig. 13.7(b), nonadjacent weights λ0 and λ2 are actually
preferred to the approximation curve. Consequently, for nonconcave functions some effort must be expended
to ensure that the adjacency condition is satisfied.
Returning to the portfolio-selection example, we can write the approximation problem:
Maximize z = f a (x ) + f a (x ) + f a (x ),
Figure 13.7 Need for the adjacency condition
in terms of weighting variables λi j . Here we use the first subscript i to denote the weights to attach to
variable i. The weights λ0 , λ1 , λ2 , and λ3 used above for variable x1 thus become λ10 , λ11 , λ12 , and λ13 .
0λ10 + 18λ11 + 42λ12 + 50λ13 + 0λ20 + 39λ21 + 55λ22 − 0λ30 − 4λ31 − 25λ32 ,
0λ10 + 1λ11 + 3λ12 + 5λ13 + 0λ20 + 3λ21 + 5λ22
0λ10 + 1λ11 + 3λ12 + 5λ13 + 0λ20 + 3λ21 + 5λ22 − 0λ30 − 2λ31 − 5λ32
Since each of the functions f 1 (x1 ), f 2 (x2 ), and f 3 (x3 ) is concave, the adjacency condition can be ignored and
the problem can be solved as a linear program. Solving by the simplex method gives an optimal objective
value of 44 with λ11 = λ12 = 0.5, λ21 = 1, and λ32 = 1 as the positive variables in the optimal solution.
The corresponding values for the original problem variables are:
This solution should be contrasted with the true solution
Note that the approximation problem has added several λ variables and that one weighting constraint in
(2) is associated with each x j variable. Fortunately, these weighting constraints are of a special generalized
upper-bounding type, which add little to computational effort and keep the number of effective constraints
essentially unchanged. Thus, the technique can be applied to fairly large nonlinear programs, depending of
course upon the capabilities of available linear-programming codes.
Once the approximation problem has been solved, we can obtain a better solution by introducing more
breakpoints. Usually more breakpoints will be added near the optimal solution given by the original approximation.
Adding a single new breakpoint at x1 = 2 leads to an improved approximation for this problem with a
linear-programming objective value of 46 and
In this way, an approximate solution can be found as close as desired to the actual solution.
The general problem must be approached more carefully, since linear programming can give nonadjacent
weights. The procedure is to express each variable∗ in terms of breakpoints, e.g., as above
Variables that appear in the model in only a linear fashion should not be approximated and remain as x j variables.
and then use these breakpoints to approximate the objective function and each constraint, giving the approximation problem:
If each original function f j (x j ) is concave and each gi j (x j ) convex,† then the λi j version is solved as a linear
program. Otherwise, the simplex method is modified to enforce the adjacency condition. A natural approach
is to apply the simplex method as usual, except for a modified rule that maintains the adjacency condition at
Restricted-Entry Criterion. Use the simplex criterion, butdo not introduce a λik variable into the basis
unless there is only one λi j variable currently in the basis and it is of the form λi,k−1 or λi,k+1 , i.e.,it is
Note that, when we use this rule, the optimal solution may contain a nonbasic variable λik that would
ordinarily be introduced into the basis by the simplex method (since its objective cost in the canonical form is
positive), but is not introduced because of the restricted-entry criterion. If the simplex method would choose
a variable to enter the basis that is unacceptable by the restricted-entry rule, then we choose the next best
variable according to the greatest positive reduced cost.
An attractive feature of this procedure is that it can be obtained by making very minor modifications to
any existing linear-programming computer code. As a consequence, most commercial linear-programming
packages contain a variation of this separable-programming algorithm. However, the solution determined by
this method in the general case can only be shown to be a localoptimum to the approximation problem (3).
Nonseparable problems frequently can be reduced to a separable form by a variety of formulation tricks. A
number of such transformations are summarized in Table 13.1.
Table 13.1 Representative transformations
∗ The term y x should now be separated by the first transformation, followed by
an application of the last transformation to separate the resulting power-of-10 term.
† Because the constraints are written as (≤), the constraints should be convex; they should be concave for (≥) inequalities.
Similarly, for a minimization problem, the objective functions f j (x j ) should be convex.
Linear Approximations of Nonlinear Programs
To see the versatility of these transformations, suppose that the nonseparable term x1 x22 /(1 + x3 ) appears
either in the objective function or in a constraint of a problem. Letting y1 = 1/(1 + x3 ), the term becomes
x1 x22 y1 . Now if x1 > 0, x22 > 0, and y1 > 0 over the feasible region, thenletting y2 = x1 x22 y1 , the original
term is replaced by y2 and the separable constraints
are introduced. If the restrictions x1 > 0, x22 > 0, y1 > 0 arenot met, we may let y2 = x1 x22 , substitute y1 y2
for the original term, and append the constraints:
The nonseparable terms y1 y2 and x1 x22 can now be separated using the first transformation in Table 13.1 (for
the last expression, let x22 replace x2 in the table).
Using the techniques illustrated by this simple example, we may, in theory, state almost any optimization
problem as a separable program. Computationally, though, the approach is limited since the number of added
variables and constraints may make the resulting separable program too large to be manageable.
LINEAR APPROXIMATIONS OF NONLINEAR PROGRAMS
Algebraic procedures such as pivoting are so powerful for manipulating linear equalities and inequalities that
many nonlinear-programming algorithms replace the given problem by an approximating linear problem.
Separable programming is a prime example, and also one of the most useful, of these procedures. As in
separable programming, these nonlinear algorithms usually solve several linear approximations by letting the
solution of the last approximation suggest a new one.
By using different approximation schemes, this strategy can be implemented in several ways. This section
introduces three of these methods, all structured to exploit the extraordinary computational capabilities of the
simplex method and the wide-spread availability of its computer implementation.
There are two general schemes for approximating nonlinear programs. The last section used linear approximation for separable problems by weighting selected values of each function. This method is frequently
referred to as inner linearization since, as shown in Fig. 13.8 when applied to a convex programming problem (i.e., constraints gi (x) ≥ 0 with gi concave, or gi (x) ≤ 0 with gi convex), the feasible region for the
approximating problem lies inside that of the original problem. In contrast, other approximation schemes use
slopes to approximate each function. These methods are commonly referred to as outer linearizations since,
for convex-programming problems, the feasible region for the approximating problem encompasses that of
the original problem. Both approaches are illustrated further in this section.
Let x 0 = (x10 , x20 , . . . , xn0 ) be any feasible solution to a nonlinear program with linear constraints:
Figure 13.8 Inner and outer linearizations of g(x) ≥ 0.
Here x 0 might be determined by phase I of the simplex method. This algorithm forms a linear approximation
at the point x 0 by replacing the objective function with its current value plus a linear correction term; that is,
where c j is the slope, or partial derivative, of f with respect to x j , evaluated at the point x 0 . Since f (x 0 ), c j ,
and x 0j are fixed, maximizing this objective function is equivalent to maximizing:
The linear approximation problem is solved, giving an optimal solution y = (y1 , y2 , . . . , yn ). At this
point the algorithm recognizes that, although the linear approximation problem indicates that the objective
improves steadily from x 0 to y, the nonlinear objective might not continue to improve from x 0 to y. Therefore,
the algorithm uses a procedure to determine the maximum value for f (x1 , x2 , . . . , xn ) along the line segment
joining x 0 to y. Special methods for performing optimization along the line segment are discussed in Section
13.9. For now, let us assume that there is a method to accomplish this line-segment maximization for us.
Letting x 1 = (x11 , x21 , . . . , xn1 ) denote the optimal solution of the line-segment optimization, we repeat
the procedure by determining a new linear approximation to the objective function with slopes c j evaluated
at x 1 . Continuing in this way, we determine a sequence of points x 1 , x 2 , . . . , x n , . . . ; any point x ∗ =
(x1∗ , x2∗ , . . . , xn∗ ) that these points approach in the limit is an optimal solution to the original problem.
Let us illustrate the method with the portfolio-selection example from Section 13.1:
Maximize f (x) = 20x1 + 16x2 − 2x12 − x22 − (x1 + x2 )2 ,
The partial derivatives of the objective function at any point x = (x1 , x2 ) are given by:
c1 = 20 − 4x1 − 2(x1 + x2 ) = 20 − 6x1 − 2x2 ,
c2 = 16 − 2x2 − 2(x1 + x2 ) = 16 − 2x1 − 4x2 .
Linear Approximations of Nonlinear Programs
Suppose that the initial point is x 0 = (0, 0). At this point c1 = 20 and c2 = 16 and the linear approximation
uses the objective function 20x1 + 16x2 . The optimal solution to this linear program is y1 = 5, y2 = 0,
and the line-segment optimization is made on the line joining x 0 = (0, 0) to y = (5, 0); that is, with
0 ≤ x1 ≤ 5, x2 = 0. The optimal solution can be determined to be x1 = 3 31 , x2 = 0, so that the procedure is
The partial derivatives are now c1 = 0, c2 = 9 13 , and the solution to the resulting linear program of
maximizing 0x1 + 9 31 x2 is y1 = 0, y2 = 5. The line segment joining x 1 and y is given by
as θ varies between 0 and 1. The optimal value of θ over the line segment is θ =
Figure 13.9 illustrates these two steps of the algorithm and indicates the next few points x 4 , x 5 , and x 6
Figure 13.9 Example of the Frank–Wolfe algorithm.
The Frank–Wolfe algorithm is convenient computationally because it solves linear programs with the
same constraints as the original problem. Consequently, any structural properties of these constraints are
available when solving the linear programs. In particular, network-flow techniques or large-scale system
methods can be used whenever the constraints have the appropriate structure. Also, note from Fig. 13.9
that the points x 1 , x 2 , x 3 , . . . oscillate. The even-numbered points x 2 , x 4 , x 6 , . . . lie on one line directed
toward the optimal solution, and the odd-numbered points x 1 , x 3 , x 5 , . . . , lie on another such line. This
general tendency of the algorithm slows its convergence. One approach for exploiting this property to speed
convergence is to make periodic optimizations along the line generated by every other point x k+2 and x k for
MAP (Method of Approximation Programming)
The Frank–Wolfe algorithm can be extended to general nonlinear programs by making linear approximations
to the constraints as well as the objective function. When the constraints are highly nonlinear, however, the
solution to the approximation problem can become far removed from feasible region since the algorithm
permits large moves from any candidate solution. The Method of Approximation Programming (MAP) is a
simple modification of this approach that limits the size of any move. As a result, it is sometimes referred to
Let x 0 = (x10 , x20 , . . . , xn0 ) be any candidate solution to the optimization problem:
Each constraint can be linearized, using its current value gi (x 0 ) plus a linear correction term, as:
where ai j is the partial derivative of constraint gi with respect to variable x j evaluated at the point x 0 . This
approximation is a linear inequality, which can be written as:
since the terms on the righthand side are all constants.
The MAP algorithm uses these approximations, together with the linear objective-function approximation,
and solves the linear-programming problem:
The last constraints restrict the step size; they specify that the value for x j can vary from x 0j by no more than
When the parameters δ j are selected to be small, the solution to this linear program is not far removal
from x 0 . We might expect then that the additional work required by the line-segment optimization of the
Linear Approximations of Nonlinear Programs
Frank–Wolfe algorithm is not worth the slightly improved solution that it provides. MAP operates on this
premise, taking the solution to the linear program (4) as the new point x 1 . The partial-derivative data ai j , bi ,
and c j is recalculated at x 1 , and the procedure is repeated. Continuing in this manner determines points
x 1 , x 2 , . . . , x k , . . . and as in the Frank–Wolfe procedure, any point x ∗ = (x1∗ , x2∗ , . . . , xn∗ ) that these points
approach in the limit is considered a solution.
STEP (0): Let x 0 = (x10 , x20 , . . . , xn0 ) be any candidate solution, usually selected to be feasible or nearfeasible. Set k = 0.
STEP (1): Calculate c j and ai j (i = 1, 2, . . . , m), the partial derivatives of the objective function and
constraints evaluated at x k = (x1k , x2k , . . . , xnk ). Let bik = ai j x k − gi (x k ).
STEP (2): Solve the linear-approximation problem (4) with bik and x kj replacing bi0 and x 0j , respectively.
Let x k+1 = (x1k+1 , x2k+1 , . . . , xnk+1 ) be its optimal solution. Increment k to k + 1 and return to
Since many of the constraints in the linear approximation merely specify upper and lower bounds on the
decision variables x j , the bounded-variable version of the simplex method is employed in its solution. Also,
usually the constants δ j are reduced as the algorithm proceeds. There are many ways to implement this idea.
One method used frequently in practice, is to reduce each δ j by between 30 and 50 percent at each iteration.
To illustrate the MAP algorithm, consider the problem:
The partial derivatives evaluated at the point x = (x1 , x2 ) are given by:
Since linear approximations of any linear function gives that function again, no data needs to be calculated
for the linear constraints x1 ≥ 0 and x2 ≥ 0.
Using these relationships and initiating the procedure at x 0 = (0, 2) with δ1 = δ2 = 2 gives the linearapproximation problem:
The righthand sides are determined as above by evaluating ai1 x10 + ai2 x20 − gi (x 0 ).
The feasible region and this linear approximation are depicted in Fig. 13.10. Geometrically, we see that
the optimalsolution occurs at x11 = 1, x21 = 4. Using this point and reducing both δ1 and δ2 to 1 generates
The solution indicated in Fig. 13.10 occurs at x12 = 2,
Figure 13.10 Example of the MAP algorithm.
If the procedure is continued, the points x 3 , x 4 , . . . that it generates approach the optimal solution x ∗
shown in Fig. 13.10. As a final note, let us observe that the solution x 1 is not feasible for the linear program
that was constructed by making linear approximations at x 1 . Thus, in general, both Phase I and Phase II of
the simplex method may be required to solve each linear-programming approximation.
Linear Approximations of Nonlinear Programs
This algorithm is applied to the optimization problem of selecting decision variables x1 , x2 , . . . , xn from a
The procedure uses inner linearization and extends the decomposition and column-generation algorithms
introduced in Chapter 12. When the objective function and constraints gi are linear and C consists of the
feasible points for a linear-programming subproblem, generalized programming reduces to the decomposition
As in decomposition, the algorithm starts with k candidate solutions x j = (x1 , x2 , . . . , xn ) for j =
1, 2, . . . , k, all lying the region C. Weighting these points by λ1 , λ2 , . . . , λk generates the candidate solution:
Any choices can be made for the weights as long as they are nonnegative and sum to one. The ‘‘best’’ choice
is determined by solving the linear-approximation problem in the variables λ1 , λ2 , . . . , λk :
Maximize λ1 f (x 1 ) + λ2 f (x 2 ) + · · · + λk f (x k ),
λ1 g1 (x 1 ) + λ2 g1 (x 2 ) + · · · + λk g1 (x k ) ≤ 0,
λ1 gm (x 1 ) + λ2 gm (x 2 ) + · · · + λk gm (x k ) ≤ 0,
The coefficients f (x j ) and gi (x j ) of the weights λ j in this linear program are fixed by our choice of the
candidate solutions x 1 , x 2 , . . . , x k . In this problem, the original objective function and constraints have
been replaced by linear approximations. When x is determined from expression (5) by weighting the points
x 1 , x 2 , . . . , x k by the solution of problem (6), the linear approximations at x are given by applying the same
weights to the objective function and constraints evaluated at these points; that is,
f a (x) = λ1 f (x 1 ) + λ2 f (x 2 ) + · · · + λk f (x k )
gia (x) = λ1 gi (x 1 ) + λ2 gi (x 2 ) + · · · + λk gi (x k ).
The approximation is refined by applying column generation to this linear program. In this case, a new
column with coefficients f (x k+1 ), g1 (x k+1 ), . . . , gm (x k+1 ) is determined by the pricing-out operation:
v = Max [ f (x) − y1 g1 (x) − y2 g2 (x) − · · · − ym gm (x)],
This itself is a nonlinear programming problem but without the gi constraints. If v − σ ≤ 0, then no new
column improves the linear program and the procedure terminates. If v − σ > 0, then the solution x k+1
giving v determines a new column to be added to the linear program (6) and the procedure continues.
The optimal weights λ∗1 , λ∗2 , . . . , λ∗k to the linear program provide a candidate solution
xi∗ = λ∗1 xi1 + λ∗2 xi2 + · · · + λ∗k xik
to the original optimization problem. This candidate solution is most useful when C is a convex set and each
constraint is convex, for then xi∗ is a weighted combination of points x 1 , x 2 , . . . , x k in C and thus belongs to
C; and, since linear interpolation overestimates convex functions,
gi (x ∗ ) ≤ λ∗1 gi (x 1 ) + λ∗2 gi (x 2 ) + · · · + λ∗k gi (x k ).
The righthand side is less than or equal to zero by the linear-programming constraints; hence, gi (x ∗ ) ≤ 0
and x ∗ is a feasible solution to the original problem.
As an illustration of the method, consider the nonlinear program:
We let C be the region with x1 ≥ 0 and x2 ≥ 0, and start with the three points x 1 = (0, 0), x 2 = (5, 0), and
x 3 = (0, 5) from C. The resulting linear approximation problem:
is sketched in Fig. 13.11, together with the original problem. The feasible region for the approximation
problem is given by plotting the points defined by (5) that correspond to feasible weights in this linear
Figure 13.11 An example of generalized programming.
x ∗ = 0.36(0, 0) + 0.64(0, 5) = (0, 3.2).
Maximize [ f (x) − yg(x)] = x1 − (x2 − 5)2 − yx12 − yx22 + 16y + 9,
For y > 0 the solution to this problem can be shown to be x1 = 1/(2y) and x2 = 5/(1 + y), by setting the
partial derivatives of f (x) − yg(x), with respect to x1 and x2 , equal to zero.
In particular, the optimal shadow price y = 1 gives the new point x 4 = 21 , 2 21 . Since f (x 4 ) = 3 41 and
g(x 4 ) = −9 21 , the updated linear programming approximation is:
Maximize z = −16λ1 − 11λ2 + 9λ3 + 3 41 λ4 ,
The optimal solution has λ3 and λ4 basic with λ∗3 =
As we continue in this way, the approximate solutions will approach the optimal solution x1 = 1.460 and
We should emphasize that the generalized programming is unlike decomposition for linear programs in
that it does not necessarily determine the optimal solution in a finite number of steps. This is true because
nonlinearity does not permit a finite number of extreme points to completely characterize solutions to the
Quadratic programming concerns the maximization of a quadratic objective function subject to linear constraints, i.e., the problem:
The data c j , ai j , and bi are assumed to be known, as are the additional q jk data. We also assume the symmetry condition q jk = qk j . This condition is really no restriction, since q jk can be replaced by 21 (q jk + qk j ).
The symmetry condition is then met, and a straightforward calculation shows that the old and new q jk coefficients give the same quadratic contribution to the objective function. The factor 21 has been included to
simplify later calculations; if desired, it can be incorporated into the q jk coefficients. Note that, if every
q jk = 0, then the problem reduces to a linear program.
The first and third examples of Section 13.1 show that the quadratic-programming model arises in constrained regression and portfolio selection. Additionally, the model is frequently applied to approximate
problems of maximizing general functions subject to linear constraints.
In Chapter 4 we developed the optimality conditions for linear programming. Now we will indicate
the analogous results for quadratic programming. The motivating idea is to note that, for a linear objective
the derivative (i.e., the slope or marginal return) of f with respect to x j is given by c j , whereas, for a quadratic
program, the slope at a point is given by
Pn conditions are then stated by replacing every c j in the linear-programming optimality
conditions by c j + k=1 q jk xk . (See Tableau 1.)
Note that the primal and dual feasibility conditions for the quadratic program are linear inequalities in
nonnegative variables x j and yi . As such, they can be solved by the Phase I simplex method. A simple
modification to that method will permit the complementary-slackness conditions to be maintained as well.
To discuss the modification, let us introduce slack variables si for the primal constraints and surplus variables
Then the complementary slackness conditions become:
The variables yi and si are called complementary, as are the variables v j and x j . With this notation, the
technique is to solve the primal and dual conditions by the Phase I simplex method, but not to allow any
complementary pair of variables to appear in the basis both at the same time. More formally, the Phase I
Restricted-Entry Rule. Never introduce avariable into the basis if its complementary variable is already
a member of the basis, even if the usual simplex criterion says to introduce the variable.
Otherwise, the Phase I procedure is applied as usual. If the Phase I procedure would choose a variable to enter
the basis that is unacceptable by the restricted-entry rule, then we choose the next best variable according to
the greatest positive reduced cost in the Phase I objective function.
An example should illustrate the technique. Again, the portfolio-selection problem of Section 13.1 will
Maximize f (x) = 20x1 + 16x2 − 2x12 − x22 − (x1 + x2 )2 ,
Expanding (x1 + x2 as + 2x1 x2 + and incorporating the factor 21 , we rewrite the objective function
Maximize f (x) = 20x1 + 16x2 + 21 (−6x1 x1 − 4x2 x2 − 2x1 x2 − 2x2 x1 ),
so that q11 = −6, q12 = −2, q21 = −2, q22 = −4, and the optimality conditions are:
Letting s1 be the basic variable isolated in the first constraint and adding artificial variables a1 and a2 in the
second and third constraints, the Phase I problem is solved in Table 13.2.
For this problem, the restricted-entry variant of the simplex Phase I procedure has provided the optimal
solution. It should be noted, however, that the algorithm will not solve every quadratic program. As an
As the reader can verify, the algorithm gives the solutionx1 = x2 = 0. But this solution is not even a
local optimum, since increasing either x1 or x2 increases the objective value.
It can be shown, however, that the algorithm does determine an optimal solution if f (x) is strictly concave
for a maximization problem or strictly convex for a minimization problem. For the quadratic problem, f (x)
for every choice of α1 , α2 , . . . , αn ,
such that some α j 6= 0. In this case, the matrix of coefficients (qi j ) is called negative definite. Thus the
algorithm will always work for a number of important applications including the least-square regression and
portfolio-selection problems introduced previously.
variables values x1 x2 s1 y1 v1∗ v2∗ a1 a2
variables values x1 x2 s1∗ y1 v1∗ v2∗ a1 a2
* Starred variables cannot be introduced into the basis since their
Conceptually, the simplest type of optimization is unconstrained. Powerful solution techniques have been
developed for solving these problems, which are based primarily upon calculus, rather than upon algebra and
pivoting, as in the simplex method. Because the linear-programming methods and unconstrained-optimization
techniques are so efficient, both have been used as the point of departure for constructing more generalpurpose nonlinear-programming algorithms. The previous sections have indicated some of the algorithms
using the linear-programming-based approach. This section briefly indicates the nature of the unconstrainedoptimization approaches by introducing algorithms for unconstrained maximization and showing how they
might be used for problems with constraints.
Suppose that we want to maximize the function f (x) of n decision variables x = (x1 , x2 , . . . , xn ) and that
this function is differentiable. Let ∂ f /∂ x j denote the partialderivative of f with respect to x j , defined by
This section requires some knowledge of differential calculus.
where u j is a decision vector u j = (0, 0, . . . , 0, 1, 0, . . . , 0), with all zeros except for the jth component,
which is 1. Thus, x + θ u j corresponds to the decisions (x1 , x2 , . . . , x j−1 , x j + θ, x j+1 , . . . , xn ), in which
only the jth decision variable is changed from the decision vector x.
and therefore x + θ u j is preferred to x for a maximization problem. Similarly, if ∂ f /∂ x j < 0, then
and x + θ u j is again preferred to x. Therefore, at any given point with at least one partial derivative
∂ f /∂ x j > 0, we can improve the value of f by making a one dimensional search
Maximize f (x1 , x2 , . . . , x j−1 , x j + θ, x j+1 , . . . , xn ),
in which only the value of x j is varied. Similarly, if ∂ f /∂ x j < 0, we can alter x j to x j − θ and search on
θ ≥ 0 to improve the function’s value. The one-dimensional search can be made by using any of a number
of procedures that are discussed in the next section. One algorithm using this idea, called cyclic coordinate
ascent, searches by optimizing in turn with respect to x1 , then x2 , then x3 and so on, holding all other variables
constant at stage j when optimizing with respect to variable x j . After optimizing with xn , the method starts
In fact, there is a large class of algorithms known as ascent algorithms that implement the ‘‘uphill
movement’’ philosophy of cyclic coordinate ascent. Suppose that we consider moving in a general direction
d = (d1 , d2 , . . . , dn ) instead of in a coordinate, or unit, direction. Then, instead of considering the partial
derivative, as in (7), we consider the directional derivative. The directional derivative, which indicates how
the function varies as we move away from x in the direction dis defined by:
The directional derivative is just the slope of the function f (x) in the direction d and reduces to the definition
of the partial derivative ∂ f /∂ x j in Eq. (7) when the direction is taken to be d = u j . Just as in the case of
partial derivatives, if the directional derivative in Eq. (8) is positive, then f increases in the direction d; that
f (x1 + θ d1 , x2 + θ d2 , . . . , xn + θ dn ) > f (x1 , x2 , . . . , xn )
for θ > 0 small enough. At any given point x, the ascent algorithms choose an increasing direction d (i.e.,
such that Eq. (8) is positive), and then select the next point x̄i = xi + θ̄di as the solution θ = θ̄ to the
Maximize f (x1 + θ d1 , x2 + θ d2 , . . . , xn + θ dn ).
From x̄, the ascent algorithms select a new direction and solve another one-dimensional problem, and then
continue by repeating this procedure. Cyclic coordinate ascent is a special case in which, at each step, all but
one d j , say di , is set to zero; di is set to di = +1 if ∂ f /∂ xi > 0 and di = −1 if ∂ f /∂ xi < 0.
One natural choice for the direction d for this general class of algorithms is:
since then Eq. (8) is positive as long as ∂ f /∂ x j 6= 0 for some variable x j . This choice for d is known as
To illustrate the ascent algorithms, consider the objective function
f (x1 , x2 ) = 20x1 + 16x2 − 2x12 − x22 − (x1 + x2 )2
introduced earlier in this chapter for a portfolio-selection problem. The partial derivatives of this function
Figure 13.12 shows the result of applying the first few iterations of both cyclic coordinate ascent and steepest
ascent for maximizing this function, starting at the point x1 = x2 = 0.
Cyclic coordinate ascent first increases x1 from the starting point x1 = x2 = 0 since ∂ f /∂ x1 = 20 > 0.
Holding x2 = 0 and setting ∂ f /∂ x1 = 0 gives the solution to the first one-dimensional problem at 2 as
x1 = 3 13 and x2 = 0. At this point ∂ f /∂ x2 = 9 31 > 0 and we increase x2 , holding x1 = 3 13 . The optimum to
this one-dimensional problem occurs at point 3 with ∂ f /∂ x2 = 0 and x1 = 3 31 , x2 = 2 13 . We now decrease
x1 since ∂ f /∂ x1 = −4 23 , generating the next point x1 = 2.56 and x2 = 2 13 . The last point 5 shown has
x1 = 2.56 and x2 = 2.72. Continuing in this way from this point, the algorithm approaches the optimal
Since the partial derivatives at x1 = x2 = 0 are ∂ f /∂ x1 = 20 and ∂ f /∂ x2 = 16, the first direction for
steepest ascent is d1 = 20 and d2 = 16, giving the one-dimensional problem:
Maximize f (0 + 20θ, 0 + 16θ ) = 20(20θ) + 16(16θ ) − 2(20θ )2 − (16θ )2
Setting the derivative with respect to θ equal to zero gives the optimal solution
At this point, the partial derivatives of f are
= 20 − 6x1 − 2x2 = 20 − 6(2.79) − 2(2.23) = −1.2,
= 16 − 2x1 − 4x2 = 16 − 2(2.79) − 4(2.23) = 1.5.
Therefore, the next one-dimensional optimization is in the direction d1 = −1.2 and d2 = 1.5 from the last
The optimal choice for θ is θ̄ = 0.354, giving
as the next point. Evaluating derivatives gives the direction d1 = 0.26 and d2 = 0.22 and the point 4 with
x1 = 2.40 and x2 = 2.79, which is practically the optimal solution x1 = 2.4 and x2 = 2.8.
As we have noted, if any partial derivative is nonzero, then the current solution can be improved by an
ascent algorithm. Therefore any optimal solution must satisfy the (first order) optimality conditions
As Fig. 13.13 illustrates, these conditions can be satisfied for nonoptimal points as well. Nevertheless,
solving the system (9) permits us to generate potential solutions. In fact, we have used this observation above
by setting ∂ f /∂θ to zero to find the solution to the one-dimensional problems. Usually, though, we cannot
easily solve for a point that gives zero derivatives, and must rely on numerical methods such as those given
Figure 13.13 Partial derivatives are zero at maximum points.
Since the partial derivatives of the objective function are zero at an optimal solution, ‘‘first-order’’ methods
like those described in this section, which rely only upon first-derivative information, may encounter numerical
difficulties near an optimal solution. Also, in general, first-order methods do not converge to an optimal
solution particularly fast. Other methods that use curvature, or second-derivative, information (or more often,
approximations to the inverse of the matrix of second partial derivatives) overcome these difficulties, at the
expense of more computational work at each step. The Newton–Raphson algorithm, which is described in the
next section for the special case of one-dimensional optimization, is one popular example of these methods.
An entire class of methods known as conjugate direction algorithms also use second-derivative information.
Instead of reviewing these more advanced methods here, we show how unconstrained algorithms can be used
to solve constrained optimization problems.
SUMT (Sequential Unrestrained Maximization Technique)
In principle, any optimization problem can be converted into an unconstrained optimization, as illustrated by
Suppose that we let P(x) denote a penalty for being infeasible, given by:
if x is infeasible (that is, x > 4 or x > 1),
Then the constrained optimization problem (10) can be restated in unconstrained form as
since the objective function with the penalty term agrees with the original objective function for any feasible
point and is +∞ for every infeasible point.
Although this conceptualization in terms of penalties is useful, the method cannot be implemented easily
because of numerical difficulties caused by the +∞ terms. In fact, even if a large penalty M > 0 is used to
replace the +∞ penalty, the method is difficult to implement, since the objective function is discontinuous
(i.e., jumps) at the boundary of the feasible region; for example, with M = 1000, the term x 2 + P(x) would
equal x 2 + 1000 to the left of x = 1 and only x 2 at x = 1. Consequently, we cannot use the algorithms for
unconstrained optimization presented in this section, which require differentiability.
We can overcome this difficulty by approximating the penalty term by a smooth function and refining the
approximation sequentially by a method known as the Sequential Unconstrained Maximization Technique,
or SUMT. In this method, instead of giving every infeasible point the same penalty, such as +∞ or a large
constant M, we impose a penalty that increases the more a point becomes infeasible.
The curve with r = 1 in Fig. 13.14 shows a penalty term used frequently in practice, in which the penalty
P(x) grows quadratically as points move farther from the feasible region. In this case, the penalty is zero for
feasible points 1 ≤ x ≤ 4. To the left of x = 1, the penalty is the quadratic term (1 − x)2 , and to the right of
x = 4, the penalty is the quadratic term (x − 4)2 , and to the right of x = 4, the penalty is the quadratic term
P(x) = Max (1 − x, 0)2 + Max (x − 4, 0)2 .
Note that when 1 ≤ x ≤ 4, both maximum terms in this expression are zero and no penalty is incurred; when
Figure 13.14 Imposing penalty terms sequentially.
x ≤ 1 or x ≥ 4, the last expression reduces to the appropriate penalty term in (11).
As Fig. 13.14 illustrates, the infeasible point x = 21 solves the problem
Minimize { f (x) + P(x)} = Minimize {x 2 + P(x)},
since the quadratic penalty term does not impose a stiff enough penalty for near-feasible points. Note,
however, that if the penalty term P(x) is replaced by 2P(x), 3P(x), 4P(x), or, in general, r P(x) for r > 1,
the penalty increases for any infeasible point. As the penalty scale-factor r becomes very large, the penalty
associated with any particular infeasible point also becomes large, so that the solution to the modified penalty
is driven closer and closer to the feasible region. The example problem illustrates this behavior. From Fig.
13.14 we see that, for any r > 1, the solution to the penalty problem occurs to the left of x = 1, where the
penalty term is r (1 − x)2 . In this region, the penalty problem of minimizing x 2 + r P(x) reduces to:
Setting the first derivative of this objective function to zero gives
as the optimal solution. At this point, the objective value of the penalty problem is:
x + r Max (1 − x, 0) + r Max (4 − x, 0) =
Consequently, as r approaches +∞, both the optimal solution r/(r + 1) and the optimal value r/(r + 1) to
the penalty problem approach the optimal values x ∗ = 1 and f (x ∗ ) = 1 to the original problem.
Although the penalty function cannot always be visualized as nicely as in this simple example, and
the computations may become considerably more involved for more realistic problems, the convergence
properties exhibited by this example are valid for any constrained problem. The general problem
is converted into a sequence of unconstrained penalty problems
introduces a quadratic penalty [gi (x) − bi ]2 for any constraint i that is violated; that is, gi (x) > bi . If x r
denotes the solution to the penalty problem (12) when the penalty scale factor is r, then any point x ∗ that
these points approach in the limit solves the original constrained problem. Moreover, the optimal objective
values f (x r ) + r P(x r ) to the penalty problems approach the optimal value z ∗ to the constrained optimization
The general theory underlying penalty-function approaches to constrained optimization permits many
variations to the methodology that we have presented, but most are beyond the scope of our introduction to the
subject. For example, the absolute value, or any of several other functions of the terms Max (gi (x) − bi , 0),
can be used in place of the quadratic terms. When equality constraints h i (x) = bi appear in the problem
formulation, the term r (h i (x) − bi )2 is used in the penalty function.
In addition, barrier methods can be applied, in which the penalty terms are replaced by barrier terms:
In contrast to the SUMT procedure, these methods always remain within the feasible region. Since the
barrier term 1/(gi (x) − bi )2 becomes infinite as x approaches the boundary of the constraint gi (x) ≤ bi ,
where gi (x) = bi , if the method starts with an initial feasible point, the minimization will not let it cross
the boundary and become infeasible. As r becomes large, the barrier term decreases near the boundary and
the terms (13) begin to resemble the penalty function with P(x) = 0 when x is feasible and P(x) = +∞
when x is infeasible. Figure 13.15 illustrates this behavior when the barrier method is applied to our example
To conclude this section, let us see how the standard penalty procedure, without any of these variations,
performs on the portfolio-selection problem that has been solved by several other methods in this chapter.
Maximize {20x1 + 16x2 − 2x12 − x22 − (x1 + x2 )2 },
Max [20x1 + 16x2 − 2x12 − x22 − (x1 + x2 )2 − r Max (x1 + x2 − 5, 0)2
We can find the solution to this problem for any value of r by setting to zero the partial derivatives of the
terms in braces with respect to both x1 and x2 , that is, by solving the equations.†
20 − 6x1 − 2x2 − 2r Max (x1 + x2 − 5, 0) − 2r Max (−x1 , 0) = 0,
16 − 2x1 − 4x2 − 2r Max (x1 + x2 − 5, 0) − 2r Max (−x2 , 0) = 0.
The solution to these equations is given by
as can be verified by substitution in the equations. Figure 13.16 shows how the solutions approach the optimal
solution x1∗ = 2 13 , x2∗ = 2 23 , and the optimal objective value 46 13 as r increases.
Figure 13.16 Penalty method for portfolio selection.
Many algorithms in optimization are variations on the following general approach: given a current feasible
solution x = (x1 , x2 , . . . , xn ), find a direction of improvement d = (d1 , d2 , . . . , dn ) and determine the
next feasible solution x̄ = (x̄1 , x̄2 , . . . , x̄n ) as the point that optimizes the objective function along the line
segment x̄i = xi + θ di pointing away from x in the direction d. For a maximization problem, the new point
Maximize f (x1 + θ d1 , x2 + θd2 , . . . , xn + θ dn ).
∗ Note that we subtract the penalty term from the objective function in this example because we are maximizing rather
† The partial derivative of Max (x1 + x2 − 5, 0)2 with respect to x1 or x2 equals 2(x1 + 22 − 5) if x1 + x2 ≥ 5 and equals
zero if x1 + x2 ≤ 5. Therefore it equals 2 Max (x1 + x2 − 5, 0). Generally, the partial derivative of Max (gi (x) − bi , 0)2
Figure 13.17 Bolzano search for a concave function.
Since the current point (x1 , x2 , . . . , xn ) and direction (d1 , d2 , . . . , dn ) are fixed, this problem is a onedimensional optimization in the variable θ . The direction d used in this method is chosen so that the solution
to this one-dimensional problem improves upon the previous point; that is,
f (x̄1 , x̄2 , . . . , x̄n ) > f (x1 , x2 , . . . , xn ).
Choosing the direction-finding procedure used to implement this algorithm in various ways gives rise to
many different algorithms. The Frank-Wolfe algorithm discussed in Section 13.6, for example, determines
the direction from a linear program related to the given optimization problem; algorithms for unconstrained
optimization presented in the last section select the direction based upon the partial derivatives of the objective
function evaluated at the current point x. This section briefly discusses procedures for solving the onedimensional problem common to this general algorithmic approach; i.e., it considers maximizing a function
Whenever g(θ ) is concave and differentiable, we can eliminate certain points as non-optimal by evaluating
the slope g 0 (θ ) of the function as shown in Fig. 13.17; if g 0 (θ1 ) > 0, then no point θ ≤ θ1 can maximize g,
and if g 0 (θ2 ) < 0, then no point θ ≥ θ2 can maximize g. This observation is the basis for a method known
Suppose that the maximum of g(θ ) is known to occur in some interval such as 0 ≤ θ ≤ 5 in Fig. 13.17.
Then, evaluating the slope at the midpoint θ = 2 21 of the interval permits us to eliminate half of the inerval
from further consideration—here, 2 21 ≤ θ ≤ 5. By evaluating the slope again at the midpoint θ = 1 41 of
the remaining interval, we can eliminate half of this interval. Continuing, we can halve the search interval
in which the optimum is known to lie at each step, until we obtain a very small interval. We can then find a
point as close as we like to a point that optimizes the given function.
The same type of procedure can be used without evaluating slopes. This extension is important, since
derivatives must be evaluated numerically in many applications. Such numerical calculations usually require
several function calculations. Instead of evaluating the slope at any point θ = θ̄ , we make function evaluations
at two points θ = θ1 and θ = θ2 close to θ = θ̄, separated from each other only enough so that we can
distinguish between the values g(θ1 ) and g(θ2 ). If g(θ1 ) < g(θ2 ), then every point with θ ≤ θ1 can be
eliminated from further consideration; if g(θ1 ) > g(θ2 ), then points with θ ≥ θ2 can be eliminated. With this
modification; Bolzano search can be implemented by making two function evaluations near the midpoint of
any interval, in place of the derivative calculation.
Bolzano’s method does not require concavity of the function being maximized. All that it needs is that,
if θ1 ≤ θ2 , then (i) g(θ1 ) ≤ g(θ2 ) implies that g(θ ) ≤ g(θ1 ) for all θ ≤ θ1 , and (ii) g(θ1 ) ≥ g(θ2 ) implies
that g(θ) ≤ g(θ2 ) for all θ ≥ θ2 . We call such functions unimodal, or single-peaked, since they cannot
contain any more than a single local maximum. Any concave function, of course, is unimodal. Figure 13.18
illustrates Bolzano’s method, without derivative evaluations, for a unimodal function.
The Bolzano search procedure for unimodal functions can be modified to be more efficient by a method
Figure 13.18 Bolzano search for a unimodal function.
known as Fibonacci search. This method is designed to reduce the size of the search interval at each step by
making only a single function evaluation instead of two evaluations or a derivative calculation, as in Bolzano
Figure 13.19 illustrates the method for the previous example. The first two points selected at θ1 = 2
and θ2 = 3 eliminate the interval θ ≤ 2 from further consideration, by the unimodal property. Note that
θ2 = 3stays within the search interval that remains. By selecting the next point at θ3 = 4, we eliminate
θ ≥ 4 from further consideration. Finally, by selecting the last point close to θ2 at θ = 3, we eliminate
θ ≥ 3. Consequently, by making four function evaluations, Fibonacci search has reduced the length of the
final search interval to 1 unit, whereas four function evaluations (or two, usually more expensive, derivative
calculations) in Bolzano search reduced the length of the final search interval to only 1 41 .
In general, Fibonacci search chooses the function evaluations so that each new point is placed symmetrically in the remaining search interval with respect to the point already in that interval. As Fig. 13.19 illustrates
for k = 1, the symmetry in placing the function evaluations implies that the length `k of successive search
This expression can be used to determine how many function evaluations are required in order to reduce the
final interval to length `n . By scaling our units of measurement, let us assume that `n = 1 (for example, if we
want the final interval to have length 0.001, we measure in units of 0.001). Since the final function evaluation
just splits the last interval in two, we know that the second-to-last interval has length `n−1 = 2. Then, from
Eq. 14, the length of succeeding intervals for function evaluations numbered 3, 4, 5, 6, 7, . . . , is given by
Figure 13.20 A seven-point Fibonacci search.
Consequently, if the initial interval has length 21 (i.e., 21 times larger than the desired length of the final
interval), then seven function evaluations are required, with the initial two evaluations being placed at θ = 8
and θ = 13, and each succeeding evaluation being placed symmetrically with respect to the point remaining
in the search interval to be investigated further. Figure 13.20 shows a possibility for the first three steps of this
application. Fibonacci search is known to be optimal in the sense that, of all search methods guaranteed to
reduce the length of the final interval to `n , it uses the fewest function evaluations. Unfortunately, the length of
the final interval must be known in advance, before the location of the initial two function evaluations can be
determined. This a priori determination of `n may be inconvenient in practice. Therefore, an approximation
to Fibonacci search, called the method of golden sections, is used frequently. As the number of function
evaluations√becomes large, the ratio between succeeding Fibonacci numbers approaches 1/γ ≈ 0.618, where
γ = (1 + 5)/2 is known as the golden ratio. This observation suggests that the first two evaluations be
placed symmetrically in the initial interval, 61.8 percent of the distance between the two endpoints, as in
golden-section search. Each succeeding point then is placed, as in Fibonacci search, symmetrically with
respect to the point remaining in the search interval. Note that this approximation is very close to Fibonacci
search even for a procedure with as few as seven points, as in the example shown in Fig. 13.20, since the
21 = 0.619, or 61.9 percent, of the distance between the two endpoints when applying
Fibonacci search. When applied to this example, the first five golden-section points are θ1 = 8.022, θ2 =
12.978, θ3 = 4.956, θ4 = 9.912, and θ5 = 6.846, as compared to θ1 = 8, θ2 = 13, θ3 = 5, θ4 = 10, and
Another technique for one-dimensional optimization replaces the given function to be maximized by an
approximation that can be optimized easily, such as a quadratic or cubic function. Figure 13.21, for instance,
illustrates a quadratic approximation to our previous example. By evaluating the given function g(θ ) at three
points θ = θ1 , θ2 , and θ3 , we can determine a quadratic function
which agrees with g(θ ) at θ1 , θ2 , and θ3 . In this case, the resulting quadratic approxi- mation is:
By setting the first derivative q 0 (θ ) of the approximation to 0, we can solve for an approximate optimal
∗ The method is called Fibonacci search because the numbers in expression (15), which arise in many other applications,
After determining this approximation, we can use the new point θ̂ , together with two of the points θ1 , θ2 ,
and θ3 , to define a new approximation. We select the three points, θ̂ and two others, so that the middle point
has the highest value for the objective function, since then the approximating quadratic function has to be
concave. Since g(θ̂ ) = g(2.6) > 30 in this case, we take θ2 , θ̂ , and θ3 as the new points. If g(θ ) ≤ 30, we
would take θ1 , θ2 , and θ̂ as the three points to make the next approximation. By continuing to make quadratic
approximations in this way, the points θ̂1 , θ̂2 , . . . determined at each step converge to an optimal solution θ ∗ .
† In practice, the method may not find an optimal solution θ ∗ and stop in a finite number of steps; therefore,
some finite termination rule is used. For example, we might terminate when the function values g(θ̂ j ) and
g(θ̂ j+1 ) for two succeeding points become sufficiently small—say, within  = 0.00001 of each other.
Similar types of approximation methods can be devised by fitting with cubic functions, or by using other
information such as derivatives of the function for the approximation. Newton’s method for example, which
is possibly the most famous of all the approximating schemes, uses a quadratic approximation based upon
first- and second-derivative information at the current point θ j , instead of function evaluations at three points
as in the method just described. The approximation is given by the quadratic function:
q(θ ) = g(θ j ) + g 0 (θ j )(θ − θ j ) + 21 g 00 (θ j )(θ − θ j )2 .
Note that the q(θ j ) = g(θ j ) and that the first and second derivatives of q(θ ) agree with the first derivative
g 0 (θ j ) and the second derivative g 00 (θ j ) of g(θ ) at θ = θ j .
The next point θ j+1 is chosen as the point maximizing q(θ ). Setting the first derivative of q(θ) in Eq. 16
to zero and solving for θ j+1 gives the general formula
In the sense that for any given  > 0, infinitely many of the θ̂ j are within  of θ ∗ ; that is,
Figure 13.22 Newton’s method for solving h θ = 0.
for generating successive points by the algorithm.
Letting h(θ ) = g 0 (θ ) denote the first derivative of g(θ ) suggests an interesting interpretation of expression
(17). Since g 0 (θ̂ ) = 0 at any point θ̂ maximizing g(θ ), θ̂ must be a solution to the equation h(θ̂ ) = 0.
Newton’s method for solving this equation approximates h(θ ) at any potential solution θ j by a line tangent
Approximation: y = h(θ j ) + h 0 (θ j )(θ − θ j ).
Since h(θ j ) = g 0 (θ j ) and h 0 (θ j ) = g 00 (θ j ), the solution y = 0 to this approximation is the point θ j+1 specified
in (17). It is because of this association with Newton’s well- known method for solving equations h(θ) = 0
that the quadratic-approximation scheme considered here is called Newton’s method.
To illustrate Newton’s method, let g(θ ) = (θ − 3)4 . Then h(θ ) = g 0 (θ ) = 4(θ − 3)3 and h 0 (θ) =
g (θ ) = 12(θ − 3)2 . Starting with θ0 = 0, Newton’s method gives:
The points θ1 = 1, θ2 = 1 23 , θ3 = 2 19 , θ3 = 2 11
27 , θ4 = 2 81 , . . . that the method generates converge to the
optimal solution θ = 3. Figure 13.22 shows the first twoapproximations to h(θ ) for this example.
Newton’s method is known to converge to an optimal solution θ ∗ that maximizes g(θ ) as long as g 00 (θ ∗ ) 6=
0 and the initial point θ0 is close enough to θ ∗ . The precise definition of what is meant by ‘‘close enough
to θ ∗ ’’ depends upon the problem data and will not be developed here. We simply note that, because the
rate of convergence to an optimal solution has been shown to be good for Newton’s method, it often is used
in conjunction with other procedures for one-dimensional optimizations that are used first to find a point θ0
1. a) Over what region is the function f (x) = x 3 convex? Over what region is f concave?
b) Over what region is the function f (x) = −12x + x 3 convex (concave)?
c) Plot the function f (x) = −12x + x 3 over the region −3 ≤ x ≤ 3. Identify local minima and local
maxima of f over this region. What is the global minimum and what is the global maximum?
2. a) Which of the following functions are convex, which are concave, and which are neither convex nor
iii) f (x) = log (x) over the region x > 0.
b) Graph the feasible solution region for each of the following constraints:
c) Is the function f (x1 , x2 ) = x2 − |x1 | concave?
3. Because of the significance of convexity in nonlinear programming, it is useful to be able to identify
convex sets and convex (or concave) functions easily. Apply the definitions given in this chapter to
a) If C1 and C2 are two convex sets, then the intersection of C1 and C2 (that is, points lying in both) is
a convex set. For example, since the set C1 of solutions to the inequality
is convex and the set C2 of points satisfying
is convex, then the feasible solution to the system
which is the intersection of C1 and C2 , is also convex. Is the intersection of more than two convex
b) Let f 1 (x), f 2 (x), . . . , f m (x) be convex functions and let α1 , α2 , . . . , αm be nonnegative numbers;
is convex. For example, since f 1 (x1 , x2 ) = x12 and f 2 (x1 , x2 ) = |x2 | are both convex functions of x1
c) Let f 1 (x) and f 2 (x) be convex functions; then the function f (x) = f 1 (x) f 2 (x) need not be convex.
[Hint. See part (a(v)) of the previous exercise.]
d) Let g(y) be a convex and nondecreasing function [that is, y1 ≤ y2 implies that g(y1 ) ≤ g(y2 )] and
let f (x) be a convex function; then the composite function h(x) = g[ f (x)] is convex. For example,
since the function e y is convex and nondecreasing, and the function f (x1 , x2 ) = x12 + x22 is convex,
4. One of the equivalent definitions for convexity of a differentiable function f of single variable x given
in this chapter is that the slopes of the function be nondecreasing with respect to the variable x; that is,
For a strictly convex function, the condition becomes:
Similar conditions can be given for concave functions. If the function f has second derivations, these
conditions are equivalent to the very useful second-order criteria shown in Table E13.1.
Function property d f2 implying the function property
Not only do the second-order conditions imply convexity or concavity, but any convex or concave
function must also satisfy the second-order condition. Consequently, since
can be both positive and negative for the function f (x) = x 3 , we know that x 3 is neither convex nor
Use these criteria to show which of the following functions are convex, concave, strictly convex, or
i) x 4 [Hint. Can a function be strictly convex even if its second derivative is zero at some point?]
means the derivative of f with respect to x evaluated at x = y.
5. Brite-lite Electric Company produces two types of electric lightbulbs; a 100-watt bulb and a 3-way
(50–100–150) bulb. The machine that produces the bulbs is fairly old. Due to higher maintenance costs
and down time, the contribution per unit for each additional unit produced decreases as the machine is
used more intensely. Brite-lite has fit the following functions to per-unit contribution (in $) for the two
f 1 (x1 ) = 50 − 2x1 , for x1 units of 100-watt bulbs;
f 2 (x2 ) = 70 − 3x2 , for x2 units of 3-way bulbs.
The Brite-lite Company is in the unusual position of being able to determine the number of units demanded
of a particular type of lightbulb from the amount (in $) it spends on advertisements for that particular
= Number of units of 100-watt bulbs demanded,
= Number of units of 3-way bulbs demanded,
where y1 is the amount (in $) spent on advertisements for 100-watt bulbs, and y2 is the amount (in $)
Brite-lite has an advertising budget of $1500. Its management is committed to meeting demand.
Present production capacity is 125 and 175 units of 100-watt and 3-way bulbs, respectively.
Finally, the production of a unit of lightbulb j consumes ai j units of resource i for i = 1, 2, . . . , m,
6. Besides its main activity of providing diaper service, Duke-Dee Diapers, a small workshop owned by a
large fabrics firm, produces two types of diapers. The diapers are constructed from a special thin cloth
and an absorbent material. Although both materials are manufactured by the fabrics company, only
limited monthly amounts, b1 and b2 , respectively, are available because this activity always has been
considered as secondary to production of other fabrics. Management has decided to analyze the activity
of the workshop in terms of profits, to decide whether or not to continue its diaper-service operation.
A limited market survey showed that the following linear functions give good approximations of the
demand curves for the two types of diapers:
α jk = Coefficient related to the substitutability of the two types of diapers
(if α11 = 1, α12 = 0, α22 = 1, α21 = 0, there is no substitutability), and
diaper costs c j ( j = 1, 2) to produce and uses ai j (i = 1, 2; j = 1, 2) units of resource i.
a) Formulate a model to determine the profits from diaper production.
b) Show how you would transform the model into a separable program.
7. A connoisseur has m bottles of rare wine in his cellar. Bottle j is currently t j years old. Starting next
year, he wishes to drink one bottle each year on his birthday, until his supply is exhausted. Suppose
that his utility for drinking bottle j is given by U j (t) (t is its age when consumed) and that utility is
additive. The connoisseur wishes to know in what order to drink the wine to maximize his total utility
a) Formulate his decision problem of which bottle to select each year as an integer linear program. What
is the special structure of the formulation? How can this structure help in solving the problem?
b) Suppose that the utility for consuming each bottle of wine is the same, given by a convex function
U (t). Show that it is optimal to select the youngest available bottle each year.
8. Consider a directed communications network, where each arc represents the communication link between
two geographically distant points. Each communication link between points i and j has a probability
of failure of pi j . Then, for any path through the network, the probability of that particular path being
operative is the product of the probabilities (1 − pi j )(1 − p jk )(1 − pkl ) . . . of the communication links
a) Formulate a network model to determine the path from s to t having the highest probability of being
b) In what class does the problem formulated in (a) fall?
c) How can this formulation be transformed into a network problem?
9. In Section 4 of Chapter 1, we formulated the following nonlinear-programming version of the custommolder example:
Using the following breakpoints, indicate a separable-programming approximation to this problem:
10. In the network of Fig. E13.1, we wish to ship 10 units from node 1 to node 4 as cheaply as possible.
The flow on each arc is uncapacitated. The costs on arcs 1–2, 2–3, and 3–4 are linear, with costs per
unit of 8, 2, and 4, respectively; the costs on arcs 1–3 and 2–4 are quadratic and are given by x13
a) Suppose that we apply the separable-programming δ-technique discussed in Chapter 9, using the
Figure E13.2 Linear approximation with parallel arcs.
Interpret the resulting linear-programming approximation as a network-flow problem with parallel
arcs joining nodes 1 and 3 and nodes 2 and 4, as in Fig. E13.2. Specify the per-unit cost and the arc
capacity for each arc in the linear approximation.
b) Solve the separable-programming approximation from part (a), comparing the solution with the
and minimum cost = 110.25, to the original nonlinear problem formulation.
11. a) What is the special form of the linear approximation problem when the Frank-Wolfe algorithm is
applied to the network example in the previous exercise?
b) Complete Table E13.2 for applying the first two steps of the Frank-Wolfe algorithm to this example.
Initial Solution to linear Second Solution to linear Next
solution approximation solution approximation solution
12. Solve the following nonlinear program using the λ-method of separable programming described in this
Carry out calculations using two decimal places. For each decision variable, use a grid of 5 points
13. Two chemicals can be produced at one facility, and each takes one hour per ton to produce. Both exhibit
diseconomies of scale: If x1 tons of the first are produced, the contribution is 6x1 − (x12 /2); for the
second chemical, the contribution is 50x2 for x2 tons produced. The facility can work 23 hours per
day (one hour is required for maintenance) and, because of raw materials availability, no more than 10
tons of the first chemical and 18 tons of the second can be produced daily. What is the optimal daily
production schedule, to maximize contribution?
Solve by separable programming, using the δ-method described in Chapter 9. For x1 use a grid: 0,
3, 6, 10, and for x2 use a grid 0, 2, 5, 18.
14. A young R & D engineer at Carron Chemical Company has synthesized a sensational new fertilizer
made of just two interchangeable basic raw materials. The company wants to take advantage of this
opportunity and produce as much as possible of the new fertilizer. The company currently has $40, 000
to buy raw materials at a unit price of $8000 and $5000 per unit, respectively. When amounts x1 and x2
of the basic raw materials are combined, a quantity q of fertilizer results given by:
b) Apply four iterations of the Frank-Wolfe algorithm; graphically identify the optimal point, using the
property that even- and odd-numbered points lie on lines directly toward the optimum. Start from
x 0 = (0, 0) and use three decimal places in your computations.
c) Solve the problem using the algorithm for quadratic programming discussed in Section 13.7.
15. A balloon carrying an x-ray telescope and other scientific equipment must be designed and launched. A
rough measure of performance can be expressed in terms of the height reached by the balloon and the
weight of the equipment lifted. Clearly, the height itself is a function of the balloon’s volume.
From past experience, it has been concluded that a satisfactory performance function to be maximized
is P = f (V, W) = 100V − 0.3V 2 + 80W − 0.2W 2 where V is the volume, and W the equipment
The project to be undertaken has a budget constraint of $1040. The cost associated with the volume
V is 2V, and the cost of the equipment is 4W . In order to ensure that a reasonable balance is obtained
between performance due to the height and that due to the scientific equipment, the designer has to meet
Find the optimal design in terms of volume and equipment weight, solving by the Frank-Wolfe
16. Consider the nonlinear-programming problem:
a) Carry out two iterations of the generalized programming algorithm on this problem. Let
leaving only one constraint to handle explicitly. Start with the following two initial candidate solutions:
Is the solution optimal after these two iterations?
b) Carry out two iterations of the MAP algorithm on the same problem. Start with x1 = 0, x2 = 0, as the
initial solution, and set the parameters δ1 = δ2 = 2 at iteration 1 and δ1 = δ2 = 1 at iteration 2. Is the
solution optimal after these two iterations?
17. An orbital manned scientific lab is placed on an eccentric elliptical orbit described by x 2 +5y 2 +x +3y =
10, the reference system (x, y) being the center of the earth. All radio communications with the ground
stations are going to be monitored via a satellite that will be fixed with respect to the reference system.
The power required to communicate between the satellite and the lab is proportional to the square of the
Assuming that the satellite will be positioned in the plane of the ellipse, what should be the position
of the satellite so that the maximum power required for transmissions between the lab and the satellite
can be minimized? Formulate as a nonlinear program.
18. An investor has $2 million to invest. He has 5 opportunities for investment, with the following characteristics:
i) The yield on the first investment is given by a linear function:
where r1 = yield per year (%), and x1 = amount invested ($).
where r2 = yield per year (%), and x2 = amount invested ($).
iii) An investment at 5% per year with interest continuously compounded. (An amount A invested at 5%
per year with continuously compounded interest becomes Ae0.05 after one year.)
iv) Category 1 of government bonds that yield 6% per year.
v) Category 2 of government bonds that yield 5.5% per year.
The average years to maturity of the entire portfolio must not exceed 5 years.
a) The objective of the investor is to maximize accumulated earnings at the end of the first year. Formulate
a model to determine the amounts to invest in each of the alternatives. Assume all investments are
b) Identify the special type of nonlinear program obtained in part (a).
19. Since its last production diversification, New Home Appliances, Inc. (NHA), a kitchen equipment
manufacturer, has encountered unforeseen difficulty with the production scheduling and pricing of its
product line. The linear model they have used for a number of years now no longer seems to be a valid
In the last decade, the output of the firm has more than tripled and they have become the major
supplier of kitchen equipment in the southeastern United States market. After conducting a market
survey as well as a production-cost analysis, the consulting firm hired by NHA has concluded that the
old linear model failed to optimize the activity of the firm because it did not incorporate the following
new characteristics of NHA as a major supplier in the southeastern market;
I. NHA was no longer in a perfectly competitive situation, so that it had to take into account the market
demand curve for its products. The consulting firm found that for NHA’s 15 principal products, the
price elasticity of demand was roughly 1.2; hence, the market demand curve can be expressed by:
where x j = units of product j sold; and p j = unit price of product j. For the remaining 25 products,
the price is known and can be considered constant for all levels of sales.
II. Since output has increased, the firm has reached the stage where economies of scale prevail; thus, the
per-unit production cost c j decreases according to:
where γ j and δ j are coefficients determined individually for the 15 principal products. For the
remaining 25 products, constant returns to scale is a reasonable assumption (i.e., a linear relationship
exists between the amount produced and the cost); consider the production costs per unit as known.
III. Production of each unit of product j consumes ai j units of resource i. Resource utilization is limited
by a budget of B dollars, which is available for the purchase of raw materials and labor. The suppliers
of sheet steel and aluminum are offering discount prices for larger quantities. Linear regression leads
to the following equations that show the relationship between the amount ordered and the unit price
Where µs , µa are the unit prices for steel and aluminum, respectively; bs , ba are the amounts contracted, and αs , αa , βs , βa are coefficients. No discounts are available for other resources, because
NHA’s consumption falls below the level at which such discounts are offered. Unit prices for all
other resources are constant and known. Besides steel and aluminum, 51 resources are used.
Formulate a mathematical program that incorporates the above information; the objective is the
maximization of contribution (revenues – costs). what type of nonlinear program have you obtained?
20. A rent-a-car company operating in New York City serves the three major airports—Kennedy, La Guardia,
and Newark—and has two downtown distribution centers. On Sunday evenings most of the cars are
returned to the downtown locations by city residents returning from weekend travels. On Monday
morning, most of the cars are needed at the airports and must be ‘‘deadheaded’’ by company drivers.
The two downtown distribution centers have ai (i = 1, 2) excess cars available. The three airports
must be supplied with cars at a transportation cost of ci j (i = 1, 2; j = 1, 2, 3) for deadheading from
distribution center i to airport j. The Monday morning demand r j for cars at airport j is uncertain
and is described by the probability distribution p j (r j ). If the demand exceeds supply at airport j, the
unsatisfied demand is lost, with an average lost contribution per car of u j .
a) Formulate a mathematical program to minimize total deadheading transportation cost plus expected
b) Suppose now that the manager of fleet allocation is also concerned with supply over demand. All
cars in excess of 50 cars above demand must be parked in an overflow lot at a cost of s j per car.
Reformulate the program to include these expected average costs.
21. After the admissions decisions have been made for the graduate engineering school, it is the Scholarship
Committee’s job to award financial aid. There is never enough money to offer as much scholarship aid
Each admitted applicant’s financial need is determined by comparing an estimate of his sources
of revenue with a reasonable school and personal expense budget for the normal academic year. An
admittee’s need, if any, is the difference between the standard budget and the expected contribution
from him and his family. Scholarship offers provide an amount of aid equal to some fraction of each
applicant’s need. In cases where need is not met in full, the school is able to supply low-cost loans to
cover the difference between scholarships and need.
Besides receiving funds from the university, a needy admittee might receive a scholarship from
nonuniversity funds. In this case the admittee, if he decides to matriculate, is expected to accept the
outside funds. His total scholarship award is then the greater of the university offer or the outside offer,
because the university supplements any outside offer up to the level awarded by the scholarship committee. Prior to the deadline for determining a school scholarship-offer policy, the committee has a good
estimate of the amount of outside aid that each needy admittee will be offered.
The most important function of the scholarship policy is to enroll the highest-quality needy admittees
possible. The admissions committee’s rank list of all needy admittees is used as the measurement of
In using this list, the top 100α% of the needy group ordered by quality is expected to yield at least βT
enrollees, where T is the total desired number of enrollees from the needy group. In addition to satisfying
the above criteria, the dean wants to minimize the total expected cost of the scholarship program to the
As a last point, Pi , the probability that needy admittee i enrolls, is an increasing function of yi , the
fraction of the standard budget B covered by the total scholarship offer. An estimate of this function is
given in Fig. E13.3.Here, xi B is the dollar amount of aid offered admittee i and n i B is the dollar amount
a) Formulate a nonlinear-programming model that will have an expected number T of enrolling needy
admittees, and minimize the scholarship budget. (Assume that Pi can be approximated by a linear
b) Suggest two different ways of solving the model formulated in (a). [Hint. What special form does
c) Reformulate the model so as to maximize the expected number of enrolling needy students from the
top 100α% of the need group, subject to a fixed total scholarship budget. Comment on how to solve
d) suppose that, in the formulation proposed in (a), the probability Pi that admittee i enrolls is approx1/2
imated by Pi = ai + bi yi . Comment on how to solve this variation of the model.
22. A well-known model to solve the aggregate production-planning problem that permits quadratic cost
functions in the model’s objective was developed by Holt, Modigliani, Muth, and Simon.∗ The model
allocates manpower, production, and inventories during a prescribed planning horizon, divided into t
time periods denoted by t = 1, 2, . . . , T . The decision variables of the model are:
If dt is the demand to be satisfied during period t, the constraints of the model are:
The objective function is to minimize the sum of the cost elements involved in the production process.
Holt, Modigliani, Muth, and Simon identified the following cost elements for each time period:
Hiring and firing cost = c2 (Wt − Wt−1 − c11 )2 ;
Overtime and idle cost = c3 (Pt − c4 Wt )2 + c5 Pt − c6 Wt + c12 Pt Wt ;
Inventory and back-order cost = c7 [It − (c8 + c9 dt )]2 .
a) Discuss and interpret the assumption made on the behavior of the cost components. Is it reasonable
to assume quadratic functions to characterize costs (ii), (iii), and (iv)?
b) Formulate the overall objective function and the constraints of the model.
c) Suggest a procedure to obtain the optimum solution to the model.
23. In an application of the Holt, Modigliani, Muth, and Simon model (see Exercise 22) to a paint factory,
the following decision rules were derived for optimal values of Pt and Wt for a twelve-month period
∗ Holt, C. C., F. Modigliani, J. F. Muth, H. A. Simon, Planning Production, Inventories, and Work-Force, Prentice-Hall,
a) Study the structure of the decision rules. How would you apply them? Are you surprised that the
decision rules are linear (as opposed to quadratic)?
b) Note the weights that are given to the demand forecast dt (t = 1, 2, . . . , T ). Comment on the
c) How would you obtain the resulting optimum inventory levels, It ?
24. An important problem in production management is the allocation of a given production quantity (determined by an aggregate model or by subjective managerial inputs) among a group of items. For example,
let us assume that we have decided to produce P = 6000 units of a given product line consisting of
three individual items. The allocation of the total quantity among the three items will be decided by the
= Production quantity for item i (in units),
= Inventory holding cost for item i (in $ /month × unit),
= Total amount to be produced (in units).
a) Interpret the suggested model. What is the meaning of the objective function? What implicit assumption is the model making?
b) The model can be proved to be equivalent to the following unconstrained minimization problem (by
State the optimality conditions for this unconstrained problem (see Section 13.8). Note that the
unknowns are Q i , i = 1, 2, 3, and λ. What is the interpretation of λ?
c) Given the following values for the parameters of the problem, establish a procedure to obtain the
[Hint. Perform a search on λ; plot the resulting values of Q and λ. Select the optimum value of
λ from the graph corresponding to Q = 6000.]
d) Apply the SUMT method to the original model. How do you compare the SUMT procedure with the
25. When applying the Frank-Wolfe algorithm to the optimization problem
we replace the given problem by a linear approximation at the current solution x ∗ = (x1∗ , x2∗ , . . . , xn∗ )
The Partial derivatives (∂ f /∂ x j ) are evaluated at the point x ∗ . We then perform a one-dimensional
optimization along the line segment joining x ∗ with the solution to the linear approximation.
a) Suppose that x ∗ solves the linear approximation problem so that the solution does not change after
solving the linear approximation problem. Show that there are ‘‘Lagrange multipliers" λ1 , λ2 , . . . , λm
satisfying the Kuhn-Tucker Optimality Conditions for linearly-constrained nonlinear programs:
b) What is the form of these Kuhn-Tucker conditions when (1) is a linear program or a quadratic program?
c) Suppose that x ∗ = (x1∗ , x2∗ , . . . , xn∗ ) solves the original optimization problem (1). Show that x ∗
also solves the linear approximation problem (2) and therefore satisfies the Kuhn-Tucker conditions.
d) Suppose that f (x1 , x2 , . . . , xn ) is a convex function. Show that if x ∗ = (x1∗ , x2∗ , . . . , xn∗ ) solves the
Kuhn-Tucker conditions, then x ∗ is a global minimum to the original non-linear program (1).
26. When discussing sensitivity analysis of linear programs in Chapter ??, we indicated that the optimal
objective value of a linear program is a concave function of the righthand-side values. More generally,
v(b1 , b2 , . . . , bm ) = Maximize f (x),
where x = (x1 , x2 , . . . , xn ) are the problem variables; for linear programs
a) Show that if each gi (x) is a convex function, then the values of b1 , b2 , . . . , bm for which the problem
has a feasible solution form a convex set C.
b) Show that if, in addition, f (x) is a concave function, then the optimal objective value v(b1 , b2 , . . . , bm )
is a concave function of the righthand-side values b1 , b2 , . . . , bm on the set C.
27. In many applications, the ratio of two linear functions is to be maximized subject to linear constraints.
a) Assuming that the optimal solution to the linear fractional program occurs in a region where the
denominator of the objective function is strictly positive, show that:
i) If y ∗j ( j = 0, 1, 2, . . . , n) is a finite optimal solution to (2) with y0∗ > 0, then x ∗j = y ∗j /y0∗ is a finite
ii) If λy ∗j ( j = 0, 1, 2, . . . , n) is an unbounded solution to (2) as x → ∞ and y0∗ > 0, then
λx ∗j = λy ∗j /y0∗ ( j = 1, 2, . . . , n) is an unbounded solution of (1) as λ → ∞.
b) Assuming that it is not known whether the optimal solution to the linear fractional program occurs in
a region where the denominator is positive or in a region where it is negative, generalize the approach
where x is understood to mean (x1 , x2 , . . . , xn ) and the set X usually means x j ≥ 0 ( j = 1, 2, . . . , n)
but allows other possibilities as well. The related Lagrangian form of the problem is:
Without making any assumptions on the functions f (x) and gi (x), show the following:
a) (Weak duality) If x j ( j = 1, 2, . . . , n) is feasible to the primal and y i (i = 1, 2, . . . , m) is feasible
b) (Unboundedness) If the primal (dual) is unbounded, then the dual (primal) is infeasible.
c) (Optimality) If x̂ j ( j = 1, 2, . . . , n) is feasible to the primal and ŷi (i = 1, 2, . . . , m) is feasible to the dual, and, further, if f (x̂) = L( ŷ), then x̂ j ( j = 1, 2, . . . , n) solves the primal and
ŷi (i = 1, 2, . . . , m) solves the dual.
29. Suppose x̂ = (x̂1 , x̂2 , . . . , x̂n ) and ŷ = ( ŷ1 , ŷ2 , . . . , ŷm ) satisfy the following saddlepoint condition:
a) Show that x̂ solves the nonlinear program
where x refers to (x1 , x2 , . . . , xn ). [Hint. (1) Show that complementary slackness holds; i.e., i=1
0, using the righthand inequality with yi = 0 (i = 1, 2, . . . , m) to show ’’≥’’, and the signs of yi
and gi (x) to ’’≤’’. (2) Use the lefthand inequality and the sign of gi (x) to complete the proof.]
b) Show that the saddlepoint condition implies a strong duality of the form
30. In linear programming, the duality property states that, whenever the primal (dual) has a finite optimal
solution, then so does the dual (primal), and the values of their objective functions are equal. In nonlinear
programming, this is not necessarily the case.
a) (Duality gap) Consider the nonlinear program:
The optimal objective-function value for the primal problem is clearly 0. The Lagrangian problem
L(y) = Maximize {Min|(x1 x2 )1/2 ; 1| + yx1 },
Show that the optimal objective value of the dual problem
is 1. (Note that y is unrestricted in the dual, since it is associated with an equality constraint in the
b) (No finite shadow prices) Consider the nonlinear program:
The optimal solution to this problem is clearly x1 = 0. The Lagrangian problem is:
where x1 is unrestricted. Show that the optimal solution to the dual does not exist but that L(y) → 0
A number of the exercises in this chapter are based on or inspired by articles in the literature.
Exercise 21: L. S. White, ’’Mathematical Programming Models for Determining Freshman Scholarship
Offers,’’ M.I.T. Sloan School Working Paper No. 379–9g.
Exercises 22 and 23:C. C. Holt, F. Modigliani, J. F. Muth, and H. A. Simon, Planning Production, Inventories,
and Work-Force, Prentice-Hall, Inc., Englewood Cliffs, New Jersey, 1960.
Exercise 24: P. R. Winters, ’’Constrained Inventory Rules for Production Smoothing,’’ Management Science,
Exercise 27: A. Charnes and W. W. Cooper, ’’Programming with Linear Fractional Functionals,’’ Naval
Research Logistics Quarterly, 9, 1962; and S. P. Bradley and S. C. Frey, Jr. ’’Fractional Programming with
Homogeneous Functions,’’ Operations Research, 22, No.2, March-April 1974.
Exercise 30: M. Slater, ’’Lagrange Multipliers Revisited: A Contribution to Nonlinear Programming,’’
Cowles Commission Paper, Mathematics 403, November 1950; and R. M. van Slyke and R. J. Wets, ’’A
Duality Theory for Abstract Mathematical Programs with Applications to Optimal Control Theory,’’ Journal
of Mathematical Analysis and Applications,22, No. 3, June 1968.
Commercial banks and, to a lesser degree, other financial institutions have substantial holdings of various
types of federal, state, and local government bonds. At the beginning of 1974, approximately twenty-five
percent of the assets of commercial banks were held in these types of securities. Banks hold bonds for a
variety of reasons. Basically, bonds provide banks with a liquidity buffer against fluctuations in demand
for funds in the rest of the bank, generate needed taxable income, satisfy certain legal requirements tied to
specific types of deposits, and make up a substantial part of the bank’s investments that are low-risk in the
In this chapter, we present a stochastic programming model to aid the investment-portfolio manager
in his planning. The model does not focus on the day-to-day operational decisions of bond trading but
rather on the strategic and tactical questions underlying a successful management policy over time. In the
hierarchical framework presented in Chapter 5, the model is generally used for tactical planning, with certain
of its constraints specified outside the model by general bank policy; the output of the model then provides
guidelines for the operational aspects of daily bond trading.
The model presented here is a large-scale linear program under uncertainty. The solution procedure
employs the decomposition approach presented in Chapter 12, while the solution of the resulting subproblems
can be carried out by dynamicprogramming, as developed in Chapter 11. The presentation does not require
knowledge of stochastic programming in general but illustrates one particular aspect of this discipline, that
of ‘‘scenario planning.’’ The model is tested by managing a hypothetical portfolio of municipal bonds within
the environment of historical interest rates.
The bond-portfolio management problem can be viewed as a multiperiod decision problem under uncertainty,
in which portfolio decisions are periodically reviewed and revised. At each decision point, the portfolio
manager has an inventory of securities and funds on hand. Based on present credit-market conditions and his
assessment of future interest-rate movements and demand for funds, the manager must decide which bonds
to hold in the portfolio over the next time period, which bonds to sell, and which bonds to purchase from the
marketplace. These decisions are made subject to constraints on total portfolio size, exposure to risk in the
sense of realized and unrealized capital losses,∗ and other policy limitations on the makeup of the portfolio.
At the next decision point, the portfolio manager faces a new set of interest rates and bond prices, and possibly
new levels for the constraints, and he must then make another set of portfolio decisions that take the new
∗ Realized capital losses refer to actual losses incurred on bonds sold, while unrealized capital losses refer to losses that
would be incurred if bonds currently held had to be sold.
Figure 14.1 (Typical yield curve for good-grade municipal bonds.
Before describing the details of the portfolio-planning problem, it is useful to point out some of the
properties of bonds. A bond is a security with a known fixed life, called its maturity, and known fixed
payment schedule, usually a semiannual coupon rate plus cash value at maturity. Bonds are bought and sold
in the market-place, sometimes above their face value, or par value, and sometimes below this value. If we
think of a bond as having a current price, coupon schedule, and cash value at maturity, there is an internal
rate of return that makes the price equal to the present value of the subsequent cash flows, including both the
interest income from the coupon schedule and the cash value at maturity. This rate of return is known as the
Given the attributes of a bond, knowing the price of a bond is equivalent to knowing the yield to maturity
of that bond. Since the payment schedule is fixed when the bond is first issued, as bond prices rise the yield
to maturity falls, and as bond prices fall the yield to maturity rises. Bond prices are a function of general
market conditions and thus rise and fall with the tightening and easing of credit. Usually the fluctuations in
bond prices are described in terms of yields to maturity, since these can be thought of as interest rates in the
economy. Hence, bond prices are often presented in the form of yield curves. Figure 14.1 gives a typical
yield curve for ‘‘good-grade’’ municipal bonds. Usually the yield curve for a particular class of securities
rises with increasing maturity, reflecting higher perceived market risk associated with the longer maturities.
One final point concerns the transaction costs associated with bond trading. Bonds are purchased at the
‘‘asked’’ price and, if held to maturity, have no transaction cost. However, if bonds are sold before their
maturity, they are sold at the ‘‘bid’’ price, which is lower than the ‘‘asked’’ price. The spread between these
prices can be thought of as the transaction cost paid at the time the securities are sold.
At the heart of the portfolio-planning problem is the question of what distribution of maturities to hold
during the next period and over the planning horizon in general. The difficulty of managing an investment portfolio stems not only from the uncertainty in future interest-rate movements but from the conflicting uses made of the portfolio. On the one hand, the portfolio is used to generate income, which
argues for investing in the highest-yielding securities. On the other hand, the portfolio acts as a liquidity buffer, providing or absorbing funds for the rest of the bank, depending upon other demand for funds.
Since this demand on the portfolio is often high when interest rates are high, a conflict occurs, since this is
exactly when bond prices are low and the selling of securities could produce capital losses that a bank is
unwilling to take. Since potential capital losses on longer maturities are generally higher than on shorter
maturities, this argues for investing in relatively shorter maturities.
Even without using the portfolio as a liquidity buffer, there is a conflict over what distribution of maturities
to hold. When interest rates are low, the bank often has a need for additional income from the portfolio;
this fact argues for investing in longer maturities with their correspondingly higher yields. However, since
interest rates are generally cyclical, if interest rates are expected to rise, the investment in longer maturities
could build up substantial capital losses in the future, thus arguing for investing in shorter maturities. The
opposite is also true. When interest rates are high, the short-term rates approach (and sometimes exceed) the
long-term rates; this fact argues for investing in shorter maturities with their associated lower risk. However,
if interest rates are expected to fall, this is exactly the time to invest in longer maturities with their potential
for substantial capital gains in a period of falling interest rates.
Many commercial banks manage their investment portfolio using a ‘‘laddered’’ maturity structure, in
which the amount invested in each maturity is the same for all maturities up to some appropriate length, say
15 years. Generally, the longer the ladder, the more risky the portfolio is considered. Figure 14.2(a) illustrates
a 15-year ladder. Each year one fifteenth (i.e., 6 23 percent) of the portfolio matures and needs to be reinvested,
along with the usual interest income. In a laddered portfolio, the cash from maturing securities is reinvested
in fifteen-year bonds while the interest income is reinvested equally in all maturities to maintain the laddered
structure. The advantages of a laddered portfolio are: no transaction costs or realized losses, since bonds
are always held to maturity rather than sold; generally high interest income, since the yield curve is usually
rising with increasing maturity; and ease of implementation, since theoretically no forecasting is needed and
a relatively small percentage of the portfolio needs to be reinvested each year.
Figure 14.2 (a) Typical laddered portfolio. (b) Typical barbell portfolio.
Some banks, on the other hand, manage their portfolio using a ‘‘barbell’’ maturity structure, in which the
maturities held are clustered at the short and long ends of the maturity spectrum, say 1 to 5 years and 26 to
30 years, with little if any investment in intermediate maturities. Figure 14.2(b) illustrates a typical barbell
portfolio structure with 70 percent short- and 30 percent long-term maturities. The riskiness of the portfolio
is judged by the percentage of the portfolio that is invested in the long maturities. Each end of the barbell
portfolio is managed similarly to a ladder. On the short end, the maturing securities are reinvested in 5-year
bonds, while on the long end the 25-year securities are sold and the proceeds reinvested in 30-year securities.
The interest income is then used to keep the percentages of the portfolio in each maturity roughly unchanged.
The advantages of a barbell portfolio are usually stated in terms of being more ‘‘efficient’’ than a laddered
portfolio. The securities on the long end provide relatively high interest income, as well as potential for
capital gains in the event of falling interest rates, while the securities on the short end provide liquid assets to
meet various demands for cash from the portfolio for other bank needs. In the barbell portfolio illustrated in
Fig. 14.2(b), 20 percent of the portfolio is reinvested each year, since 14 percent matures on the short end and
roughly 6 percent is sold on the long end. Comparing this with the 6 23 percent maturing in the 15-year ladder,
it is argued that a barbell portfolio is more flexible than a laddered portfolio for meeting liquidity needs or
anticipating movements in interest rates.
However, effectively managing a barbell portfolio over time presents a number of difficulties. First,
significant transaction costs are associated with maintaining a barbell structure since, as time passes, the
long-term securities become shorter and must be sold and reinvested in new long-term securities. Second, the
short-term securities are not risk-free, since the income and capital received at maturity must be reinvested in
new securities at rates that are currently uncertain. To what extent is a barbell portfolio optimal to maintain
over time? One might conjecture that often it would not be advantageous to sell the long-term securities of
the barbell structure and, hence, that over time the barbell would eventually evolve into a laddered structure.
In order to systematically address the question of what distribution of maturities should be held over time,
a stochastic programming model was developed. The basic approach of this model, referred to as the BONDS
model, is one of ‘‘scenario planning.’’ The essential idea of scenario planning is that a limited number of
possible evolutions of the economy, or scenarios, is postulated, and probabilities are assigned to each. All
the uncertainty in the planning process is then reduced to the question of which scenario will occur. For each
scenario, a fairly complex set of attributes might have to be determined; but, given a particular scenario, these
We can illustrate this process by considering the tree of yield curves given in Fig. 14.3. We can define a
collection of scenarios in terms of the yield curves assumed to be possible. Actually, a continuum of yield
curves can occur in each of the future planning periods; however, we approximate our uncertainty as to what
will occur by selecting a few representative yield curves. Suppose we say that in a three-period example,
interest rates can rise, remain unchanged, or fall, in each period with equal probability. Further, although
the levels of interest rates are serially correlated, there is satistical evidence that the distributions of changes
in interest rates from one period to the next are independent. If we make this assumption, then there are
three possible yield curves by the end of the first period, nine at the end of the second, and twenty-seven by
the end of the third. (The yield curves at the end of the third period have not been shown in Fig. 14.3.) A
scenario refers to one specific sequence of yield curves that might occur; for example, rates might rise, remain
unchanged, and then fall over the three periods. The total number of scenarios in this example is 3 × 9 × 27,
or 729. Of course, the large number of scenarios results from our independence assumption, and it might be
reasonable to eliminate some of these alternatives to reduce the problem size.
A scenario, defined by a sequence of yield curves, will have additional characteristics that place constraints
on the portfolio strategy for that scenario. Since rising interest rates mean a tightening of credit, often funds
are withdrawn from the portfolio, under such scenarios, to meet the demands for funds in the rest of the bank.
When interest rates are falling, funds are usually plentiful, and additional funds are often made available
to the portfolio. Further, a limitation on the investment strategy is imposed by the level of risk the bank is
willing to tolerate. This can be expressed for each scenario by limiting the losses that may be realized within
a tax year, as well as by limiting the unrealized capital losses that are allowed to build up in the portfolio
over the planning horizon. Another limitation on investment strategy results from the bank’s ‘‘pledging’’
requirements. The holdings of government securities, as well as the holdings of some state and local bonds,
are affected by the levels of certain types of deposits. The fluctuations of these deposits are then forecast
for each planning scenario, to indicate the minimum holdings of the securities that will satisfy the pledging
requirements. The minimum holdings of government securities may also be affected by the bank’s need
for taxable income, although this taxable-income requirement also could be a characteristic of each scenario
directly specified by the portfolio manager.
Scenario planning is the key to being able to concentrate on the investment portfolio. The interface
between the investment portfolio and the rest of the bank is accounted for by using consistent definitions of
scenarios for planning throughout the bank. For planning the investment portfolio, this interface is characterized by the demand on the portfolio for funds, the allowable levels of realized and unrealized losses in the
portfolio, the limits on the holdings of certain broad categories of securities, as well as any other element of a
scenario that the portfolio manager deems important for the planning problem being addressed. These characteristics of the scenarios are then tied to interest-rate movements by using the same definitions of scenarios
for assessing them as for forecasting yield-curve movements. The scenario-planning process is illustrated in
Section 14.4 where we discuss managing a hypothetical portfolio.
Figure 14.3 Tree of yield curves; probability in parentheses.
The most important assumption in the formulation of the model is that the planning is being carried out
with a limited number of economic scenarios. The scenarios are usually keyed to the movement of some
appropriate short-term interest rate, such as the 90-day treasury bill rate. The possible movements of the
short-term rate generate a collection of scenarios each of which consists of a particular sequence of yield
curves and exogenous cash flows, as well as other characteristics for each period in the planning horizon.
The assumption of a finite number of scenarios is equivalent to making a discrete approximation of the
continuous distribution of changes in the short-term rate, and this in turn, along with the finite number of
planning periods, permits the formulation of an ordinary linear program that explicitly takes uncertainty into
account. Associated with any particular scenario is its probability of occurrence, which is used to structure
the objective function of the linear program so as to maximize the expected horizon value of the portfolio.
The remaining characteristics of the economic scenarios are policy considerations involving the interface
between the investment portfolio and the rest of the bank. For each tax year in the planning horizon, a
maximum level of losses that may be realized is usually specified for each scenario. Further, the maximum
level of unrealized losses that potentially could build up in the portfolio over the planning horizon is often
specified. In the situation where more than one broad category of securities is being analyzed, either maximum
or minimum levels of the holdings of a particular category might be specified. For example, a minimum level
of U.S. Treasury holdings typically is specified, to cover the pledging of specific securities to secure certain
For any particular analysis that the portfolio manager is considering, he must first group the securities to
be included in the planning by broad categories, and then aggregate the securities available for purchase into a
number of security classes within each category. The broad categories usually refer to securities described by
the same yield curve, such as U.S. Treasury bonds or a particular grade of municipal bonds. The aggregation
of securities within these broad categories is by time to maturity, such as 3 months, 6 months, 1 year, 2
years, . . . , 30 years. These security classes will usually not include all maturities that are available but some
appropriate aggregation of these maturities.
The remainder of the section specifies the details of the mathematical formulation of the BONDS model.
The discussion is divided into three parts: the decision variables, the constraints, and the objective function.
At the beginning of each planning period, a particular portfolio of securities is currently held, and funds are
either available for investment or required from the portfolio. The portfolio manager must decide how much
of each security class k to buy, bnk (en ), and how much of each security class currently held to sell sm,n
or continue to hold h km,n (en ). The subscript n identifies the current period and m indicates the period when
the security class was purchased. Since the amount of capital gain or loss when a security class is sold will
depend on the difference between its purchase price and sale price, the portfolio manager must keeptrack
of the amount of each security class held, by its period of purchase. Further, since the model computes the
optimal decisions at the beginning of every period for each scenario, the variables that represent decisions at
the start of period n must be conditional on the scenario evolution en up to the start of period n. An example of
a scenario evolution up to the start of period 3 would be ‘‘interest rates rise in period 1 and remain unchanged
in period 2.’’ More precisely, the decision variables are defined as follows:
bnk (en ) = Amount of security class k purchased at the beginning of
period n, conditional on scenario evolution en ; in dollars
k (e ) = Amount of security class k, which had been purchased at the
beginning of period m, sold at the beginning of period n,
conditional on scenario evolution en ; in dollars of initial
h km,n (en ) = Amount of security class k, which had been purchased at the
beginning of period m, held (as opposed to sold) at the
beginning of period n, conditional on scenario evolution en ;
It should be pointed out that liabilities, as well as assets, can be included in the model at the discretion of
the planner. Banks regularly borrow funds by participating in various markets open to them, such as the CD
(negotiable certificate of deposit) or Eurodollar markets. The portfolio manager can then usethese ‘‘purchased
funds’’ for either financing a withdrawal of funds from the portfolio or increasing the size of the portfolio.
However, since the use of these funds is usually a policy decision external to the investment portfolio, an
elaborate collection of liabilities is not needed. The portfolio planner may include in the model a short-term
liability available in each period with maturity equal to the length of that period and cost somewhat above
the price of a short-term asset with the same maturity.
The model maximizes the expected value of the portfolio at the end of the planning horizon subject to five types
of constraints on the decision variables as well as nonnegativity of thesevariables. The types of constraints,
each of which will be discussed below, include the following: funds flow, inventory balance, current holdings,
net capital loss (realized andunrealized), and broad category limits. In general, there are separate constraints
for every time period in each of the planning scenarios. The mathematical formulation is given in Table
14.1, where en is a particular scenario evolution prior to period n and E n is the set of all possible scenario
Table 14.1 Formulation of the BONDS model
m m,n−1 (en−1 ) + yn−1 (en−1 )bn−1 (en−1 )
(n = 1, 2, . . . , N ; k = 1, 2, . . . , K )
(m = 1, 2, . . . , n − 1; n = 1, 2, . . . , N ; k = 1, 2, . . . , K )
The funds-flow constraints require that the funds used for purchasing securities be equal to the sum of the
funds generated from the coupon income on holdings during the previous period, funds generated from
sales of securities, and exogenous funds flow. We need to assess coefficients reflecting the income yield
stemming from the semiannual coupon interest from holding a security and the capital gain or loss from
selling a security, where each is expressed as a percent of initial purchase price. It is assumed that taxes are
paid when income and/or gains are received, so that these coefficients are defined as after-tax. Transaction
costs are taken into account by adjusting the gain coefficient for the broker’s commission; i.e., bonds are
purchased at the ‘‘asked’’ price and sold at the ‘‘bid’’ price. We also need to assess the exogenous funds
flow, reflecting changes in the level of funds made available to the portfolio. The exogenous funds flow may
be either positive or negative, depending on whether funds are being made available to or withdrawn from
The income yield from coupon interest, the capital gain or loss from selling a security, and the exogenous
k (e ) = Capital gain or loss on security class k, which had been
purchased at the beginning of period m and was sold at the
beginning of period n conditional on scenario evolution en ;
ymk (en ) = Income yield from interest coupons on security class k, which
was purchased at the beginning of period m, conditional on
scenario evolution en ; per dollar of initial purchase price.
f n (en ) = Incremental amount of funds either made available to or
withdrawn from the portfolio at the beginning of period n,
conditional on scenario evolution en ; in dollars.
Since it is always possible to purchase a one-period security that has no transaction cost, the funds-flow
constraints hold with equality implying that the portfolio is at all times fully invested. Finally, if short-term
liabilities are included in the model, then these funds-flow constraints would also reflect the possibility of
generating additional funds by selling a one-period liability.
The current holdings of each security class purchased in a particular period need to be accounted for in order
to compute capital gains and losses. The inventory-balance constraints state that the amount of these holdings
sold, plus the remaining amount held at the beginning of a period, must equal the amount on hand at the end
of the previous period. The amount on hand at the end of the previous period is either the amount purchased
at the beginning of the previous period or the amount held from an earlier purchase.
It is important to point out that this formulation of the problem includes security classes that mature
before the time horizon of the model. This is accomplished by setting the hold variable for a matured security
to zero (actually dropping the variable from the model). This has the effect, through the inventory-balance
constraints, of forcing the ‘‘sale’’ of the security at the time the security matures. In this case, the gain
coefficient reflects the fact that there are no transaction costs when securities mature.
The inventory-balance constraints also allow us to take into account the securities held in the initial portfolio.
h k0 = Amount of security class k held in the initial portfolio; in
the values of the variables that refer to the holdings of securities in the initial portfolio, h k0,0 (e0 ), are set to
Theoretically, we might like to maximize the bank’s expected utility for coupon income and capital gains
over time. However, such a function would be difficult for a portfolio manager to specify; and further,
management would be unlikely to have much confidence in recommendations based on such a theoretical
construct. Therefore, in lieu of management’s utility function, a set of constraints is added that limit the net
realized capital loss during any year, as well as the net unrealized capital loss that is allowed to build up over
Loss constraints are particularly appropriate for banks, in part because of a general aversion to capital
losses, but also because of capital adequacy and tax considerations. Measures of adequate bank capital,
such as that of the Federal Reserve Board of Governors, relate the amount of capital required to the amount
of ‘‘risk’’ in the bank’s assets. Thus, a bank’s capital position affects its willingness to hold assets with
capital-loss potential. Further, capital losses can be offset against taxable income to reduce the size of the
after-tax loss by roughly 50 percent. As a result, the amount of taxable income, which is sometimes relatively
small in commercial banks, imposes an upper limit on the level of losses a bank is willing to absorb.
The loss constraints sum over the periods contained in a particular year the gains or losses from sales of
securities in that year, and limit this value to:
L n (en ) = Upper bound on the realized net capital loss (after taxes)
from sales during the year ending with period n, conditional
In Table 14.1, N 0 is the set of indices of periods that correspond to the end of fiscal years, and n 0 is the index
of the first period in a year defined by an element of N 0 . Thus the loss constraints sum the losses incurred
in all periods that make up a fiscal year. Since the model forces the ‘‘sale’’ of all securities at the horizon
without transaction costs, the unrealized loss constraints have the same form as the realized loss constraints.
It may be of considerable interest to segment the portfolio into a number of broad asset categories each of
which is described by different yield curves, transaction costs, income-tax rates, and distribution of maturities.
There is no conceptual difficulty with this; however, some computational difficulties may arise due to problem
size. Typically the investment portfolio might be segmented into U.S. Treasury and tax-exempt securities. In
addition, the tax-exempt securities might be further segmented by quality such as prime-, good-, and mediumgrade municipals. In making such a segmentation, we often impose upper- or lower-bound constraints on the
total holdings of some of the asset categories. The example cited earlier involved placing lower limits on the
amount of U.S. Treasury bonds held for pledging purposes. Defining
Cni (ei ) = Lower (upper) bound on the level of holdings of asset
category i, at the beginning of period n, conditional on
scenario evolution en ; in dollars of initial purchase price,
and letting K i be the index set of the ith asset category, the constraints in Table ?? merely place an upper or
lower bound on the holdings of a particular broad asset category.
The objective of the model is to maximize the expected value of the portfolio at the end of the final period.
It should be pointed out that this assumes that the portfolio manager is indifferent between revenues received
from interest and revenues received from capital gains, since each add equivalent dollars to the value at the
horizon. If desired, it would be possible to include interest-income constraints to ensure that sufficient income
would be achieved by the portfolio during each period.
The final value of the portfolio consists of the interest income received in the final period, plus the value
of securities held at the horizon. It is not obvious, though, how the value of the portfolio holdings should
be measured, since they are likely to contain some unrealized gains and losses. Should these gains or losses
be calculated before or after taxes? Before or after transaction costs? At one extreme, it would be possible
to assume that the portfolio would be sold at the horizon, so that its final value would be after taxes and
transaction costs. This approach would tend to artifically encourage short maturities in the portfolio, since
they have low transaction costs. The alternative approach of valuing the portfolio before taxes and transaction
costs in equally unrealistic. For simplicity, it is usually assumed that the value of the securities at the horizon
is after taxes but before transaction costs.
The objective function can be defined in terms of the decisions made at the start of the final period,
which are conditional on the evolution of each scenario up to that point. For each scenario, the value of any
holdings at the start of the final period should reflect the expected capital gain or loss over the final period and
the coupon income to be received in the final period. The objective function can be formalized by defining
the probability of scenario evolution and the value of the noncash holdings at the start of the final period as
vm,N (e N ) = Expected (over period N ) cash value perdollar of initial
purchase price of security class k, which had been purchased
at the beginning of period m, and held at the start of
period N , conditional on scenario evolution en ;
p(e N ) = Probability that scenario evolution e N occurs prior to
The expected horizon value of the portfolio given in Table 14.1 is then determined by weight-ing the value
of the holdings at the start of the final period by the probability of each scenario.
In order to have a feeling for the potential size of the model formulated, the number of constraints implied
under various model assumptions can be computed. Assume for the moment that the number of events in
each time period is the same, and equal to D. Thus there are D scenario evolutions for the first period, D 2 for
the second, and so forth. Further, let there be a total of n time periods with n i periods in year i. Then if K is
the total number of different security classes in all categories, and I is the number of broad asset categories,
the number of equations can be calculated as follows:
Table 14.2 indicates the number of each type of constraint under a variety of assumptions. It is clear that,
for even a relatively small number of events and time periods, the problem size rapidly becomes completely
unmanageable. However, it is also clear that the main difficulty lies with the number of inventory-balance
constraints. Hence, an efficient solution procedure is likely to treat these constraints implicitly instead of
Table 14.2 Number of constraints in various models
n 1 = 1, n 2 = 1 n 1 = 2, n 2 = 1 n 1 = 3, n 2 = 1 n 1 = 2, n 2 = 1 n 1 = 2, n 2 = 1 n 1 = 3, n 2 = 1
Figure 14.4 illustrates the structure of the linear-programming tableau for a model involving three time
periods and three securities. Note that the inventory-balance constraints exhibit a block diagonal structure.
Given this structure, the inventory-balance constraints can be treated implicitly rather than explicitly by a
number of techniques of large-scale mathematical programming. For this particular application, the decomposition approach, which was introduced in Chapter 12, was used, since the resulting special structure of
the subproblems could be exploited readily, both in the solution of the subproblems and in structuring the
restricted master. In this approach, there is one subproblem for each diagonal block of inventory-balance
Figure 14.4 Tableau structure for three security classes.
constraints, while the restricted master linear program that must be solved at each iteration has constraints
corresponding to the funds flow, net capital loss, and category limit constraints.
The subproblems correspond to purchasing each security class at the start of a given period, conditional
on every scenario evolution up to that period. For example, purchasing security class k at the start of period
one defines one subproblem and purchasing the same security class at the start of period two defines one
additional subproblem for each scenario evolution in period one. This is indicated in the tableau structure
given in Fig. 14.4 by the three small rectangles following one large one on the diagonal. The decision
variables of a subproblem involve selling and holding in subsequent periods the security class purchased.
This allows capital gains and losses on sales of securities to be determined.
To illustrate the subproblems further, consider first the period 1 subproblems. Security class k is available
for purchase at the start of period 1. If a decision to purchase is made, this security class is then available
for sale at the start of period 2, or it may be held during the second period. The amount that is held is then
available for sale or holding at the start of the third period. This multistage problem, involving a sequence of
sell and hold decisions after a purchase, can be solved by a recursive procedure. The problem has a dynamicprogramming structure (see Chapter 11) where the state of the systemat time n is defined by the amount of
the initial purchase still held. This amount is constrained by the inventory-balance equations, which limit the
amount sold in any period to be less than or equal to the amount on hand.
Note that if security class k is purchased at the start of period 2, its purchase price and income yield are
conditional on the scenario evolution which occurred during period 1. Thus, one subproblem is defined for
each security class that can be purchased and every possible scenario evolution that precedes the purchase
period of that class. As would be expected, the subproblems have no decision variables in common with one
another, since each set of inventory-balance constraints simply keeps track of the remaining holdings of a
particular purchase. This approach leads to a relatively large number of subproblems; however, the rationale
is that the subproblems should be efficient to solve, since the state variable of each is one-dimensional.
Another interesting point to note about the subproblem constraints is that they are homogeneous systems
of equations (i.e., zero righthand sides). As we saw in Chapter 12, the fundamental theorem employed in
decomposition is that the feasible region defined by a system of linear equations may be represented by a
convex combination of its extreme points, plus a nonnegative combination of its extreme rays. The solutions
of any subproblem have only one extreme point, all decision variables equal to zero. For any nonzero point
satisfying the subproblem constraints, a scalar times that point also satisfies the constraints; and hence, with
a linear objective function, there exists an associated unbounded solution. As a result we need consider only
the extreme rays of the subproblems. These extreme rays may be constructed in an efficient manner either by
dynamic programming or by exploiting the triangular structure of the dual of a related ‘‘ray-finding’’ linear
program. The ray-finding problem is defined by setting the ‘‘buy’’ variable of any subproblem to one, and
then determining the optimal sequence of sell and hold decisions for this one unit.
The restricted master for this decomposition scheme reflects the fact that only extreme rays of the subproblems need to be considered. The usual constraints that require that the solution be a convex combination of
extreme points of the subproblems are not necessary, since the only restriction on the weights on the extreme
rays is that they be nonnegative. When the model is solved, all profitable rays found at an iteration are added
as columns to the restricted master. The restricted master is then solved by continuing the simplex method
from the previous solution, which yields new shadow prices, or dual variables. The shadow prices are then
used to modify the objective functions of the subproblems and the process is repeated. If no profitable ray is
found for any subproblem, then the algorithm terminates, and we have an optimal solution.
The value of the optimal solution is merely given by the nonnegative weighted combination of the subproblem solutions when the weights are determined by the values of the variables in the final restricted master.
In general, we need not add any unprofitable ray to the restricted master. However, a ray that is unprofitable
at one iteration may become profitable at a future iteration, as the objective functions of the subproblems are
modified by the shadow prices. Hence, if one profitable ray is generated for any subproblem at an iteration,
all new rays generated, profitable or not, are in fact added to the restricted master as columns.
As the restricted master is augmented by more and more columns, those columns not in the current basis
are retained, provided storage limitations permit. As storage limitations become binding, those columns that
price out most negatively are dropped. Any dropped column will be regenerated automatically if needed.
Further details in the computational procedure are included in the exercises.
In the remainder of this chapter, the use of the BONDS model is illustrated by addressing the question of
what portfolio strategy should be adopted over time. The model is used to ‘‘manage’’ a hypothetical portfolio
of municipal securities over a 10-year historical period. The important advantage derived from using such a
model to aid in planning the portfolio maturity structure is that it gives the portfolio manager the opportunity
to take explicitly into account the characteristics of the current portfolio, as well as expected interest-rate
swings, liquidity needs, programs for realized losses, and exposure to unrealized losses.
Ideally, the performance of the model should be evaluated using Monte Carlo simulation. However, such
an experiment would involve a significant number of simulation trials, where portfolio revisions would have
to be made by the optimization model at the beginning of each year of the simulation. Updating and running
the BONDS model such a large number of times would be prohibitively expensive, from the standpoints of
As an alternative to the Monte Carlo simulation, it is possible to perform a historical simulation, which
considers how interest rates actually behaved over a particular period of time,and then attempts to plan a
portfolio strategy that could have been followed over this period. To implement this approach, the ten-year
historical period starting with January 1, 1964 was chosen. In order to keep the simulation simple, portfolio
decisions were allowed to be made once a year and the resulting portfolio was held for the entire year. It
is not suggested that any bank would have followed the strategy proposed by the model for the entire year;
however, it can be considered a rough approximation of such a strategy over the ten-year period.
It should be strongly emphasized that it is difficult to draw firm conclusions from the results of a historical
Figure 14.5 Yields of good-grade municipals.
simulation against one particular realization of interest rates. A strategy that performed well against that
particular sequence of rates might have performed poorly against some other sequence of rates that had a
relatively high likelihood of occurring. The opposite is, of course, also true. However, it does allow us to
make comparisons between strategies for a particular sequence of interest rates that indeed did occur.
The historical simulation covered January 1964 through January 1974, a period of ten years. However, a
number of years of history prior to the beginning of the simulation period were included, since it was necessary to assess interest-rate expectations for a portfolio manager at the beginning of 1964. Figure 14.5 gives
the yields on one-, ten-, and thirty-year maturities for good-grade municipal bonds covering the appropriate
period. Although some years exhibited a great deal of variation within a year, with a potential for improving
performance through an active trading policy, this variation was not included, since in the historical simulation
the portfolio was revised only at the beginning of each year.
The basic approach of the historical simulation was to use the BONDS model to make portfolio decisions
at the beginning of each year, given the current actual yield curve and the portfolio manager’s ‘‘reasonable
expectations’’ of future interest-rate movements. These decisions were then implemented, the actual performance of the portfolio in that year was revealed, and the process was repeated. There were two steps in
modeling the yield curves needed for the simulation. First, eleven actual yield curves were of interest—one
for the beginning of each year when portfolio decisions were made, and one for the final performance evaluation. These yield curves were developed by fitting a functional form to historical data. Second, the portfolio
manager’s reasonable expectations about future interest-rate fluctuations were modeled by constructing a tree
of yield curves, similar to those given in Fig. 14.3, for each year in the simulation.
Modeling the eleven yield curves that occurred was relatively straightforward. Data were available from
the actual yield curves at each point in time covering the 1-, 2-, 5-, 10-, 20-, and 30-year maturities. Since yield
curves are generally considered to be smooth curves, the data for each curve were fitted with the following
where Rm is the yield to maturity on securities with m years to maturity, and a, b, and c are constants to be
determined from the data. In the simulation, the yield for any maturity was then taken from the derived yield
Modeling the tree of yield curves reflecting the portfolio manager’s reasonable expectations of future
interest-rate movements was more complicated. In the historical simulation, portfolio decisions were made
as if it were January 1964; it was important not to use any information that was not available to a portfolio
manager at that time. It is difficult to imagine or reconstruct exactly what a portfolio manager would have
forecast for future interest-rate changes in January 1964. Therefore, for the purpose of the simulation, the
portfolio manager’s interest-rate assessments were mechanically based on the previous seven years of data at
each stage. The simulation started with the interest-rate data for the years 1957 through and including 1963;
and, based on these data, a tree of yield curves reflecting the portfolio manager’s expectations of interest rates
was constructed. This tree of yield curves was then used in making portfolio decisions for the year 1964. For
each subsequent year, the data corresponding to the year just past was added to the data base and the data
more than seven years old were dropped; a new tree of yield curves was then constructed.
Two separate analyses were performed to estimate the tree of yield curves representing the portfolio manager’s reasonable expectations of interest rates at the beginning of each of the ten years of the simulation.
First, the distributions of one-year changes in the one-year rate were estimated for each year in the simulation. A monthly time series covering the prior seven years was used to determine the actual distribution
of the one-year changes in the one-year rate. Table 14.3 gives the means and standard deviations of these
Table 14.3 Distribution of one-year changes
∗ 100 basis-point change equals 1 percentage-point
Second, the changes in two other rates, the twenty- and thirty-year rates, were forecast, conditional on
the changes in the one-year rate. Then, given a forecast change in the one-year rate, three points on the
corresponding forecast future-yield curve could be determined, by adding the current levels for these rates to
the forecast changes in these rates. The new levels for the one-, twenty-, and thirty-year rates then determined
the constants a, b, and c for the functional form of the yield curve given above.
To forecast the changes in the twenty- and thirty-year rates, conditional on the changes in the one-year
rate, two regressions were performed for each year in the simulation. The changes in each of these two rates
were separately regressed against changes in the one-year rate. The two regression equations were then used
to compute the changes in these rates as deterministic functionsof the changes in the one-year rate. Table 14.4
shows the means and standard deviations of the regression coefficients as well as a goodness-of-fit measure.
The mean of the regression coefficient gives the change in the twenty-year rate or the change in the thirty-year
rate as a fraction of the change in the one-year rate. Given a forecast change in the one-year rate, forecasts of
the changes in the twenty- and thirty-year rates were determined by multiplying the change in the one-year
Table 14.4 Changes in the 20- and 30-year rates as a fraction of the changes in the
An important question to address regarding the assessment of future scenarios for each year of the
simulation concerned the handling of the time trend in the interest-rate data. In Table14.4, the mean of the
distribution of one-year changes in the one-year rate is almost always positive, indicating increasing rates,
on the average. Would a portfolio manager have assumed that interest rates would continue to increase
according to these historical means, when he was forecasting future rates at the beginning of each year of the
simulation? It was assumed that a portfolio manager would have initially forecast the upward drift in rates
prior to 1970, corresponding to the mean based on the previous seven years of data. In 1969, interest rates
dropped precipitously and uncertainty increased about the direction of future changes. Hence, from 1970
until the end of the simulation, it was assumed that the portfolio manager would have forecast no net drift in
interest rates, but would have had a variance of that forecast corresponding to that observed in the previous
Finally, a tree of scenarios for bank planning purposes was determined at each stage by making a discrete
approximation of the distribution of changes in the one-year rate. For ease of computation, it was assumed
that there were only three possible changes that could occur during each period in the planning horizon.
Further, the distribution of one-year changes in the one-year rate was approximately normal; this allowed
these changes to be approximated by the mean and the mean plus-or-minus one standard deviation.
By approximating the distribution of one-year changes in the one-year rate with three points, the number
of branches on the scenario-planning tree at each stage is 3 in the first period, 9 in the second period, and 27
in the third period. The method just described generates a yield curve for each branch of the planning tree
similar to those given in Fig. 14.3. Normally, theportfolio manager would also assess the exogenous cash
flow either to or from the portfolio on each branch of the scenario. However, since the main interest was in
evaluating the performance of the portfolio, the assumption was made that all cash generated by the portfolio
was reinvested, and that no net cash was either made available to or withdrawn from the portfolio after the
The only securities under consideration in the stimulation were good-grade municipal bonds. The purchase
of nine different maturities was allowed—1-, 2-, 3-, 4-, 5-, 10-, 15-, 20-, and 30-years. This is a robust enough
collection to show how the model behaves, although at times some of the maturities that were not included
might have been slightly preferable. Trading these securities involves a cost, which is paid at the point of
sale of the securities and amounts to the spread between the ‘‘bid" and ‘‘asked" prices of the market. For
bond prices quoted in terms of $100 per bond, the bid–asked spread ranged from 18 for bonds with two years
or less to maturity, to 43 for bonds with 11 years or more to maturity.
The planning horizon for the bank was taken to be three years. Since this was a yearly simulation,
three one-year periods were then used in structuring the model. Assuming a three-year horizon for planning
purposes indicates that the bank is willing to say that its objective is to maximize the value of the portfolio
at the end of three years. Therefore, at any point in time, the bank is planning as if it wants to maximize its
portfolio value at the end of the next three years, but in fact it is always rolling over the horizon, so the end
Throughout the simulation, the limit on realized losses within any one year on any scenario was held to
0.5 percent of the initial book value of the portfolio. That is, at the beginning of each year in the simulation,
the current book value of the portfolio was computed and the losses that were allowed to be realized that
year and planned for over each of the years of the planning horizon were limited to 0.5 percent of this
The unrealized losses were handled differently. Since the actual interest rates rose over the course of
the simulation, fairly large amounts of unrealized losses tended to build up in the portfolio. The potential
unrealized losses were constrained to be the same for all scenarios, and the level of these unrealized losses,
under moderately adverse circumstances, was kept as small as possible. With this view, the limits on potential
unrealized losses were as low as 1 percent and as high as 5 percent, depending on how much the interest rates
had risen to date. In the first year of the simulation, the allowable unrealized losses on all scenarios at the
end of the three years in the planning horizon were limited to 1 percent of the initial book value.
Rather than examine the details of the transactions each time the portfolio was revised, let us consider only the
general structure of the portfolio over time. Figure 14.6 illustrates theholdings of the portfolio over time in
broad maturity categories. It is interesting to note the extent to which a roughly barbell portfolio strategy was
maintained. Initially, some intermediate maturities (15- and 20-year) were purchased. However, the 15-year
maturity was sold off as soon as the program for realized losses would allow, and the 20-year maturity was
gradually sold off. No other investments in intermediate securities were made during the simulation. The
final portfolio was essentially a barbell structure with 1-, 2-, 3-, and 5-year maturities on the short end; and
26-, 28-, and 30-year maturities on the long end.
We can get an idea of how the value of the portfolio increased over time from Table 14.5. It should be
emphasized that the period of the simulation shows a very large increase in interest rates in general, and
therefore a potential for large capital losses for programs involving active trading of securities. The generally
high interest income exhibited by the portfolio is not completely reflected in the increased book value of the
portfolio the next year, because losses resulting from trading have reduced the book value of the portfolio.
However, the year-to-year increase in the book value of the portfolio generally follows the interest-rate pattern.
The final value of $141,269 for the portfolio in January 1974 corresponds to a compounded rate of return on
the initial investment of 3.52 percent per year.
Table 14.5 also indicates the level of the losses realized by selling securities, and the limit placed on the
level of unrealized losses that could potentially build up in the portfolio. The realized losses were constrained
in each year on every scenario to be less than or equal to one-half percent of the current book value of the
portfolio. In the years 1966 through 1971, the maximum level of realized losses was attained. In each year
the potential unrealized losses at the horizon three years hence were approximately equal to the level of losses
The performance of the BONDS model can be compared with the results of applying various laddered
and barbell strategies to the same historical interest-rate sequence. Alternative portfolio strategies were
implemented essentially the same way as in the BONDS model, except that no forecasting procedure was
needed since the strategies were applied in a mechanical manner. For the laddered portfolios, at the beginning
of each year of the simulation, the funds from maturing securities were reinvested in the longest security
allowed in the ladder, and the coupon income was distributed equally among all maturities to keep the
Figure 14.6 Maturity distributions of managed portfolios (beginning of year).
proportions in each fixed. For the barbell portfolios, at the beginning of each year of the simulation, the
shortest securities in the long end of the barbell were sold and reinvested in the longest security allowed.
Similarly, the maturing securities were reinvested in the longest security allowed on the short end. The coupon
income was allocated between the long or short ends of the barbell to maintain the stated proportions, and
within either end it was distributed equally among the maturities included.
Table 14.6 summarizes the results of using various laddered portfolio strategies in the same historical
environment. Any relatively short ladder would seem to be a good strategy against such a rising interest-rate
sequence. The five-year ladder gives the highest final value, which is slightly less than that obtained by the
BONDS model. However, had the interest-rate sequence been decreasing or had it shown more fluctuation,
the BONDS model would have performed significantly better than the five-year ladder, by being able to
balance capital losses against gains in each period while retaining a relatively large proportion of the portfolio
in longer maturities with higher interest income.
Table 14.7 summarizes the performance of using various barbell portfolio strategies in the same historical
environment. The column labeled ‘‘Strategy’’ gives the maturities held in the portfolio at all times and the
percentage of the portfolio that was reinvested in the long end of the barbell. For example, 1–7, 24–30, 20%
means a barbell portfolio structure with seven bonds on the short end, and seven bonds on the long end, but
with only twenty percent of the total value of the portfolio invested in the long end.
It is useful to compare laddered portfolios with barbell portfolios having the same number of bonds on
the short end. It is clear that, for this particular realization of interest rates, the laddered portfolios did better
than the comparable barbell portfolios. This is due to the fact that, although the barbell portfolios had higher
interest incomes, these were offset by having to realize losses from selling a relatively long maturity during a
period of increasing interest rates. If interest rates had fallen, the barbell portfolios would still have had higher
average interest incomes than the ladders but would have realized capital gains rather than losses. Hence, for
this historicalsimulation in a period of rising rates, the laddered portfolios outperformed the barbell portfolios
Within any barbell structure, as the percent of the portfolio invested in the long end was increased, the
performance of the portfolio deteriorated. This is again due to the fact that the realized losses were so large
Table 14.5 Portfolio characteristics for each year
∗ Maximum allowable realized losses taken.
over this period of rising interest rates. Larger amounts invested in the long end produced larger total interest
income, since the yield curves were generally increasing with longer maturities. However, the increased
interest income was not sufficient to offset the capital losses incurred in trading.
Finally, the riskiness of the portfolio strategies can be analyzed by looking at the amount of unrealized
losses that had built up under each strategy in the year of peak interest rates, 1970. Table 14.8 gives the
book value, market value, and unrealized after-tax losses as a percent of book value, for the strategy followed
by the BONDS model and for various laddered and barbell strategies. In a period of rising rates, strategies
that keep most of their assets in short-term securities would be expected to have lower unrealized losses. In
the extreme case, a ladder consisting of only the one-year maturity would have zero unrealized losses at the
beginning of each year, since the entire portfolio would mature at the end of each period.
Table 14.8 Unrealized losses, January 1, 1970
On this dimension, the strategy followed by the BONDS model builds up significant losses, roughly
comparable to a ten-year ladder, or a barbell with five maturities on each end and, say, thirty percent of the
portfolio value invested in the long end. However, this general level of unrealized losses in the credit crunch
of 1969 might have been considered very reasonable. Any strategy that places a significant proportion of its
assets in relatively short-term securities will not develop unrealized losses. However, just as there is potential
for losses with these strategies, there is also potential for similar gains.
We can sum up the performance of the BONDS model by comparing it to the best of the mechanicallymanaged laddered or barbell strategies. The performance of the five-year laddered portfolio was almost as
good as that of the BONDS model against the particular sequence of interest rates that occurred. However,
it should be noted that a portfolio laddered out only to five years is a very conservative strategy, which is
rather unlikely to be followed in practice. It happened to turn out, after the fact, that this was a good strategy
to have adopted; but it is not clear that any portfolio manager would have been motivated to adopt such a
conservative strategy consistently over the period of the simulation.
Finally, had interest rates been level or falling, the BONDS model would certainly have outperformed the
five-year ladder. In these instances, some other laddered or barbell portfolio might perform competitively
with the BONDS model. However, the important characteristic of the BONDS model is that it produces a
strategy that is adaptive to the environment over time. The BONDS model should perform well against any
interest-rate sequence, while a particular laddered or barbell portfolio will perform well for some realizations
of interest rates and poorly for others. In actual practice, the portfolio manager would be actively forecasting
interest rates, and the BONDS model provides a method of systematically taking advantage of these forecasts.
1. A bank considering using the BONDS model to aid in portfolio planning divides its portfolio into two pools of
funds—U.S. Governments and all grades of municipals. The bank managers forecast a yield curve for their group
of municipals and are willing to treat them as one category. The investment portfolio decisions are revised monthly,
but no securities with less than three months to maturity are purchased.
a) Assuming that the bank employs a two-year planning horizon with four planning periods of 3 months, 3 months,
6 months, and one year, how many constraints of each type will their model have, using 5-point approximations
to the uncertainties in the first two periods and 3-point approximations in the last two periods? (Assume no initial
holdings, but include the remaining constraints of Table 14.1.)
The bank feels that it can aggregate the purchase decisions on individual securities into the following maturities:
3 months, 6 months, 1, 2, 3, 5, 10, and 20 years for U.S. Governments and 1, 2, 3, 4, 5, 10, 20, and 30 years
for the municipal group. How many decision variables will the model sketched in (a) have? (Again, assume no
In fact, the bank does have initial holdings of both Governments and municipals. The bank is willing to aggregate
these holdings in the same maturities as used for new purchases. How many additional constraints and variables
need to be added to account for the initial holdings?
How is a subproblem defined for the model described in (a), (b), and (c)? How many such subproblems are there?
Why is it impossible to combine the subproblem from initial holdings with those of subsequent purchases?
How many constraints does the restricted master have? How would you find an initial basic feasible solution to
2. For the model described in Exercise 1, the demands for information from the portfolio manager are extensive.
a) How many yield curves need to be assessed to use the proposed planning model?
b) How would you think about the problem of assessing the exogenous cash flows in such a way that they are
consistent with the yield curves assessed?
c) What is the interpretation of using the same level of realized and unrealized losses on all scenarios? Which
scenarios are likely to produce the binding realized and unrealized loss constraints? Can the loss constraints on
d) Suppose that the lower-bound constraint on the holdings of government securities could be dropped from the
model. How might this change in the model formulation affect the optimal solution? Could the value of the
3. The objective function of the BONDS model is given in terms of the horizon value of the portfolio. Suppose that
we wish to reformulate the model in terms of the interest income and capital gains in each period. The decision
variables remain the same; all constraints are unchanged, but the objective function changes.
a) Formulate a new objective function that maximizes the expected increase in the size of the portfolio by summing,
over all time periods, the interest income plus capital gains (or losses) in each time period.
b) Show that the two formulations are equivalent, in the sense that the optimal values of the decision variable using
c) Show that the difference between the optimal values of the two objective functions is the expected exogenous
4. Upon seeing your formulation in Exercise 2, the portfolio manager argues that the cash flows in the objective function
a) Will discounting the cash flows change the optimal values of the decision variables?
b) What are the arguments for and against discounting in this situation? How could a single discount rate be chosen?
c) What is the relationship between the shadow prices on the funds-flow constraints of the undiscounted formulation
and the discount rate? (See exercises in Chapter 4.)
d) Suppose you win the argument with the portfolio manager and do not use a discounted objective function. Other
departments in the bank place demands on the portfolio for funds in various time periods. Can you suggest an
approach to choosing among various requests for funds? How does the approach relate to discounting the cash
5. Consider the subproblems generated by the decomposition approach. Formulate the subproblem corresponding to
buying a 20-year U.S. Government security at the beginning of the first period of a model consisting of 3 one-year
periods. The generic decision variables to use are as follows:
(Do not include buying a similar security at the beginning of the second or third periods.)
a) How many constraints and decision variables does the subproblem have?
b) The constraints of the subproblems are homogeneous (i.e., zero righthand sides). Suppose that purchasing 1 unit
of this security, b1 = 1, gives a positive rate of return. What can be said about purchasing λb1 units of this
c) Formulate a dynamic-programmig model to solve this subproblem, assuming that b1 = 1. Show that this solution
6. Suppose that, for the subproblems formulated in Exercise 5, we define a ray-finding subproblem as follows: b1 is
set equal to 1 and moved to the righthand side; the resulting subproblem is solved by linear programming.
Find the dual of the ray-finding problem.
Show that a basis for the dual problem is triangular.
Write down a recursive method for calculating the optimal solution of the dual of the ray-finding problem. [Hint.
Exploit the triangular property of the basis to solve for the dual variables by back-substitution.]
e) How is the solution of the primal ray-finding problem determined from the solution of the dual?
7. As a follow-up to Exercises 5 and 6, once the subproblems have been solved, the rays generated are added to the
Describe how the columns of the restricted master are computed.
Why are weighting constraints not needed for the restricted master in this particular application?
What is the stopping rule for this variation of the decomposition algorithm?
Suppose that storage limitations force you to drop some of the nonbasic columns from the restricted master at
some iteration. Is it possible that the algorithm will be unable to find the overall optimal solution as a result?
8. There are at least two ways to define subproblems for this model. First, a subproblem can be defined for each
maturity and each year it can be purchased. In Fig. 14.4 there are a total of 12 subproblems using this definition.
Second, a subproblem can be defined for each maturity regardless of when it is purchased. In Fig. 14.4 there are a
total of 3 subproblems using this definition.
a) Explain why the choice of subproblem definitions need have no impact on the solution procedure adopted for
b) Explain how the restricted master will differ under each definition of the subproblmes.
c) Which choice of subproblem definitions will make the restricted master more efficient to solve? Why?
d) If there was a weighting constraint for each subproblem, how would your answer to (c) be affected? [Hint.
Which definition would add more weighting constraints?]
9. Suppose that a new objective function is to be considered that is a nonlinear function of the holdings entering the
final period. More precisely, assume that we wish to maximize the expected utility of these holdings, with the utility
where a > 0 and 0 < c < 1. The objective function is then of the form:
(ym (em ) + vm,N (e N ))h m,N (e N ) + (y N (e N ) + v N ,N (e N ))b N (e N ) .
a) Show that this problem cannot be handled directly by decomposition. [Hint. Is this objective function separable
b) If the nonlinear-programming problem were solved by the Frank-Wolfe algorithm, a sequence of linear programs
would be solved. How can the decomposition approach presented in this chapter be used to solve one of these
c) How can the Frank-Wolfe algorithm be efficiently combined with the decomposition approach presented in this
chapter, to find the optimal solution to the nonlinear program defined by maximizing the expected utility given
d) Does your proposed method generalize to other nonlinear problems?
10. Describe the method of producing scenarios used in the historical simulation over the first three decisions (two
a) How many yield curves need to be assessed at the beginning of ’64 for the years ’64, ’65, and ’66?
b) Draw a decision tree depicting the probability that each of the yield curves indicated in (a) occurs. What use is
made of the uncertainty in the estimates of the change in the twenty-year rate (thirty-year rate) as a fraction of
the change in the one-year rate? How could this be modified?
c) Show how to compute the parameters of the functional form for each of the yield curves forecast for the start of
d) Explain how you might assess the required information in actual practice, using a model similar to that described
in Exercise 1. Draw a distinction between short-term forecasting (3 months) and long-term forecasting (2 years).
11. The performance of the laddered portfolio structure with five equally spaced maturities proved to be the best among
the ladders investigated. Similarly, the performance of the 1–5, 26–30 barbell, with 20% invested in the long end,
proved the best among the barbells. The BONDS model outperformed these strategies in the historical simulation
a) How would you expect these strategies to compare with the BONDS model in a period of falling rates?
b) How would you choose an appropriate ladder or barbell strategy without the benefit of 20/20 hindsight?
c) What benefits does the BONDS model have over either a ladder or barbell approach to portfolio management?
This chapter is based primarily on material drawn from ‘‘Managing a Bank Bond Portfolio Over Time,’’ by
S. P. Bradley and D. B. Crane, to appear in Stochastic Programming (ed. M. A. H. Dempster), Academic
Press, in press. A broad coverage of the area is contained in Management of Bank Portfolios by S. P. Bradley
and D. B. Crane, John Wiley & Sons, New York, 1975.
Vectors and matrices are notational conveniences for dealing with systems of linear equations and inequalities.
In particular, they are useful for compactly representing and discussing the linear programming problem:
This appendix reviews several properties of vectors and matrices that are especially relevant to this
problem. We should note, however, that the material contained here is more technical than is required for
understanding the rest of this book. It is included for completeness rather than for background.
We begin by defining vectors, relations among vectors, and elementary vector operations.
Definition. A k-dimensional vector y is an ordered collection of k real numbers y1 , y2 , . . . , yk , and is
written as y = (y1 , y2 , . . . , yk ). The numbers y j ( j = 1, 2, . . . , k) are called the components of the
Each of the following are examples of vectors:
i) (1, −3, 0, 5) is a four-dimensional vector. Its first component is 1, its second component is −3, and its
third and fourth components are 0 and 5, respectively.
ii) The coefficients c1 , c2 , . . . , cn of the linear-programming objective function determine the n-dimensional
iii) The activity levels x1 , x2 , . . . , xn of a linear program define the n-dimensional vector x = (x1 , x2 , . . . , xn ).
iv) The coefficients ai1 , ai2 , . . . , ain of the decision variables in the ith equation of a linear program determine an n-dimensional vector Ai = (ai1 , ai2 , . . . , ain ).
v) The coefficients a1 j , a2 j , . . . , an j of the decision variable x j in constraints 1 through m of a linear
program define an m-dimensional vector which we denote as A j = (a1 j , a2 j , . . . , am j ).
Equality and ordering of vectors are defined by comparing the vectors’ individual components. Formally,
let y = (y1 , y2 , . . . , yk ) and z = (z 1 , z 2 , . . . , z k ) be two k-dimensional vectors. We write:
and say, respectively, that y equals z, y is greater than or equal to z and that y is greater than z. In the last two
cases, we also say that z is less than or equal to y and less than y. It should be emphasized that not all vectors
are ordered. For example, if y = (3, 1, −2) and x = (1, 1, 1), then the first two components of y are greater
than or equal to the first two components of x but the third component of y is less than the corresponding
A final note: 0 is used to denote the null vector (0, 0, …, 0), where the dimension of the vector is
understood from context. Thus, if x is a k-dimensional vector, x ≥ 0 means that each component x j of the
We also define scalar multiplication and addition in terms of the components of the vectors.
Definition. Scalar multiplication of a vector y = (y1 , y2 , . . . , yk ) and a scalar α is defined to be a new
vector z = (z 1 , z 2 , . . . , z k ), written z = αy or z = yα, whose components are given by z j = αy j .
Definition. Vector addition of two k-dimensional vectors x = (x1 , x2 , . . . , xk ) and y = (y1 , y2 , . . . , yk )
is defined as a new vector z = (z 1 , z 2 , . . . , z k ), denoted z = x +y, with components given by z j = x j +y j .
As an example of scalar multiplication, consider
(3, 4, 1, −3) + (1, 3, −2, 5) = (4, 7, −1, 2).
Using both operations, we can make the following type of calculation:
(1, 0)x1 + (0, 1)x2 + (−3, −8)x3 = (x1 , 0) + (0, x2 ) + (−3x3 , −8x3 )
It is important to note that y and z must have the same dimensions for vector addition and vector
comparisons. Thus (6, 2, −1) + (4, 0) is not defined, and (4, 0, −1) = (4, 0) makes no sense at all.
We can now extend these ideas to any rectangular array of numbers, which we call a matrix.
Definition. A matrix is defined to be a rectangular array of numbers
whose dimension is m by n. A is called square if m = n. The numbers ai j are referred to as the elements
The tableau of a linear programming problem is an example of a matrix.
We define equality of two matrices in terms of their elements just as in the case of vectors.
Definition. Two matrices A and B are said to be equal, written A = B, if they have the same dimension
and their corresponding elements are equal, i.e., ai j = bi j for all i and j.
In some instances it is convenient to think of vectors as merely being special cases of matrices. However, we
will later prove a number of properties of vectors that do not have straightforward generalizations to matrices.
Definition. A k-by-1 matrix is called a column vector and a 1-by-k matrix is called a row vector.
The coefficients in row i of the matrix A determine a row vector Ai = (ai1 , ai2 , …, ain ), and the coefficients
of column j of A determine a column vector A j = ha1 j , a2 j , . . . , am j i. For notational convenience, column
vectors are frequently written horizontally in angular brackets.
We can define scalar multiplication of a matrix, and addition of two matrices, by the obvious analogs of
Definition. Scalar multiplication of a matrix A and a real number α is defined to be a new matrix B,
written B = α A or B = Aα, whose elements bi j are given by bi j = αai j .
Definition. Addition of two matrices A and B, both with dimension m by n, is defined as a new matrix
C, written C = A + B, whose elements ci j are given by ci j = ai j + bi j .
If two matrices A and B do not have the same dimension, then A + B is undefined.
The product of two matrices can also be defined if the two matrices have appropriate dimensions.
Definition. The product of an m-by- p matrix A and a p-by-n matrix B is defined to be a new m-by-n
matrix C, written C = AB, whose elements ci j are given by:
If the number of columns of A does not equal the number of rows of B, then AB is undefined. Further,
from these examples, observe that matrix multiplication is not commutative; that is, AB 6 = B A, in general.
If π = (π1 , π2 , . . . , πm ) is a row vector and q = hq1 , q2 , . . . , qm i a column vector, then the special case
of matrix multiplication is sometimes referred to as an inner product. It can be visualized by placing the
elements of π next to those of q and adding, as follows:
In these terms, the elements ci j of matrix C = AB are found by taking the inner product of Ai (the ith row
of A) with B j (the jth column of B); that is, ci j = Ai B j .
The following properties of matrices can be seen easily by writing out the appropriate expressions in each
As a result, A + B + C or ABC is well defined, since the evaluations can be performed in any order.
There are a few special matrices that will be useful in our discussion, so we define them here.
Definition. The identity matrix of order m, written Im (or simply I , when no confusion arises) is a
square m-by-m matrix with ones along the diagonal and zeros elsewhere.
It is important to note that for any m-by-m matrix B, B Im = Im B = B. In particular, Im Im = Im or
Definition. The transpose of a matrix A, denoted At , is formed by interchanging the rows and columns
We can show that (AB)t = B t At since the i jth element of both sides of the equality is
Definition. An elementary matrix is a square matrix with one arbitrary column, but otherwise ones
along the diagonal and zeros elsewhere (i.e., an identify matrix with the exception of one column).
can now be written in matrix form in a straightforward manner. If we let:
be column vectors, the linear system of inequalities is written in matrix form as Ax ≤ b. Letting c =
(c1 , c2 , . . . , cn ) be a row vector, the objective function is written as cx. Hence,the linear program assumes
The same problem can also be written in terms of the column vectors A j of the matrix A as:
At various times it is convenient to use either of these forms.
The appropriate dual linear program is given by:
be a column vector, since the dual variables are associated with the constraints of the primal problem, we can
write the dual linear program in compact form as follows:
We can also write the dual in terms of the untransposed vectors as follows:
In this form it is easy to write the problem in terms of the row vectors Ai of the matrix A, as:
Finally, we can write the primal and dual problems in equality form. In the primal, we merely define an
m-dimensional column vector s measuring the amount of slack in each constraint, and write:
In the dual, we define an n-dimensional row vector u measuring the amount of surplus in each dual constraint
Definition. Given a square m-by-m matrix B, if there is an m-by-m matrix D such that
then D is called the inverse of B and is denoted B −1 .
Note that B −1 does not mean 1/B or I /B, since division is not defined for matrices. The symbol B −1 is just
a convenient way to emphasize the relationship between the inverse matrix D and the original matrix B.
There are a number of simple properties of inverses that are sometimes helpful to know.
i) The inverse of a matrix B is unique if it exists.
Proof. Suppose that B −1 and A are both inverses of B. Then
B −1 = I B −1 = (AB)B −1 = A(B B −1 ) = A.
iii) If the inverse of A and B exist, then the inverse of AB exists and is given by (AB)−1 = B −1 A−1 .
Proof. (AB)(B −1 A−1 ) = A(B B −1 )A−1 = AI A−1 = A A−1 = I.
iv) If the inverse of B exists, then the inverse of B −1 exists and is given by (B −1 )−1 = B.
Proof. I = I −1 = (B −1 B)−1 = B −1 (B −1 )−1 .
v) If the inverse of B exists, then the inverse of B t exists and is given by (B t )−1 = (B −1 )t .
Proof. I = I t = (B −1 B)t = B t (B −1 )t .
The natural question that arises is: Under what circumstances does the inverse of a matrix exist? Consider
If B has an inverse, then multiplying on the left by B −1 yields
which ‘‘solves’’ the original square system of equations for any choice of y. The second system of equations
has a unique solution in terms of x for any choice of y, since one variable x j is isolated in each equation.
The first system of equations can be derived from the second by multiplying on the left by B; hence, the
two systems are identical in the sense that any x̄, ȳ that satisfies one system will also satisfy the other. We
can now show that a square matrix B has an inverse if the square system of equations Bx = y has a unique
The solution to this system of equations can be obtained by successively isolating one variable in each
equation by a procedure known as Gauss–Jordan elimination, which is just the method for solving square
systems of equations learned in high-school algebra. Assuming b11 6 = 0, we can use the first equation to
eliminate x1 from the other equations, giving:
If b11 = 0, we merely choose some other variable to isolate in the first equation. In matrix form, the new
matrices of the x and y coefficients are given respectively by E 1 B and E 1 I , where E 1 is an elementary matrix
Further, since b11 is chosen to be nonzero, E 1 has an inverse given by:
Thus by property (iii) above, if B has an inverse, then E 1 B has an inverse and the procedure may be repeated.
Some x j coefficient in the second row of the updated system must be nonzero, or no variable can be isolated
in the second row, implying that the inverse does not exist. The procedure may be repeated by eliminating
this x j from the other equations. Thus, a new elementary matrix E 2 is defined, and the new system
has x1 isolated in equation 1 and x2 in equation 2.
(E m E m−1 · · · E 2 E 1 B)x = (E m E m−1 · · · E 2 E 1 )y
with one variable isolated in each equation. If variable x j is isolated in equation j, the final system reads:
Equivalently, B −1 = E m E m−1 · · · E 2 E 1 is expressed in product form as the matrix product of elementary
matrices. If, at any stage in the procedure, it is not possible to isolate a variable in the row under consideration,
then the inverse of the original matrix does not exist.
If x j has not been isolated in the jth equation, the equations may have to be permuted to determine B −1 .
This point is illustrated by the following example:
Rearranging the first and second rows of the last table gives the desired transformation of B into the
Alternately, if the first and second columns of the last table are interchanged, an identity matrix is produced.
Interchanging the first and second columns of B, and performing the same operations as above, has this same
In many applications the column order, i.e., the indexing of the variables x j , is arbitrary, and this last procedure
is utilized. That is, one variable is isolated in each row and the variable isolated in row j is considered the
jth basic variable (above, the second basic variable would be x1 ). Then the product form gives the inverse
of the columns to B, reindexed to agree with the ordering of the basic variables.
In computing the inverse of a matrix, it is often helpful to take advantage of any special structure that the
matrix may have. To take advantage of this structure, we may partition a matrix into a number of smaller
matrices, by subdividing its rows and columns.
For example, the matrix A below is partitioned into four submatrices A11 , A12 , A21 , and A22 :
The important point to note is that partitioned matrices obey the usual rules of matrix algebra. For example,
multiplication of two partitioned matrices
assuming the indicated products are defined; i.e., the matrices Ai j and B jk have the appropriate dimensions.
To illustrate that partitioned matrices may be helpful in computing inverses, consider the following
where 0 denotes a matrix with all zero entries. Then
which implies the following matrix equations:
Solving these simultaneous equations gives
Note that we need only compute R −1 in order to determine M −1 easily. This type of use of partitioned
matrices is the essence of many schemes for handling large-scale linear programs with special structures.
In Chapters 2, 3, and 4, the concept of a basis plays an important role in developing the computational
procedures and fundamental properties of linear programming. In this section, we present the algebraic
Definition. m-dimensional real space R m is defined as the collection of all m-dimensional vectors
Definition. A set of m-dimensional vectors A1 , A2 , . . . , Ak is linearly dependent if there exist real
numbers α1 , α2 , . . . , αk , not all zero, such that
If the only set of α j ’s for which (1) holds is α1 = α2 = · · · = αk = 0, then the m-vectors A1 , A2 , . . . , Ak
For example, the vectors (4, 1, 0, −1), (3, 1, 1, −2), and (1, 1, 3, −4) are linearly dependent, since
2(4, 1, 0, −1) − 3(3, 1, 1, −2) + 1(1, 1, 3, −4) = 0.
Further, the unit m-dimensional vectors u j = (0, . . . , 0, 1, 0, . . . , 0) for j = 1, 2, . . . , m, with a plus one in
the jth component and zeros elsewhere, are linearly independent, since
If any of the vectors A1 , A2 , . . . , Ak , say Ar , is the 0 vector (i.e., has all zero components), then, taking
αr = 1 and all other α j = 0 shows that the vectors are linearly dependent. Hence, the null vector is linearly
Definition. An m-dimensional vector Q is said to be dependent on the set of m-dimensional vectors
A1 , A2 , . . . , Ak if Q can be written as a linear combination of these vectors; that is,
for some real numbers λ1 , λ2 , . . . , λk . The k-dimensional vector (λ1 , λ2 , . . . , λk ) is said to be the
representation of Q in terms of A1 , A2 , . . . , Ak .
Note that (1, 1, 0) is not dependent upon (0, 4, 2) and (0, −1, 3), since λ1 (0, 4, 2) + λ2 (0, −1, 3) =
(0, 4λ1 − λ2 , 2λ1 + 3λ2 ) and can never have 1 as its first component.
The m-dimensional vector (λ1 , λ2 , . . . , λm ) is dependent upon the m-dimensional unit vectors u 1 , u 2 , . . . , u m ,
Thus, any m-dimensional vector is dependent on the m-dimensional unit vectors. This suggests the following
Definition. A basis of R m is a set of linearly independent m-dimensional vectors with the property that
every vector of R m is dependent upon these vectors.
Note that the m-dimensional unit vectors u 1 , u 2 , . . . , u m are a basis for R m , since they are linearly independent
and any m-dimensional vector is dependent on them.
We now sketch the proofs of a number of important properties relating bases of real spaces, representations
of vectors in terms of bases, changes of bases, and inverses of basis matrices.
Property 1. A set of m-dimensional vectors A1 , A2 , . . . , Ar is linearly dependent if and only if one of
these vectors is dependent upon the others.
so that Ar is dependent upon A1 , A2 , . . . , Ar −1 . Then, setting λr = −1, we have
which shows that A1 , A2 , . . . , Ar are linearly dependent.
Next, if the set of vectors is dependent, then
with at least one α j 6= 0, say αr 6= 0. Then,
and Ar depends upon A1 , A2 , . . . , Ar −1 . 
Property 2. The representation of any vector Q in terms of basis vectors A1 , A2 , . . . , Am is unique.
Proof. Suppose that Q is represented as both
Eliminating Q gives 0 = mj=1 (λ j − λ0j )A j . Since A1 , A2 , . . . , Am constitute a basis, they are linearly
independent and each (λ j − λ0j ) = 0. That is, λ j = λ0j , so that the representation must be unique. 
This proposition actually shows that if Q can be represented in terms of the linearly independent vectors
A1 , A2 , . . . , Am , whether a basis or not, then the representation is unique. If A1 , A2 , . . . , Am is a basis, then
the representation is always possible because of the definition of a basis.
Several mathematical-programming algorithms, including the simplex method for linear programming,
move from one basis to another by introducing a vector into the basis in place of one already there.
Property 3. Let A1 , A2 , . . . , Am be a basis for R m ; let Q 6 = 0 be any m-dimensional vector; and let
(λ1 , λ2 , . . . , λm ) be the representation of Q in terms of this basis; that is,
Then, if Q replaces any vector Ar in the basis with λr 6 = 0, the new set of vectors is a basis for R m .
Proof. Suppose that λm 6 = 0. First, we show that the vectors A1 , A2 , . . . , Am−1 , Q are linearly independent. Let α j for j = 1, 2, . . . , m and α Q be any real numbers satisfying:
which with (2) gives two representations of Q in terms of the basis A1 , A2 , . . . , Am . By Property 2, this
is impossible, so α Q = 0. But then, α1 = α2 = · · · = αm−1 = 0, since A1 , A2 , . . . , Am−1 are linearly
independent. Thus, as required, α1 = α2 = · · · = αm−1 = α Q = 0 is the only solution to (3).
Second, we show that any m-dimensional vector P can be represented in terms of the vectors A1 , A2 , . . . , Am−1 , Q.
Since A1 , A2 , . . . , Am is a basis, there are constants α1 , α2 , . . . , αm such that
Using expression (2) to eliminate Am , we find that
which by definition shows that A1 , A2 , . . . , Am−1 , Q is a basis. 
Property 4. Let Q 1 , Q 2 , . . . , Q k be a collection of linearly independent m-dimensional vectors, and let
A1 , A2 , . . . , Ar be a basis for R m . Then Q 1 , Q 2 , . . . , Q k can replace k vectors from A1 , A2 , . . . , Ar to
Proof. First recall that the 0 vector is not one of the vectors Q j , since 0 vector is dependent on any set
of vectors. For k = 1, the result is a consequence of Property 3. The proof is by induction. Suppose,
by reindexing if necessary, that Q 1 , Q 2 , . . . , Q j , A j+1 , A j+2 , . . . , Ar is a basis. By definition of basis,
there are real numbers λ1 , λ2 , . . . , λr such that
Q j+1 = λ1 Q 1 + λ2 Q 2 + · · · + λ j Q j + λ j+1 A j+1 + λ j+2 A j+2 + · · · + λr Ar .
If λi = 0 for i = j + 1, j + 2, . . . , r, then Q is represented in terms of Q 1 , Q 2 , . . . , Q j , which,
by Property 1, contradicts the linear independence of Q 1 , Q 2 , . . . , Q k . Thus some, λi 6 = 0 for i =
j + 1, j + 2, . . . , r , say, λ j+1 6= 0. By Property 3, then, Q 1 , Q 2 , . . . , Q j+1 , A j+1 , A j+2 , . . . , Ar is
also a basis. Consequently, whenever j < k of the vectors Q i can replace j vectors from A1 , A2 , . . . , Ar
to form a basis, ( j + 1) of them can be used as well, and eventually Q 1 , Q 2 , . . . , Q k can replace k vectors
from A1 , A2 , . . . , Ar to form a basis. 
Property 5. Every basis for R m contains m vectors.
Proof. If Q 1 , Q 2 , . . . , Q k and A1 , A2 , . . . , Ar are two bases, then Property 4 implies that k ≤ r . By
reversing the roles of the Q j and Ai , we also have r ≤ k and thus k = r , and every two bases contain
the same number of vectors. But the unit m-dimensional vectors u 1 , u 2 , . . . , u m constitute a basis with
m-dimensional vectors, and consequently, every basis of R m must contain m vectors. 
Property 6. Every collection Q 1 , Q 2 , . . . , Q k of linearly independent m-dimensional vectors is contained in a basis.
Proof. Apply Property 4 with A1 , A2 , . . . , Am the unit m-dimensional vectors. 
Property 7. Every m linearly-independent vectors of R m form a basis. Every collection of (m + 1) or
more vectors in R m are linearly dependent.
Proof. Immediate, from Properties 5 and 6. 
If a matrix B is constructed with m linearly-independent column vectors B1 , B2 , . . . , Bm , the properties
just developed for vectors are directly related to the concept of a basis inverse introduced previously. We
will show the relationships by defining the concept of a nonsingular matrix in terms of the independence of
its vectors. The usual definition of a nonsingular matrix is that the determinant of the matrix is nonzero.
However, this definition stems historically from calculating inverses by the method of cofactors, which is of
little computational interest for our purposes and will not be pursued.
Definition. An m-by-m matrix B is said to be nonsingular if both its column vectors B1 , B2 , . . . , Bm
and rows vectors B 1 , B 2 , . . . , B m are linearly independent.
Although we will not establish the property here, defining nonsingularity of B merely in terms of linear
independence of either its column vectors or row vectors is equivalent to this definition. That is, linear
independence of either its column or row vectors automatically implies linear independence of the other
Property 8. An m-by-m matrix B has an inverse if and only if it is nonsingular.
Proof. First, suppose that B has an inverse and that
Letting α = hα1 , α2 , . . . , αm i, in matrix form, this expression says that
Thus (B −1 )(Bα) = B −1 (0) = 0 or (B −1 B)α = I α = α = 0. That is, α1 = α2 = · · · = αm = 0, so
that vectors B1 , B2 , . . . , Bm are linearly independent. Similarly, α B = 0 implies that
so that the rows B 1 , B 2 , . . . , B m are linearly independent.
Next, suppose that B1 , B2 , . . . , Bm are linearly independent. Then, by Property 7, these vectors are a
basis for R m , so that each unit m-dimensional vector u j is dependent upon them. That is, for each j,
for some real numbers λ1 , λ2 , . . . , λm . Letting D j be the column vector D j = hλ1 , λ2 , . . . , λm i, Eq. (4)
where D is a matrix with columns D1 , D2 , . . . , Dm . The same argument applied to the row vectors
B 1 , B 2 , . . . , B m shows that there is a matrix D 0 with D 0 B = I . But D = I D = (D 0 B)D = D 0 (B D) =
D 0 I = D 0 , so that D = D 0 is the inverse of B. 
Property 8 shows that the rows and columns of a nonsingular matrix inherit properties of bases for R m
Definition. Let A be an m-by-n matrix and B be any m-by-m submatrix of A. If B is nonsingular, it is
Let B be a basis for A and let A j be any column of A. Then there is a unique solution Ā j =
hā1 j , ā2 j , . . . , ān j i to the system of equations B Ā j = A j given by multiplying both sides of the equality
B Ā j = B1 ā1 j + B2 ā2 j + · · · + Bm ān j = A j ,
the vector Ā j is the representation of the column A j in terms of the basis. Applying Property 3, we
see that A j can replace column Bk to form a new basis if āk j 6 = 0. This result is essential for several
mathematical-programming algorithms, including the simplex method for solving linear programs.
In our discussion of linear programs in the text, we have alluded to the connection between extreme points,
or corner points, of feasible regions and basic solutions to linear programs. the material in this section
delineates this connection precisely, using concepts of vectors and matrices. In pursuing this objective, this
section also indicates why a linear program can always be solved at a basic solution, an insight which adds to
our seemingly ad hoc choice of basic feasible solutions in the text as the central focus for the simplex method.
Definition. Let S be a set of points in R n . A point y in S is called an extreme point of S if y cannot be
written as y = λw + (1 − λ)x for two distinct points w and x in S and 0 < λ < 1. That is, y does not
lie on the line segment joining any two points of S.
For example, if S is the set of feasible points to the system
then the extreme points are (0, 0), (0, 3), (3, 3), and (6, 0) (see Fig. (A.1).
The next result interprets the geometric notion of an extreme point for linear programs algebraically in
Feasible Extreme Point Theorem. Let S be the set of feasible solutions to the linear program Ax =
b, x ≥ 0. Then the feasible point y = (y1 , y2 , . . . , yn ) is an extreme point of S if and only if the columns
of A with yi > 0 are linearly independent.
Proof. By reindexing if necessary, we may assume that only the first r components of y are positive; that
We must show that any vector y solving Ay = b, y ≥ 0, is an extreme point if and only if the first r
column A1 , A2 , . . . , Ar of A are linearly independent. First, suppose that these columns are not linearly
for some real numbers α1 , α2 , . . . , αr not all zero. If we let x denote the vector x = (α1 , α2 , . . . , αr , 0, . . . , 0),
then expression (5) can be written as Ax = 0. Now let w = y + λx and w̄ = y − λx. Then, as long
as λ is chosen small enough to satisfy λ|α j | ≤ y j for each component j = 1, 2, . . . , r, both w ≥ 0 and
w̄ ≥ 0. But then, both w and w̄ are contained in S, since
and, similarly, A(y − λx) = b. However, since y = 21 (w + w̄), we see that y is not an extreme point of
S in this case. Consequently, every extreme point of S satisfies the linear independence requirement.
Conversely, suppose that A1 , A2 , . . . Ar are linearly independent. If y = λw + (1 − λ)x for some points
w and x of S and some 0 < λ < 1, then y j = λw j + (1 − λ)x j . Since y j = 0 for j ≥ r + 1 and
w j ≥ 0, x j ≥ 0, then necessarily w j = x j = 0 for j ≥ r + 1. Therefore,
A1 y1 + A2 y2 + · · · + Ar yr = A1 w1 + A2 w2 + · · · + Ar wr
Since, by Property 2 in Section A.5, the representation of the vector b in terms of the linearly independent
vectors A1 , A2 , . . . , Ar is unique, then y j = z j = x j . Thus the two points w and x cannot be distinct
and therefore y is an extreme point of S. 
If A contains a basis (i.e., the tows of A are linearly independent), then, by Property 6, any collection
A1 , A2 , . . . , Ar of linearly independent vectors can be extended to a basis A1 , A2 , . . . , Am . The extremepoint theorem shows, in this case, that every extreme point y can be associated with a basic feasible solution,
i.e., with a solution satisfying y j = 0 for nonbasic variables y j , for j = m + 1, m + 2, . . . , n.
Chapter 2 shows that optimal solutions to linear programs can be found at basic feasible solutions or
equivalently, now, at extreme points of the feasible region. At this point, let us use the linear-algebra tools
of this appendix to drive this result independently. This will motivate the simplex method for solving linear
Suppose that y is a feasible solution to the linear program
and, by reindexing variables if necessary, that y1 > 0, y2 > 0, . . . , yr +1 > 0 and yr +2 = yr +3 = · · · =
yn = 0. If the column Ar +1 is linearly dependent upon columns A1 , A2 , . . . , Ar , then
with at least one of the constants α j nonzero for j = 1, 2, . . . , r . Multiplying both sides of this expression
Ar +1 θ = A1 (α1 θ ) + A2 (α2 θ ) + · · · + Ar (αr θ),
which states that we may simulate the effect of setting xr +1 = θ in (6) by setting x1 , x2 , . . . , xr , respectively,
to (α1 θ), (α2 θ), . . . , (αr θ ). Taking θ = 1 gives:
as the per-unit profit from the simulated activity of using α1 units of x1 , α2 units of x2 , through αr units of
Letting x̄ = (−α1 , −α2 , . . . , −αr , + 1, 0, . . . , 0), Eq. (8) is rewritten as A(θ x) = θ A x̄ = 0. Here x̄ is
interpreted as setting xr +1 to 1 and decreasing the simulated activity to compensate. Thus,
so that y + θ x̄ is feasible as long as y + θ x̄ ≥ 0 (this condition is satisfied if θ is chosen so that |θα j | ≤ y j
for every component j = 1, 2, . . . , r ). The return from y + θ x̄ is given by:
c(y + θ x̄) = cy + θc x̄ = cy + θ(cr +1 − c̃r +1 ).
Consequently, if c̃r +1 < cr +1 , the simulated activity is less profitable than the (r + 1)st activity itself, and
return improves by increasing θ . If c̃r +1 > cr +1 , return increases by decreasing θ (i.e., decreasing yr +1 and
increasing the simulated activity). If c̃r +1 = cr +1 , return is unaffected by θ .
These observation imply that, if the objective function is bounded from above over the feasible region,
then by increasing the simulated activity and decreasing activity yr +1 , or vice versa, we can find a new feasible
solution whose objective value is at least as large as cy but which contains at least one more zero component
For, suppose that c̃r +1 ≥ cr +1 . Then by decreasing θ from θ = 0, c(y + θ x̄) ≥ cy; eventually
y j + θ x̄ j = 0 for some component j = 1, 2, . . . , r + 1 (possibly yr +1 + θ x̄r +1 = yr +1 + θ = 0). On the
other hand, if c̃r +1 < cr +1 , then c(y + θ x̄) > cy as θ increases from θ = 0; if some component of α j from
(7) is positive, then eventually y j + θ x̄ j = y j − θα j reaches 0 as θ increases. (If every α j ≤ 0, then we
may increase θ indefinitely, c(y + θ x̄) → +∞, and the objective value is unbounded over the constraints,
contrary to our assumption.) Therefore, if
we can find a value for θ such that at least one component of y j + θ x̄ j becomes zero for j = 1, 2, . . . , r + 1.
Since y j = 0 and x̄ j = 0 for j > r + 1, y j + θ x̄ j remains at 0 for j > r + 1. Thus, the entire vector y + θ x̄
contains at least one more positive component than y and c(y + θ x̄) ≥ cy.
With a little more argument, we can use this result to show that there must be an optimal extreme-point
Optimal Extreme-Point Theorem. If the objective function for a feasible linear program is bounded
from above over the feasible region, then there is an optimal solution at an extreme point of the feasible
Proof. If y is any feasible solution and the columns A j of A, with y j > 0, are linearly dependent, then
one of these columns depends upon the others (Property 1).
From above, there is a feasible solution x to the linear program with both cx ≥ cy and x having one
less positive component than y. Either the columns of A with x j > 0 are linearly independent, or the
argument may be repeated to find another feasible solution with one less positive component. Continuing,
we eventually find a feasible solution w with cw ≥ cy, and the columns of A with w j > 0 are linearly
independent. By the feasible extreme-point theorem, w is an extreme point of the feasible region.
Consequently, given any feasible point, there is always an extreme point whose objective value is at least
as good. Since the number of extreme points is finite (the number of collections of linear independent
vectors of A is finite), the extreme point giving the maximum objective value solves the problem. 
We first introduce matrix concepts in linear programming by developing a variation of the simplex method
called the revised simplex method. This algorithm, which has become the basis of all commercial computer
codes for linear programming, simply recognizes that much of the information calculated by the simplex
method at each iteration, as described in Chapter 2, is not needed. Thus, efficiencies can be gained by
computing only what is absolutely required.
Then, having introduced the ideas of matrices, some of the material from Chapters 2,3, and 4 is recast
in matrix terminology. Since matrices are basically a notational convenience, this reformulation provides
essentially nothing new to the simplex method, the sensitivity analysis, or the duality theory. However, the
economy of the matrix notation provides added insight by streamlining the previous material and, in the
process, highlighting the fundamental ideas. Further, the notational convenience is such that extending some
of the results of the previous chapters becomes more straightforward.
The revised simplex method, or the simplex method with multipliers, as it is often referred to, is a modification
of the simplex method that significantly reduces the total number of calculations that must be performed at
each iteration of the algorithm. Essentially, the revised simplex method, rather than updating the entire tableau
at each iteration, computes only those coefficients that are needed to identify the pivot element. Clearly, the
reduced costs must be determined so that the entering variable can be chosen. However, the variable that
leaves the basis is determined by the minimum-ratio rule, so that only the updated coefficients of the entering
variable and the current righthand-side values are needed for this purpose. The revised simplex method then
keeps track of only enough information to compute the reduced costs and the minimum-ratio rule at each
The motivation for the revised simplex method is closely related to our discussion of simple sensitivity
analysis in Section 3.1, and we will re-emphasize some of that here. In that discussion of sensitivity analysis,
we used the shadow prices to help evaluate whether or not the contribution from engaging in a new activity
was sufficient to justify diverting resources from the current optimal group of activities. The procedure was
essentially to ‘‘price out’’ the new activity by determining the opportunity cost associated with introducing
one unit of the new activity, and then comparing this value to the contribution generated by engaging in one
unit of the activity. The opportunity cost was determined by valuing each resource consumed, by introducing
one unit of the new activity, at the shadow price associated with that resource. The custom-molder example
used in Chapter 3 to illustrate this point is reproduced in Tableau B.1. Activity 3, producing one hundred
cases of champagne glasses, consumes 8 hours of production capacity and 10 hundred cubic feet of storage
per hour of hour of production time and $ 35
space. The shadow prices, determined in Chapter 3, are $ 14
hundred cubic feet of storage capacity, measured in hundreds of dollars. The resulting opportunity cost of
diverting resources to produce champagne glasses is then:
Comparing this opportunity cost with the $6 contribution results in a net loss of $ 47 per case, or a loss of
$57 17 per one hundred cases. It would clearly not be advantageous to divert resources from the current basic
solution to the new activity. If, on the other hand, the activity had priced out positively, then bringing the
new activity into the current basic solution would appear worthwhile. The essential point is that, by using the
shadow prices and the original data, it is possible to decide, without elaborate calculations, whether or not a
new activity is a promising candidate to enter the basis.
It should be quite clear that this procedure of pricing out a new activity is not restricted to knowing in
advance whether the activity will be promising or not. The pricing-out mechanism, therefore, could in fact
be used at each iteration of the simplex method to compute the reduced costs and choose the variable to enter
the basis. To do this, we need to define shadow prices at each iteration.
In transforming the initial system of equations into another system of equations at some iteration, we
maintain the canonical form at all times. As a result, the objective-function coefficients of the variables
that are currently basic are zero at each iteration. We can therefore define simplex multipliers, which are
essentially the shadow prices associated with a particular basic solution, as follows:
Definition. The simplex multipliers (y1 , y2 , . . . , ym ) associated with a particular basic solution are the
multiples of their initial system of equations such that, when all of these equations are multiplied by their
respective simplex multipliers and subtracted from the initial objective function, the coefficients of the
Thus the basic variables must satisfy the following system of equations:
y1 a1 j + y2 a2 j + · · · + ym am j = c j
The implication is that the reduced costs associated with the nonbasic variables are then given by:
c j = c j − (y1 a1 j + y2 a2 j + · · · + ym am j )
If we then performed the simplex method in such a way that we knew the simplex multipliers, it would be
straightforward to find the largest reduced cost by pricing out all of the nonbasic variables and comparing
In the discussion in Chapter 3 we showed that the shadow prices were readily available from the final
system of equations. In essence, since varying the righthand side value of a particular constraint is similar to
adjusting the slack variable, it was argued that the shadow prices are the negative of the objective-function
coefficients of the slack (or artificial) variables in the final system of equations. Similarly, the simplex
multipliers at each intermediate iteration are the negative of the objective-function coefficients of these
variables. In transforming the initial system of equations into any intermediate system of equations, a
number of iterations of the simplex method are performed, involving subtracting multiples of a row from
the objective function at each iteration. The simplex multipliers, or shadow prices in the final tableau, then
reflect a summary of all of the operations that were performed on the objective function during this process.
If we then keep track of the coefficients of the slack (or artificial) variables in the objective function at each
iteration, we immediately have the necessary simplex multipliers to determine the reduced costs c j of the
nonbasic variables as indicated above. Finding the variable to introduce into the basis, say xs , is then easily
accomplished by choosing the maximum of these reduced costs.
The next step in the simplex method is to determine the variable xr to drop from the basis by applying
Hence, in order to determine which variable to drop from the basis, we need both the current righthand-side
values and the current coefficients, in each equation, of the variable we are considering introducing into the
basis. It would, of course, be easy to keep track of the current righthand-side values for each iteration, since
this comprises only a single column. However, if we are to significantly reduce the number of computations
performed in carrying out the simplex method, we cannot keep track of the coefficients of each variable in
each equation on every iteration. In fact, the only coefficients we need to carry out the simplex method are
those of the variable to be introduced into the basis at the current iteration. If we could find a way to generate
these coefficients after we knew which variable would enter the basis, we would have a genuine economy of
computation over the standard simplex method.
It turns out, of course, that there is a way to do exactly this. In determining the new reduced costs for an
iteration, we used only the initial data and the simplex multipliers, and further, the simplex multipliers were
the negative of the coefficients of the slack (or artificial) variables in the objective function at that iteration.
In essence, the coefficients of these variables summarize all of the operations performed on the objective
function. Since we began our calculations with the problem in canonical form with respect to the slack (or
artificial) variables and −z in the objective function, it would seem intuitively appealing that the coefficients
of these variables in any equation summarize all of the operations performed on that equation.
To illustrate this observation, suppose that we are given only the part of the final tableau that corresponds
to the slack variables for our custom-molder example. This is reproduced from Chapter 3 in Tableau B.2.
In performing the simplex method, multiples of the equations in the initial Tableau B.1 have been added
to and subtracted from one another to produce the final Tableau B.2. What multiples of Eq. 1 have been
added to Eq. 2? Since x4 is isolated in Eq. 1 in the initial tableau, any multiples of Eq. 1 that have been
added to Eq. 2 must appear as the coefficient of x4 in Eq. 2 of the final tableau. Thus, without knowing the
actual sequence of pivot operations, we know their net effect has been to subtract 27 times Eq. 1 from Eq. 2
in the initial tableau to produce the final tableau. Similarly, we can see that 27 times Eq. 1 has been added to
Eq. 3 Finally, we see that Eq. 1 (in the initial tableau) has been scaled by multiplying it by − 17 to produce the
final tableau. The coefficient of x5 and x6 in the final tableau can be similarly interpreted as the multiples of
Eqs. 2 and 3, respectively, in the initial tableau that have been added to each equation of the initial tableau to
We can summarize these observations by remarking that the equations of the final tableau must be given
in terms of multiples of the equations of the initial tableau as follows:
The coefficients of the slack variables in the final tableau thus summarize the operations performed on the
equations of the initial tableau to produce the final tableau.
We can now use this information to determine the coefficients in the final tableau of x3 , the production
of champagne glasses, from the initial tableau and the coefficients of the slack variables in the final tableau.
From the formulas developed above we have:
The resulting values are, in fact, the appropriate coefficients of x3 for each of the equations in the final tableau,
as determined in Chapter 3. Hence, we have found that it is only necessary to keep track of the coefficients
of the slack variables at each iteration.
The coefficients of the slack variables are what is known as the ‘‘inverse’’ of the current basis. To see this
relationship more precisely, let us multiply the matrix∗ corresponding to the slack variables by the matrix
of columns from the initial tableau corresponding to the current basis, arranged in the order in which the
variables are basic. In matrix notation, we can write these multiplications as follows:
which, in symbolic form, is B −1 B = I . The information contained in the coefficients of the slack variables
is then the inverse of the current basis, since the multiplication produces the identity matrix. In general,
to identify the basis corresponding to the inverse, it is only necessary to order the variables so that they
correspond to the rows in which they are basic. In this case, the order is x2 , x6 , and x1 .
In matrix notation, the coefficients A j of any column in the current tableau can then be determined from
their coefficients A j in the initial tableau and the basis inverse by B −1 A j . For example,
If we now consider the righthand-side values as just another column b in the initial tableau, we can, by
analogy, determine the current righthand–side values by:
discussion of vectors and matrices is included in Appendix A.
Hence, had x3 been a promising variable to enter the basis, we could have easily computed the variable to
drop from the basis by the minimum-ratio rule, once we had determined A3 and b.
In performing the revised simplex method, then, we need not compute all of the columns of the tableau
at each iteration. Rather, we need only keep track of the coefficients of the slack variables in all the equations
including the objective function. These coefficients contain the simplex multipliers y and inverse of the
current basis B −1 . Using the original data and the simplex multipliers, the reduced costs can be calculated
easily and the entering variable selected. Using the original data and the inverse of the current basis, we can
easily calculate the coefficients of the entering variable in the current tableau and the current righthand-side
values. The variable to drop from the basis is then selected by the minimum-ratio rule. Finally, the basis
inverse and the simplex multipliers are updated by performing the appropriate pivot operation on the current
tableau, as will be illustrated, and the procedure then is repeated.
We can formalize the ideas presented in the previous section by developing the revised simplex method in
matrix notation. We will assume from here on that the reader is familiar with the first three sections of the
At any point in the simplex method, the initial canonical form has been transformed into a new canonical
form by a sequence of pivot operations. The two canonical forms can be represented as indicated in Fig. B.1.
The basic variables in the initial basis may include artificial variables, as well as variables from the
original problem; the initial canonical form is determined by the procedures discussed in Chapter 2. The new
basis may, of course, contain variables in common with the initial basis. To make Fig. B.1 strictly correct,
we need to imagine including some of these variables twice.
We can derive the intermediate tableau from the initial tableau in a straight-forward manner. The initial
system of equations in matrix notation is:
where the superscripts B, N and I refer to basic variables, nonbasic variables, and variables in the initial
identity basis, respectively. The constraints of the intermediate system of equations are determined by
multiplying the constraints of the initial system (1) on the left by B −1 . Hence,
which implies that the updated nonbasic columns and righthand-side vector of the intermediate canonical
forms are given N = B −1 N and b = B −1 b, respectively.
Since the objective function of the intermediate canonical form must have zeros for the coefficients of the
basic variables, this objective function can be determined by multiplying each equation of (2) by the cost of
the variable that is basic in that row and subtracting the resulting equations from the objective function of (1).
In matrix notation, this means multiplying (2) by c B on the left and subtracting from the objective function
0x B + (c N − c B B −1 N )x N − c B B −1 x I − z = −c B B −1 b.
We can write the objective function of the intermediate tableau in terms of the simplex multipliers by recalling
that the simplex multipliers are defined to be the multiples of the equations in the initial tableau that produce
zero for the coefficients of the basic variables when subtracted from the initial objective function. Hence,
which corresponds to the intermediate canonical form in Fig. B.1. The coefficients in the objective function
of variables in the initial identity basis are the negative of the simplex multipliers as would be expected.
Note also that, since the matrix N is composed of the nonbasic columns A j from the initial tableau,
the relation N = B −1 N states that each updated column A j of N is given by A j = B −1 A j . Equivalently,
A j = B1 a 1 j + B2 a 2 j + · · · + Bm a m j .
This expression states that the column vector A j can be written as a linear combination of columns B1 , B2 , . . . , Bm
of the basis, using the weights a 1 j , a 2 j , . . . , a m j . In vector terminology, we express this by saying that the
is the representation of A j in terms of the basis B.
Let us review the relationships that we have established in terms of the simplex method. Given the current
canonical form, the current basic feasible solution is obtained by setting the nonbasic variables to their lower
The value of the objective function associated with this basis is then
To determine whether or not the current solution is optimal, we look at the reduced costs of the nonbasic
If c j ≤ 0 for all j nonbasic, then the current solution is optimal. Assuming that the current solution is
not optimal and that the maximum c j corresponds to xs , then, to determine the pivot element, we need the
representation of the entering column As in the current basis and the current righthand side,
If cs > 0 and As ≤ 0, the problem is unbounded. Otherwise, the variable to drop from the basis xr is
determined by the usual minimum-ratio rule. The new canonical form is then found by pivoting on the
Note that, at each iteration of the simplex method, only the column corresponding to the variable entering
the basis needs to be computed. Further, since this column can be obtained by B −1 As , only the initial data
and the inverse of the current basis need to be maintained. Since the inverse of the current basis can be
obtained from the coefficients of the variables that were slack (or artificial) in the initial tableau, we need
only perform the pivot operation on these columns to obtain the updated basis inverse. This computational
efficiency is the foundation of the revised simplex method.
STEP (0) : An initial basis inverse B −1 is given with b = B −1 b ≥ 0. The columns of B are [A j1 , A j2 , . . . , A jm ]
and y = c B B −1 is the vector of simplex multipliers.
STEP (1) : The coefficients of c for the nonbasic variables x j are computed by pricing out the original data
If all c j ≤ 0 then stop; we are optimal. If we continue, then there exists some c j > 0.
STEP (2) : Choose the variable to introduce into the basis by
Compute As = B −1 As . If As ≤ 0, then stop; the problem is unbounded. If we continue, there exists
STEP (3) : Choose the variable to drop from the basis by the minimum-ratio rule:
The variable basic in row r is replaced by variable s giving the new basis B = [A ji , . . . , A jr −1 , As , A jr +1 , . . . , A jm ].
STEP (4) : Determine the new basis inverse B −1 , the new righthand-side vector b, and new vector of simplex
multipliers y = c B B −1 , by pivoting on a r s .
We should remark that the initial basis in STEP (0) usually is composed of slack variables and artificial
variables constituting an identity matrix, so that B = I and B −1 = I , also. The more general statement of
the algorithm is given, since, after a problem has been solved once, a good starting feasible basis is generally
known, and it is therefore unnecessary to start with the identity basis.
The only detail that remains to be specified is how the new basis inverse, simplex multipliers, and
righthand-side vector are generated in STEP (4). The computations are performed by the usual simplex
pivoting procedure, as suggested by Fig. B.2. We know that the basis inverse for any canonical form is
always given by the coefficients of the slack variables in the initial tableau. Consequently, the new basis
inverse will be given by pivoting in the tableau on a r s as usual. Observe that whether we compute the new
Figure B.2 Updating the basis inverse and simplex multipliers.
columns A j for j 6= s or not, pivoting has the same effect upon B −1 and b. Therefore we need only use the
After pivoting, the coefficients in place of the βi j and bi will be, respectively, the new basis inverse and
the updated righthand-side vector, while the coefficients in the place of −y and −z will be the new simplex
multipliers and the new value of the objective function, respectively. These ideas will be reinforced by looking
To illustrate the procedures of the revised simplex method, we will employ the same example used at the
end of Chapter 2. It is important to keep in mind that the revised simplex method is merely a modification
of the simplex method that performs fewer calculations by computing only those quantities that are essential
to carrying out the steps of the algorithm. The initial tableau for our example is repeated as Tableau B.3.
Note that the example has been put in canonical form by the addition of artificial variables, and the necessary
At each iteration of the revised simplex method, the current inverse of the basis, and a list of the basic
variables and the rows in which they are basic, must be maintained. This information, along with the initial
tableau, is sufficient to allow us to carry out the steps of the algorithm. As in Chapter 2, we begin with
the Phase I objective, maximizing the negative of the sum of the artificial variables, and carry along the
Phase II objective in canonical form. Initially, we have the identity basis consisting of the slack variable x8 ,
the artificial variables x9 , x10 , and x11 , as well as −z and −w, the Phase II and Phase I objective values,
respectively. This identity basis is shown in Tableau B.4. Ignore for the moment the column labeled x6 ,
Now, to determine the variable to enter the basis, find d s = Max d j for j nonbasic. From the initial
tableau, we can see that d s = d6 = 3, so that variable x6 will enter the basis and is appended to the current
basis in Tableau B.4. We determine the variable to drop from the basis by the minimum-ratio rule:
Since the minimum ratio occurs in row 3, variable x10 drops from the basis. We now perform the calculations
implied by bringing x3 into the basis and dropping x10 , but only on that portion of the tableau where the basis
inverse will be stored. To obtain the updated inverse, we merely perform a pivot operation to transform the
coefficients of the incoming variable x6 so that a canonical form is maintained. That is, the column labeled
x6 should be transformed into all zeros except for a one corresponding to the circled pivot element, since
variable x6 enters the basis and variable x10 is dropped from the basis. The result is shown in Tableau B.5
including the list indicating which variable is basic in each row. Again ignore the column labeled x3 which
We again find the maximum reduced cost, d s = Max d j , for j nonbasic, where d j = d j − y A j .
Recalling that the simplex multipliers are the negative of the coefficients of the slack (artificial) variables in
the objective fuction, we have y = (0, 0, 3, 0). We can compute the reduced costs for the nonbasic variables
from: d j = d j − y1 a1 j − y2 a2 j − y3 a3 j − y4 a4 j , which yields the following values:
Since d 3 = 4 is the largest reduced cost, x3 enters the basis. To find the variable to drop from the basis, we
Now to do this, we need the representation of A3 in the current basis. For this calculation, we consider the
Phase II objective function to be a constraint, but never allow −z to drop from the basis.
so that the minimum ratio is zero and variable x11 , which is basic in row 4, drops from the basis. The updated
tableau is found by a pivot operation, such that the column A3 is transformed into a column containing all
zeros except for a one corresponding to the circled in pivot element in Tableau B.5, since x3 enters the basis
and x11 drops from the basis. The result (ignoring the column labeled x2 ) is shown in Tableau B.6.
Now again find d s = Max d j for j nonbasic. Since y = (0, 0, 3, 4) and d j = d j − y A j , we have
Since d 2 = 2 is the largest reduced cost, x2 enters the basis. To find the variable to drop from the basis,
we find the representation of A2 in the current basis:
and append it to Tableau B.6. Applying the minimum-ratio rule gives:
and x9 , which is basic in row 1, drops from the basis. Again a pivot is performed on the circled element in
the column labeled x2 in Tableau B.6, which results in Tableau B.7 (ignoring the column labeled x5 ).
Since the value of the Phase I objective is equal to zero, we have found a feasible solution. We end Phase
I, dropping the Phase I objective function from any further consideration, and proceed to Phase II. We must
now find the maximum reduced cost of the Phase II objective function. That is, find cs = Max c j, for j
nonbasic, where cs = c j − y A j. The simplex multipliers to initiate Phase II are the negative of the coefficients
of the slack (artificial) variables in the −z equation. Therefore, y = ( 29 , 0, −5, − 15
for the nonbasic variables are: Since c5 is the maximum reduced cost, variable x5 enters the basis. To find
the variable to drop from the basis, compute:
Since only a 25 is greater than zero, variable x8 , which is basic in row 2, drops from the basis. Again a
pivot operation is performed on the circled element in the column labeled x5 in Tableau B.7 and the result is
We again find cs = Max c j for j nonbasic. Since y = (− 29
2 , 2 , 33, 40) and c j = c j − y A j , we
have: The only positive reduced cost is associated with the artificial variable x9 . Since artificial variables are
never reintroduced into the basis once they have become nonbasic, we have determined an optimal solution
x2 = 2, x5 = 2, x6 = 5, x3 = 4, and z = −32.
Finally, it should be pointed out that the sequence of pivots produced by the revised simplex method is
exactly the same as that produced by the usual simplex method. (See the identical example in Chapter 2).
COMPUTER CONSIDERATIONS AND THE PRODUCT FORM
The revised simplex method is used in essentially all commercial computer codes for linear programming,
both for computational and storage reasons.
For any problem of realistic size, the revised simplex method makes fewer calculations than the ordinary
simplex method. This is partly due to the fact that, besides the columns corresponding to the basis inverse and
the righthand side, only the column corresponding to the variable entering the basis needs to be computed at
each iteration. Further, in pricing out the nonbasic columns, the method takes advantage of the low density
of nonzero elements in the initial data matrix of most real problems, since the simplex multipliers need to be
multiplied only by the nonzero coefficients in a nonbasic column. Another reason for using the revised simplex
method is that roundoff error tends to accumulate in performing these algorithms. Since the revised simplex
method maintains the original data, the inverse of the basis may be recomputed from this data periodically,
to significantly reduce this type of error. Many large problems could not be solved without such a periodic
reinversion of the basis to reduce roundoff error.
Equally important is the fact that the revised simplex method usually requires less storage than does
the ordinary simplex method. Besides the basis inverse B −1 and the current righthand-side vector b, which
generally contain few zeros, the revised simplex method must store the original data. The original data, on
the other hand, generally contains many zeros and can be stored compactly using the following methods.
First, we eliminate the need to store zero coefficients, by packing the nonzero coefficients in an array, with
reference pointers indicating their location. Second, often the number of significant digits in the original data
is small—say, three or fewer—so that these can be handled compactly by storing more than one coefficient
in a computer word. In contrast, eight to ten significant digits must be stored for every nonzero coefficient in
a canonical form of the usual simplex method, and most coefficients will be nonzero.
There is one further refinement of the revised simplex method that deserves mention, since it was a
fundamental breakthrough in solving relatively large-scale problems on second-generation computers. The
product form of the inverse was developed as an efficient method of storing and updating the inverse of the
current basis, when this inverse has to be stored on a peripheral device.
When recomputing B −1 and b in the revised simplex method, we pivot on a r s , in a reduced tableau,
illustrated by Fig. B.3. The pivot operation first multiplies row r by 1/a r s , and then subtracts a is /a r s times
row r from row i for i = 1, 2,…,m and i 6= r . Equivalently, pivoting premultiplies the above tableau by the
Computer Considerations and the Product Form
where ηr = 1/a r s and ηi = −a is /a r s for i 6 = r .
An elementary matrix is defined to be an identity matrix except for one column. If the new basis is B ∗ ,
then the new basis inverse (B ∗ )−1 and new righthand-side vector b∗ are computed by:
After the next iteration, the new basis inverse and righthand-side vector will be given by premultiplying
by another elementary matrix. Assuming that the initial basis is the identity matrix and letting E j be the
elementary matrix determined by the jth pivot step, after k iterations the basis inverse can be expressed as:
This product form of the inverse is used by almost all commercial linear-programming codes. In these
codes, b is computed and maintained at each step by (6), but the basis inverse is not computed explicitly.
Rather, the elementary matrices are stored and used in place of B −1 . These matrices can be stored compactly
by recording only the special column hη1 , η2 , . . . , ηm i, together with a marker indicating the location of this
column in E j . Using a pivoting procedure for determining the inverse, B −1 can always be expressed as the
product of no more than m elementary matrices. Consequently, when k is large, the product form for B −1
is recomputed. Special procedures are used in this calculation to express the inverse very efficiently and,
consequently, to cut down on the number of computations required for the revised simplex method. The
details are beyond the scope of our coverage here.
Since the basis inverse is used only for computing the simplex multipliers and finding the representation
of the incoming column in terms of the basis, the elementary matrices are used only for the following two
Most commercial codes solve problems so large that the problem data cannot be kept in the computer itself,
but must be stored on auxiliary storage devices. The product form of the inverse is well suited for sequentialaccess devices such as magnetic tapes or drums. The matrices E k , E k−1 , . . . , E 1 are stored sequentially
on the device and, by accessing the device in one direction, the elementary matrices are read in the order
E k , E k−1 , . . . , E 1 and applied sequentially to c B for computing (7). When rewinding the device, they are
read in opposite order E 1 , E 2 , . . . , E k and applied to As for computing (8). The new elementary matrix E k+1
is then added to the device next to E k . Given this procedure and the form of the above calculations, (7) is
sometimes referred to as the b-tran (backward transformation) and (8) as the f-tran (forward transformation).
In Chapter 3 we gave a detailed discussion of sensitivity analysis in terms of a specific example. There the
analysis depended upon recognizing certain relationships between the initial and final tableaus of the simplex
method. Now that we have introduced the revised simplex method, we can review that discussion and make
some of it more rigorous. Since the revised simplex method is based on keeping track of only the original
data tableau, the simplex multipliers, the inverse of the current basis, and which variable is basic in each row,
the final tableau for the simplex method can be computed from this information. Therefore, all the remarks
that we made concerning sensitivity analysis may be derived formally by using these data.
We will review, in this section, varying the coefficients of the objective function, the values of the righthand
side, and the elements of the coefficient matrix. We will not need to review our discussion of the existence of
alternative optimal solutions, since no simplifications result from the introduction of matrices. Throughout
this section, we assume that we have a maximization problem, and leave to the reader the derivation of the
analogous results for minimization problems.
To begin with, we compute the ranges on the coefficients of the objective function so that the basis remains
unchanged. Since only the objective-function coefficients are varied, and the values of the decision variables
are given by x B = B −1 b, these values remain unchanged. However, since the simplex multipliers are given
by y = c B B −1 , varying any of the objective-function coefficients associated with basic variables will alter
Suppose that variable x j is nonbasic, and we let its coefficient in the objective function c j be changed by
an amount 1c j , with all other data held fixed. Since x j is currently not in the optimal solution, it should be
clear that 1c j may be made an arbitrarily large negative number without x j becoming a candidate to enter
the basis. On the other hand, if 1c j is increased, x j will not enter the basis so long as its new reduced cost
At the upper end of the range, x j becomes a candidate to enter the basis.
Now suppose that x j is a basic variable and, further that it is basic in row i. If we let its coefficient in
the objective function c j = ciB be changed by an amount 1ciB , the first thing we note is that the value of the
simplex multipliers will be affected, since:
where u i is a row vector of zeros except for a one in position i. The basis will not change so long as the
reduced costs of all nonbasic variables satisfy:
Substituting in (11) for y given by (10),
and noting that B −1 A j is just the representation of A j in the current basis, we have
Finally, since (13) must be satisfied for all nonbasic variables, we can define upper and lower bounds on
Note that, since c j ≤ 0, the lower bound on 1ciB is nonpositive and the upper bound is nonnegative, so that
the range on the cost coefficient ciB + 1ciB is determined by adding ciB to each bound in (14). Note that 1ciB
may be unbounded in either direction if there are no a i j of appropriate sign.
At the upper bound in (14), the variable producing the minimum ratio is a candidate to enter the basis,
while at the lower bound in (14), the variable producing the maximum ratio is a candidate to enter the basis.
These candidate variables are clearly not the same, since they have opposite signs for a i j . In order for any
candidate to enter the basis, the variable to drop from the basis xr is determined by the usual minimum-ratio
If As ≤ 0, then variable xs can be increased without limit and the objective function is unbounded. Otherwise,
the variable corresponding to the minimum ratio in (15) will drop from the basis if xs is introduced into the
We turn now to the question of variations in the righthand-side values. Suppose that the righthand-side
value bk is changed by an amount 1bk , with all other data held fixed. We will compute the range so that
the basis remains unchanged. The values of the decision variables will change, since they are given by
x B = B −1 b, but the values of the simplex multipliers, given by y = c B B −1 , will not. The new values of the
basic variables, x new must be nonnegative in order for the basis to remain feasible. Hence,
Where u k is a column vector of all zeros except for a one in position k. Nothing that B −1 b is just the
representation of the righthand side in the current basis, (16) becomes
and, letting βi j be the elements of the basis inverse matrix B −1 , we have:
Finally, since (18) must be satisfied for all basic variables, we can define upper and lower bounds on 1bi
Note that since bi ≥ 0, the lower bound on 1bk is nonpositive and the upper bound is nonnegative. The
range on the righthand-side value bk + 1bk is then determined by adding bk to each bound in (19).
At the upper bound in (19) the variable basic in the row producing the minimum ratio is a candidate
to be dropped from the basis, while at the lower bound in (19) the variable basic in the row producing the
maximum ratio is a candidate to be dropped from the basis. The variable to enter the basis in each of these
cases can be determined by the ratio test of the dual simplex method. Suppose the variable basic in row r is
to be dropped; then the entering variable xs is determined from:
If there does not exist a r j < 0, then no entering variable can be determined. When this is the case, the
Now let us turn to variations in the coefficients in the equations of the model. In the case where the
coefficient corresponds to a nonbasic activity, the situation is straightforward. Suppose that the coefficient
ai j is changed by an amount 1ai j . We will compute the range so that the basis remains unchanged. In this
case, both the values of the decision variables and the shadow prices also remain unchanged. Since x j is
assumed nonbasic, the current basis remains optimal so long as the new reduced cost cnew
where u i is a column vector of zeros except for a one in position i. Since c j = c j − y A j , (21) reduces to:
Hence, (22) gives either an upper or a lower bound on 1ai j . If yi > 0, the appropriate range is:
The range on the variable coefficient ai j + 1ai j is simply given by adding ai j to the bounds in (23) and (24).
In either situation, some xs becomes a candidate to enter the basis, and the corresponding variable to drop
from the basis is determined by the usual minimum-ratio rule given in (15).
The case where the coefficient to be varied corresponds to a basic variable is a great deal more difficult
and will not be treated in detail here. Up until now, all variations in coefficients and righthand-side values
have been such that the basis remains unchanged. The question we are asking here violates this principle.
We could perform a similar analysis, assuming that the basic variables should remain unchanged, but the
basis and its inverse will necessarily change. There are three possible outcomes from varying a coefficient
of a basic variable in a constraint. Either (1) the basis may become singular; (2) the basic solution may
become infeasible; or (3) the basic solution may become nonoptimal. Any one of these conditions would
define an effective bound on the range of 1ai j . A general derivation of these results is beyond the scope of
Having discussed changes in individual elements of the data such that the basis remains unchanged, the
natural question to ask is what happens when we make simultaneous variations in the data or variations that
go beyond the ranges derived in the previous section. We can give rigorous answers to these questions for
cases where the problem is made a function of one parameter. Here we essentially compute ranges on this
parameter in a manner analogous to computing righthand-side and objective-function ranges.
We begin by defining three different parametric-programming problems, where each examines the optimal
value of a linear program as a function of the scalar (not vector) parameter θ . In Chapter 3, we gave examples
Note that, when the parameter θ is fixed at some value, each type of problem becomes a simple linear
We first consider the parametric righthand-side problem. In this case, the feasible region is being modified
as the parameter θ is varied. Suppose that, for θ and θ , (25) is a feasible linear program. Then, assuming
that θ < θ , (25) must be feasible for all θ in the interval θ ≤ θ ≤ θ . To see this, first note that any θ in the
interval may be written as θ = λθ + (1 − λ)θ , where 0 ≤ λ ≤ 1. (This is called a convex combination of θ
and θ .) Since (25) is feasible for θ and θ , there must exist corresponding x and x satisfying:
Multiplying the former by λ and the latter by (1 − λ) and adding yields:
λAx + (1 − λ)Ax = λ(b1 + θ b2 ) + (1 − λ)(b1 + θ b2 ),
A(λx + (1 − λ)x) = b1 + (λθ + (1 − λ)θ )b2 ,
Equation (28) implies that there exists a feasible solution for any θ in the interval θ ≤ θ ≤ θ .
The implication for the parameteric righthand-side problem is that, when increasing (decreasing) θ , once
the linear program becomes infeasible it will remain infeasible for any further increases (decreases) in θ .
Let us assume that (25) is feasible for θ = θ0 and examine the implications
B be the optimal basis with decision variables x B = B −1 b1 + θ0 b2 and shadow prices y = c B B −1 . The
current basis B remains optimal as θ is varied, so long as the current solution remains feasible; that is,
Equation (29) may imply both upper and lower bounds, as follows:
and these define the following range on θ :
If we now move θ to either its upper or lower bound, a basis change can take place. At the upper bound, the
variable basic in the row producing the minimum ratio becomes a candidate to drop from the basis, while at
the lower bound the variable producing the maximum ratio becomes a candidate to drop from the basis. In
either case, assuming the variable to drop is basic in row r , the variable to enter the basis is determined by
the usual rule of the dual simplex method:
If a r j ≥ 0 for all j, then no variable can enter the basis and the problem is infeasible beyond this bound. If
an entering variable is determined, then a new basis is determined and the process is repeated. The range on
θ such that the new basis remains optimal, is then computed in the same manner.
On any of these successive intervals where the basis is unchanged, the optimal value of the linear program
is given by P(θ ) = y(b1 + θ b2 ), where the vector y = c B B −1 of shadow prices is not a function of θ .
Therefore, P(θ ) is a straight line with slope yb2 on a particular interval.
Further, we can easily argue that P(θ ) is also a concave function of θ, that is,
P(λθ + (1 − λ)θ ) ≥ λP(θ ) + (1 − λ)P(θ )
Suppose that we let θ and θ be two values of θ such that the corresponding linear programs defined by P(θ )
and P(θ ) in (25) have finite optimal solutions. Let their respective optimal solutions be x and x. We have
already shown in (28) that λx +(1−λ)x is a feasible solution to the linear program defined by P(λθ +(1−λ)θ )
in (25). However, λx + (1 − λ)x may not be optimal to this linear program, and hence
Rearranging terms and noting that x and x are optimal solutions to P(θ) and P(θ ), respectively, we have:
c(λx + (1 − λ)x) = λcx + (1 − λ)cx = λP(θ ) + (1 − λ)P(θ ).
The last two expressions imply the condition that P(θ) is a concave function of θ . Hence, we have shown
that P(θ ) is a concave piecewise-linear function of θ. This result can be generalized to show that the optimal
value of a linear program is a concave polyhedral function of its righthand-side vector.
Let us now turn to the parametric objective-function problem. Assuming that the linear program defined
in (26) is feasible, it will remain feasible regardless of the value of θ . However, this linear program may
become unbounded. Rather than derive the analogous properties of Q(θ) directly, we can determine the
properties of Q(θ ) from those of P(θ ) by utilizing the duality theory of Chapter 4. We may rewrite Q(θ ) in
terms of the dual of its linear program as follows:
and, recognizing that a minimization problem can be transformed into a maximization problem by multiplying
Here P 0 (θ ) must be a concave piecewise-linear function of θ , since it is the optimal value of a linear
program considered as a function of its righthand side. Therefore,
Q(λθ + (1 − λ)θ ) ≤ λQ(θ ) + (1 − λ)Q(θ )
P 0 (λθ + (1 − λ)θ ) ≥ λP 0 (θ) + (1 − λ)P 0 (θ )
which says that Q(θ ) is a convex function.
Further, since the primal formulation of Q(θ ) is assumed to be feasible, whenever the dual formulation is
infeasible the primal must be unbounded. Hence, we have a result analogous to the feasibility result for P(θ ).
Suppose that for θ and θ , (26) is a bounded linear program; then, assuming θ < θ , (26) must be bounded
for all θ in the interval θ ≤ θ ≤ θ . The implication for the parametric objective-function problem is that,
when increasing (decreasing) θ , once the linear program becomes unbounded it will remain unbounded for
Let us assume that (26) is bounded for θ = θ0 and examine the implications of varying θ . For θ = θ0 , let
B be the optimal basis with decision variables x B = B −1 b and shadow prices y = (c1B + θ c2B )B −1 . The
current basis B remains optimal as θ is varied, so long as the reduced costs remain nonpositive; that is,
c j (θ ) = (c1j + θ c2j ) − (c1B + θ c2B )B −1 A j ≤ 0;
c j (θ ) = c1j − c1B B −1 A j + θ c2j − c2B B −1 A j ≤ 0,
Equation (34) may imply both upper and lower bounds, as follows:
and these define the following range on θ :
If we move θ to either its upper or lower bound, a basis change can take place. At the upper bound, the
variable producing the minimum ratio becomes a candidate to enter the basis, while at the lower bound, the
variable producing the maximum ratio becomes a candidate to enter the basis. In either case, the variable to
drop from the basis is determined by the usual rule of the primal simplex method.
If As ≤ 0, then xs may be increased without limit and the problem is unbounded beyond this bound. If
a variable to drop is determined, then a new basis is determined and the process is repeated. The range on θ
such that the new basis remains optimal is then again computed in the same manner.
On any of these successive intervals where the basis is unchanged, the optimal value of the linear program
where x B = B −1 b and is not a function of θ. Therefore, Q(θ ) is a straight line with slope c2B x B on a
Finally, let us consider the parametric rim problem, which has the parameter in both the objective function
and the righthand side. As would be expected, the optimal value of the linear program defined in (27) is neither
a concave nor a convex function of the parameter θ. Further, R(θ) is not a piecewise-linear function, either.
Let us assume that (27) is feasible for θ = θ0 , and examine the implications of varying θ. For θ = θ0, let B
be the optimal basis with decision variables x B = B −1 (b1 + θ b2 ) and shadow prices y = c1B + θ c2B B −1 .
The current basis remains optimal so long as the current solution remains feasible and the reduced costs
remain nonpositive. Hence, the current basis remains optimal so long as both ranges on θ given by (30) and
(35) are satisfied. Suppose we are increasing θ . If the upper bound of (30) is reached before the upper bound
of (34), then a dual simplex step is performed according to (31). If the opposite is true, then a primal simplex
step is performed according to (36). Once the new basis is determined, the process is repeated. The same
For a given basis, the optimal value of the objective function is given by multiplying the basic costs by
the value of the basic variables x B ; that is,
R(θ ) = c1B B −1 b1 + θ c2B B −1 b1 + c1B B −1 b2 + θ 2 c2B B −1 b2 .
Hence, the optimal value of the parametric rim problem is a quadratic function of θ for a fixed basis B. In
general, this quadratic may be either a concave or convex function over the range implied by (30) and (35).
It should be clear that the importance of parametric programming in all three cases is the efficiency of
the procedures in solving a number of different cases. Once an optimal solution has been found for some
value of the parameter, say θ = θ0 , increasing or decreasing θ amounts to successively computing the points
at which the basis changes and then performing a routine pivot operation.
The duality theory introduced in Chapter 4 can be stated very concisely in matrix form. As we saw there, a
number of variations of the basic duality results can be formulated by slightly altering the form of the primal
problem. For ease of comparison with the Chapter 4 results, we will again employ the symmetric version of
Note that y and c are row vectors while x and b are column vectors. Let z and v denote the optimal values
of the objective functions for the primal and dual problems, respectively. We will review the three key results
Weak duality. If x is a feasible solution to the primal and y is a feasible solution to the dual, then cx ≤ yb,
Strong duality. If the primal (dual) has a finite optimal solution, then so does the dual (primal), and the two
Complementary slackness. If x is a feasible solution to the primal and y is a feasible solution to the dual,
then x and y are optimal solutions to the primal and dual, respectively, if and only if
The arguments leading to these results were given in Chapter 4 but will be briefly reviewed here. Weak
duality is a consequence of primal and dual feasibility, since multiplying the primal constraints on the left by
y and the dual constraints on the right by x and combining gives:
Since the optimal values must be at least as good as any feasible value,
Weak duality implies that if cx = yb for some primal feasible x and dual feasible y, then x and y are optimal
solutions to the primal and dual, respectively.
The termination conditions of the simplex method and the concept of simplex multipliers provides the
strong duality property. Suppose that the simplex method has found an optimal basic feasible solution x to
the primal with optimal basis B. The optimal values of the decision variables and simplex multipliers are
x B = B −1 b and y = c B B −1 , respectively. The simplex optimality conditions imply:
The latter condition (38), plus the definition of the simplex multipliers, which can be restated as:
imply that c − y A ≤ 0, so that y ≥ 0 is a dual feasible solution. Now x N = 0 and (37) implies that:
Since x and y are feasible solutions to the primal and dual respectively, (39) implies z = cx = yb = v which
Finally, complementary slackness follows directly from the strong-duality property. First, we assume
that complementary slackness holds, and show optimality.
If x and y are feasible to the primal and dual, respectively, such that
Condition (40) implies the x and y are optimal to the primal and dual, respectively. Second, we assume
optimality holds, and show complementary slackness. Let x and y be optimal to the primal and dual,
by primal feasibility, and y ≥ 0. Now since 0 ≥ c − y A by dual feasibility, and x ≥ 0, we have
An analogous argument using dual feasibility and x ≥ 0 implies the other complementary slackness condition,
These results are important for applications since they suggest algorithms other than straightforward
applications of the simplex method to solve specially structured problems. The results are also central to
the theory of systems of linear equalities and inequalities, a theory which itself has a number of important
applications. In essence, duality theory provides a common perspective for treating such systems and, in the
process, unifies a number of results that appear scattered throughout the mathematics literature. A thorough
discussion of this theory would be inappropriate here, but we indicate the flavor of this point of view.
A problem that has interested mathematicians since the late 1800’s has been characterizing the situation
when a system of linear equalities and inequalities does not have a solution. Consider for example the system:
Resolving degeneracy in the Simplex Method
Suppose that y is a row vector. We multiply the system of equations by y to produce a single new equation:
If x is feasible in the original system, then it will certainly satisfy this new equation. Suppose, though, that
yb > 0 and that y A ≤ 0. Since x ≥ 0, y Ax ≤ 0, so that no x ≥ 0 solves the new equation, and thus
the original system is infeasible. We have determined a single inconsistent equation that summarizes the
inconsistencies in the original system. The characterization that we are working towards states that such a
summarizing inconsistent equation always can be found when the system has no solution. It is given by:
Farkas’ Lemma. Exactly one of the following two systems has a solution:
The proof of the lemma is straightforward, by considering the Phase I linear-programming program that
results from adding artificial variables to System (I):
where e is the sum vector consisting of all ones and t is the vector of artificial variables. Suppose that the
simplex method is applied to (43), and the optimal solution is (x, t) with shadow prices y. By the termination
conditions of the simplex method, the shadow prices satisfy:
By the duality property, we know et = yb, and since (43) is a Phase I linear program, we have:
Equations (44) and (45) together imply the lemma.
We can give a geometrical interpretation of Farkas’ Lemma by recalling that, if the inner product of two
vectors is positive, the vectors make an acute angle with each other, while if the inner product is negative, the
vectors make an obtuse angle with each other. Therefore, any vector y that solves System II must make acute
angles with all the column vectors of A and a strictly obtuse angle with the vector b. On the other hand, in
order for System I to have a feasible solution, there must exist nonnegative weights x that generate b from
the column vectors of A. These two situations are given in Figs. B.4 and B.5.
RESOLVING DEGENERACY IN THE SIMPLEX METHOD
In Chapter 2 we showed that the simplex method solves any linear program in a finite number of steps if we
assume that the righthand-side vector is strictly positive for each canonical form generated. Such a canonical
The motivation for this assumption is to ensure that the new value of the entering variable xs∗ , which is
is strictly positive; and hence, that the new value of the objective function z ∗ , given by:
shows a strict improvement at each iteration. Since the minimum-ratio rule to determine the variable to drop
from the basis ensures a r s > 0, the assumption that bi > 0 for all i implies that xs∗ > 0. Further, introducing
the variable xs requires that cs > 0 and therefore that z ∗ > z. This implies that there is a strict improvement
in the value of the objective function at each iteration, and hence that no basis is repeated. Since there is a
finite number of possible bases, the simplex method must terminate in a finite number of iterations.
The purpose of this section is to extend the simplex method so that, without the nondegeneracy assumption,
it can be shown that the method will solve any linear program in a finite number of iterations. In Chapter 2
we indicated that we would do this by perturbing the righthand-side vector. However, a simple perturbation
of the righthand side by a scalar will not ensure that the righthand side will be positive for all canonical
forms generated. As a result, we introduce a vector perturbation of the righthand side and the concept of
Resolving degeneracy in the Simplex Method
An m-element vector a = (a1 , a2 , . . . , am ) is said to be lexico-positive, written a  0, if at least one
element is nonzero and the first such element is positive. The term lexico-positive is short for lexicographically
positive. Clearly, any positive multiple of a lexico-positive vector is lexico-positive, and the sum of two
lexico-positive vectors is lexico-positive. An m-element vector a is lexico-greater than an m-element vector
b, written a  b, if (a − b) is lexico-positive; that is, if a − b  0. Unless two vectors are identical, they are
lexicographically ordered, and therefore the ideas of lexico-max and lexico-min are well-defined.
We will use the concept of lexicographic ordering to modify the simplex method so as to produce a unique
variable to drop at each iteration and a strict lexicographic improvement in the value of the objective function
at each iteration. The latter will ensure the termination of the method after a finite number of iterations.
Suppose the linear program is in canonical form initially with b ≥ 0. We introduce a unique perturbation
of the righthand-side vector by replacing the vector b with the m × (m + 1) matrix [b, I ]. By making the
vector x an n × (m + 1) matrix X , we can write the initial tableau as:
where X B , X N , and X I are the matrices associated with the basic variables, the non-basic variables, and the
variables in the initial identity basis, respectively. The intermediate tableau corresponding to the basis B is
determined as before by multiplying the constraints of (46) by B −1 and subtracting c B times the resulting
constraints from the objective function. The intermediate tableau is then:
where N = B −1 N , y = c B B −1 , c N = c N − y N , and z = yb as before. Note that if the matrices X N and
X I are set equal to zero, a basic solution of the linear program is given by X B = [b, B −1 ], where the first
column of X B , say X 1B , gives the usual values of the basic variables X 1B = b.
We will formally prove that the simplex method, with a lexicographic resolution of degeneracy, solves
any linear program in a finite number of iterations. An essential aspect of the proof is that at each iteration
of the algorithm, each row vector of the righthand-side perturbation matrix is lexico-positive.
In the initial tableau, each row vector of the righthand-side matrix is lexico-positive, assuming b ≥ 0. If
bi > 0, then the row vector is lexico-positive, since its first element is positive. If bi = 0, then again the row
vector is lexico-positive since the first nonzero element is a plus one in position (i + 1).
Define B i to be row i of the righthand-side matrix [b, B −1 ] of the intermediate tableau. In the following
proof, we will assume that each such row vector B i is lexico-positive for a particular canonical form, and
argue inductively that they remain lexico-positive for the next canonical form. Since this condition holds for
the initial tableau, it will hold for all subsequent tableaus.
Now consider the simplex method one step at a time.
STEP (1): If c j ≤ 0 for j = 1, 2, . . . , n, then stop; the current solution is optimal.
Since X B = B = [b, I ], the first component of X B is the usual basic feasible solution X 1B = b.
Since the reduced costs associated with this solution are c N ≤ 0, we have:
and hence z is an upper bound on the maximum value of z. The current solution X 1B = b attains this
upper bound and is therefore optimal. If we continue the algorithm, there exists some c j > 0.
STEP (2): Choose the column s to enter the basis by:
If As ≤ 0, then stop; there exists an unbounded solution. Since As ≤ 0, then
is feasible for all nonnegative xs . Since cs > 0,
implies that the objective function becomes unbounded as xs is increased without limit. If we continue
the algorithm, there exists some a is > 0.
STEP (3): Choose the row to pivot in by the following modified ratio rule:
We should point out that the lexico-min produces a unique variable to drop from the basis. There must
be a unique lexico-min, since, if not, there would exist two vectors B i /a is that are identical. This would
imply that two rows of B are proportional and, hence, that two rows of B −1 are proportional, which is
STEP (4): Replace the variable basic in row r with variable s and re-establish the canonical form by pivoting
We have shown that, in the initial canonical form, the row vectors of the righthand-side matrix
are each lexico-positive. It remains to show that, assuming the vectors B i are lexico-positive at an
iteration, they remain lexico-positive at the next iteration. Let the new row vectors of the righthand-side
since B r  0, by assumption, and a r s > 0. Second,
If a is ≤ 0, then B i  0, since it is then the sum of two lexico-positive vectors. If a is > 0, then (48)
Since B r /a r s is the unique lexico-min in the modified ratio rule, (49) implies B i  0 for a is > 0, also.
We would like to show that there is a strict lexicographic improvement in the objective-value
vector at each iteration. Letting −Z = [−z, −y] be the objective-value vector, and Z be the new
then, since cs > 0 and X s∗ = B r  0, we have
which states that Z is lexico-greater than Z . Hence we have a strict lexicographic improvement in the
objective-value vector at each iteration.
Finally, since there is a strict lexicographic improvement in the objective-value vector for each new basis,
no basis can then be repeated. Since there are a finite number of bases and no basis is repeated, the algorithm
solves any linear program in a finite number of iterations.
Network-flow problems can be solved by several methods. In Chapter 8 we introduced this topic by exploring
the special structure of network-flow problems and by applying the simplex method to this structure. This
appendix continues the analysis of network problems by describing the application of the labeling algorithm to
the maximum-flow network problem. Labeling methods provide an alternative approach for solving network
problems. The basic idea behind the labeling procedure is to systematically attach labels to the nodes of a
network until the optimum solution is reached.
Labeling techniques can be used to solve a wide variety of network problems, such as shortest-path
problems, maximal-flow problems, general minimal-cost network-flow problems, and minimal spanningtree problems. It is the purpose of this appendix to illustrate the general nature of the labeling algorithms by
describing a labeling method for the maximum-flow problem.
The maximal-flow problem was introduced in Section 8.2 of the text. If v denotes the amount of material
sent from node s, called the source, to note t, called the sink, the problem can be formulated as follows:
We assume that there is no arc from t to s. Also, u i j = +∞ if arc i– j has unlimited capacity. The
interpretation is that v units are supplied at s and consumed at t.
Letting xts denote the variable v and rearranging, we see that the problem assumes the following special
(i = 1, 2, . . . , n; j = 1, 2, . . . , n).
A Labeling Algorithm for the Maximum-Flow Network Problem
Here arc t − s has been introduced into the network with u ts defined to be +∞, xts simply returns the v units
from node t back to node s, so that there is no formal external supply of material. Let us recall the example
(see Fig. C.1) that was posed in Chapter 8 in terms of a water-pipeline system. The numbers above the arcs
indicate flow capacity and the bold-faced numbers below the arcs specify a tentative flow plan.
The algorithm for finding maximal flow rests on observing two ways to improve the flow in this example.
The following two ‘‘paths’’ appear in Fig. C.1
In the first case, the directed path 1–3–6 has the capacity to carry 2 additional units from the source to
the sink, as given by the capacity of its weakest link, arc 3–5. Note that adding this flow gives a feasible flow
pattern, since 2 units are added as input as well as output to both of nodes 3 and 5.
The second case is not a directed path from the source to the sink since arc 2–4 appears with the wrong
orientation. Note, however, that adding one unit of flow to the ‘‘forward arcs’’ from 1 to 6 and subtracting
one unit from the ‘‘reverse arc’’ 2-4 provides a feasible solution, with increased source-to-sink flow. Mass
balance is maintained at node 4, since the one more unit sent from node 3 cancels with the one less unit sent
from node 2. Similarly, at node 2 the one additional unit sent to node 5 cancels with the one less unit sent to
The second case is conceptually equivalent to the first if we view decreasing the flow along arc 2-4 as
sending flow from node 4 back to node 2 along the reverse arc 4-2. That is, the unit of flow from 2 to 4
increases the effective capacity of the ‘‘return’’ arc 4-2 from 0 in the original network to 1. At the same
time, it decreases the usable or effective capacity along arc 2-4 from 3 to 2. With this view, the second case
Now both instances have determined a directed flow-carrying path from source to sink, that is, a directed
path with the capacity to carry additional flow.
The maximal-flow algorithm inserts return, arcs, such as 4–2 here, and searches for flow-carrying paths.
It utilizes a procedure common to network algorithms by ‘‘fanning our’’ from the source node, constructing
flow-carrying paths to other nodes, until the sink node is reached.
The procedure starts by labeling all nodes with the capacity to receive flow from the source node by a
single arc. For the pipeline example, arc 1–2 is saturated and has a zero effective capacity, whereas are 1–3
can carry 8 additional units. thus, only node 3 is labeled from the source
The procedure is repeated by labeling all nodes with the capacity to receive flow directly from node 3 by
a single arc. In this case, nodes 4 and 5 are labeled and the labeled nodes become:
Additional nodes can now be labeled from either node 4 or 5. If node 4 is selected next, then node 2 is
labeled, since the effective capacity (return capacity) of arc 4-2 is positive (node 6 cannot be labeled from
node 4 since arc 4-6 is saturated). The labeled nodes are:
At any point in the algorithm, some of the labeled nodes, here nodes 1, 3 and 4, will already have been
used to label additional nodes. We will say that these nodes have been scanned. Any unscanned labeled node
Scanning node 2 produces no additional labelings, since node 2 can only send flow directly to nodes 1,
4, and 5, and these have been labeled previously. Node 6 is labeled when node 5 is scanned, and the labeled
A flow-carrying path has been identified, since the sink has been labeled. In this case, the path discovered
is 1–3–5–6, which was the first path given above. The flow along this path is updated by increasing the
flow along each arc in the path by the flow capacity of the path, here 2 units. Effective capacities are now
recomputed and the labeling procedure is repeated, starting with only the source node labeled.
Following is a formal description of the algorithm and a solution of the water-pipeline example. Notice
that the flow value on the arcs need not be recorded from step to step in the algorithm since this information
is computed easily from the effective (or usable) capacities of the arcs and their return arcs. For the example
above, the effective capacity on arc 2–4 is less than its initial capacity.
The difference 3 = 2 − 1 must be the flow value on that arc that resulted in the reduced capacity. The
effective capacity on arc 4–2 has been increased from 0 to 1 by adding return-flow capacity to that arc, not
A Labeling Algorithm for the Maximum-Flow Network Problem
by physically adding flow to that arc. In general, this is the case whenever effective capacity exceeds the
original capacity. These arcs, consequently, carry no flow.
When a flow-carrying path has been found from source to terminal, that is able to carry θ additional units,
the effective capacity in every arc i– j of that path is reduced by θ . At the same time, the effective capacity
of each reverse arc j–i increases by θ , since they can now be used to divert (or back up) these units of flow.
C.2 MAXIMAL-FLOW ALGORITHM—FORMAL STATEMENT
Assume a given feasible flow plan xi j (if none is given, use the feasible plan with all xi j = 0). The initial
effective capacity u i∗j on arc i– j is given by calculating u i∗j = u i j − xi j + x ji (i.e., unused capacity u i j − xi j
Start with the source node s and label (mark) every node k with u ∗sk > 0. Then, in turn, select any labeled
node i not already scanned (i.e., used to label other nodes) and label every node j with u i∗j > 0 until either t
has been labeled or no further labeling can take place.
If t has been labeled, then a flow-carrying path P has been found from source to sink (u i∗j > 0 for every arc
is the flow capacity of the path. For every arc i– j of P, change u i∗j to u i∗j − θ , and change u ∗ji to u ∗ji + θ ; i.e.,
increase the effective capacity of the return path. (Adding or subtracting finite θ to any u i∗j = +∞ keeps the
u i∗j at +∞. If every u i∗j in P is +∞, then θ = +∞ and the optimal flow is infinite.)
If the path search ends without labeling t, then terminate. The optimal flow pattern is given by:
Figure C.2 solves the water-pipeline example in Fig. C.1 by this algorithm. Checks next to the rows indicate
that the node corresponding to that row has already been scanned. The first three tableaus specify the first
application of the path-search step in detail. In Tableau 1, node 1 has been used to label node 3. In Tableau 2,
node 3 was used to label nodes 4 and 5 (since u ∗34 > 0, u ∗35 > 0). At this point either node 4 or 5 can be used
next for labeling. The choice is arbitrary, and in Tableau 3, node 5 has been used to label node 6. Since 6 is
the sink, flow is updated. The last column in the tableau keeps track of how nodes have been labeled.† By
backtracking, we get a flow-carrying path P from source to terminal. For instance, from Tableau 3, we know
that 6 has been labeled from 5, 5 form 3, and 3 from 1, so that the path is 1–3–5–6.
† For computer implementation, another column might be maintained in the tableau to keep track of the capacity of the
flow-carrying paths as they are extended. In this way, θ need not be calculated at the end.
Figure C.2 Tableaus for the maximal-flow algorithm.
A Labeling Algorithm for the Maximum-Flow Network Problem
Tableau 4 contains the updated capacities and a summary of the next path search, which used nodes 1, 3,
4, 2, and 5 for labeling. The fifth tableau contains the final updated capacities and path search. Only nodes
1, 3, and 4 can be labeled in this tableau, so the algorithm is completed.
The flow at any point in the algorithm is obtained by subtracting effective capacities from initial capacities,
u i j − u i∗j , and discarding negative numbers. For Tableaus 1, 2, or 3, the flow is given by Fig. C.1. After
making the two indicated flow changes to obtain Tableau 4 and then Tableau 5, the solutions are given in two
networks shown in Figs. C.3 and C.4. The optimal solution sends two units along each of the paths 1–2–5–6
The final solution to the sample problem shown in Fig. C.4 illustrates an important conceptual feature of the
maximum-flow problem. The heavy dashed line in that figure ‘‘cuts" the network in two, in the sense that it
divides the nodes into two groups, one group containing the source node and one group containing the sink
node. Note that the most that can ever be sent across this cut to the sink is two units from node 1 to node 2,
one unit from 4 to 6, and two units from 3 to 5, for a total of 5 units (arc 2–5 connects nodes that are both to
the right of the cut and is not counted). Since no flow pattern can ever send more than these 5 units and the
final solution achieves this value, it must be optimal.
Similarly, the cut separating labeled from unlabeled nodes when the algorithm terminates (see Fig. C.5)
shows that the final solution will be optimal.
By conservation of mass, v equals the net flow from left to right across this cut, so that v can be no
greater than the total capacity of all arcs i– j pictured. In fact, this observation applies to any cut separating
A Labeling Algorithm for the Maximum-Flow Network Problem
As in the example discussed above, the capacity of any cut is defined as the total capacity of all arcs directed
By virtue of the labeling scheme, however, every arc i– j directed from left to right across the cut
separating the labeled and unlabeled nodes must have u i∗j = 0; otherwise j would have been labeled from i.
since if either xi j < u i j or x ji > 0, then u i∗j = (u i j − xi j ) + x ji would be positive. Consequently, the net
flow across the cut, and thus v, equals the cut capacity. Since no flow can do any better, this flow pattern is
We can recast this observation in a slightly different way. The inequality stated above shows that any
feasible flow v form source to sink is bounded from above by the capacity of any cut. Consequently, the
maximum flow from source to sink is bounded by the capacity of any cut separating the source and sink. In
particular, the maximum flow from source to sink is bounded from above by the minimum capacity of any cut.
We have just shown, though, that the maximum flow v equals the capacity of the cut separating the labeled
and unlabeled nodes when the algorithm terminates; therefore, we have verified the famous max-flow/min-cut
 v from node s to  =  of any cut separating  .
There are many important ramifications of this theorem. It can be used, for example, to establish elegant
results in combinatorial theory. Although such results lead to many useful applications of combinatorial
analysis, their development is beyond the scope of our coverage here. We have merely shown how the maxflow/min-cut theorem arises, and used the theorem to show that when the maximum flow-labeling algorithm
terminates, it has found the maximum possible flow from the source node to the sink node.
Finally, we should note that the maximum-flow procedure eventually terminates, as in the above example,
and does not continue to find flow-carrying paths from s to t forever. For certain cases this is easy to show.
If the capacity data u i j is all integral and every xi j in the original flow plan is an integer, then every u i∗j and
θ encountered will be integral. But then, if the maximal flow v is not +∞, we approach it in integral steps
and must eventually reach it. Similarly, if the original data and flow is fractional, v increases at each step
by at least a given fractional amount and the procedure terminates in a finite number of steps. If the data is
irrational, then it is known that the algorithm finds the maximum flow in a finite number of steps as long as
the nodes are considered during path search on a first-labeled–first-scanned basis.
Note that starting with an integral flow plan xi j when all u i j are integral leads to integral u i∗j . Consequently,
the final (and optimal) flow plan will be integral. This is a special instance of the network integrality property
